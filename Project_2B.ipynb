{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7JDizsmycpF"
   },
   "source": [
    "# Project 2B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR2JmMPUVbWr"
   },
   "source": [
    "### Import thu vien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3WyGADblG_m"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\OneDrive\\Desktop\\test\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import string\n",
    "from transformers import PreTrainedModel\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm3\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import (\n",
    "   AutoModelForSequenceClassification,\n",
    "   AutoTokenizer,\n",
    "   BitsAndBytesConfig,\n",
    "   TrainingArguments,\n",
    "   Trainer)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9m0kWGlUEi0",
    "outputId": "6155652a-dc96-4eca-c765-bea292b1fa38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2iteBc96mTVh"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0k0M7m2yQvQ"
   },
   "source": [
    "### read data and info data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ew-rm4Knyixd",
    "outputId": "266a77a1-17ca-49d2-cd0f-839d291dc015"
   },
   "outputs": [],
   "source": [
    "classifirer = pd.read_json(path_or_buf=r\"D:\\22DKHA1\\social\\Final\\2A\\Dataset\\readme_data.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwlmVX7jcS7j",
    "outputId": "c122207f-76d7-4990-895f-936fc16a2cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57383 entries, 0 to 57382\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   repo_id    57383 non-null  object        \n",
      " 1   full_name  57383 non-null  object        \n",
      " 2   readme     57383 non-null  object        \n",
      " 3   timestamp  57383 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "classifirer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n9uE6VnkXvom"
   },
   "outputs": [],
   "source": [
    "label = pd.read_csv(r\"D:\\22DKHA1\\social\\Final\\2A\\Dataset\\github_repos_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZBuU3A3HYows"
   },
   "outputs": [],
   "source": [
    "label = label[['repo_id','category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "TbwbL3UkY0qW"
   },
   "outputs": [],
   "source": [
    "final_dataset = pd.merge(classifirer,label,on='repo_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5V60JG5FcDYu"
   },
   "outputs": [],
   "source": [
    "final_dataset = final_dataset[['repo_id','readme','category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vU6nbQE2LvC",
    "outputId": "694d8825-f1a3-42d6-e9c3-cc36ef96591e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57413 entries, 0 to 57412\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   repo_id   57413 non-null  object\n",
      " 1   readme    57413 non-null  object\n",
      " 2   category  57413 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLl0z6yqcaaK",
    "outputId": "40d3ce71-2767-400a-8168-b1a030649b9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "collapsed": true,
    "id": "EIezMgEfcdHw",
    "outputId": "c2e693ac-6ca0-43d5-c15c-60afb5861ec1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "repo_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "readme",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f6c9c530-c022-4533-a767-3be9754f38b8",
       "rows": [
        [
         "0",
         "MDEwOlJlcG9zaXRvcnkxNTUyMjA2NDE=",
         "<!---\nCopyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n<p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg\">\n    <img alt=\"Hugging Face Transformers Library\" src=\"https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg\" width=\"352\" height=\"59\" style=\"max-width: 100%;\">\n  </picture>\n  <br/>\n  <br/>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://huggingface.com/models\"><img alt=\"Checkpoints on Hub\" src=\"https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen\"></a>\n    <a href=\"https://circleci.com/gh/huggingface/transformers\"><img alt=\"Build\" src=\"https://img.shields.io/circleci/build/github/huggingface/transformers/main\"></a>\n    <a href=\"https://github.com/huggingface/transformers/blob/main/LICENSE\"><img alt=\"GitHub\" src=\"https://img.shields.io/github/license/huggingface/transformers.svg?color=blue\"></a>\n    <a href=\"https://huggingface.co/docs/transformers/index\"><img alt=\"Documentation\" src=\"https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online\"></a>\n    <a href=\"https://github.com/huggingface/transformers/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/huggingface/transformers.svg\"></a>\n    <a href=\"https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md\"><img alt=\"Contributor Covenant\" src=\"https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg\"></a>\n    <a href=\"https://zenodo.org/badge/latestdoi/155220641\"><img src=\"https://zenodo.org/badge/155220641.svg\" alt=\"DOI\"></a>\n</p>\n\n<h4 align=\"center\">\n    <p>\n        <b>English</b> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md\">ÁπÅÈ´î‰∏≠Êñá</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md\">ÌïúÍµ≠Ïñ¥</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_es.md\">Espa√±ol</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md\">Êó•Êú¨Ë™û</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md\">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md\">–†—É—Å—Å–∫–∏–π</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md\">Portugu√™s</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_te.md\">‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md\">Fran√ßais</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_de.md\">Deutsch</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md\">Ti·∫øng Vi·ªát</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md\">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md\">ÿßÿ±ÿØŸà</a> |\n        <a href=\"https://github.com/huggingface/transformers/blob/main/i18n/README_bn.md\">‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</a> |\n    </p>\n</h4>\n\n<h3 align=\"center\">\n    <p>State-of-the-art pretrained models for inference and training</p>\n</h3>\n\n<h3 align=\"center\">\n    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/transformers_as_a_model_definition.png\"/>\n</h3>\n\nTransformers acts as the model-definition framework for state-of-the-art machine learning models in text, computer\nvision, audio, video, and multimodal model, for both inference and training.\n\nIt centralizes the model definition so that this definition is agreed upon across the ecosystem. `transformers` is the\npivot across frameworks: if a model definition is supported, it will be compatible with the majority of training\nframeworks (Axolotl, Unsloth, DeepSpeed, FSDP, PyTorch-Lightning, ...), inference engines (vLLM, SGLang, TGI, ...),\nand adjacent modeling libraries (llama.cpp, mlx, ...) which leverage the model definition from `transformers`.\n\nWe pledge to help support new state-of-the-art models and democratize their usage by having their model definition be\nsimple, customizable, and efficient.\n\nThere are over 1M+ Transformers [model checkpoints](https://huggingface.co/models?library=transformers&sort=trending) on the [Hugging Face Hub](https://huggingface.com/models) you can use.\n\nExplore the [Hub](https://huggingface.com/) today to find a model and use Transformers to help you get started right away.\n\n## Installation\n\nTransformers works with Python 3.9+, and [PyTorch](https://pytorch.org/get-started/locally/) 2.1+.\n\nCreate and activate a virtual environment with [venv](https://docs.python.org/3/library/venv.html) or [uv](https://docs.astral.sh/uv/), a fast Rust-based Python package and project manager.\n\n```py\n# venv\npython -m venv .my-env\nsource .my-env/bin/activate\n# uv\nuv venv .my-env\nsource .my-env/bin/activate\n```\n\nInstall Transformers in your virtual environment.\n\n```py\n# pip\npip install \"transformers[torch]\"\n\n# uv\nuv pip install \"transformers[torch]\"\n```\n\nInstall Transformers from source if you want the latest changes in the library or are interested in contributing. However, the *latest* version may not be stable. Feel free to open an [issue](https://github.com/huggingface/transformers/issues) if you encounter an error.\n\n```shell\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\n\n# pip\npip install .[torch]\n\n# uv\nuv pip install .[torch]\n```\n\n## Quickstart\n\nGet started with Transformers right away with the [Pipeline](https://huggingface.co/docs/transformers/pipeline_tutorial) API. The `Pipeline` is a high-level inference class that supports text, audio, vision, and multimodal tasks. It handles preprocessing the input and returns the appropriate output.\n\nInstantiate a pipeline and specify model to use for text generation. The model is downloaded and cached so you can easily reuse it again. Finally, pass some text to prompt the model.\n\n```py\nfrom transformers import pipeline\n\npipeline = pipeline(task=\"text-generation\", model=\"Qwen/Qwen2.5-1.5B\")\npipeline(\"the secret to baking a really good cake is \")\n[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]\n```\n\nTo chat with a model, the usage pattern is the same. The only difference is you need to construct a chat history (the input to `Pipeline`) between you and the system.\n\n> [!TIP]\n> You can also chat with a model directly from the command line.\n> ```shell\n> transformers chat Qwen/Qwen2.5-0.5B-Instruct\n> ```\n\n```py\nimport torch\nfrom transformers import pipeline\n\nchat = [\n    {\"role\": \"system\", \"content\": \"You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986.\"},\n    {\"role\": \"user\", \"content\": \"Hey, can you tell me any fun things to do in New York?\"}\n]\n\npipeline = pipeline(task=\"text-generation\", model=\"meta-llama/Meta-Llama-3-8B-Instruct\", dtype=torch.bfloat16, device_map=\"auto\")\nresponse = pipeline(chat, max_new_tokens=512)\nprint(response[0][\"generated_text\"][-1][\"content\"])\n```\n\nExpand the examples below to see how `Pipeline` works for different modalities and tasks.\n\n<details>\n<summary>Automatic speech recognition</summary>\n\n```py\nfrom transformers import pipeline\n\npipeline = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\")\npipeline(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n```\n\n</details>\n\n<details>\n<summary>Image classification</summary>\n\n<h3 align=\"center\">\n    <a><img src=\"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\"></a>\n</h3>\n\n```py\nfrom transformers import pipeline\n\npipeline = pipeline(task=\"image-classification\", model=\"facebook/dinov2-small-imagenet1k-1-layer\")\npipeline(\"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\")\n[{'label': 'macaw', 'score': 0.997848391532898},\n {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',\n  'score': 0.0016551691805943847},\n {'label': 'lorikeet', 'score': 0.00018523589824326336},\n {'label': 'African grey, African gray, Psittacus erithacus',\n  'score': 7.85409429227002e-05},\n {'label': 'quail', 'score': 5.502637941390276e-05}]\n```\n\n</details>\n\n<details>\n<summary>Visual question answering</summary>\n\n<h3 align=\"center\">\n    <a><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg\"></a>\n</h3>\n\n```py\nfrom transformers import pipeline\n\npipeline = pipeline(task=\"visual-question-answering\", model=\"Salesforce/blip-vqa-base\")\npipeline(\n    image=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg\",\n    question=\"What is in the image?\",\n)\n[{'answer': 'statue of liberty'}]\n```\n\n</details>\n\n## Why should I use Transformers?\n\n1. Easy-to-use state-of-the-art models:\n    - High performance on natural language understanding & generation, computer vision, audio, video, and multimodal tasks.\n    - Low barrier to entry for researchers, engineers, and developers.\n    - Few user-facing abstractions with just three classes to learn.\n    - A unified API for using all our pretrained models.\n\n1. Lower compute costs, smaller carbon footprint:\n    - Share trained models instead of training from scratch.\n    - Reduce compute time and production costs.\n    - Dozens of model architectures with 1M+ pretrained checkpoints across all modalities.\n\n1. Choose the right framework for every part of a models lifetime:\n    - Train state-of-the-art models in 3 lines of code.\n    - Move a single model between PyTorch/JAX/TF2.0 frameworks at will.\n    - Pick the right framework for training, evaluation, and production.\n\n1. Easily customize a model or an example to your needs:\n    - We provide examples for each architecture to reproduce the results published by its original authors.\n    - Model internals are exposed as consistently as possible.\n    - Model files can be used independently of the library for quick experiments.\n\n<a target=\"_blank\" href=\"https://huggingface.co/enterprise\">\n    <img alt=\"Hugging Face Enterprise Hub\" src=\"https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925\">\n</a><br>\n\n## Why shouldn't I use Transformers?\n\n- This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.\n- The training API is optimized to work with PyTorch models provided by Transformers. For generic machine learning loops, you should use another library like [Accelerate](https://huggingface.co/docs/accelerate).\n- The [example scripts](https://github.com/huggingface/transformers/tree/main/examples) are only *examples*. They may not necessarily work out-of-the-box on your specific use case and you'll need to adapt the code for it to work.\n\n## 100 projects using Transformers\n\nTransformers is more than a toolkit to use pretrained models, it's a community of projects built around it and the\nHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyone\nelse to build their dream projects.\n\nIn order to celebrate Transformers 100,000 stars, we wanted to put the spotlight on the\ncommunity with the [awesome-transformers](./awesome-transformers.md) page which lists 100\nincredible projects built with Transformers.\n\nIf you own or use a project that you believe should be part of the list, please open a PR to add it!\n\n## Example models\n\nYou can test most of our models directly on their [Hub model pages](https://huggingface.co/models).\n\nExpand each modality below to see a few example models for various use cases.\n\n<details>\n<summary>Audio</summary>\n\n- Audio classification with [Whisper](https://huggingface.co/openai/whisper-large-v3-turbo)\n- Automatic speech recognition with [Moonshine](https://huggingface.co/UsefulSensors/moonshine)\n- Keyword spotting with [Wav2Vec2](https://huggingface.co/superb/wav2vec2-base-superb-ks)\n- Speech to speech generation with [Moshi](https://huggingface.co/kyutai/moshiko-pytorch-bf16)\n- Text to audio with [MusicGen](https://huggingface.co/facebook/musicgen-large)\n- Text to speech with [Bark](https://huggingface.co/suno/bark)\n\n</details>\n\n<details>\n<summary>Computer vision</summary>\n\n- Automatic mask generation with [SAM](https://huggingface.co/facebook/sam-vit-base)\n- Depth estimation with [DepthPro](https://huggingface.co/apple/DepthPro-hf)\n- Image classification with [DINO v2](https://huggingface.co/facebook/dinov2-base)\n- Keypoint detection with [SuperPoint](https://huggingface.co/magic-leap-community/superpoint)\n- Keypoint matching with [SuperGlue](https://huggingface.co/magic-leap-community/superglue_outdoor)\n- Object detection with [RT-DETRv2](https://huggingface.co/PekingU/rtdetr_v2_r50vd)\n- Pose Estimation with [VitPose](https://huggingface.co/usyd-community/vitpose-base-simple)\n- Universal segmentation with [OneFormer](https://huggingface.co/shi-labs/oneformer_ade20k_swin_large)\n- Video classification with [VideoMAE](https://huggingface.co/MCG-NJU/videomae-large)\n\n</details>\n\n<details>\n<summary>Multimodal</summary>\n\n- Audio or text to text with [Qwen2-Audio](https://huggingface.co/Qwen/Qwen2-Audio-7B)\n- Document question answering with [LayoutLMv3](https://huggingface.co/microsoft/layoutlmv3-base)\n- Image or text to text with [Qwen-VL](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)\n- Image captioning [BLIP-2](https://huggingface.co/Salesforce/blip2-opt-2.7b)\n- OCR-based document understanding with [GOT-OCR2](https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf)\n- Table question answering with [TAPAS](https://huggingface.co/google/tapas-base)\n- Unified multimodal understanding and generation with [Emu3](https://huggingface.co/BAAI/Emu3-Gen)\n- Vision to text with [Llava-OneVision](https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf)\n- Visual question answering with [Llava](https://huggingface.co/llava-hf/llava-1.5-7b-hf)\n- Visual referring expression segmentation with [Kosmos-2](https://huggingface.co/microsoft/kosmos-2-patch14-224)\n\n</details>\n\n<details>\n<summary>NLP</summary>\n\n- Masked word completion with [ModernBERT](https://huggingface.co/answerdotai/ModernBERT-base)\n- Named entity recognition with [Gemma](https://huggingface.co/google/gemma-2-2b)\n- Question answering with [Mixtral](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)\n- Summarization with [BART](https://huggingface.co/facebook/bart-large-cnn)\n- Translation with [T5](https://huggingface.co/google-t5/t5-base)\n- Text generation with [Llama](https://huggingface.co/meta-llama/Llama-3.2-1B)\n- Text classification with [Qwen](https://huggingface.co/Qwen/Qwen2.5-0.5B)\n\n</details>\n\n## Citation\n\nWe now have a [paper](https://www.aclweb.org/anthology/2020.emnlp-demos.6/) you can cite for the ü§ó Transformers library:\n```bibtex\n@inproceedings{wolf-etal-2020-transformers,\n    title = \"Transformers: State-of-the-Art Natural Language Processing\",\n    author = \"Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n    month = oct,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-demos.6\",\n    pages = \"38--45\"\n}\n```\n",
         "AI_DataScience"
        ],
        [
         "1",
         "MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==",
         "![PyTorch Logo](https://github.com/pytorch/pytorch/blob/9708fcf92db88b80b9010c68662d634434da3106/docs/source/_static/img/pytorch-logo-dark.png)\n\n--------------------------------------------------------------------------------\n\nPyTorch is a Python package that provides two high-level features:\n- Tensor computation (like NumPy) with strong GPU acceleration\n- Deep neural networks built on a tape-based autograd system\n\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n\nOur trunk health (Continuous Integration signals) can be found at [hud.pytorch.org](https://hud.pytorch.org/ci/pytorch/pytorch/main).\n\n<!-- toc -->\n\n- [More About PyTorch](#more-about-pytorch)\n  - [A GPU-Ready Tensor Library](#a-gpu-ready-tensor-library)\n  - [Dynamic Neural Networks: Tape-Based Autograd](#dynamic-neural-networks-tape-based-autograd)\n  - [Python First](#python-first)\n  - [Imperative Experiences](#imperative-experiences)\n  - [Fast and Lean](#fast-and-lean)\n  - [Extensions Without Pain](#extensions-without-pain)\n- [Installation](#installation)\n  - [Binaries](#binaries)\n    - [NVIDIA Jetson Platforms](#nvidia-jetson-platforms)\n  - [From Source](#from-source)\n    - [Prerequisites](#prerequisites)\n      - [NVIDIA CUDA Support](#nvidia-cuda-support)\n      - [AMD ROCm Support](#amd-rocm-support)\n      - [Intel GPU Support](#intel-gpu-support)\n    - [Get the PyTorch Source](#get-the-pytorch-source)\n    - [Install Dependencies](#install-dependencies)\n    - [Install PyTorch](#install-pytorch)\n      - [Adjust Build Options (Optional)](#adjust-build-options-optional)\n  - [Docker Image](#docker-image)\n    - [Using pre-built images](#using-pre-built-images)\n    - [Building the image yourself](#building-the-image-yourself)\n  - [Building the Documentation](#building-the-documentation)\n    - [Building a PDF](#building-a-pdf)\n  - [Previous Versions](#previous-versions)\n- [Getting Started](#getting-started)\n- [Resources](#resources)\n- [Communication](#communication)\n- [Releases and Contributing](#releases-and-contributing)\n- [The Team](#the-team)\n- [License](#license)\n\n<!-- tocstop -->\n\n## More About PyTorch\n\n[Learn the basics of PyTorch](https://pytorch.org/tutorials/beginner/basics/intro.html)\n\nAt a granular level, PyTorch is a library that consists of the following components:\n\n| Component | Description |\n| ---- | --- |\n| [**torch**](https://pytorch.org/docs/stable/torch.html) | A Tensor library like NumPy, with strong GPU support |\n| [**torch.autograd**](https://pytorch.org/docs/stable/autograd.html) | A tape-based automatic differentiation library that supports all differentiable Tensor operations in torch |\n| [**torch.jit**](https://pytorch.org/docs/stable/jit.html) | A compilation stack (TorchScript) to create serializable and optimizable models from PyTorch code  |\n| [**torch.nn**](https://pytorch.org/docs/stable/nn.html) | A neural networks library deeply integrated with autograd designed for maximum flexibility |\n| [**torch.multiprocessing**](https://pytorch.org/docs/stable/multiprocessing.html) | Python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and Hogwild training |\n| [**torch.utils**](https://pytorch.org/docs/stable/data.html) | DataLoader and other utility functions for convenience |\n\nUsually, PyTorch is used either as:\n\n- A replacement for NumPy to use the power of GPUs.\n- A deep learning research platform that provides maximum flexibility and speed.\n\nElaborating Further:\n\n### A GPU-Ready Tensor Library\n\nIf you use NumPy, then you have used Tensors (a.k.a. ndarray).\n\n![Tensor illustration](https://github.com/pytorch/pytorch/blob/9708fcf92db88b80b9010c68662d634434da3106/docs/source/_static/img/tensor_illustration.png)\n\nPyTorch provides Tensors that can live either on the CPU or the GPU and accelerates the\ncomputation by a huge amount.\n\nWe provide a wide variety of tensor routines to accelerate and fit your scientific computation needs\nsuch as slicing, indexing, mathematical operations, linear algebra, reductions.\nAnd they are fast!\n\n### Dynamic Neural Networks: Tape-Based Autograd\n\nPyTorch has a unique way of building neural networks: using and replaying a tape recorder.\n\nMost frameworks such as TensorFlow, Theano, Caffe, and CNTK have a static view of the world.\nOne has to build a neural network and reuse the same structure again and again.\nChanging the way the network behaves means that one has to start from scratch.\n\nWith PyTorch, we use a technique called reverse-mode auto-differentiation, which allows you to\nchange the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes\nfrom several research papers on this topic, as well as current and past work such as\n[torch-autograd](https://github.com/twitter/torch-autograd),\n[autograd](https://github.com/HIPS/autograd),\n[Chainer](https://chainer.org), etc.\n\nWhile this technique is not unique to PyTorch, it's one of the fastest implementations of it to date.\nYou get the best of speed and flexibility for your crazy research.\n\n![Dynamic graph](https://github.com/pytorch/pytorch/blob/9708fcf92db88b80b9010c68662d634434da3106/docs/source/_static/img/dynamic_graph.gif)\n\n### Python First\n\nPyTorch is not a Python binding into a monolithic C++ framework.\nIt is built to be deeply integrated into Python.\nYou can use it naturally like you would use [NumPy](https://www.numpy.org/) / [SciPy](https://www.scipy.org/) / [scikit-learn](https://scikit-learn.org) etc.\nYou can write your new neural network layers in Python itself, using your favorite libraries\nand use packages such as [Cython](https://cython.org/) and [Numba](http://numba.pydata.org/).\nOur goal is to not reinvent the wheel where appropriate.\n\n### Imperative Experiences\n\nPyTorch is designed to be intuitive, linear in thought, and easy to use.\nWhen you execute a line of code, it gets executed. There isn't an asynchronous view of the world.\nWhen you drop into a debugger or receive error messages and stack traces, understanding them is straightforward.\nThe stack trace points to exactly where your code was defined.\nWe hope you never spend hours debugging your code because of bad stack traces or asynchronous and opaque execution engines.\n\n### Fast and Lean\n\nPyTorch has minimal framework overhead. We integrate acceleration libraries\nsuch as [Intel MKL](https://software.intel.com/mkl) and NVIDIA ([cuDNN](https://developer.nvidia.com/cudnn), [NCCL](https://developer.nvidia.com/nccl)) to maximize speed.\nAt the core, its CPU and GPU Tensor and neural network backends\nare mature and have been tested for years.\n\nHence, PyTorch is quite fast ‚Äî whether you run small or large neural networks.\n\nThe memory usage in PyTorch is extremely efficient compared to Torch or some of the alternatives.\nWe've written custom memory allocators for the GPU to make sure that\nyour deep learning models are maximally memory efficient.\nThis enables you to train bigger deep learning models than before.\n\n### Extensions Without Pain\n\nWriting new neural network modules, or interfacing with PyTorch's Tensor API was designed to be straightforward\nand with minimal abstractions.\n\nYou can write new neural network layers in Python using the torch API\n[or your favorite NumPy-based libraries such as SciPy](https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html).\n\nIf you want to write your layers in C/C++, we provide a convenient extension API that is efficient and with minimal boilerplate.\nNo wrapper code needs to be written. You can see [a tutorial here](https://pytorch.org/tutorials/advanced/cpp_extension.html) and [an example here](https://github.com/pytorch/extension-cpp).\n\n\n## Installation\n\n### Binaries\nCommands to install binaries via Conda or pip wheels are on our website: [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)\n\n\n#### NVIDIA Jetson Platforms\n\nPython wheels for NVIDIA's Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, and Jetson AGX Orin are provided [here](https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048) and the L4T container is published [here](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch)\n\nThey require JetPack 4.2 and above, and [@dusty-nv](https://github.com/dusty-nv) and [@ptrblck](https://github.com/ptrblck) are maintaining them.\n\n\n### From Source\n\n#### Prerequisites\nIf you are installing from source, you will need:\n- Python 3.10 or later\n- A compiler that fully supports C++17, such as clang or gcc (gcc 9.4.0 or newer is required, on Linux)\n- Visual Studio or Visual Studio Build Tool (Windows only)\n\n\\* PyTorch CI uses Visual C++ BuildTools, which come with Visual Studio Enterprise,\nProfessional, or Community Editions. You can also install the build tools from\nhttps://visualstudio.microsoft.com/visual-cpp-build-tools/. The build tools *do not*\ncome with Visual Studio Code by default.\n\nAn example of environment setup is shown below:\n\n* Linux:\n\n```bash\n$ source <CONDA_INSTALL_DIR>/bin/activate\n$ conda create -y -n <CONDA_NAME>\n$ conda activate <CONDA_NAME>\n```\n\n* Windows:\n\n```bash\n$ source <CONDA_INSTALL_DIR>\\Scripts\\activate.bat\n$ conda create -y -n <CONDA_NAME>\n$ conda activate <CONDA_NAME>\n$ call \"C:\\Program Files\\Microsoft Visual Studio\\<VERSION>\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64\n```\n\nA conda environment is not required.  You can also do a PyTorch build in a\nstandard virtual environment, e.g., created with tools like `uv`, provided\nyour system has installed all the necessary dependencies unavailable as pip\npackages (e.g., CUDA, MKL.)\n\n##### NVIDIA CUDA Support\nIf you want to compile with CUDA support, [select a supported version of CUDA from our support matrix](https://pytorch.org/get-started/locally/), then install the following:\n- [NVIDIA CUDA](https://developer.nvidia.com/cuda-downloads)\n- [NVIDIA cuDNN](https://developer.nvidia.com/cudnn) v8.5 or above\n- [Compiler](https://gist.github.com/ax3l/9489132) compatible with CUDA\n\nNote: You could refer to the [cuDNN Support Matrix](https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html) for cuDNN versions with the various supported CUDA, CUDA driver, and NVIDIA hardware.\n\nIf you want to disable CUDA support, export the environment variable `USE_CUDA=0`.\nOther potentially useful environment variables may be found in `setup.py`.  If\nCUDA is installed in a non-standard location, set PATH so that the nvcc you\nwant to use can be found (e.g., `export PATH=/usr/local/cuda-12.8/bin:$PATH`).\n\nIf you are building for NVIDIA's Jetson platforms (Jetson Nano, TX1, TX2, AGX Xavier), Instructions to install PyTorch for Jetson Nano are [available here](https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/)\n\n##### AMD ROCm Support\nIf you want to compile with ROCm support, install\n- [AMD ROCm](https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html) 4.0 and above installation\n- ROCm is currently supported only for Linux systems.\n\nBy default the build system expects ROCm to be installed in `/opt/rocm`. If ROCm is installed in a different directory, the `ROCM_PATH` environment variable must be set to the ROCm installation directory. The build system automatically detects the AMD GPU architecture. Optionally, the AMD GPU architecture can be explicitly set with the `PYTORCH_ROCM_ARCH` environment variable [AMD GPU architecture](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus)\n\nIf you want to disable ROCm support, export the environment variable `USE_ROCM=0`.\nOther potentially useful environment variables may be found in `setup.py`.\n\n##### Intel GPU Support\nIf you want to compile with Intel GPU support, follow these\n- [PyTorch Prerequisites for Intel GPUs](https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html) instructions.\n- Intel GPU is supported for Linux and Windows.\n\nIf you want to disable Intel GPU support, export the environment variable `USE_XPU=0`.\nOther potentially useful environment variables may be found in `setup.py`.\n\n#### Get the PyTorch Source\n\n```bash\ngit clone https://github.com/pytorch/pytorch\ncd pytorch\n# if you are updating an existing checkout\ngit submodule sync\ngit submodule update --init --recursive\n```\n\n#### Install Dependencies\n\n**Common**\n\n```bash\n# Run this command from the PyTorch directory after cloning the source code using the ‚ÄúGet the PyTorch Source‚Äú section above\npip install --group dev\n```\n\n**On Linux**\n\n```bash\npip install mkl-static mkl-include\n# CUDA only: Add LAPACK support for the GPU if needed\n# magma installation: run with active conda environment. specify CUDA version to install\n.ci/docker/common/install_magma_conda.sh 12.4\n\n# (optional) If using torch.compile with inductor/triton, install the matching version of triton\n# Run from the pytorch directory after cloning\n# For Intel GPU support, please explicitly `export USE_XPU=1` before running command.\nmake triton\n```\n\n**On MacOS**\n\n```bash\n# Add this package on intel x86 processor machines only\npip install mkl-static mkl-include\n# Add these packages if torch.distributed is needed\nconda install pkg-config libuv\n```\n\n**On Windows**\n\n```bash\npip install mkl-static mkl-include\n# Add these packages if torch.distributed is needed.\n# Distributed package support on Windows is a prototype feature and is subject to changes.\nconda install -c conda-forge libuv=1.51\n```\n\n#### Install PyTorch\n\n**On Linux**\n\nIf you're compiling for AMD ROCm then first run this command:\n\n```bash\n# Only run this if you're compiling for ROCm\npython tools/amd_build/build_amd.py\n```\n\nInstall PyTorch\n\n```bash\nexport CMAKE_PREFIX_PATH=\"${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}\"\npython -m pip install --no-build-isolation -v -e .\n```\n\n**On macOS**\n\n```bash\npython -m pip install --no-build-isolation -v -e .\n```\n\n**On Windows**\n\nIf you want to build legacy python code, please refer to [Building on legacy code and CUDA](https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda)\n\n**CPU-only builds**\n\nIn this mode PyTorch computations will run on your CPU, not your GPU.\n\n```cmd\npython -m pip install --no-build-isolation -v -e .\n```\n\nNote on OpenMP: The desired OpenMP implementation is Intel OpenMP (iomp). In order to link against iomp, you'll need to manually download the library and set up the building environment by tweaking `CMAKE_INCLUDE_PATH` and `LIB`. The instruction [here](https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source) is an example for setting up both MKL and Intel OpenMP. Without these configurations for CMake, Microsoft Visual C OpenMP runtime (vcomp) will be used.\n\n**CUDA based build**\n\nIn this mode PyTorch computations will leverage your GPU via CUDA for faster number crunching\n\n[NVTX](https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm) is needed to build Pytorch with CUDA.\nNVTX is a part of CUDA distributive, where it is called \"Nsight Compute\". To install it onto an already installed CUDA run CUDA installation once again and check the corresponding checkbox.\nMake sure that CUDA with Nsight Compute is installed after Visual Studio.\n\nCurrently, VS 2017 / 2019, and Ninja are supported as the generator of CMake. If `ninja.exe` is detected in `PATH`, then Ninja will be used as the default generator, otherwise, it will use VS 2017 / 2019.\n<br/> If Ninja is selected as the generator, the latest MSVC will get selected as the underlying toolchain.\n\nAdditional libraries such as\n[Magma](https://developer.nvidia.com/magma), [oneDNN, a.k.a. MKLDNN or DNNL](https://github.com/oneapi-src/oneDNN), and [Sccache](https://github.com/mozilla/sccache) are often needed. Please refer to the [installation-helper](https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers) to install them.\n\nYou can refer to the [build_pytorch.bat](https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat) script for some other environment variables configurations\n\n```cmd\ncmd\n\n:: Set the environment variables after you have downloaded and unzipped the mkl package,\n:: else CMake would throw an error as `Could NOT find OpenMP`.\nset CMAKE_INCLUDE_PATH={Your directory}\\mkl\\include\nset LIB={Your directory}\\mkl\\lib;%LIB%\n\n:: Read the content in the previous section carefully before you proceed.\n:: [Optional] If you want to override the underlying toolset used by Ninja and Visual Studio with CUDA, please run the following script block.\n:: \"Visual Studio 2019 Developer Command Prompt\" will be run automatically.\n:: Make sure you have CMake >= 3.12 before you do this when you use the Visual Studio generator.\nset CMAKE_GENERATOR_TOOLSET_VERSION=14.27\nset DISTUTILS_USE_SDK=1\nfor /f \"usebackq tokens=*\" %i in (`\"%ProgramFiles(x86)%\\Microsoft Visual Studio\\Installer\\vswhere.exe\" -version [15^,17^) -products * -latest -property installationPath`) do call \"%i\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%\n\n:: [Optional] If you want to override the CUDA host compiler\nset CUDAHOSTCXX=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.27.29110\\bin\\HostX64\\x64\\cl.exe\n\npython -m pip install --no-build-isolation -v -e .\n```\n\n**Intel GPU builds**\n\nIn this mode PyTorch with Intel GPU support will be built.\n\nPlease make sure [the common prerequisites](#prerequisites) as well as [the prerequisites for Intel GPU](#intel-gpu-support) are properly installed and the environment variables are configured prior to starting the build. For build tool support, `Visual Studio 2022` is required.\n\nThen PyTorch can be built with the command:\n\n```cmd\n:: CMD Commands:\n:: Set the CMAKE_PREFIX_PATH to help find corresponding packages\n:: %CONDA_PREFIX% only works after `conda activate custom_env`\n\nif defined CMAKE_PREFIX_PATH (\n    set \"CMAKE_PREFIX_PATH=%CONDA_PREFIX%\\Library;%CMAKE_PREFIX_PATH%\"\n) else (\n    set \"CMAKE_PREFIX_PATH=%CONDA_PREFIX%\\Library\"\n)\n\npython -m pip install --no-build-isolation -v -e .\n```\n\n##### Adjust Build Options (Optional)\n\nYou can adjust the configuration of cmake variables optionally (without building first), by doing\nthe following. For example, adjusting the pre-detected directories for CuDNN or BLAS can be done\nwith such a step.\n\nOn Linux\n\n```bash\nexport CMAKE_PREFIX_PATH=\"${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}\"\nCMAKE_ONLY=1 python setup.py build\nccmake build  # or cmake-gui build\n```\n\nOn macOS\n\n```bash\nexport CMAKE_PREFIX_PATH=\"${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}\"\nMACOSX_DEPLOYMENT_TARGET=11.0 CMAKE_ONLY=1 python setup.py build\nccmake build  # or cmake-gui build\n```\n\n### Docker Image\n\n#### Using pre-built images\n\nYou can also pull a pre-built docker image from Docker Hub and run with docker v19.03+\n\n```bash\ndocker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest\n```\n\nPlease note that PyTorch uses shared memory to share data between processes, so if torch multiprocessing is used (e.g.\nfor multithreaded data loaders) the default shared memory segment size that container runs with is not enough, and you\nshould increase shared memory size either with `--ipc=host` or `--shm-size` command line options to `nvidia-docker run`.\n\n#### Building the image yourself\n\n**NOTE:** Must be built with a docker version > 18.06\n\nThe `Dockerfile` is supplied to build images with CUDA 11.1 support and cuDNN v8.\nYou can pass `PYTHON_VERSION=x.y` make variable to specify which Python version is to be used by Miniconda, or leave it\nunset to use the default.\n\n```bash\nmake -f docker.Makefile\n# images are tagged as docker.io/${your_docker_username}/pytorch\n```\n\nYou can also pass the `CMAKE_VARS=\"...\"` environment variable to specify additional CMake variables to be passed to CMake during the build.\nSee [setup.py](./setup.py) for the list of available variables.\n\n```bash\nmake -f docker.Makefile\n```\n\n### Building the Documentation\n\nTo build documentation in various formats, you will need [Sphinx](http://www.sphinx-doc.org)\nand the pytorch_sphinx_theme2.\n\nBefore you build the documentation locally, ensure `torch` is\ninstalled in your environment. For small fixes, you can install the\nnightly version as described in [Getting Started](https://pytorch.org/get-started/locally/).\n\nFor more complex fixes, such as adding a new module and docstrings for\nthe new module, you might need to install torch [from source](#from-source).\nSee [Docstring Guidelines](https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines)\nfor docstring conventions.\n\n```bash\ncd docs/\npip install -r requirements.txt\nmake html\nmake serve\n```\n\nRun `make` to get a list of all available output formats.\n\nIf you get a katex error run `npm install katex`.  If it persists, try\n`npm install -g katex`\n\n> [!NOTE]\n> If you installed `nodejs` with a different package manager (e.g.,\n> `conda`) then `npm` will probably install a version of `katex` that is not\n> compatible with your version of `nodejs` and doc builds will fail.\n> A combination of versions that is known to work is `node@6.13.1` and\n> `katex@0.13.18`. To install the latter with `npm` you can run\n> ```npm install -g katex@0.13.18```\n\n> [!NOTE]\n> If you see a numpy incompatibility error, run:\n> ```\n> pip install 'numpy<2'\n> ```\n\nWhen you make changes to the dependencies run by CI, edit the\n`.ci/docker/requirements-docs.txt` file.\n\n#### Building a PDF\n\nTo compile a PDF of all PyTorch documentation, ensure you have\n`texlive` and LaTeX installed. On macOS, you can install them using:\n\n```\nbrew install --cask mactex\n```\n\nTo create the PDF:\n\n1. Run:\n\n   ```\n   make latexpdf\n   ```\n\n   This will generate the necessary files in the `build/latex` directory.\n\n2. Navigate to this directory and execute:\n\n   ```\n   make LATEXOPTS=\"-interaction=nonstopmode\"\n   ```\n\n   This will produce a `pytorch.pdf` with the desired content. Run this\n   command one more time so that it generates the correct table\n   of contents and index.\n\n> [!NOTE]\n> To view the Table of Contents, switch to the **Table of Contents**\n> view in your PDF viewer.\n\n\n### Previous Versions\n\nInstallation instructions and binaries for previous PyTorch versions may be found\non [our website](https://pytorch.org/get-started/previous-versions).\n\n\n## Getting Started\n\nThree pointers to get you started:\n- [Tutorials: get you started with understanding and using PyTorch](https://pytorch.org/tutorials/)\n- [Examples: easy to understand PyTorch code across all domains](https://github.com/pytorch/examples)\n- [The API Reference](https://pytorch.org/docs/)\n- [Glossary](https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md)\n\n## Resources\n\n* [PyTorch.org](https://pytorch.org/)\n* [PyTorch Tutorials](https://pytorch.org/tutorials/)\n* [PyTorch Examples](https://github.com/pytorch/examples)\n* [PyTorch Models](https://pytorch.org/hub/)\n* [Intro to Deep Learning with PyTorch from Udacity](https://www.udacity.com/course/deep-learning-pytorch--ud188)\n* [Intro to Machine Learning with PyTorch from Udacity](https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229)\n* [Deep Neural Networks with PyTorch from Coursera](https://www.coursera.org/learn/deep-neural-networks-with-pytorch)\n* [PyTorch Twitter](https://twitter.com/PyTorch)\n* [PyTorch Blog](https://pytorch.org/blog/)\n* [PyTorch YouTube](https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw)\n\n## Communication\n* Forums: Discuss implementations, research, etc. https://discuss.pytorch.org\n* GitHub Issues: Bug reports, feature requests, install issues, RFCs, thoughts, etc.\n* Slack: The [PyTorch Slack](https://pytorch.slack.com/) hosts a primary audience of moderate to experienced PyTorch users and developers for general chat, online discussions, collaboration, etc. If you are a beginner looking for help, the primary medium is [PyTorch Forums](https://discuss.pytorch.org). If you need a slack invite, please fill this form: https://goo.gl/forms/PP1AGvNHpSaJP8to1\n* Newsletter: No-noise, a one-way email newsletter with important announcements about PyTorch. You can sign-up here: https://eepurl.com/cbG0rv\n* Facebook Page: Important announcements about PyTorch. https://www.facebook.com/pytorch\n* For brand guidelines, please visit our website at [pytorch.org](https://pytorch.org/)\n\n## Releases and Contributing\n\nTypically, PyTorch has three minor releases a year. Please let us know if you encounter a bug by [filing an issue](https://github.com/pytorch/pytorch/issues).\n\nWe appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion.\n\nIf you plan to contribute new features, utility functions, or extensions to the core, please first open an issue and discuss the feature with us.\nSending a PR without discussion might end up resulting in a rejected PR because we might be taking the core in a different direction than you might be aware of.\n\nTo learn more about making a contribution to Pytorch, please see our [Contribution page](CONTRIBUTING.md). For more information about PyTorch releases, see [Release page](RELEASE.md).\n\n## The Team\n\nPyTorch is a community-driven project with several skillful engineers and researchers contributing to it.\n\nPyTorch is currently maintained by [Soumith Chintala](http://soumith.ch), [Gregory Chanan](https://github.com/gchanan), [Dmytro Dzhulgakov](https://github.com/dzhulgakov), [Edward Yang](https://github.com/ezyang), [Alban Desmaison](https://github.com/albanD), [Piotr Bialecki](https://github.com/ptrblck) and [Nikita Shulga](https://github.com/malfet) with major contributions coming from hundreds of talented individuals in various forms and means.\nA non-exhaustive but growing list needs to mention: [Trevor Killeen](https://github.com/killeent), [Sasank Chilamkurthy](https://github.com/chsasank), [Sergey Zagoruyko](https://github.com/szagoruyko), [Adam Lerer](https://github.com/adamlerer), [Francisco Massa](https://github.com/fmassa), [Alykhan Tejani](https://github.com/alykhantejani), [Luca Antiga](https://github.com/lantiga), [Alban Desmaison](https://github.com/albanD), [Andreas Koepf](https://github.com/andreaskoepf), [James Bradbury](https://github.com/jekbradbury), [Zeming Lin](https://github.com/ebetica), [Yuandong Tian](https://github.com/yuandong-tian), [Guillaume Lample](https://github.com/glample), [Marat Dukhan](https://github.com/Maratyszcza), [Natalia Gimelshein](https://github.com/ngimel), [Christian Sarofeen](https://github.com/csarofeen), [Martin Raison](https://github.com/martinraison), [Edward Yang](https://github.com/ezyang), [Zachary Devito](https://github.com/zdevito). <!-- codespell:ignore -->\n\nNote: This project is unrelated to [hughperkins/pytorch](https://github.com/hughperkins/pytorch) with the same name. Hugh is a valuable contributor to the Torch community and has helped with many things Torch and PyTorch.\n\n## License\n\nPyTorch has a BSD-style license, as found in the [LICENSE](LICENSE) file.\n",
         "AI_DataScience"
        ],
        [
         "2",
         "R_kgDOJ-2MVA",
         "# Build a Large Language Model (From Scratch)\n\nThis repository contains the code for developing, pretraining, and finetuning a GPT-like LLM and is the official code repository for the book [Build a Large Language Model (From Scratch)](https://amzn.to/4fqvn0D).\n\n<br>\n<br>\n\n<a href=\"https://amzn.to/4fqvn0D\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover.jpg?123\" width=\"250px\"></a>\n\n<br>\n\nIn [*Build a Large Language Model (From Scratch)*](http://mng.bz/orYv), you'll learn and understand how large language models (LLMs) work from the inside out by coding them from the ground up, step by step. In this book, I'll guide you through creating your own LLM, explaining each stage with clear text, diagrams, and examples.\n\nThe method described in this book for training and developing your own small-but-functional model for educational purposes mirrors the approach used in creating large-scale foundational models such as those behind ChatGPT. In addition, this book includes code for loading the weights of larger pretrained models for finetuning.\n\n- Link to the official [source code repository](https://github.com/rasbt/LLMs-from-scratch)\n- [Link to the book at Manning (the publisher's website)](http://mng.bz/orYv)\n- [Link to the book page on Amazon.com](https://www.amazon.com/gp/product/1633437167)\n- ISBN 9781633437166\n\n<a href=\"http://mng.bz/orYv#reviews\"><img src=\"https://sebastianraschka.com//images/LLMs-from-scratch-images/other/reviews.png\" width=\"220px\"></a>\n\n\n<br>\n<br>\n\nTo download a copy of this repository, click on the [Download ZIP](https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip) button or execute the following command in your terminal:\n\n```bash\ngit clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git\n```\n\n<br>\n\n(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) for the latest updates.)\n\n<br>\n<br>\n\n\n# Table of Contents\n\nPlease note that this `README.md` file is a Markdown (`.md`) file. If you have downloaded this code bundle from the Manning website and are viewing it on your local computer, I recommend using a Markdown editor or previewer for proper viewing. If you haven't installed a Markdown editor yet, [Ghostwriter](https://ghostwriter.kde.org) is a good free option.\n\nYou can alternatively view this and other files on GitHub at [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) in your browser, which renders Markdown automatically.\n\n<br>\n<br>\n\n\n> **Tip:**\n> If you're seeking guidance on installing Python and Python packages and setting up your code environment, I suggest reading the [README.md](setup/README.md) file located in the [setup](setup) directory.\n\n<br>\n<br>\n\n[![Code tests Linux](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml/badge.svg)](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml)\n[![Code tests Windows](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml/badge.svg)](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml)\n[![Code tests macOS](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml/badge.svg)](https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml)\n\n\n\n\n<br>\n\n| Chapter Title                                              | Main Code (for Quick Access)                                                                                                    | All Code + Supplementary      |\n|------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|-------------------------------|\n| [Setup recommendations](setup)                             | -                                                                                                                               | -                             |\n| Ch 1: Understanding Large Language Models                  | No code                                                                                                                         | -                             |\n| Ch 2: Working with Text Data                               | - [ch02.ipynb](ch02/01_main-chapter-code/ch02.ipynb)<br/>- [dataloader.ipynb](ch02/01_main-chapter-code/dataloader.ipynb) (summary)<br/>- [exercise-solutions.ipynb](ch02/01_main-chapter-code/exercise-solutions.ipynb)               | [./ch02](./ch02)            |\n| Ch 3: Coding Attention Mechanisms                          | - [ch03.ipynb](ch03/01_main-chapter-code/ch03.ipynb)<br/>- [multihead-attention.ipynb](ch03/01_main-chapter-code/multihead-attention.ipynb) (summary) <br/>- [exercise-solutions.ipynb](ch03/01_main-chapter-code/exercise-solutions.ipynb)| [./ch03](./ch03)             |\n| Ch 4: Implementing a GPT Model from Scratch                | - [ch04.ipynb](ch04/01_main-chapter-code/ch04.ipynb)<br/>- [gpt.py](ch04/01_main-chapter-code/gpt.py) (summary)<br/>- [exercise-solutions.ipynb](ch04/01_main-chapter-code/exercise-solutions.ipynb) | [./ch04](./ch04)           |\n| Ch 5: Pretraining on Unlabeled Data                        | - [ch05.ipynb](ch05/01_main-chapter-code/ch05.ipynb)<br/>- [gpt_train.py](ch05/01_main-chapter-code/gpt_train.py) (summary) <br/>- [gpt_generate.py](ch05/01_main-chapter-code/gpt_generate.py) (summary) <br/>- [exercise-solutions.ipynb](ch05/01_main-chapter-code/exercise-solutions.ipynb) | [./ch05](./ch05)              |\n| Ch 6: Finetuning for Text Classification                   | - [ch06.ipynb](ch06/01_main-chapter-code/ch06.ipynb)  <br/>- [gpt_class_finetune.py](ch06/01_main-chapter-code/gpt_class_finetune.py)  <br/>- [exercise-solutions.ipynb](ch06/01_main-chapter-code/exercise-solutions.ipynb) | [./ch06](./ch06)              |\n| Ch 7: Finetuning to Follow Instructions                    | - [ch07.ipynb](ch07/01_main-chapter-code/ch07.ipynb)<br/>- [gpt_instruction_finetuning.py](ch07/01_main-chapter-code/gpt_instruction_finetuning.py) (summary)<br/>- [ollama_evaluate.py](ch07/01_main-chapter-code/ollama_evaluate.py) (summary)<br/>- [exercise-solutions.ipynb](ch07/01_main-chapter-code/exercise-solutions.ipynb) | [./ch07](./ch07)  |\n| Appendix A: Introduction to PyTorch                        | - [code-part1.ipynb](appendix-A/01_main-chapter-code/code-part1.ipynb)<br/>- [code-part2.ipynb](appendix-A/01_main-chapter-code/code-part2.ipynb)<br/>- [DDP-script.py](appendix-A/01_main-chapter-code/DDP-script.py)<br/>- [exercise-solutions.ipynb](appendix-A/01_main-chapter-code/exercise-solutions.ipynb) | [./appendix-A](./appendix-A) |\n| Appendix B: References and Further Reading                 | No code                                                                                                                         | -                             |\n| Appendix C: Exercise Solutions                             | No code                                                                                                                         | -                             |\n| Appendix D: Adding Bells and Whistles to the Training Loop | - [appendix-D.ipynb](appendix-D/01_main-chapter-code/appendix-D.ipynb)                                                          | [./appendix-D](./appendix-D)  |\n| Appendix E: Parameter-efficient Finetuning with LoRA       | - [appendix-E.ipynb](appendix-E/01_main-chapter-code/appendix-E.ipynb)                                                          | [./appendix-E](./appendix-E) |\n\n<br>\n&nbsp;\n\nThe mental model below summarizes the contents covered in this book.\n\n<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg\" width=\"650px\">\n\n\n<br>\n&nbsp;\n\n## Prerequisites\n\nThe most important prerequisite is a strong foundation in Python programming.\nWith this knowledge, you will be well prepared to explore the fascinating world of LLMs\nand understand the concepts and code examples presented in this book.\n\nIf you have some experience with deep neural networks, you may find certain concepts more familiar, as LLMs are built upon these architectures.\n\nThis book uses PyTorch to implement the code from scratch without using any external LLM libraries. While proficiency in PyTorch is not a prerequisite, familiarity with PyTorch basics is certainly useful. If you are new to PyTorch, Appendix A provides a concise introduction to PyTorch. Alternatively, you may find my book, [PyTorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs](https://sebastianraschka.com/teaching/pytorch-1h/), helpful for learning about the essentials.\n\n\n\n<br>\n&nbsp;\n\n## Hardware Requirements\n\nThe code in the main chapters of this book is designed to run on conventional laptops within a reasonable timeframe and does not require specialized hardware. This approach ensures that a wide audience can engage with the material. Additionally, the code automatically utilizes GPUs if they are available. (Please see the [setup](https://github.com/rasbt/LLMs-from-scratch/blob/main/setup/README.md) doc for additional recommendations.)\n\n\n&nbsp;\n## Video Course\n\n[A 17-hour and 15-minute companion video course](https://www.manning.com/livevideo/master-and-build-large-language-models) where I code through each chapter of the book. The course is organized into chapters and sections that mirror the book's structure so that it can be used as a standalone alternative to the book or complementary code-along resource.\n\n<a href=\"https://www.manning.com/livevideo/master-and-build-large-language-models\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/video-screenshot.webp?123\" width=\"350px\"></a>\n\n\n&nbsp;\n\n\n## Companion Book / Sequel\n\n[*Build A Reasoning Model (From Scratch)*](https://mng.bz/lZ5B), while a standalone book, can be considered as a sequel to *Build A Large Language Model (From Scratch)*.\n\nIt starts with a pretrained model and implements different reasoning approaches, including inference-time scaling, reinforcement learning, and distillation, to improve the model's reasoning capabilities. \n\nSimilar to *Build A Large Language Model (From Scratch)*, [*Build A Reasoning Model (From Scratch)*](https://mng.bz/lZ5B) takes a hands-on approach implementing these methods from scratch.\n\n<a href=\"https://mng.bz/lZ5B\"><img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/cover.webp?123\" width=\"120px\"></a>\n\n- Amazon link (TBD)\n- [Manning link](https://mng.bz/lZ5B)\n- [GitHub repository](https://github.com/rasbt/reasoning-from-scratch)\n\n<br>\n\n&nbsp;\n## Exercises\n\nEach chapter of the book includes several exercises. The solutions are summarized in Appendix C, and the corresponding code notebooks are available in the main chapter folders of this repository (for example,  [./ch02/01_main-chapter-code/exercise-solutions.ipynb](./ch02/01_main-chapter-code/exercise-solutions.ipynb).\n\nIn addition to the code exercises, you can download a free 170-page PDF titled  [Test Yourself On Build a Large Language Model (From Scratch)](https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch) from the Manning website. It contains approximately 30 quiz questions and solutions per chapter to help you test your understanding.\n\n<a href=\"https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/test-yourself-cover.jpg?123\" width=\"150px\"></a>\n\n\n\n&nbsp;\n## Bonus Material\n\nSeveral folders contain optional materials as a bonus for interested readers:\n\n- **Setup**\n  - [Python Setup Tips](setup/01_optional-python-setup-preferences)\n  - [Installing Python Packages and Libraries Used In This Book](setup/02_installing-python-libraries)\n  - [Docker Environment Setup Guide](setup/03_optional-docker-environment)\n- **Chapter 2: Working with text data**\n  - [Byte Pair Encoding (BPE) Tokenizer From Scratch](ch02/05_bpe-from-scratch/bpe-from-scratch.ipynb)\n  - [Comparing Various Byte Pair Encoding (BPE) Implementations](ch02/02_bonus_bytepair-encoder)\n  - [Understanding the Difference Between Embedding Layers and Linear Layers](ch02/03_bonus_embedding-vs-matmul)\n  - [Dataloader Intuition with Simple Numbers](ch02/04_bonus_dataloader-intuition)\n- **Chapter 3: Coding attention mechanisms**\n  - [Comparing Efficient Multi-Head Attention Implementations](ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb)\n  - [Understanding PyTorch Buffers](ch03/03_understanding-buffers/understanding-buffers.ipynb)\n- **Chapter 4: Implementing a GPT model from scratch**\n  - [FLOPS Analysis](ch04/02_performance-analysis/flops-analysis.ipynb)\n  - [KV Cache](ch04/03_kv-cache)\n- **Chapter 5: Pretraining on unlabeled data:**\n  - [Alternative Weight Loading Methods](ch05/02_alternative_weight_loading/)\n  - [Pretraining GPT on the Project Gutenberg Dataset](ch05/03_bonus_pretraining_on_gutenberg)\n  - [Adding Bells and Whistles to the Training Loop](ch05/04_learning_rate_schedulers)\n  - [Optimizing Hyperparameters for Pretraining](ch05/05_bonus_hparam_tuning)\n  - [Building a User Interface to Interact With the Pretrained LLM](ch05/06_user_interface)\n  - [Converting GPT to Llama](ch05/07_gpt_to_llama)\n  - [Llama 3.2 From Scratch](ch05/07_gpt_to_llama/standalone-llama32.ipynb)\n  - [Qwen3 Dense and Mixture-of-Experts (MoE) From Scratch](ch05/11_qwen3/)\n  - [Gemma 3 From Scratch](ch05/12_gemma3/)\n  - [Memory-efficient Model Weight Loading](ch05/08_memory_efficient_weight_loading/memory-efficient-state-dict.ipynb)\n  - [Extending the Tiktoken BPE Tokenizer with New Tokens](ch05/09_extending-tokenizers/extend-tiktoken.ipynb)\n  - [PyTorch Performance Tips for Faster LLM Training](ch05/10_llm-training-speed)\n- **Chapter 6: Finetuning for classification**\n  - [Additional experiments finetuning different layers and using larger models](ch06/02_bonus_additional-experiments)\n  - [Finetuning different models on 50k IMDb movie review dataset](ch06/03_bonus_imdb-classification)\n  - [Building a User Interface to Interact With the GPT-based Spam Classifier](ch06/04_user_interface)\n- **Chapter 7: Finetuning to follow instructions**\n  - [Dataset Utilities for Finding Near Duplicates and Creating Passive Voice Entries](ch07/02_dataset-utilities)\n  - [Evaluating Instruction Responses Using the OpenAI API and Ollama](ch07/03_model-evaluation)\n  - [Generating a Dataset for Instruction Finetuning](ch07/05_dataset-generation/llama3-ollama.ipynb)\n  - [Improving a Dataset for Instruction Finetuning](ch07/05_dataset-generation/reflection-gpt4.ipynb)\n  - [Generating a Preference Dataset with Llama 3.1 70B and Ollama](ch07/04_preference-tuning-with-dpo/create-preference-data-ollama.ipynb)\n  - [Direct Preference Optimization (DPO) for LLM Alignment](ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb)\n  - [Building a User Interface to Interact With the Instruction Finetuned GPT Model](ch07/06_user_interface)\n\n<br>\n&nbsp;\n\n## Questions, Feedback, and Contributing to This Repository\n\n\nI welcome all sorts of feedback, best shared via the [Manning Forum](https://livebook.manning.com/forum?product=raschka&page=1) or [GitHub Discussions](https://github.com/rasbt/LLMs-from-scratch/discussions). Likewise, if you have any questions or just want to bounce ideas off others, please don't hesitate to post these in the forum as well.\n\nPlease note that since this repository contains the code corresponding to a print book, I currently cannot accept contributions that would extend the contents of the main chapter code, as it would introduce deviations from the physical book. Keeping it consistent helps ensure a smooth experience for everyone.\n\n\n&nbsp;\n## Citation\n\nIf you find this book or code useful for your research, please consider citing it.\n\nChicago-style citation:\n\n> Raschka, Sebastian. *Build A Large Language Model (From Scratch)*. Manning, 2024. ISBN: 978-1633437166.\n\nBibTeX entry:\n\n```\n@book{build-llms-from-scratch-book,\n  author       = {Sebastian Raschka},\n  title        = {Build A Large Language Model (From Scratch)},\n  publisher    = {Manning},\n  year         = {2024},\n  isbn         = {978-1633437166},\n  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},\n  github       = {https://github.com/rasbt/LLMs-from-scratch}\n}\n```\n",
         "AI_DataScience"
        ],
        [
         "3",
         "MDEwOlJlcG9zaXRvcnk3MTU4MzYwMg==",
         "<!-- omit in toc -->\n# Computer Science courses with video lectures\n\n<!-- omit in toc -->\n## Introduction\n\n- Please check [NOTES](https://github.com/Developer-Y/cs-video-courses/blob/master/NOTES.md) for general information about this list.\n- Please refer [CONTRIBUTING.md](https://github.com/Developer-Y/cs-video-courses/blob/master/CONTRIBUTING.md) for contribution guidelines.\n- Please feel free to raise any genuine issue you may have, however, it has been noticed that few people open empty issues to raise their GitHub contribution on their account. Such spammers will be blocked. \n- You are welcome to contribute, please create PR for actual college/University level courses. Please do not add links for small MOOCs, basic tutorials, or advertisements for some sites/channels.\n\n------------------------------\n\nTable of Contents\n\n------------------------------\n- [Introduction to Computer Science](#introduction-to-computer-science)\n- [Data Structures and Algorithms](#data-structures-and-algorithms)\n- [Systems Programming](#systems-programming)\n  * [Operating Systems](#operating-systems)\n  * [Distributed Systems](#distributed-systems)\n  * [Real-Time Systems](#real-time-systems) \n- [Database Systems](#database-systems)\n- [Software Engineering](#software-engineering)\n  * [Object Oriented Design](#object-oriented-design)\n  * [Software Engineering](#software-engineering)\n  * [Software Architecture](#software-architecture)\n  * [Concurrency](#concurrency)\n  * [Mobile Application Development](#mobile-application-development)\n- [Artificial Intelligence](#artificial-intelligence)\n- [Machine Learning](#machine-learning)\n  * [Introduction to Machine Learning](#introduction-to-machine-learning)\n  * [Data Mining](#data-mining)\n  * [Probabilistic Graphical Modeling](#probabilistic-graphical-modeling)\n  * [Deep Learning](#deep-learning)\n  * [Reinforcement Learning](#reinforcement-learning)\n  * [Advanced Machine Learning](#advanced-machine-learning)\n  * [Natural Language Processing](#natural-language-processing)\n  * [Generative AI](#generative-ai)\n  * [Computer Vision](#computer-vision)\n  * [Time Series Analysis](#time-series-analysis)\n  * [Optimization](#optimization)\n  * [Unsupervised Learning](#unsupervised-learning)\n  * [Misc Machine Learning Topics](#misc-machine-learning-topics)\n- [Computer Networks](#computer-networks)\n- [Math for Computer Scientist](#math-for-computer-scientist)\n- [Web Programming and Internet Technologies](#web-programming-and-internet-technologies)\n- [Theoretical CS and Programming Languages](#theoretical-cs-and-programming-languages)\n- [Embedded Systems](#embedded-systems)\n- [Real time system evaluation](#real-time-system-evaluation)\n- [Computer Organization and Architecture](#computer-organization-and-architecture)\n- [Security](#security)\n- [Computer Graphics](#computer-graphics)\n- [Image Processing and Computer Vision](#image-processing-and-computer-vision)\n- [Computational Physics](#computational-physics)\n- [Computational Biology](#computational-biology)\n- [Quantum Computing](#quantum-computing)\n- [Robotics and Control](#robotics-and-control)\n- [Computational Finance](#computational-finance)\n- [Network Science](#network-science)\n- [Blockchain Development](#blockchain-development)\n- [Misc](#misc)\n\n<!-- omit in toc -->\n## Courses\n\n------------------------------\n\n### Introduction to Computer Science\n\n- [CS 10 - The Beauty and Joy of Computing - Spring 2015 - Dan Garcia - UC Berkeley InfoCoBuild](http://www.infocobuild.com/education/audio-video-courses/computer-science/cs10-spring2015-berkeley.html)\n- [6.0001 - Introduction to Computer Science and Programming in Python - MIT OCW](https://ocw.mit.edu/courses/6-0001-introduction-to-computer-science-and-programming-in-python-fall-2016/video_galleries/lecture-videos/)\n- [6.001 - Structure and Interpretation of Computer Programs, MIT](https://ocw.mit.edu/courses/6-001-structure-and-interpretation-of-computer-programs-spring-2005/video_galleries/video-lectures/)\n- [Introduction to Computational Thinking - MIT](https://computationalthinking.mit.edu/Fall22/)\n- [CS 50 - Introduction to Computer Science, Harvard University](https://online-learning.harvard.edu/course/cs50-introduction-computer-science) ([cs50.tv](http://cs50.tv/2017/fall/))\n- [CS50R - Introduction to Programming with R](https://cs50.harvard.edu/r/2024/) ([Lecture Videos](https://www.youtube.com/playlist?list=PLhQjrBD2T382yfNp_-xzX244d-O9W6YmD))\n- [CS50: Introduction to Computer Science with Python - Harvard (David J. Malan)](https://www.youtube.com/playlist?list=PLhQjrBD2T3817j24-GogXmWqO5Q5vYy0V)\n- [CS 61A - Structure and Interpretation of Computer Programs [Python], UC Berkeley](https://cs61a.org/)\n- [CPSC 110 - Systematic Program Design [Racket], University of British Columbia](https://www.youtube.com/channel/UC7dEjIUwSxSNcW4PqNRQW8w/playlists?view=1&flow=grid&sort=da)\n- [CS50's Understanding Technology](https://www.youtube.com/playlist?list=PLhQjrBD2T382p8amnvUp1rws1p7n7gJ2p)\n- [CSE 142 Computer Programming I (Java Programming), Spring 2016 - University of Washington](https://courses.cs.washington.edu/courses/cse142/16sp/calendar.shtml)\n- [CS 1301 Intro to computing - Gatech](https://www.cc.gatech.edu/classes/AY2016/cs1301c_fall/)\n- [CS 106A - Programming Methodology, Stanford University](https://see.stanford.edu/Course/CS106A) ([Lecture Videos](https://www.youtube.com/playlist?list=PL84A56BC7F4A1F852))\n- [CS 106B - Programming Abstractions, Stanford University](https://see.stanford.edu/Course/CS106B) ([Lecture Videos](https://www.youtube.com/playlist?list=PLnfg8b9vdpLn9exZweTJx44CII1bYczuk))\n- [CS 106L - Standard C++ Programming](https://web.stanford.edu/class/cs106l/)([Lecture Videos](https://www.youtube.com/playlist?list=PLCgD3ws8aVdolCexlz8f3U-RROA0s5jWA))\n- [CS 106X - Programming Abstractions in C++](http://web.stanford.edu/class/cs106x/) ([Lecture Videos](https://www.youtube.com/playlist?list=PLrivl8gTKLcpIJ-ktHCxMEgWOn8LawYhb))\n- [CS 107 - Programming Paradigms, Stanford University](https://see.stanford.edu/Course/CS107)\n- [CmSc 150 - Introduction to Programming with Arcade Games, Simpson College](http://ProgramArcadeGames.com)\n- [IN2377 - Concepts of C++ programming (Winter 2023), TUM](https://live.rbg.tum.de/?year=2023&term=W&slug=cpp&view=3) ([Winter 2022](https://live.rbg.tum.de/?year=2022&term=W&slug=cpp&view=3)) ([Summer 2022](https://live.rbg.tum.de/?year=2022&term=S&slug=ccppprog&view=3)) ([Summer 2021](https://live.rbg.tum.de/?year=2021&term=S&slug=ccppprog&view=3))\n- [IN1503 - Advanced C++ Programming, TUM](https://live.rbg.tum.de/?year=2023&term=W&slug=AdvProg&view=3)\n- [LINFO 1104 - Paradigms of computer programming, Peter Van Roy, Universit√© catholique de Louvain, Belgium - EdX](https://www.youtube.com/playlist?list=PLw454N-VXALSIzIe_eL5U8L4S68v2X_ak)\n- [FP 101x - Introduction to Functional Programming, TU Delft](https://ocw.tudelft.nl/courses/introduction-to-functional-programming/)\n- [Introduction to Problem Solving and Programming - IIT Kanpur](https://nptel.ac.in/courses/106104074/)\n- [Introduction to programming in C - IIT Kanpur](https://nptel.ac.in/courses/106104128/)\n- [Programming in C++ - IIT Kharagpur](https://nptel.ac.in/courses/106105151/)\n- [Python Boot Camp Fall 2016 - Berkeley Institute for Data Science (BIDS)](https://www.youtube.com/playlist?list=PLKW2Azk23ZtSeBcvJi0JnL7PapedOvwz9)\n- [CS 101 - Introduction to Computer Science - Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPmjFQ2w9j05WDX8Jtg5RXWW)\n- [6.00SC - Introduction to Computer Science and Programming (Spring 2011) - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00sc-introduction-to-computer-science-and-programming-spring-2011/)\n- [6.00 - Introduction to Computer Science and Programming (Fall 2008) - MIT OCW](https://ocw.mit.edu/courses/6-00-introduction-to-computer-science-and-programming-fall-2008/video_galleries/video-lectures/)\n- [6.01SC - Introduction to Electrical Engineering and Computer Science I - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-01sc-introduction-to-electrical-engineering-and-computer-science-i-spring-2011/)\n- [Modern C++ Course (2018) - Bonn University](https://www.youtube.com/playlist?list=PLgnQpQtFTOGR50iIOtO36nK6aNPtVq98C)\n- [Modern C++ (Lecture & Tutorials, 2020, Vizzo & Stachniss) - University of Bonn](https://www.youtube.com/playlist?list=PLgnQpQtFTOGRM59sr3nSL8BmeMZR9GCIA)\n- [UW Madison CS 368 C++ for Java Programmers Fall 2020, by Michael Doescher](https://www.youtube.com/playlist?list=PLXY5xcFHqg33srpQjC7q7jqITLxcErPCM)\n- [UW Madison CS 354 Machine Organization and Programming spring 2020, 2021, by Michael Doescher](https://www.youtube.com/playlist?list=PLXY5xcFHqg32r5MZ-HfpA2Tr8Ke2lDYwI)\n- [Cornell CS 1110 Introduction to Computing using Python fall 2020, by Walker White](https://www.cs.cornell.edu/courses/cs1110/2020fa/lessons/) ([Lecture Videos](https://vod.video.cornell.edu/channel/CS+1110+Fall+2020/179890731))\n- [Cornell ECE 4960 Computational and Software Engineering spring 2017, by Edwin Kan](https://www.youtube.com/playlist?list=PLcVqWUh-bHiFN2CY1KMTw0-L39iDXlemi)\n\n------------------------------\n\n### Data Structures and Algorithms\n\n- [ECS 36C - Data Structures and Algorithms (C++) - Spring 2020 - Jo√´l Porquet-Lupine - UC Davis](https://lupteach.gitlab.io/courses/ucd-ecs36c/online/)\n- [Programming and Data Structures with Python, 2021-2022, Sem I - by Prof. Madhavan Mukund, CMI](https://www.cmi.ac.in/~madhavan/courses/python2021sep/)\n- [Graph Algorithms - Robert Sedgewick - Princeton University](https://www.youtube.com/watch?v=0qF7tPSQdCg)\n- [6.006 - Introduction to Algorithms, MIT OCW](https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/video_galleries/lecture-videos/)\n- [MIT 6.006 Introduction to Algorithms, Spring 2020](https://www.youtube.com/playlist?list=PLUl4u3cNGP63EdVPNLG3ToM6LaEUuStEY)\n- [Algorithms: Design and Analysis 1 - Stanford University](https://www.youtube.com/playlist?list=PLXFMmlk03Dt7Q0xr1PIAriY5623cKiH7V)\n- [Algorithms: Design and Analysis 2 - Stanford University](https://www.youtube.com/playlist?list=PLXFMmlk03Dt5EMI2s2WQBsLsZl7A5HEK6)\n- [COS 226 Algorithms, Youtube, Princeton - by Robert Sedgewick and Kevin Wayne](https://www.youtube.com/watch?v=1QZDe28peZk&list=PLRdD1c6QbAqJn0606RlOR6T3yUqFWKwmX&index=1)\n- [CSE 331 Introduction to Algorithm Design and Analysis, SUNY University at Buffalo, NY - Fall 2017](http://www-student.cse.buffalo.edu/~atri/cse331/fall17/index.html) ([Lectures](https://www.youtube.com/playlist?list=PLZBCR-EGqNpoiHeO17FlLADJ38Kb3EiPU)) ([Homework Walkthroughs](https://www.youtube.com/playlist?list=PLZBCR-EGqNpoVyQCIUDHiXnL-zdFD_ixk))\n- [CSE 373 - Analysis of Algorithms, Stony Brook - Prof Skiena](http://www.cs.sunysb.edu/~algorith/video-lectures/)\n- [COP 3530 Data Structures and Algorithms, Prof Sahni, UFL](http://www.cise.ufl.edu/~sahni/cop3530/) ([Videos](http://www.cise.ufl.edu/academics/courses/preview/cop3530sahni/))\n- [CS225 - Data Structures - University of Illinois at Urbana-Champaign](https://cs.illinois.edu/courses/profile/CS225)([Video lectures](https://www.youtube.com/playlist?list=PLRdSp8jtJxBqG3KNQPKKB-0Z2hh9omoDo))\n- [CS2 - Data Structures and Algorithms - Richard Buckland - UNSW](https://www.youtube.com/playlist?list=PLE621E25B3BF8B9D1)\n- [Data Structures - Pepperdine University](https://itunes.apple.com/us/course/data-structures/id546468797)\n- [CS 161 - Design and Analysis of Algorithms, Prof. Tim Roughgarden, Stanford University](http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=IntroToAlgorithms)\n- [6.046J - Introduction to Algorithms - Fall 2005, MIT OCW](https://ocw.mit.edu/courses/6-046j-introduction-to-algorithms-sma-5503-fall-2005/)\n- [Introduction to Algorithms (Spring 2020), MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-spring-2020/)\n- [6.046 - Design and Analysis of Algorithms, Spring 2015 - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2015/lecture-videos/)\n- [CS 473 - Algorithms - University of Illinois at Urbana-Champaign](https://courses.engr.illinois.edu/cs473/sp2016/lectures.html) ([Notes - Jeff Erickson](http://jeffe.cs.illinois.edu/teaching/algorithms/)) ([YouTube](https://www.youtube.com/playlist?list=PL0v718LJg-78SFq81e4kJh_rS8XbKZ7Kn))\n- [COMP300E - Programming Challenges, Prof Skiena, Hong Kong University of Science and Technology - 2009](https://www.youtube.com/playlist?list=PL07B3F10B48592010)\n- [16s-4102 - Algorithms, University of Virginia](http://www.cs.virginia.edu/~shelat/16s-4102/) ([Youtube](https://www.youtube.com/channel/UCxXYk53cSZof2bR_Ax0uJYQ/videos))\n- [CS 61B - Data Structures (Java) - UC Berkeley](https://inst.eecs.berkeley.edu/~cs61b/)([Youtube](https://www.youtube.com/watch?v=gG4--V_PpEk&list=PLjuu7kFWxFtZBm-5GifiVpqdAxeW7Hsax))\n- [CS 170 Algorithms - UCBerkeley](https://cs170.org/) [Fall 2019, Youtube](https://www.youtube.com/playlist?list=PLIygTcviGPKD4TU_QsvJI0G7QnrIS_7Wn) [Fall 2018, Youtube](https://www.youtube.com/watch?v=fd5P-8IQwMY&list=PLkFD6_40KJIx8lWWbE-Uk069aZ1R-W-VU&index=2&t=0s) [Fall 2018,Bilibili](https://www.bilibili.com/video/av43955743/?p=1) [2013 Bilibili](https://www.bilibili.com/video/av26670685/)\n- [CS 159 Data-Driven Algorithm Design - Caltech](https://sites.google.com/view/cs-159-spring-2020/lectures?authuser=0) [Spring 2020, Youtube](https://www.youtube.com/playlist?list=PLuz4CTPOUNi4Dz6zBPypcI8I3oJUjFKk4)\n- [ECS 122A - Algorithm Design and Analysis, UC Davis](http://web.cs.ucdavis.edu/~gusfield/cs122f10/videolist.html)\n- [CSE 373 - Data Structures and Algorithms, Winter 2024 - University of Washington](https://courses.cs.washington.edu/courses/cse373/24wi/) ([Winter 2024, Youtube](https://www.youtube.com/playlist?list=PLEcoVsAaONjd5n69K84sSmAuvTrTQT_Nl)) ([Spring 2023, Notes](https://courses.cs.washington.edu/courses/cse373/23sp/)) ([Spring 2023, Youtube](https://www.youtube.com/playlist?list=PLEcoVsAaONjfHSAbP1AsVjAxIOFue6uWh))\n- [CSEP 521 - Applied Algorithms, Winter 2013 - University of Washington](https://courses.cs.washington.edu/courses/csep521/13wi/) ([Videos](https://courses.cs.washington.edu/courses/csep521/13wi/video/))\n- [Data Structures And Algorithms - IIT Delhi](https://nptel.ac.in/courses/106102064/)\n- [Design and Analysis of Algorithms - IIT Bombay](https://nptel.ac.in/courses/106101060/)\n- [Programming, Data Structures and Algorithms - IIT Madras](https://nptel.ac.in/courses/106106127/)\n- [Design and Analysis of Algorithms - IIT Madras](https://nptel.ac.in/courses/106106131/)\n- [Fundamental Algorithms:Design and Analysis - IIT Kharagpur](https://nptel.ac.in/courses/106105157/)\n- [Programming and Data Structure - IIT Kharagpur](https://nptel.ac.in/courses/106105085/)\n- [Programming, Data structures and Algorithms - IIT Madras](https://nptel.ac.in/courses/106106133/)\n- [Programming, Data Structures and Algorithms in Python - IIT Madras](https://nptel.ac.in/courses/106106145/)\n- [Programming and Data structures (PDS) - IIT Madras](https://nptel.ac.in/courses/106106130/)\n- [COP 5536 Advanced Data Structures, Prof Sahni - UFL](http://www.cise.ufl.edu/~sahni/cop5536/index.html) ([Videos](http://www.cise.ufl.edu/academics/courses/preview/cop5536sahni/))\n- [CS 261 - A Second Course in Algorithms, Stanford University](http://theory.stanford.edu/~tim/w16/w16.html) ([Youtube](https://www.youtube.com/playlist?list=PLEGCF-WLh2RJh2yDxlJJjnKswWdoO8gAc))\n- [CS 224 - Advanced Algorithms, Harvard University](http://people.seas.harvard.edu/~minilek/cs224/fall14/index.html) ([Lecture Videos](http://people.seas.harvard.edu/~minilek/cs224/fall14/lec.html)) ([Youtube](https://www.youtube.com/playlist?list=PL2SOU6wwxB0uP4rJgf5ayhHWgw7akUWSf))\n- [CS 6150 - Advanced Algorithms (Fall 2016), University of Utah](https://www.youtube.com/playlist?list=PLbuogVdPnkCp8X9FHOglnLqFjyvqGLftx)\n- [CS 6150 - Advanced Algorithms (Fall 2017), University of Utah](https://www.youtube.com/playlist?list=PLbuogVdPnkCqS9Z419eky9m6gJP7zfhO9)\n- [ECS 222A - Graduate Level Algorithm Design and Analysis, UC Davis](http://web.cs.ucdavis.edu/~gusfield/cs222f07/videolist.html)\n- [6.851 - Advanced Data Structures, MIT](http://courses.csail.mit.edu/6.851/spring14/lectures/) ([MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-851-advanced-data-structures-spring-2012/lecture-videos/))\n- [6.854 - Advanced Algorithms, MIT](https://www.youtube.com/playlist?list=PL6ogFv-ieghdoGKGg2Bik3Gl1glBTEu8c) ([Prof. Karger lectures](https://www.youtube.com/channel/UCtv9PiQVUDzsT4yl7524DCg/videos))\n- [CS264 Beyond Worst-Case Analysis, Fall 2014 - Tim Roughgarden Lecture](http://theory.stanford.edu/~tim/f14/f14.html) ([Youtube](https://www.youtube.com/playlist?list=PLEGCF-WLh2RL8jsZpaf2tLHa5LotFEt5b))\n- [CS364A Algorithmic Game Theory, Fall 2013 - Tim Roughgarden Lectures](https://www.youtube.com/playlist?list=PLEGCF-WLh2RJBqmxvZ0_ie-mleCFhi2N4)\n- [CS364B Advanced Mechanism Design, Winter 2014 - Tim Roughgarden Lectures](https://www.youtube.com/playlist?list=PLEGCF-WLh2RI77PL4gwLld_OU9Zh3TCX9)\n- [Algorithms - Aduni](http://aduni.org/courses/algorithms/index.php?view=cw)\n- [6.889 - Algorithms for Planar Graphs and Beyond (Fall 2011) MIT](http://courses.csail.mit.edu/6.889/fall11/lectures/)\n- [6.890 Algorithmic Lower Bounds: Fun with Hardness Proofs - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-890-algorithmic-lower-bounds-fun-with-hardness-proofs-fall-2014/)\n- [Computer Algorithms - 2 - IIT Kanpur](https://nptel.ac.in/courses/106104019/)\n- [Parallel Algorithm - IIT Kanpur](https://nptel.ac.in/courses/106104120/)\n- [Graph Theory - IISC Bangalore](https://nptel.ac.in/courses/106108054/)\n- [Data Structures - mycodeschool](https://www.youtube.com/watch?v=92S4zgXN17o&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)\n- [Algorithmic Game Theory, Winter 2020/21 - Uni Bonn](https://www.youtube.com/playlist?list=PLyzcvvgje7aD_DjpmhFzQ9DVS8zzhrgp6)\n- [NETS 4120: Algorithmic Game Theory, Spring 2023 - UPenn](https://www.youtube.com/playlist?list=PLlIlhe_rS4U1MfB0NzG4IWb7CM0xKkx4d)\n- [Introduction to Game Theory and Mechanism Design - IIT Kanpur](https://www.youtube.com/playlist?list=PL3eEm6KzZ3lF2TlVOnPyJHyGWJhUogn-D)\n- [15-850 Advanced Algorithms - CMU Spring 2023](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%2253c58248-7fd4-4f71-8774-af85013a570a%22&page=1)\n- [CS 270. Combinatorial Algorithms and Data Structures, Spring 2021](https://people.eecs.berkeley.edu/~prasad/spring2021.html) ([Youtube](https://www.youtube.com/playlist?list=PLfkeJ2f4i0AfWApBP8X8YvQfN4WbRQTC3))\n- [CMU 15 850 Advanced Algorithms spring 2023, by Anupam Gupta](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%2253c58248-7fd4-4f71-8774-af85013a570a%22&page=1)\n- [UC Berkeley CS 294-165 Sketching Algorithms fall 2020, by Jelani Nelson](https://www.sketchingbigdata.org/fall20/lec/) ([Youtube](https://www.youtube.com/playlist?list=PLIygTcviGPKCdx1AVD-CAzNk5uXDu9wIA))\n- [UIUC CS 498 ABD / CS 598 CSC Algorithms for Big Data fall 2020, by Chandra Chekuri](https://www.youtube.com/playlist?list=PL682UO4IMem_OA8_wY3nnSDLOSWr3PgYa)\n- [Algorithms for Data Science spring 2021, by Anil Maheshwari ](https://people.scs.carleton.ca/~maheshwa/courses/ADS/ADS-S20.html)\n- [CMU 15 859 Algorithms for Big Data fall 2020, by David Woodruff](http://www.cs.cmu.edu/~dwoodruf/teaching/15859-fall20/index.html)\n- [CO 642 Graph Theory - University of Waterloo](https://www.youtube.com/playlist?list=PL2BdWtDKMS6mplieDd_vls0TBX9Fq2jht)\n- [COMS W4241 Numerical Algorithms spring 2006, by Henryk Wozniakowski - Columbia](https://www.youtube.com/playlist?list=PL682UO4IMem98vm26lNUJ0TV0-EFrcUJb)\n- [Bonn Algorithms and Uncertainty summer 2021, by Thomas Kesselheim](https://www.youtube.com/playlist?list=PLyzcvvgje7aDZRFMJZgaVgOW5t5KLvD1-)\n- [Harvard Information Theory 2022, by Gregory Falkovich](https://www.youtube.com/playlist?list=PLDEN2FPNHwVZKAFqfFl1b_NNAESTJwV9o)\n- [Math 510 - Linear Programming and Network Flows - Colorado State University](https://www.math.colostate.edu/~adams/teaching/math510fall2020/)\n- [LINFO 2266 Advanced Algorithms for Optimization 2021, by Pierre Schaus - UCLouvain](https://www.youtube.com/playlist?list=PL682UO4IMem-wgYnJl5yMswlNkve_8oGU)\n- [MIT 6.5210 / 6.854 / 18.415 Advanced Algorithms Fall 2013, 2020, 2021, 2022, by David Karger](https://6.5210.csail.mit.edu/materials) ([Spring 2016, by Ankur Moitra](https://www.youtube.com/playlist?list=PL6ogFv-ieghdoGKGg2Bik3Gl1glBTEu8c))\n- [CMU 10 801 Advanced Optimization and Randomized Algorithms spring 2014, by Suvrit Sra and Alex Smola](https://www.cs.cmu.edu/~suvrit/teach/)\n- [Purdue CS 381 Fundamental Algorithms, by Kent Quanrud](https://fas22.s3.amazonaws.com/fas22-book.pdf) ([Spring 2022](https://www.youtube.com/playlist?list=PL0YFU3y0Z_gb6P9jG0-40AgZapdGGXPTD))\n- [Purdue CS 390 ATA Fundamental Algorithms Advanced, by Kent Quanrud](https://fas25.s3.amazonaws.com/fas25.pdf) ([Spring 2025](https://www.youtube.com/playlist?list=PL0YFU3y0Z_gYOC4uogZcu54XKq57TVEs3))\n- [Purdue CS 580 Graduate Algorithms, by Kent Quanrud](https://fas23.s3.amazonaws.com/fas23.pdf) ([Spring 2023](https://www.youtube.com/playlist?list=PL0YFU3y0Z_gYAwo5Tg4kP91ifXPF_FIQ1)) ([Spring 2024](https://www.youtube.com/playlist?list=PL0YFU3y0Z_gaGD6jZLeuLHTRW0ISFn6AU))\n- [Purdue CS 588 Randomized Algorithms, by Kent Quanrud](https://ras24.s3.amazonaws.com/ras24.pdf) ([Fall 2022](https://www.youtube.com/playlist?list=PL0YFU3y0Z_gbjvT1yDQkwRU9UXahd0BP1)) ([Spring 2024](https://www.youtube.com/playlist?list=PL0YFU3y0Z_gZxc-FeLhbOFS99ZzlWl4He))\n- [UC Santa Cruz CSE 101 Intro to Data Structures and Algorithms fall 2022, by Seshadhri Comandur](https://www.youtube.com/playlist?list=PLOQjlWvnI0fY1BCDxdiUSwkRHjnNI73G6) ([Fall 2020](https://www.youtube.com/playlist?list=PLOQjlWvnI0fZGffr1_MqCoaC5nUVtQIWz))\n- [UC Santa Cruz CSE 201 Analysis of Algorithms winter 2022, by Seshadhri Comandur](https://www.youtube.com/playlist?list=PLOQjlWvnI0fYmOmrAAN-g1d4nFB2uz6tU)\n- [UC Santa Cruz CSE 202 Combinatorial Algorithms spring 2021, by Seshadhri Comandur](https://www.youtube.com/playlist?list=PLOQjlWvnI0fbn9zAJfvJoQF1nc50KQR9g)\n- [UC Santa Cruz CSE 104, 204 Computational Complexity spring 2022, by Seshadhri Comandur](https://www.youtube.com/playlist?list=PLOQjlWvnI0fYMPFnJeVZ0kt4KPwWcbF0o) ([Fall 2020](https://www.youtube.com/playlist?list=PLOQjlWvnI0fas529oXenovd3MyafNQbKl))\n- [UC Santa Cruz CSE 290A Randomized Algorithms spring 2020, by Seshadhri Comandur](https://www.youtube.com/playlist?list=PLOQjlWvnI0faRpH2oJcyW4CuM5Clt8a2n)\n- [Algorithms for Big-Data (Fall 2020) - Saket Saurabh](https://sites.google.com/view/sakethome/teaching/algorithms-for-big-data-fall-2020)\n- [CS498ABD - Algorithms for Big Data - UIUC, Fall 2020](https://courses.engr.illinois.edu/cs498abd/fa2020/schedule.html)\n- [Advanced Data Structures](https://www.youtube.com/playlist?list=PLN-ShipRKQ0h6jIphD381pHdQtj_APRM8)\n- [CS60025 Algorithmic Game Theory - IIT KGP - Winter 2020](http://cse.iitkgp.ac.in/~palash/Courses/2020AlgorithmicGameTheory/agt2020.html)\n- [CS60083 Parameterized Algorithms - IIT KGP](http://cse.iitkgp.ac.in/~palash/Courses/2020ParameterizedAlgo/paramAlgo.html)\n- [Parameterized Complexity](https://sites.google.com/view/sakethome/teaching/parameterized-complexity)\n- [Structural Graph Theory - IIT Madras](https://www.youtube.com/playlist?list=PLtDHG-2klXcEedB8L-jjvb17OIUZbF3gW)\n- [Information Theory - IISC Bangalore](https://nptel.ac.in/courses/108/108/108108168/)\n\n\n\n\n------------------------------\n\n### Systems Programming\n\n- [15-213 Introduction to Computer Systems, Fall 2015  - CMU](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22b96d90ae-9871-4fae-91e2-b1627b43e25e%22&maxResults=150)\n- [Computer Systems: A programmer's Perspective](https://www.youtube.com/playlist?list=PLyboo2CCDSWnhzzzzDQ3OBPrRiIjl-aIE)\n- [CS361 - COMPUTER SYSTEMS - UIC](https://www.cs.uic.edu/~ckanich/cs361/f20/)\n- [CS 3650 - Computer Systems - Fall 2020 - Nat Tuck - NEU](https://web.archive.org/web/20210423030302/https://ntuck-neu.site/2020-09/cs3650/) ([Lectures - YouTube](https://www.youtube.com/playlist?list=PLtg_A_3rzLAtBuwQp6mA3WveYw9Q7GzIZ))\n- [CS 4400 ‚Äì Computer Systems   Fall 2016 - UoUtah](https://www.eng.utah.edu/~cs4400/)\n- [Systems - Aduni](http://aduni.org/courses/systems/index.php?view=cw)\n- [CS110: Principles of Computer Systems - Stanford](https://web.stanford.edu/class/archive/cs/cs110/cs110.1202/)\n- #### **Operating Systems**\n  - [ECS 150 - Operating Systems and Systems Programming - Fall 2020 - Jo√´l Porquet-Lupine - UC Davis](https://lupteach.gitlab.io/courses/ucd-ecs150/online/)\n  - [CS124 Operating Systems - California Institute of Technology, Fall 2018 - Youtube](https://www.youtube.com/playlist?list=PL3swII2vlVoVbav6FV98pidq6BsTN4u56)\n  - [CS 162 Operating Systems and Systems Programming, Spring 2015 - University of California, Berkeley](https://archive.org/details/ucberkeley-webcast-PL-XXv-cvA_iBDyz-ba4yDskqMDY6A1w_c?sort=titleSorter) ([Fall 2020 - YouTube](https://www.youtube.com/playlist?list=PLF2K2xZjNEf97A_uBCwEl61sdxWVP7VWC))\n  - [CS 4414 - Operating Systems, University of Virginia (rust-class)](http://rust-class.org/pages/classes.html)\n  - [CS 4414 Operating Systems, Fall 2018 - University of Virginia](https://www.cs.virginia.edu/~cr4bd/4414/F2018/schedule.html)\n  - [CSE 421/521 - Introduction to Operating Systems, SUNY University at Buffalo, NY - Spring 2016](https://www.ops-class.org/courses/buffalo/CSE421_Spring2016/) ([Lectures - YouTube](https://www.youtube.com/playlist?list=PLE6LEE8y2Jp-kbEcVR2W3vfx0Pdca0BD3)) ([Recitations 2016](https://www.youtube.com/playlist?list=PLE6LEE8y2Jp_YJn8wu9aJTPOgeWqiaJDF)) ([Assignment walkthroughs](https://www.youtube.com/playlist?list=PLE6LEE8y2Jp9PC8fyzc2meL4XvrVSyP8O))\n  - [CS 377 - Operating Systems, Fall 16 - Umass OS](https://www.youtube.com/playlist?list=PLacuG5pysFbDTmsCRGWsMW_PzIOpXnckw)\n  - [CS 577 - Operating Systems, Spring 20 - Umass OS](https://www.youtube.com/playlist?list=PLacuG5pysFbB2_z9EkSfQIjq3yNzy8igs)\n  - [6.828 - Operating System Engineering [Fall 2014]](https://www.youtube.com/playlist?list=PLfciLKR3SgqNJKKIKUliWoNBBH1VHL3AP)\n  - [6.S081 - Operating System Engineering [Fall 2020]](https://pdos.csail.mit.edu/6.828/2020/schedule.html)\n  - [CSE 30341 - Operating Systems, Spr 2008](https://www.youtube.com/playlist?list=PLAB7D5CA7E262B0E2)\n  - [CSEP 551 Operating Systems Autumn 2014 - University of Washington](https://courses.cs.washington.edu/courses/csep551/14au/video/)\n  - [Introduction to Operating Systems - IIT Madras](https://nptel.ac.in/courses/106106144/)\n  - [CS194 Advanced Operating Systems Structures and Implementation, Spring 2013 InfoCoBuild, UC Berkeley](http://www.infocobuild.com/education/audio-video-courses/computer-science/cs194-spring2013-berkeley.html)\n  - [CSE 60641 - Graduate Operating Systems, Fall 08](https://www.youtube.com/view_play_list?p=22B10D854588E20C)\n  - [Advanced Programming in the UNIX Environment](https://stevens.netmeister.org/631/)\n  - [Operating System - IIT Madras](https://www.youtube.com/playlist?list=PLZ2ps__7DhBYcwlZ7GPCBzbowmiiF4BYR)\n- #### **Distributed Systems**\n  - [CS 677 - Distributed Operating Systems, Spring 24 - Umass OS](https://www.youtube.com/playlist?list=PLacuG5pysFbBpWHfKUU9Dfdk8RmQ7B9EH)\n  - [CS 436 - Distributed Computer Systems - U Waterloo](https://www.youtube.com/playlist?list=PLawkBQ15NDEkDJ5IyLIJUTZ1rRM9YQq6N)\n  - [6.824 - Distributed Systems, Spring 2015 - MIT](https://www.youtube.com/playlist?list=PLkcQbKbegkMqiWf7nF8apfMRL4P4sw8UL)\n  - [6.824 Distributed Systems - Spring 2020 - MIT](https://pdos.csail.mit.edu/6.824/schedule.html) ([Youtube](https://www.youtube.com/playlist?list=PLrw6a1wE39_tb2fErI4-WkMbsvGQk9_UB))\n  - [Distributed Systems Lecture Series](https://www.youtube.com/playlist?list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB)\n  - [Distributed Algorithms, https://canvas.instructure.com/courses/902299](https://www.youtube.com/playlist?list=PL700757A5D4B3F368)\n  - [CSEP 552 - PMP Distributed Systems, Spring 2013 - University of Washington](https://courses.cs.washington.edu/courses/csep552/13sp/) ([Videos](https://courses.cs.washington.edu/courses/csep552/13sp/video/))\n  - [CSE 490H - Scalable Systems: Design, Implementation and Use of Large Scale Clusters, Autumn 2008 - University of Washington](https://courses.cs.washington.edu/courses/cse490h/08au/lectures.htm) ([Videos](https://courses.cs.washington.edu/courses/cse490h/08au/video.htm))\n  - [MOOC - Cloud Computing Concepts - UIUC](https://www.youtube.com/playlist?list=PLFd87qVsaLhOkTLvfp6MC94iFa_1c9wrU)\n  - [Distributed Systems (Prof. Pallab Dasgupta)](https://www.youtube.com/playlist?list=PLUJ7JmcrTifBROWODSG8wgyl20XgBuE-N)\n  - [EdX KTHx ID2203 Reliable Distributed Algorithms](https://www.youtube.com/playlist?list=PLx3mQFFeHPjndmQ0iP9j6C58b90hqGa0X)\n  - [Distributed Data Management - Technische Universit√§t Braunschweig, Germany](http://www.ifis.cs.tu-bs.de/teaching/ss-15/ddm)\n  - [Information Retrieval and Web Search Engines - Technische Universit√§t Braunschweig, Germany](http://www.ifis.cs.tu-bs.de/teaching/ws-1516/IRWS)\n  - [Middleware and Distributed Systems (WS 2009/10) - Dr. Martin von L√∂wis - HPI](https://www.tele-task.de/series/729/)\n  - [CSE 138 - Distributed Systems - UC Santa Cruz, Spring 2020](https://www.youtube.com/playlist?list=PLNPUF5QyWU8O0Wd8QDh9KaM1ggsxspJ31) ([2021](https://www.youtube.com/playlist?list=PLNPUF5QyWU8PydLG2cIJrCvnn5I_exhYx))\n  - [CMU 15 440 / 640 Distributed Systems Spring 2022, by Mahadev Satyanarayanan, Padmanabhan Pillai](https://www.youtube.com/playlist?list=PLIygTcviGPKAp30J9kcVW9jPzFC7Otpol)\n  - [UNC Comp533 - Distributed Systems Spring 2020](https://www.youtube.com/playlist?list=PLH5XTBxCO2hzgww9p5sew30lx3ngJsxcB)\n  - [Brown CSCI 1380 Distributed Computer Systems spring 2016, by Tom Doeppner & Rodrigo Fonseca](https://cs.brown.edu/courses/cs138/s16/syllabus.html)\n  - [Distributed Systems lecture series - Martin Kleppmann](https://www.youtube.com/playlist?list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB)\n  - [Distributed Algorithms - Jukka Suomela](https://www.youtube.com/playlist?list=PL2RY7P3JxZN8g9hFCasNqzuDhZbIbAj54)\n  - [Programming Parallel Computers - Jukka Suomela](https://www.youtube.com/playlist?list=PL2RY7P3JxZN-Pz1nwvnoJ9uEHmOmv4jmi)\n- #### **Real-Time Systems**\n  - [CPCS 663 - Real-Time Systems: Video Material - TAMU](http://faculty.cs.tamu.edu/bettati/Courses/663/Video/presentation.html)\n  - [Real Time Systems - IIT Kharagpur](https://nptel.ac.in/courses/106105036/)\n- [6.172 Performance Engineering of Software Systems - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-172-performance-engineering-of-software-systems-fall-2018/)\n- [Performance Evaluation of Computer Systems - IIT Madras](https://nptel.ac.in/courses/106106048/)\n- [Storage Systems - IISC Bangalore](https://nptel.ac.in/courses/106108058/)\n- [MAP6264 - Queueing Theory - FAU](http://www.cse.fau.edu/~bob/courses/map6264/)([Video Lectures](https://vimeo.com/album/171324/))\n- [EE 380 Colloquium on Computer Systems - Stanford University](http://web.stanford.edu/class/ee380/) ([Lecture videos](https://www.youtube.com/playlist?list=PLoROMvodv4rMWw6rRoeSpkiseTHzWj6vu))\n\n------------------------------\n\n### Database Systems\n\n- [CMPSC 431W Database Management Systems, Fall 2015 - Penn State University](http://www.cse.psu.edu/~wul2/cmpsc431w/) [Lectures - YouTube](https://www.youtube.com/playlist?list=PLstRzn3gXZMdXqAiVJ1NN2CoyXHqma7pQ)\n- [CS121 - Introduction to Relational Database Systems, Fall 2016 - Caltech](http://users.cms.caltech.edu/~donnie/cs121/)\n- [CS 5530 - Database Systems, Spring 2016 - University of Utah](https://www.youtube.com/playlist?list=PLbuogVdPnkCrercQNP9tTsjjPdgRVYvC7)\n- [Distributed Data Management (WT 2018/19) - HPI University of Potsdam](https://www.tele-task.de/series/1224/)\n- [MOOC - Database Stanford Dbclass](https://www.youtube.com/playlist?list=PL6hGtHedy2Z4EkgY76QOcueU8lAC4o6c3)\n- [CSEP 544, Database Management Systems, Au 2015 - University of Washington](https://www.youtube.com/playlist?list=PLTPQEx-31JXjQYrUKvAjUTWgCYluHGs_L)\n- [Database Design - IIT Madras](https://nptel.ac.in/courses/106106093/)\n- [Fundamentals of Database Systems - IIT Kanpur](https://nptel.ac.in/courses/106104135/)\n- [Principles of Database Management, Bart Baesens](https://www.youtube.com/playlist?list=PLdQddgMBv5zEhlpqdiUcf9aTNEtmESgyl)\n- [FIT9003 Database Systems Design - Monash University](https://itunes.apple.com/us/podcast/fit9003-database-systems-design/id306569364)\n- [15-445 - Introduction to Database Systems, CMU](https://15445.courses.cs.cmu.edu/fall2022/) ([YouTube-2017](https://www.youtube.com/playlist?list=PLSE8ODhjZXjYutVzTeAds8xUt1rcmyT7x), [YouTube-2018](https://www.youtube.com/playlist?list=PLSE8ODhjZXja3hgmuwhf89qboV1kOxMx7), [YouTube-2019](https://www.youtube.com/playlist?list=PLSE8ODhjZXjbohkNBWQs_otTrBTrjyohi), [YouTube-2021](https://www.youtube.com/playlist?list=PLSE8ODhjZXjZaHA6QcxDfJ0SIWBzQFKEG), [YouTube-2022](https://www.youtube.com/playlist?list=PLSE8ODhjZXjaKScG3l0nuOiDTTqpfnWFf))\n- [15-721 - Database Systems, CMU](http://15721.courses.cs.cmu.edu/spring2017) ([YouTube-2017](https://www.youtube.com/playlist?list=PLSE8ODhjZXjYgTIlqf4Dy9KQpQ7kn1Tl0), [YouTube-2016](https://www.youtube.com/playlist?list=PLSE8ODhjZXjbisIGOepfnlbfxeH7TW-8O))\n- [15-721 Advanced Database Systems (Spring 2019) - CMU](https://www.youtube.com/playlist?list=PLSE8ODhjZXja7K1hjZ01UTVDnGQdx5v5U)\n- [CS122 - Relational Database System Implementation, Winter 2014-2015 - Caltech](http://users.cms.caltech.edu/~donnie/cs122/)\n- [CS 186 - Database Systems, UC Berkeley, Spring 2015](http://www.infocobuild.com/education/audio-video-courses/computer-science/cs186-spring2015-berkeley.html)\n- [CS 6530 - Graduate-level Database Systems, Fall 2016, University of Utah](https://www.cs.utah.edu/~lifeifei/cs6530/) ([Lectures - YouTube](https://www.youtube.com/playlist?list=PLbuogVdPnkCqwHUcieMrytP453Ep0y6eI))\n- [6.830/6.814 - Database Systems [Fall 2014]](https://www.youtube.com/playlist?list=PLfciLKR3SgqOxCy1TIXXyfTqKzX2enDjK)\n- [Informatics 1 - Data & Analysis 2014/15- University of Edinburgh](http://groups.inf.ed.ac.uk/vision/VIDEO/2014/da.htm)\n- [Database Management Systems, Aduni](http://aduni.org/courses/databases/index.php?view=cw)\n- [D4M - Signal Processing on Databases](https://ocw.mit.edu/resources/res-ll-005-d4m-signal-processing-on-databases-fall-2012/)\n- [In-Memory Data Management (2013)Prof. Hasso Plattner - HPI](https://open.hpi.de/courses/imdb2013/items/72j6pftms3dOSunM98JhfW)\n- [Distributed Data Management (WT 2019/20) - Dr. Thorsten Papenbrock - HPI](https://www.tele-task.de/series/1285/)\n- [CS122d - NoSQL Data Management (Spring 21) - Prof. Mike Carey - UC Irvine](https://uci.yuja.com/V/PlayList?node=9933576&a=1583628376&autoplay=1)\n\n------------------------------\n\n### Software Engineering\n\n- #### **Object Oriented Design**\n  - [ECE 462 Object-Oriented Programming using C++ and Java - Purdue](https://engineering.purdue.edu/OOSD/F2008/F2008.html)\n  - [Object-oriented Program Design and Software Engineering - Aduni](http://aduni.org/courses/java/index.php?view=cw)\n  - [OOSE - Object-Oriented Software Engineering, Dr. Tim Lethbridge](https://www.youtube.com/playlist?list=PL6iDJCG2nkhfNlig8NY5ePPfGvtQX6yLa)\n  - [Object Oriented Systems Analysis and Design (Systems Analysis and Design in a Changing World)](https://www.youtube.com/playlist?list=PL6XklZATqYx9dj72MKG6wLYjljeB2odra)\n  - [CS 251 - Intermediate Software Design (C++ version) - Vanderbilt University](https://www.youtube.com/playlist?list=PLZ9NgFYEMxp4ZsvD10uXmClGnukcu3Uff)\n  - [OOSE - Software Dev Using UML and Java](https://www.youtube.com/playlist?list=PLJ9pm_Rc9HesnkwKlal_buSIHA-jTZMpO)\n  - [Object-Oriented Analysis and Design - IIT Kharagpur](https://nptel.ac.in/courses/106105153/)\n  - [CS3 - Design in Computing - Richard Buckland UNSW](https://www.youtube.com/playlist?list=PL0C5D85DBA20E685C)\n  - [Informatics 1 - Object-Oriented Programming 2014/15- University of Edinburgh](http://groups.inf.ed.ac.uk/vision/VIDEO/2014/inf1op.htm)\n  - [Software Engineering with Objects and Components 2015/16- University of Edinburgh](http://groups.inf.ed.ac.uk/vision/VIDEO/2015/seoc.htm)\n- #### **Software Engineering**\n  - [Computer Science 169- Software Engineering - Spring 2015 - UCBerkeley](https://youtube.com/playlist?list=PLVEFwJhglgHJQEQ6RjMMjcclix94gp1k2)\n  - [Computer Science 169- Software Engineering - Fall 2019 - UCBerkeley](https://www.youtube.com/playlist?list=PLkFD6_40KJIxCKgzL0uysjsAtfY3JawLS)\n  - [CS 5150 -  Software Engineering, Fall 2014 - Cornell University](http://www.cs.cornell.edu/courses/cs5150/2014fa/materials.html)\n  - [Introduction to Service Design and Engineering - University of Trento, Italy](https://www.youtube.com/playlist?list=PLBdajHWwi0JCn87QuFT3e58mekU0-6WUT)\n  - [CS 164 Software Engineering - Harvard](https://www.youtube.com/watch?v=3zdfCR6c8vw&list=PLuhjguFxSeVLvKvWwTUIpVwXdLtZPX1ZS)\n  - [System Analysis and Design - IISC Bangalore](https://nptel.ac.in/courses/106108102/)\n  - [Software Engineering - IIT Bombay](https://nptel.ac.in/courses/106101061/)\n  - [Dependable Systems (SS 2014)- HPI University of Potsdam](https://www.tele-task.de/series/1005/)\n  - [Automated Software Testing - ETH Z√ºrich | Spring 2024](https://video.ethz.ch/lectures/d-infk/2024/spring/263-2815-00L/9c81df65-d04d-411a-bea4-cbd32eb249e5.html)\n  - [Software Testing - IIT Kharagpur](https://nptel.ac.in/courses/106105150/)\n  - [Software Testing - Udacity, course-cs258 | 2015](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkWVHeC_8aSIbSxE_NXI76g)\n  - [Software Debugging - Udacity, course-cs259 | 2015](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkxK63TiT88oEe-AIBhr96A)\n  - [Software Engineering - Bauhaus-Uni Weimar](https://www.youtube.com/watch?v=jouBM4AH0jw&list=PLjEglKdMOevU2STTGq79duxTXDFuO-k1H&index=2)\n  - [CMU 17-445 Software Engineering for AI-Enabled Systems summer 2020, by Christian Kaestner](https://www.youtube.com/playlist?list=PLDS2JMJnJzdkQPdkhcuwcbJpjB84g9ffX)\n- #### **Software Architecture**\n  - [CS 411 - Software Architecture Design - Bilkent University](http://video.bilkent.edu.tr/course_videos.php?courseid=10)\n  - [MOOC - Software Architecture & Design - Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkMTetlG7xKWaI5ZAZFX8fL)\n  - [CS-310 Scalable Software Architectures](https://www.youtube.com/playlist?list=PLWl7jvxH18r0u5VRZsOjhghNXc_Ec4dZz)\n- #### **Concurrency**\n  - [CS176 - Multiprocessor Synchronization - Brown University](http://cs.brown.edu/courses/cs176/course_information.shtml) ([Videos from 2012](http://www.brown.edu/cis/sta/dev/herlihy_csci1760_fa12/#vid))\n  - [CS 282 (2014): Concurrent Java Network Programming in Android](https://www.youtube.com/playlist?list=PLZ9NgFYEMxp4KSJPUyaQCj7x--NQ6kvcX)\n  - [CSE P 506 ‚Äì Concurrency, Spring 2011 - University of Washington](https://courses.cs.washington.edu/courses/csep506/11sp/Home.html) ([Videos](https://courses.cs.washington.edu/courses/csep506/11sp/Videos.html))\n  - [CSEP 524 - Parallel Computation - University of Washington](https://courses.cs.washington.edu/courses/csep524/10sp/) ([Videos](https://courses.cs.washington.edu/courses/csep524/10sp/lectures/video.html))\n  - [Parallel Programming Concepts (WT 2013/14) - HPI University of Potsdam](https://www.tele-task.de/series/977/)\n  - [Parallel Programming Concepts (WT 2012/13) - HPI University of Potsdam](https://www.tele-task.de/series/924/)\n  - [UIUC ECE 408 / CS 408 Applied Parallel Programming fall 2022, by Wen-mei Hwu, Sanjay Patel](https://www.youtube.com/playlist?list=PL6RdenZrxrw-UKfRL5smPfFFpeqwN3Dsz) ([Spring 2018](https://www.youtube.com/playlist?list=PLRRuQYjFhpmvu5ODQoY2l7D0ADgWEcYAX))\n  - [UIUC ECE 508 / CS 508 Manycore Parallel Algorithms spring 2019, by Wen-mei Hwu](https://www.youtube.com/playlist?list=PLRRuQYjFhpmspsME4LmLbuCG1VHbJmIcy)\n  - [UIUC CS 420 / ECE 492 / CSE 402 Introduction to Parallel Programming for Scientists and Engineers fall 2015, by Sanjay Kale](https://www.youtube.com/playlist?list=PL682UO4IMem9cAjfy_RPjAc6k-HPYpTa9)\n  - [Stanford CME 213 Introduction to Parallel Computing using MPI, openMP, and CUDA winter 2020, by Eric Darve](https://www.youtube.com/playlist?list=PLAtMgFDMfGy2mysjPHN_d1cf9sR1muRkq)\n- #### **Mobile Application Development**\n  - [MOOC Programming Mobile Applications for Android Handheld Systems - University of Maryland](https://www.youtube.com/playlist?list=PLkHsKoi6eZnwilGXUc95CqS7Vw4uLLDLG)\n  - [CS 193p - Developing Applications for iOS, Stanford University](https://cs193p.sites.stanford.edu/)\n  - [CS S-76 Building Mobile Applications - Harvard](http://cs76.tv/2013/summer/)\n  - [CS 251 (2015): Intermediate Software Design](https://www.youtube.com/playlist?list=PLZ9NgFYEMxp7lylj-XC8h1kjatOjbh9ne)\n  - [Android App Development for Beginners Playlist - thenewboston](https://www.youtube.com/playlist?list=PL6gx4Cwl9DGBsvRxJJOzG4r4k_zLKrnxl)\n  - [Android Application Development Tutorials - thenewboston](https://www.youtube.com/playlist?list=PL2F07DBCDCC01493A)\n  - [MOOC - Developing Android Apps - Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPnMwH5-FNkErnnq_aSy706S)\n  - [MOOC - Advanced Android App Development - Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPmETCT07vnDSiIaUBuyut0X)\n  - [CSSE490 Android Development Rose-Hulman Winter 2010-2011, Dave Fisher](https://www.youtube.com/playlist?list=PLF3EEB647F6B52F03)\n  - [iOS Course, Dave Fisher](https://www.youtube.com/playlist?list=PL96C635E4DCD393A8)\n  - [Developing iPad Applications for Visualization and Insight - Carnegie Mellon University](https://itunes.apple.com/us/course/developing-ipad-applications/id499050344)\n  - [Mobile Computing - IIT Madras](https://nptel.ac.in/courses/106106147/)\n  - [Mobile Information Systems - Bauhaus-Uni Weimar](https://www.youtube.com/watch?v=8EmbrZJwMOI&list=PLjEglKdMOevWv4zPW0diw7iJFdT7s4sTP)\n\n------------------------------\n\n### Artificial Intelligence\n\n- [CS50 - Introduction to Artificial Intelligence with Python (and Machine Learning), Harvard OCW](https://cs50.harvard.edu/ai/2023/)\n- [CS 188 - Introduction to Artificial Intelligence, UC Berkeley - Spring 2025, by John Canny, Oliver Grillmeyer](https://inst.eecs.berkeley.edu/~cs188/sp25/) ([Spring 2024](https://inst.eecs.berkeley.edu/~cs188/sp24/)) ([Spring 2023](https://www.youtube.com/playlist?list=PLp8QV47qJEg7WWVg_5eOECzVPpy23UjJz))\n- [6.034 Artificial Intelligence, MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/)\n- [CS221: Artificial Intelligence: Principles and Techniques - Autumn 2019 - Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX)\n- [15-780 - Graduate Artificial Intelligence, Spring 14, CMU](http://www.cs.cmu.edu/~zkolter/course/15-780-s14/lectures.html)\n- [CSE 592 Applications of Artificial Intelligence, Winter 2003 - University of Washington](https://courses.cs.washington.edu/courses/csep573/03wi/lectures/index.htm)\n- [CS322 - Introduction to Artificial Intelligence, Winter 2012-13 - UBC](http://www.cs.ubc.ca/~mack/CS322/) ([YouTube](https://www.youtube.com/playlist?list=PLDPnGbm0sUmpzvcGvktbz446SLdFbfZVU))\n- [CS 4804: Introduction to Artificial Intelligence, Fall 2016](https://www.youtube.com/playlist?list=PLUenpfvlyoa1iiSbGy9BBewgiXjzxVgBd)\n- [CS 5804: Introduction to Artificial Intelligence, Spring 2015](https://www.youtube.com/playlist?list=PLUenpfvlyoa0PB6_kqJ9WU7m6i6z1RhfJ)\n- [Artificial Intelligence, Fall 2023 - FAU](https://www.fau.tv/course/id/3595) ([Spring 2023](https://www.fau.tv/course/id/3386)) ([Fall 2022](https://www.fau.tv/course/id/3180)) ([Spring 2021](https://www.fau.tv/course/id/2095)) ([Fall 2020](https://www.fau.tv/course/id/1690)) ([Fall 2018](https://www.fau.tv/course/id/713)) ([Spring 2018](https://www.fau.tv/course/id/657))\n- [Artificial Intelligence - IIT Kharagpur](https://nptel.ac.in/courses/106105077/)\n- [Artificial Intelligence - IIT Madras](https://nptel.ac.in/courses/106106126/)\n- [Artificial Intelligence(Prof.P.Dasgupta) - IIT Kharagpur](https://nptel.ac.in/courses/106105079/)\n- [MOOC - Intro to Artificial Intelligence - Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPlqMkzr4xyuD6cXTIgPuzgn)\n- [MOOC - Artificial Intelligence for Robotics - Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkCSYXw6-a_aAoXVKLDwnHK)\n- [Graduate Course in Artificial Intelligence, Autumn 2012 - University of Washington](https://www.youtube.com/playlist?list=PLbQ3Aya0VERDoDdbMogU9EASJGWris9qG)\n- [Agent-Based Systems 2015/16- University of Edinburgh](http://groups.inf.ed.ac.uk/vision/VIDEO/2015/abs.htm)\n- [Informatics 2D - Reasoning and Agents 2014/15- University of Edinburgh](http://groups.inf.ed.ac.uk/vision/VIDEO/2014/inf2d.htm)\n- [Artificial Intelligence - Hochschule Ravensburg-Weingarten](https://www.youtube.com/playlist?list=PL39B5D3AFC249556A)\n- [Deductive Databases and Knowledge-Based Systems - Technische Universit√§t Braunschweig, Germany](http://www.ifis.cs.tu-bs.de/teaching/ws-1516/KBS)\n- [Artificial Intelligence: Knowledge Representation and Reasoning - IIT Madras](https://nptel.ac.in/courses/106106140/)\n- [Semantic Web Technologies by Dr. Harald Sack - HPI](https://www.youtube.com/playlist?list=PLoOmvuyo5UAeihlKcWpzVzB51rr014TwD)\n- [Knowledge Engineering with Semantic Web Technologies by Dr. Harald Sack - HPI](https://www.youtube.com/playlist?list=PLoOmvuyo5UAcBXlhTti7kzetSsi1PpJGR)\n- [T81-558: Applications of Deep Neural Networks by Jeff Heaton, 2022, Washington University in St. Louis](https://sites.wustl.edu/jeffheaton/t81-558/)\n- [MSU programming for AI](https://www.youtube.com/playlist?list=PLZ-krWGO-UEz84TseDMIlx2Set6xZp0YP)\n\n------------------------------\n\n### Machine Learning\n\n- #### **Introduction to Machine Learning**\n  - [Introduction to Machine Learning for Coders](https://course18.fast.ai/ml)\n  - [MOOC - Statistical Learning, Stanford University](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n  - [Statistical Learning with Python - Stanford Online](https://www.youtube.com/playlist?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ)\n  - [Foundations of Machine Learning Boot Camp, Berkeley Simons Institute](https://www.youtube.com/playlist?list=PLgKuh-lKre11GbZWneln-VZDLHyejO7YD)\n  - [CS 155 - Machine Learning & Data Mining, 2023 - Caltech](https://www.youtube.com/playlist?list=PLu5yXJ11s4r-nBlojSQC9seeUF1IxX-_z) ([Notes-2020](http://www.yisongyue.com/courses/cs155/2020_winter/)) ([YouTube-2020](https://www.youtube.com/playlist?list=PLuz4CTPOUNi67hPzb9zJXH1cbeN7LKNiD)) ([Notes-2019](http://www.yisongyue.com/courses/cs155/2019_winter/)) ([YouTube-2019](https://www.youtube.com/playlist?list=PLuz4CTPOUNi7r2trKGgwaedY17MADTay4)) ([Notes-2018](http://www.yisongyue.com/courses/cs155/2018_winter/)) ([YouTube-2018](https://www.youtube.com/playlist?list=PLuz4CTPOUNi644ypoxzP1frkPYVHdjDJU)) ([Notes-2017](http://www.yisongyue.com/courses/cs155/2017_winter/)) ([YouTube-2017](https://www.youtube.com/playlist?list=PLuz4CTPOUNi6BfMrltePqMAHdl5W33-bC)) ([Notes-2016](http://www.yisongyue.com/courses/cs155/2016_winter/)) ([YouTube-2016](https://www.youtube.com/playlist?list=PL5HdMttxBY0BVTP9y7qQtzTgmcjQ3P0mb))\n  - [CS 156 - Learning from Data, Caltech](https://work.caltech.edu/lectures.html)\n  - [10-601 - Introduction to Machine Learning (MS) - Tom Mitchell - 2015, CMU](http://www.cs.cmu.edu/~ninamf/courses/601sp15/lectures.shtml) ([YouTube](https://www.youtube.com/playlist?list=PLAJ0alZrN8rD63LD0FkzKFiFgkOmEtltQ))\n  - [10-601 Machine Learning | CMU | Fall 2017](https://www.youtube.com/playlist?list=PL7k0r4t5c10-g7CWCnHfZOAxLaiNinChk)\n  - [10-701 - Introduction to Machine Learning (PhD) - Tom Mitchell, Spring 2011, CMU](http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml) ([Fall 2014](https://www.youtube.com/playlist?list=PL7y-1rk2cCsDZCVz2xS7LrExqidHpJM3B)) ([Spring 2015 by Alex Smola](https://www.youtube.com/playlist?list=PLZSO_6-bSqHTTV7w9u7grTXBHMH-mw3qn)) ([Fall 2020 by Ziv Bar-Joseph, Eric Xing](https://www.youtube.com/playlist?list=PLsWN0V-b507g7dbQTUvFkKZEqdHR5Fh4P))\n  - [10 - 301/601 - Introduction to Machine Learning - Fall 2023 - CMU](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22d5bf275d-ff88-4bf6-a865-b065010f55c2%22)\n  - [6.036 - Machine Learning, Broderick - MIT Fall 2020](https://www.youtube.com/playlist?list=PLxC_ffO4q_rW0bqQB80_vcQB09HOA3ClV)\n  - [Mediterranean Machine Learning summer school 2024](https://www.youtube.com/playlist?list=PLF-wkqRv4u1bV4Zd1UepYfyZXkv6Bz6ra) ([YouTube-2023](https://www.youtube.com/playlist?list=PLF-wkqRv4u1Y-Bret-wrcPypPCZ3Gg_3L)) ([YouTube-2022](https://www.youtube.com/playlist?list=PLF-wkqRv4u1agtfVaDsDUaMHmToP84Fk6)) ([YouTube-2021](https://www.youtube.com/playlist?list=PLF-wkqRv4u1YRbfnwN8cXXyrmXld-sked))\n  - [LxMLS Lisbon Machine Learning School 2024](https://www.youtube.com/playlist?list=PLQl_xdhSmQeh4eRfAwETbtJJLPKcDLrzw) ([YouTube-2023](https://www.youtube.com/playlist?list=PLQl_xdhSmQeikRCf-wJ8NCK51JOMHGOCP)) ([YouTube-2022](https://www.youtube.com/playlist?list=PLQl_xdhSmQejdxQL7qI5aJkLcAQJ68Abp)) ([YouTube-2021](https://www.youtube.com/playlist?list=PLQl_xdhSmQegzsLin54NbfePFAuTUEmUj)) ([YouTube-2020](https://www.youtube.com/playlist?list=PLQl_xdhSmQehE6aAk774yWMag4NNBGr5k))\n  - [Applied Machine Learning (Cornell Tech CS 5787, Fall 2020)](https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83)\n  - [Stanford CS229: Machine Learning Course | Summer 2019 (Anand Avati)](https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu_q2_bPuy0adh) ([Spring 2022](https://www.youtube.com/playlist?list=PLoROMvodv4rNyWOpJg_Yh4NSqI4Z4vOYy))\n  - [CMS 165 Foundations of Machine Learning - 2019 - Caltech](http://tensorlab.cms.caltech.edu/users/anima/cms165-2019.html) ([Youtube](https://www.youtube.com/playlist?list=PLVNifWxslHCA5GUh0o92neMiWiQiGVFqp))\n  - [CMS 165 Foundations of Machine Learning and Statistical Inference - 2020 - Caltech](https://www.youtube.com/playlist?list=PLVNifWxslHCDlbyitaLLYBOAEPbmF1AHg)\n  - [Microsoft Research - Machine Learning Course](https://www.youtube.com/playlist?list=PL34iyE0uXtxo7vPXGFkmm6KbgZQwjf9Kf)\n  - [CS 446 - Machine Learning, Fall 2016, UIUC](https://www.youtube.com/playlist?list=PLQcasX5-oG91TgY6A_gz-IW7YSpwdnD2O)\n  - [undergraduate machine learning at UBC 2012, Nando de Freitas](https://www.youtube.com/playlist?list=PLE6Wd9FR--Ecf_5nCbnSQMHqORpiChfJf)\n  - [CS 229 - Machine Learning - Stanford University](https://see.stanford.edu/Course/CS229) ([Autumn 2018](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU))\n  - [CS 189/289A Introduction to Machine Learning, Prof Jonathan Shewchuk - UCBerkeley](https://people.eecs.berkeley.edu/~jrs/189/)\n  - [CPSC 340: Machine Learning and Data Mining (2018) - UBC](https://www.youtube.com/playlist?list=PLWmXHcz_53Q02ZLeAxigki1JZFfCO6M-b)\n  - [CS391L Machine Learning, Spring 2025 - UT Austin](https://utcs-ml-course.github.io/main/Lectures/)\n  - [CS4780/5780 Machine Learning, Fall 2013 - Cornell University](http://www.cs.cornell.edu/courses/cs4780/2013fa/)\n  - [CS4780/5780 Machine Learning, Fall 2018 - Cornell University](http://www.cs.cornell.edu/courses/cs4780/2018fa/page18/index.html) ([Youtube](https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS))\n  - [CSE474/574 Introduction to Machine Learning - SUNY University at Buffalo](https://www.youtube.com/playlist?list=PLEQDy5tl3xkMzk_zlo2DPzXteCquHA8bQ)\n  - [CS 5350/6350 - Machine Learning, Spring 2024, University of Utah](https://svivek.com/teaching/machine-learning/spring2024/) ([Youtube](https://www.youtube.com/playlist?list=PLbuogVdPnkCr-ANNi5GZid3MvSkzm_wnM))\n  - [ECE 4252/8803 Fundamentals of Machine Learning (FunML), Spring 2024 - Georgia Tech](https://alregib.ece.gatech.edu/georgia-tech-courses/funml/)\n  - [ECE 5984 Introduction to Machine Learning, Spring 2015 - Virginia Tech](https://filebox.ece.vt.edu/~s15ece5984/)\n  - [CSx824/ECEx242 Machine Learning, Bert Huang, Fall 2015 - Virginia Tech](https://www.youtube.com/playlist?list=PLUenpfvlyoa0rMoE5nXA8kdctBKE9eSob)\n  - [STA 4273H - Large Scale Machine Learning, Winter 2015 - University of Toronto](http://www.cs.toronto.edu/~rsalakhu/STA4273_2015/lectures.html)\n  - [CSC 2515 Introduction to Machine Learning, Amir-massoud Farahmand, Fall 2021, University of Toronto](https://www.youtube.com/playlist?list=PLCveiXxL2xNZRg7PVp-JM4teSmaBETksy)\n  - [ECE 421 Introduction to Machine Learning, Amir Ashouri, Winter 2019, University of Toronto](https://www.youtube.com/playlist?list=PL-Mfq5QS-s8iS9XqKuApPE1TSlnZblFHF)\n  - [EECS 4404E/5327 Introduction to Machine Learning, Amir Ashouri, Fall 2019, York University](https://www.youtube.com/playlist?list=PL-Mfq5QS-s8horb94sQH4xcL85zDkpL9w)\n  - [CS 480/680 Introduction to Machine Learning, Gautam Kamath, University of Waterloo](http://www.gautamkamath.com/courses/CS480-sp2021.html) ([Spring 2021](https://www.youtube.com/playlist?list=PLmd_zeMNzSvSzRRc4Q29qEcpxbhdwjMOx))\n  - [CS 480/680 Introduction to Machine Learning, Kathryn Simone, University of Waterloo](https://github.com/kpc-simone/cs480-f24) ([Fall 2024](https://www.youtube.com/playlist?list=PLH84ETHrlsC8sbfb8WaOeXSx9ySH2Qoyc))\n  - [CS 485/685 Machine Learning, Shai Ben-David, University of Waterloo](https://www.youtube.com/channel/UCR4_akQ1HYMUcDszPQ6jh8Q/videos)\n  - [STAT 441/841 Classification Winter 2017 , Waterloo](https://www.youtube.com/playlist?list=PLehuLRPyt1HzXDemu7K4ETcF0Ld_B5adG)\n  - [10-605 - Machine Learning with Large Datasets, Fall 2016 - CMU](https://www.youtube.com/channel/UCIE4UdPoCJZMAZrTLuq-CPQ/videos)\n  - [Information Theory, Pattern Recognition, and Neural Networks - University of Cambridge](https://www.youtube.com/playlist?list=PLruBu5BI5n4aFpG32iMbdWoRVAA-Vcso6)\n  - [Pattern Analysis (2018) - FAU](https://www.fau.tv/course/id/655) ([Class 2017](https://www.fau.tv/course/id/544)) ([Class 2016](https://www.fau.tv/course/id/449)) ([Class 2015](https://www.fau.tv/course/id/355)) ([Class 2009](https://www.fau.tv/course/id/2))\n  - [Pattern Recognition (2020-2021) - FAU](https://www.fau.tv/course/id/1579) ([Class 2012-2013](https://www.fau.tv/course/id/173))\n  - [Beyond the Patterns (2020-2021) - FAU](https://www.fau.tv/course/id/1868)\n  - [Python and machine learning - Stanford Crowd Course Initiative](https://www.youtube.com/playlist?list=PLVxFQjPUB2cnYGZPAGG52OQc9SpWVKjjB)\n  - [MOOC - Machine Learning Part 1a - Udacity/Georgia Tech](https://www.youtube.com/playlist?list=PLAwxTw4SYaPl0N6-e1GvyLp5-MUMUjOKo) ([Part 1b](https://www.youtube.com/playlist?list=PLAwxTw4SYaPlkESDcHD-0oqVx5sAIgz7O) [Part 2](https://www.youtube.com/playlist?list=PLAwxTw4SYaPmaHhu-Lz3mhLSj-YH-JnG7) [Part 3](https://www.youtube.com/playlist?list=PLAwxTw4SYaPnidDwo9e2c7ixIsu_pdSNp))\n  - [Pattern Recognition Class (2012)- Universit√§t Heidelberg](https://www.youtube.com/playlist?list=PLuRaSnb3n4kRDZVU6wxPzGdx1CN12fn0w)\n  - [Introduction to Machine Learning and Pattern Recognition - CBCSL OSU](https://www.youtube.com/playlist?list=PLcXJymqaE9PPGGtFsTNoDWKl-VNVX5d6b)\n  - [Introduction to Machine Learning - IIT Kharagpur](https://nptel.ac.in/courses/106105152/)\n  - [Introduction to Machine Learning - IIT Madras](https://nptel.ac.in/courses/106106139/)\n  - [Pattern Recognition - IISC Bangalore](https://nptel.ac.in/courses/117108048/)\n  - [Pattern Recognition and Application - IIT Kharagpur](https://nptel.ac.in/courses/117105101/)\n  - [Pattern Recognition - IIT Madras](https://nptel.ac.in/courses/106106046/)\n  - [Machine Learning Summer School 2013 - Max Planck Institute for Intelligent Systems T√ºbingen](https://www.youtube.com/playlist?list=PLqJm7Rc5-EXFv6RXaPZzzlzo93Hl0v91E)\n  - [Machine Learning - Professor Kogan (Spring 2016) - Rutgers](https://www.youtube.com/playlist?list=PLauepKFT6DK_1_plY78bXMDj-bshv7UsQ)\n  - [CS273a: Introduction to Machine Learning](http://sli.ics.uci.edu/Classes/2015W-273a) ([YouTube](https://www.youtube.com/playlist?list=PLkWzaBlA7utJMRi89i9FAKMopL0h0LBMk))\n  - [Machine Learning Crash Course 2015](https://www.youtube.com/playlist?list=PLyGKBDfnk-iD5dK8N7UBUFVVDBBtznenR)\n  - [COM4509/COM6509 Machine Learning and Adaptive Intelligence 2015-16](http://inverseprobability.com/mlai2015/)\n  - [Introduction to Machine Learning - Spring 2018 - ETH Zurich](https://www.youtube.com/playlist?list=PLzn6LN6WhlN273tsqyfdrBUsA-o5nUESV)\n  - [Machine Learning - Pedro Domingos- University of Washington](https://www.youtube.com/user/UWCSE/playlists?view=50&sort=dd&shelf_id=16)\n  - [CSE 446/546 - Machine Learning, Spring 2020 - University of Washington](https://courses.cs.washington.edu/courses/cse446/20sp/schedule/) ([Videos](https://www.youtube.com/playlist?list=PLrE1feouzSWr7LBFAeRZIb7CN9H6dB9Jt))\n  - [Machine Learning (COMP09012)](https://www.youtube.com/playlist?list=PLyH-5mHPFffFwz7Twap0XuVeUJ8vuco9t)\n  - [Probabilistic Machine Learning 2020 - University of T√ºbingen](https://www.youtube.com/playlist?list=PL05umP7R6ij1tHaOFY96m5uX3J21a6yNd)\n  - [Statistical Machine Learning 2020 - Ulrike von Luxburg - University of T√ºbingen](https://www.youtube.com/playlist?list=PL05umP7R6ij2XCvrRzLokX6EoHWaGA2cC)\n  - [COMS W4995 - Applied Machine Learning - Spring 2020 - Columbia University](https://www.cs.columbia.edu/~amueller/comsw4995s20/schedule/)\n  - [Machine Learning for Engineers 2022](https://apmonitor.com/pds) ([YouTube](https://www.youtube.com/watch?v=Gh5rbBLh4JY&list=PLLBUgWXdTBDg1K1bu60lHypSzSP-WSBmx))\n  - [10-418 / 10-618 (Fall 2019) Machine Learning for Structured Data](https://www.youtube.com/playlist?list=PL4CxkUJbvNVihRKP4bXufvRLIWzeS-ieP)\n  - [ORIE 4741/5741: Learning with Big Messy Data - Cornell](https://people.orie.cornell.edu/mru8/orie4741/lectures.html)\n  - [Machine Learning in IoT](https://www.youtube.com/playlist?list=PLeZoXD_TLsLbW_ILvL9TlhBYdW8wJyON-)\n  - [Stanford CS229M: Machine Learning Theory - Fall 2021](https://www.youtube.com/playlist?list=PLoROMvodv4rP8nAmISxFINlGKSK4rbLKh)\n  - [Intro to Machine Learning and Statistical Pattern Classification - Prof Sebastian Raschka](https://www.youtube.com/playlist?list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3)\n  - [CMU's Multimodal Machine Learning course (11-777), Fall 2020](https://www.youtube.com/playlist?list=PL-Fhd_vrvisNup9YQs_TdLW7DQz-lda0G)\n  - [EE104: Introduction to Machine Learning - Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rN_Uy7_wmS051_q1d6akXmK)\n  - [CPSC 330: Applied Machine Learning (2020) - UBC](https://www.youtube.com/playlist?list=PLWmXHcz_53Q2BXsWviGgEqdlSHmfsjSzC)\n  - [Machine Learning 2013 - Nando de Freitas, UBC](https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6)\n  - [Machine Learning, 2014-2015, University of Oxford](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)\n  - [10-702/36-702 - Statistical Machine Learning - Larry Wasserman, Spring 2016, CMU](https://www.stat.cmu.edu/~ryantibs/statml/) ([Spring 2015](https://www.youtube.com/playlist?list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r))\n  - [10-715 Advanced Introduction to Machine Learning - CMU](http://www.cs.cmu.edu/~bapoczos/Classes/ML10715_2015Fall/) ([YouTube](https://www.youtube.com/playlist?list=PL4DwY1suLMkcu-wytRDbvBNmx57CdQ2pJ))\n  - [CS 281B - Scalable Machine Learning, Alex Smola, UC Berkeley](http://alex.smola.org/teaching/berkeley2012/syllabus.html)\n  - [100 Days of Machine Learning - CampusX (Hindi)](https://www.youtube.com/playlist?list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH)\n  - [CampusX Data Science Mentorship Program 2022-23 (Hindi)](https://www.youtube.com/playlist?list=PLKnIA16_RmvbAlyx4_rdtR66B7EHX5k3z)\n  - [Statistical Machine Learning - S2023 - Benyamin Ghojogh](https://www.youtube.com/playlist?list=PLPrxGIUWsqP2g7cpk0nFFt0c4aRcREq2s)\n  - [MIT 6.5940 EfficientML.ai Lecture, Fall 2023](https://www.youtube.com/playlist?list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB)\n  - [TinyML - Tiny Machine Learning at UPenn](https://www.youtube.com/playlist?list=PL7rtKJAz_mPe6kAbiH6Ucq02Vpa95qvBJ)\n  - [ECE 4760 (Digital Systems Design Using Microcontrollers) at Cornell for the Fall, 2022](https://www.youtube.com/playlist?list=PLDqMkB5cbBA5oDg8VXM110GKc-CmvUqEZ) ([Spring 2021](https://www.youtube.com/playlist?list=PLDqMkB5cbBA6FEJuj94gl-9vw8xcHu9Gp))\n  - [EfficientML.ai Lecture, Fall 2023, MIT 6.5940](https://www.youtube.com/playlist?list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB)\n  - [SFU CMPT 727 Statistical Machine Learning, by Maxwell Libbrecht](https://coursys.sfu.ca/2023sp-cmpt-727-g1/pages/) ([Spring 2023](https://www.youtube.com/playlist?list=PL_5SuHtr8fsrK9NqWWSL4YL8urMAHLsvU)) ([Spring 2022](https://www.youtube.com/playlist?list=PL_5SuHtr8fsp95AhIKeTHbpcVdhlhB9h6))\n  - [UC Berkeley CS 189 / 289A Introduction to Machine Learning fall 2023, by Jennifer Listgarten & Jitendra Malik](https://eecs189.org/)\n  - [UC Berkeley CS 189 Introduction to Machine Learning (CDSS offering) spring 2022, by Marvin Zhang](https://www.youtube.com/playlist?list=PLCuQm2FL98HTlRmlwMk2AuFEM9n1c06HE)\n  - [UC San Diego/edX DSE 220X Machine Learning Fundamentals, by Sanjoy Dasgupta](https://www.youtube.com/playlist?list=PLUPLKa8g2P75vrLVe6HKdgAwfuU89RfqB)\n  - [MIT 6.036 Introduction to Machine Learning spring 2019, by Leslie Kaelbling](https://www.youtube.com/playlist?list=PLQEw29vp6f1Ae9dp8vkKB8H6sF1PHvP5N)\n  - [LMU Munich Introduction to Machine Learning](https://slds-lmu.github.io/i2ml/)\n  - [CMU 15 388 / 15 688 Practical Data Science, by Zico Kolter](https://www.datasciencecourse.org/lectures/) ([Fall 2019](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22618ea253-ca45-4b14-9f1d-aab501543bd2%22)) ([Spring 2018](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22912b80a3-625d-405d-8905-a8620133666b%22))\n  - [UW Madison CS 320 Data Programming II spring 2021, by Tyler R. Caraza-Harter](https://tyler.caraza-harter.com/cs320/s21/schedule.html)\n  - [UC San Diego COGS9 Introduction to Data Science fall 2020, by Jason Fleischer](https://www.youtube.com/playlist?list=PLaaNbhBDEsoFarUB58v9s7pUVoyAahMeQ)\n  - [UCLA Stats 15 Introduction to Data Science fall 2022, by Miles Chen](https://www.youtube.com/playlist?list=PLIygTcviGPKCEzYDpJha6hP6ne-50sT1o)\n  - [UCLA Stats 21 Python and Other Technologies for Data Science spring 2024, by Miles Chen](https://www.youtube.com/playlist?list=PLIygTcviGPKAdsiprcbdk5HHPxS6PloWE) ([Spring 2021](https://www.youtube.com/playlist?list=PLKR7271tMEmgBPgu4LtjDhX3ywpTxda5g))\n  - [UCLA Stats C161/C261 Introduction to Pattern Recognition and Machine Learning winter 2024, by Arash Amini](https://www.youtube.com/playlist?list=PLN_qg0-2-0SxQ2vlXxlZVMKkt4gI1YYP8) ([Winter 2023](https://www.youtube.com/playlist?list=PLN_qg0-2-0SwLCXGUyM3FNSRwG6GNgONr))\n  - [UCLA Stats 231C Theories of Machine Learning spring 2022, by Arash Amini](https://www.youtube.com/playlist?list=PLN_qg0-2-0SxKyZLv_FotPDED5ET_rQmo)\n  - [MSU Machine Learning](https://www.youtube.com/watch?v=kMf0qDtQ_PM&list=PLZ-krWGO-UEyPHsZfOjYH03_TyIN2pPhl&pp=iAQB)\n  - [Data Science for Dynamical Systems, by Oliver Wallscheid & Sebastian Peitz](https://github.com/DS-4-DS/DS4DS_Course) ([YouTube](https://www.youtube.com/@DataScience4DynamicalSystems/playlists))\n  - [Cambridge Statistical Learning in Practice 2021, by Alberto J. Coca](https://www.youtube.com/playlist?list=PLn1JSlh3WT_b7sMBktkAgV9-cP052JFhb)\n  - [Data 8: The Foundations of Data Science - UC Berkeley](http://data8.org/) ([Spring 23](https://www.data8.org/sp23/)) ([Fall 22](https://www.data8.org/fa22/)) ([Spring 22](https://www.data8.org/sp22/)) ([Summer 17](http://data8.org/su17/))\n  - [Data 144: Foundations of Data Science spring 2021 - Vassar College](https://www.youtube.com/playlist?list=PLIygTcviGPKB9hHuywn56TraSMv2pRumr) ([Course materials](https://github.com/jwaterman/data144-materials-sp21))\n  - [CSE519 - Data Science Fall 2016 - Skiena, SBU](https://www.youtube.com/playlist?list=PLOtl7M3yp-DVBdLYatrltDJr56AKZ1qXo)\n  - [CS 109 Data Science, Harvard University](http://cs109.github.io/2015/pages/videos.html) ([YouTube](https://www.youtube.com/playlist?list=PLb4G5axmLqiuneCqlJD2bYFkBwHuOzKus))\n  - [6.0002 Introduction to Computational Thinking and Data Science - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/lecture-videos/)\n  - [Data 100: Principles and Techniques of Data Science - UC Berkeley](https://ds100.org/fa24/) ([Fall 24](https://www.youtube.com/playlist?list=PLIygTcviGPKBzDKR72ILypzPQZ_Cz6HcH)) ([Spring 24](https://ds100.org/sp24/)) ([Summer 19](https://www.youtube.com/playlist?list=PLPHXc20GewP8J56CisONS_mFZWZAfa7jR))\n  - [Data 102 - Spring 21- UC Berkeley](https://data102.org/sp21/#lecture-week-14) ([YouTube](https://www.youtube.com/playlist?list=PLIygTcviGPKAEbY32OXjmkQbD0uRhge9Y))\n  - [Distributed Data Analytics (WT 2017/18) - HPI University of Potsdam](https://www.tele-task.de/series/1179/)\n  - [Data Profiling and Data Cleansing (WS 2014/15) - HPI University of Potsdam](https://www.tele-task.de/series/1027/)\n  - [CS 229r - Algorithms for Big Data, Harvard University](http://people.seas.harvard.edu/~minilek/cs229r/fall15/lec.html) ([Youtube](https://www.youtube.com/playlist?list=PL2SOU6wwxB0v1kQTpqpuu5kEJo2i-iUyf))\n  - [Algorithms for Big Data - IIT Madras](https://nptel.ac.in/courses/106106142/)\n  - [Python Data Science with the TCLab](https://github.com/APMonitor/data_science) ([YouTube](https://www.youtube.com/watch?v=pAgW_bZVo88&list=PLLBUgWXdTBDg1Qgmwt4jKtVn9BWh5-zgy))\n  - [Foundations of Data Analysis (Fall 2020)- University of Utah](https://www.youtube.com/playlist?list=PLbuogVdPnkCqB1sx1eheVmLtp2EN7osYt)\n\n  \n- #### **Data Mining**\n  - [CSEP 546, Data Mining - Pedro Domingos, Sp 2016 - University of Washington](https://courses.cs.washington.edu/courses/csep546/16sp/) ([YouTube](https://www.youtube.com/playlist?list=PLTPQEx-31JXgtDaC6-3HxWcp7fq4N8YGr))\n  - [CS 5140/6140 - Data Mining, Spring 2020, University of Utah by Prof. Jeff Phillips](https://users.cs.utah.edu/~jeffp/teaching/cs5140-S20/cs5140.html) ([Youtube](https://www.youtube.com/playlist?list=PLbuogVdPnkCrEf65zrd3J1UG3LT6TcDlt))\n  - [CS 5140/6140 - Data Mining, Spring 2023, University of Utah by Prof. Ana Marasoviƒá](https://utah-data-mining-spring23.github.io/) ([Youtube](https://www.youtube.com/playlist?list=PLbuogVdPnkCrnLNqZPnTuG_s19TNDoad0))\n  - [CS 5955/6955 - Data Mining, University of Utah](http://www.cs.utah.edu/~jeffp/teaching/cs5955.html) ([YouTube](https://www.youtube.com/channel/UCcrlwW88yMcXujhGjSP2WBg/videos))\n  - [Statistics 202 - Statistical Aspects of Data Mining, Summer 2007 - Google](http://www.stats202.com/original_index.html) ([YouTube](https://www.youtube.com/playlist?list=PLFE776F2C513A744E))\n  - [MOOC - Text Mining and Analytics by ChengXiang Zhai](https://www.youtube.com/playlist?list=PLLssT5z_DsK8Xwnh_0bjN4KNT81bekvtt)\n  - [Information Retrieval SS 2014, iTunes - HPI](https://itunes.apple.com/us/itunes-u/information-retrieval-ss-2014/id874200291)\n  - [MOOC - Data Mining with Weka](https://www.youtube.com/playlist?list=PLm4W7_iX_v4NqPUjceOGd-OKNVO4c_cPD)\n  - [CS 290 DataMining Lectures](https://www.youtube.com/playlist?list=PLB4CCA346A5741C4C)\n  - [CS246 - Mining Massive Data Sets, Winter 2016, Stanford University](https://web.stanford.edu/class/cs246/) ([YouTube](https://www.youtube.com/channel/UC_Oao2FYkLAUlUVkBfze4jg/videos))\n  - [Information Retrieval - Spring 2018 - ETH Zurich](https://www.youtube.com/playlist?list=PLzn6LN6WhlN1ktkDvNurPSDwTQ_oGQisn)\n  - [Information Retrieval - WS 2022/23 - Universit√§t Freiburg](https://ad-wiki.informatik.uni-freiburg.de/teaching/InformationRetrievalWS2223)\n  - [CAP6673 - Data Mining and Machine Learning - FAU](http://www.cse.fau.edu/~taghi/classes/cap6673/)([Video lectures](https://vimeo.com/album/1505953))\n  - [CS 412 - Introduction to Data Mining - UIUC](https://www.youtube.com/playlist?list=PLIygTcviGPKDZi44-yuH2XH9UaHdaJkxs)\n  - [CS 512 - Data Mining Principles - UIUC](https://github.com/spacemanidol/CS512DM/tree/main/lectures) ([YouTube](https://www.youtube.com/playlist?list=PLIygTcviGPKABUzEm9v1PuKLlb0AQ9tdH))\n  \n- #### **Probabilistic Graphical Modeling**\n  - [CS 6190 - Probabilistic Modeling, Spring 2016, University of Utah](https://www.youtube.com/playlist?list=PLbuogVdPnkCpvxdF-Gy3gwaBObx7AnQut)\n  - [10-708 - Probabilistic Graphical Models, Carnegie Mellon University](https://www.cs.cmu.edu/~epxing/Class/10708-20/lectures.html)\n  - [Probabilistic Graphical Models, Daphne Koller, Stanford University](http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=ProbabilisticGraphicalModels)\n  - [Probabilistic Graphical Models, Spring 2018 - Notre Dame](https://www.youtube.com/playlist?list=PLd-PuDzW85AcV4bgdu7wHPL37hm60W4RM)\n  \n- #### **Deep Learning**\n  - [Full Stack Deep Learning - Course 2022](https://www.youtube.com/watch?v=-Iob-FW5jVM&list=PL1T8fO7ArWleMMI8KPJ_5D5XSlovTW_Ur)\n  - [Full Stack Deep Learning - Course 2021](https://www.youtube.com/watch?v=fGxWfEuUu0w&list=PL1T8fO7ArWlcWg04OgNiJy91PywMKT2lv)\n  - [NYU Deep Learning Spring 2020](https://www.youtube.com/playlist?list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq)\n  - [NYU Deep Learning Spring 2021](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI)\n  - [6.S191: Introduction to Deep Learning - MIT](http://introtodeeplearning.com/)\n  - [Intro to Deep Learning and Generative Models Course - Prof Sebastian Raschka](https://www.youtube.com/playlist?list=PLTKMiZHVd_2KJtIXOW0zFhFfBaJJilH51)\n  - [Deep Learning CMU](https://www.youtube.com/channel/UC8hYZGEkI2dDO8scT8C5UQA/videos)\n  - [CS231n Deep Learning for Computer Vision - Stanford University](https://cs231n.stanford.edu/schedule.html) ([Spring 2025](https://www.youtube.com/playlist?list=PLoROMvodv4rOmsNzYBMe0gJY2XS8AQg16)) ([Winter 2016 Andrej Karpathy](https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC))\n  - [Deep Learning: CS 182 Spring 2021](https://www.youtube.com/playlist?list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A)\n  - [10-414/714: Deep Learning Systems - CMU](https://dlsyscourse.org/lectures/) ([Youtube](https://www.youtube.com/@deeplearningsystemscourse1116/videos))\n  - [11-785: Introduction to Deep Learning - CMU](https://deeplearning.cs.cmu.edu/S24/index.html) ([Lectures - YouTube-2024](https://www.youtube.com/playlist?list=PLp-0K3kfddPxUJzAW0KxNNjGiK_hISFas), [Recitations - YouTube-2024](https://www.youtube.com/playlist?list=PLp-0K3kfddPzNnco9QQAoTx_sVhZgHK-n))\n  - [Part 1: Practical Deep Learning for Coders, v3 - fast.ai](https://course.fast.ai/)\n  - [Part 2: Deep Learning from the Foundations - fast.ai](https://course19.fast.ai/part2)\n  - [Deep learning at Oxford 2015 - Nando de Freitas](https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu)\n  - [Self-Driving Cars ‚Äî Andreas Geiger, 2021/22](https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/lectures/self-driving-cars/) ([YouTube](https://www.youtube.com/watch?v=wAaSJUAKPuY&list=PL05umP7R6ij321zzKXK6XCQXAaaYjQbzr))\n  - [6.S094: Deep Learning for Self-Driving Cars - MIT](https://www.youtube.com/playlist?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)\n  - [CS294-129 Designing, Visualizing and Understanding Deep Neural Networks](https://bcourses.berkeley.edu/courses/1453965/pages/cs294-129-designing-visualizing-and-understanding-deep-neural-networks) ([YouTube](https://www.youtube.com/playlist?list=PLkFD6_40KJIxopmdJF_CLNqG3QuDFHQUm))\n  - [CS230: Deep Learning - Autumn 2018 - Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb)\n  - [STAT-157 Deep Learning 2019 - UC Berkeley](https://www.youtube.com/playlist?list=PLZSO_6-bSqHQHBCoGaObUljoXAyyqhpFW)\n  - [Deep Learning, Stanford University](http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=DeepLearning)\n  - [MOOC - Neural Networks for Machine Learning, Geoffrey Hinton 2016 - Coursera](https://www.youtube.com/playlist?list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9)\n  - [Stat 946 Deep Learning - University of Waterloo](https://www.youtube.com/playlist?list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE)\n  - [EECS 298 Theory of Computational Neural Networks and Machine Learning (Fall 2020) - UC Irvine](https://grandcentral.eee.uci.edu/syllabus/download/F-2020/17815) ([YouTube](https://www.youtube.com/playlist?list=PLIygTcviGPKBAh1HWXPOI3Rw59WdRlJXu))\n  - [ECE 1508 Applied Deep Learning - University of Toronto](https://www.bereyhi.com/deep-learning) ([Winter 2025](https://www.youtube.com/playlist?list=PLcFgNUo9s_AgsMOnniTMIWmLpjj9vZ1Wm)) ([Fall 2024](https://www.youtube.com/playlist?list=PLcFgNUo9s_Ajz1l4rBDIApwdcEKgzoMko))\n  - [Neural networks class - Universit√© de Sherbrooke](http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html) ([YouTube](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH))\n  - [DLCV - Deep Learning for Computer Vision - UPC Barcelona](https://www.youtube.com/playlist?list=PL-5eMc3HQTBavDoZpFcX-bff5WgQqSLzR)\n  - [DLAI - Deep Learning for Artificial Intelligence @ UPC Barcelona](https://www.youtube.com/playlist?list=PL-5eMc3HQTBagIUjKefjcTbnXC0wXC_vd)\n  - [Neural Networks and Applications - IIT Kharagpur](https://nptel.ac.in/courses/117105084/)\n  - [UVA DEEP LEARNING COURSE](http://uvadlc.github.io/#lecture)\n  - [Deep Learning - Winter 2020-21 - T√ºbingen Machine Learning](https://www.youtube.com/playlist?list=PL05umP7R6ij3NTWIdtMbfvX7Z-4WEXRqD)\n  - [Geometric Deep Learning - AMMI](https://www.youtube.com/playlist?list=PLn2-dEmQeTfQ8YVuHBOvAhUlnIPYxkeu3)\n  - [Math for Deep Learning ‚Äî Andreas Geiger](https://www.youtube.com/playlist?list=PL05umP7R6ij0bo4UtMdzEJ6TiLOqj4ZCm)\n  - [Applied Deep Learning 2022 - TU Wien](https://www.youtube.com/playlist?list=PLNsFwZQ_pkE_QaTwYxoTmmRJHtMXyIAU6)\n  - [Neural Networks: Zero to Hero - Andrej Karpathy](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)\n  - [CIS 522 - Deep Learning - U Penn](https://www.youtube.com/@cis522-deeplearning8/playlists)\n  - [UVA DEEP LEARNING COURSE](http://uvadlc.github.io/#lecture)\n  - [Deep Learning (Fall 2020) - FAU](https://www.fau.tv/course/id/1600) ([Spring 2020](https://www.fau.tv/course/id/925)) ([Fall 2019](https://www.fau.tv/course/id/849)) ([Spring 2019](https://www.fau.tv/course/id/758)) ([Fall 2018](https://www.fau.tv/course/id/701)) ([Spring 2018](https://www.fau.tv/course/id/662))\n  - [Deep Learning (Fall 2020) - Georgia Tech](https://www.youtube.com/playlist?list=PL-fZD610i7yB7gDnPDpFcKpHI9X8z3OQ7)\n  - [Mathematics of Deep Learning (2021) - FAU](https://www.fau.tv/course/id/878)\n  - [CS7015 - Deep Learning - Prof. Mitesh M. Khapra - IIT Madras](https://www.youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk_JKGBAYT)\n  - [ETH Z√ºrich | Deep Learning in Scientific Computing 2023](https://www.youtube.com/playlist?list=PLJkYEExhe7rYY5HjpIJbgo-tDZ3bIAqAm)\n  - [Applied Deep Learning Maziar Raissi](https://www.youtube.com/playlist?list=PLoEMreTa9CNmuxQeIKWaz7AVFd_ZeAcy4)\n  - [UC Berkeley CS 182 / 282a Deep Learning spring 2023, by Anant Sahai](https://www.youtube.com/playlist?list=PLIygTcviGPKAaj_UAJcazYN4964xZ7Lt1)\n  - [Foundations of Deep Learning - UMD](https://www.youtube.com/playlist?list=PLHgjs9ncvHi80UCSlSvQe-TK_uOyDv_Jf)\n  - [TUM IN2346 Introduction to Deep Learning Fall 2024, by Daniel Cremers](https://cvg.cit.tum.de/teaching/ws2024/i2dl) ([Summer 2023](https://www.youtube.com/playlist?list=PLQ8Y4kIIbzy_pGm2QAwF625E6nmcRu2sU))\n  - [UT Austin - Advances in Deep Learning](https://ut.philkr.net/advances_in_deeplearning/)\n  \n- #### **Reinforcement Learning**\n  - [CS234: Reinforcement Learning - Spring 2024 - Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rN4wG6Nk6sNpTEbuOSosZdX) ([Winter 2019](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u))\n  - [CSE 542: Reinforcement Learning - Spring 2024 - University of Washington](https://courses.cs.washington.edu/courses/cse542/24sp/schedule/)\n  - [CSE 579: Reinforcement Learning - Autumn 2024 - University of Washington](https://courses.cs.washington.edu/courses/cse579/24au/schedule/)\n  - [CSC 2547: Introduction to Reinforcement Learning - Spring 2021 - University of Toronto](https://amfarahmand.github.io/IntroRL/) ([YouTube](https://www.youtube.com/playlist?list=PLCveiXxL2xNbiDq51a8iJwPRq2aO0ykrq))\n  - [Introduction to reinforcement learning - UCL](https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ)\n  - [Reinforcement Learning - IIT Madras](https://www.youtube.com/playlist?list=PLyqSpQzTE6M_FwzHFAyf4LSkz_IjMyjD9) ([TA - Manav Mishra](https://www.youtube.com/playlist?list=PLpKrAXMumEsjAR1Ybb0qbTKGYd9RY0vxa), [TA - Prabhleen Kukreja](https://www.youtube.com/playlist?list=PLTt_oMmEiDJhBPjy_aedcoeIY-IsaDBOn), [TA - Sandarbh Yadav ](https://www.youtube.com/playlist?list=PLoo_WPzXEM1ShdfOxv-adi3JdhRX4rA7F), [TA - Avik Kar](https://www.youtube.com/playlist?list=PLz2x4RAIbeXkTJFEipkD_ds3z0qx8_5D7))\n  - [Special topics in ML (Reinforcement Learning) IIT madras](https://www.youtube.com/playlist?list=PLZ2ps__7DhBbDiVplM2I9q2XNso1Qfj62)\n  - [CS885 Reinforcement Learning - Spring 2018 - University of Waterloo](https://www.youtube.com/playlist?list=PLdAoL1zKcqTXFJniO3Tqqn6xMBBL07EDc)\n  - [CS 285 - Deep Reinforcement Learning- UC Berkeley](https://www.youtube.com/playlist?list=PLkFD6_40KJIwhWJpGazJ9VSj9CFMkb79A)\n  - [CS 294 112 - Reinforcement Learning](https://www.youtube.com/playlist?list=PLkFD6_40KJIxJMR-j5A1mkxK26gh_qg37)\n  - [NUS CS 6101 - Deep Reinforcement Learning](https://www.youtube.com/playlist?list=PLllwxvcS7ca5wOmRLKm6ri-OaC0INYehv)\n  - [ECE 8851: Reinforcement Learning](https://www.youtube.com/playlist?list=PL_Nk3YvgORJs1tCLQnlnSRsOJArj_cP9u)\n  - [CS294-112, Deep Reinforcement Learning Sp17](http://rll.berkeley.edu/deeprlcourse/) ([YouTube](https://www.youtube.com/playlist?list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX))\n  - [UCL Course 2015 on Reinforcement Learning by David Silver from DeepMind](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html) ([YouTube](https://www.youtube.com/watch?v=2pWv7GOvuf0))\n  - [Deep RL Bootcamp - Berkeley Aug 2017](https://sites.google.com/view/deep-rl-bootcamp/lectures)\n  - [Reinforcement Learning - IIT Madras](https://www.youtube.com/playlist?list=PLyqSpQzTE6M_FwzHFAyf4LSkz_IjMyjD9)\n  - [Reinforcement Learning Course at KTH (FDD3359 - 2022)](https://www.youtube.com/playlist?list=PL21JFJEtbq0JLNo53UIkbIwkc2njCVUUR)\n  - [Reinforcement Learning Course at ASU, Spring 2022](https://www.youtube.com/playlist?list=PLmH30BG15SIoXhxLldoio0BhsIY84YMDj)\n  - [CS 4789/5789: Introduction to Reinforcement Learning - Cornell](https://www.youtube.com/playlist?list=PLQVNhPb8ajtCjWSKUvKU8cX5lueYP9s3X)\n  - [S20/IE613 - Online (Machine) Learning/ Bandit Algorithms](https://www.youtube.com/playlist?list=PLDREIwGwrHBdiBm1q0cVJLZn4Cn6Hig2s)\n  - [Reinforcement Learning - Fall 2021 chandar-lab](https://www.youtube.com/playlist?list=PLImtCgowF_ES_JdF_UcM60EXTcGZg67Ua)\n  - [CMU 10 703 Deep Reinforcement Learning & Control fall 2022, by Katerina Fragkiadaki](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22ee5794a2-cb54-4edc-836b-aefc01023243%22)\n  - [ECE524 Foundations of Reinforcement Learning at Princeton University, Spring 2024](https://www.youtube.com/playlist?list=PLYXvCE1En13epbogBmgafC_Yyyk9oQogl)\n  - [REINFORCEMENT LEARNING AND OPTIMAL CONTROL - Dimitri P. Bertsekas, ASU](https://web.mit.edu/dimitrib/www/RLbook.html)\n  - [CMU 16 745 Optimal Control and Reinforcement Learning spring by Zac Manchester](https://www.youtube.com/@roboticexplorationlab3724/playlists)\n  - [CMU 16 899 Adaptive Control and Reinforcement Learning fall 2020, by  Changliu Liu](https://www.youtube.com/playlist?list=PLZL5VXraKdz-0zByoPNzNTqSirR4veU8z)\n  - [Jadavpur University, 2025: Introduction to Reinforcement Learning](https://www.youtube.com/playlist?list=PLcNLn_ApooUzGJW60RcD2HRrL7sm0HG-w)\n  - [EE675 (2024) Introduction to Reinforcement Learning Course | IIT Kanpur](https://www.youtube.com/playlist?list=PLZAmMLcSnKRICBNyjraAhQdtdJFFgyRL5)\n  - [Reinforcement Learning Course by Fr√©d√©ric Godin - Concordia University](https://www.youtube.com/playlist?list=PLFskzTP727yc5eXXm09Xst7bIk5fi7mD6)\n  - [CS 285: Deep RL, 2023](https://www.youtube.com/playlist?list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps)\n  - [Mathematical Foundations of Reinforcement Learning - WINDY Lab](https://www.youtube.com/playlist?list=PLEhdbSEZZbDaFWPX4gehhwB9vJZJ1DNm8)\n  - [Reinforcement Learning (HMC CS 181V)‚ÄîSpring, 2020 - Neil Rhodes](https://www.youtube.com/playlist?list=PL2Yggtk_pK69evEzfwQHm9ASOCbXPlXPS)\n  - [Reinforcement Learning Course: Lectures (Summer 2023) by Paderborn University](https://www.youtube.com/playlist?list=PL4GzQQuIDBGv-IFxRSgydCR7OrOM_xKqN)\n  - [CS292F (Spring 2021) Statistical Foundation of Reinforcement Learning - UCSD](https://cseweb.ucsd.edu/~yuxiangw/classes/RLCourse-2021Spring/)\n  - [Algorithmic Foundations of Interactive Learning - CMU](https://interactive-learning-algos.github.io/)\n  \n- #### **Advanced Machine Learning**\n  - [Advanced Machine Learning, 2021-2022, Sem I - by Prof. Madhavan Mukund, CMI](https://www.cmi.ac.in/~madhavan/courses/aml2021)\n  - [18.409 Algorithmic Aspects of Machine Learning Spring 2015 - MIT](https://www.youtube.com/playlist?list=PLB3sDpSRdrOvI1hYXNsa6Lety7K8FhPpx)\n  - [CS 330 - Deep Multi-Task and Meta Learning - Fall 2019 - Stanford University](https://cs330.stanford.edu/) ([Youtube](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5))\n  - [Stanford CS330: Deep Multi-Task and Meta Learning I Autumn 2022](https://www.youtube.com/playlist?list=PLoROMvodv4rNjRoawgt72BBNwL2V7doGI)\n  - [ES 661 (2023): Probabilistic Machine Learning - IIT Gandhinagar](https://www.youtube.com/playlist?list=PLftoLyLEwECBEJyfRBJoSBd0UaTjEcs3I)\n  - [Information Retrieval in High Dimensional Data](https://www.youtube.com/playlist?list=PLaE1lKCe0jH3ePp9wCU1ygTquVOXY-UYv)\n  - [Trustworthy Machine Learning - Winter Semester 2023-2024, University of T√ºbingen](https://scalabletrustworthyai.github.io/courses/tml_winter_2324/)\n  - [Trustworthy Machine Learning - Winter Semester 2024-2025, University of T√ºbingen](https://scalabletrustworthyai.github.io/courses/tml_winter_2425/)\n  - [ETH Z√ºrich Advanced Machine Learning fall 2019, by Joachim M. Buhmann](https://video.ethz.ch/lectures/d-infk/2019/autumn/252-0535-00L.html)\n  - [CS 159 Advanced Topics in Machine Learning, Spring 2021 - Caltech](https://1five9.github.io/)\n  - [CS 229br Advanced Topics in the theory of machine learning, Spring 2021 - Harvard](https://boazbk.github.io/mltheoryseminar/cs229br.html)\n  \n  \n- #### **Natural Language Processing**\n  - [CS 224N -Natural Language Processing with Deep Learning - Stanford University](http://web.stanford.edu/class/cs224n/) ([Lectures -  Winter 2019](https://youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)) ([Lectures -  Winter 2021](https://youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ)) ([Lectures - Spring 2024](https://www.youtube.com/playlist?list=PLoROMvodv4rOaMFbaqxPDoLWjDaRAdP9D))\n  - [CS 224N - Natural Language Processing, Stanford University](https://web.stanford.edu/~jurafsky/NLPCourseraSlides.html) ([Lecture videos](https://academictorrents.com/details/d2c8f8f1651740520b7dfab23438d89bc8c0c0ab))\n  - [Stanford XCS224U: Natural Language Understanding I Spring 2023](https://www.youtube.com/playlist?list=PLoROMvodv4rOwvldxftJTmoR3kRcWkJBp)\n  - [CS388: Natural Language Processing - UT Austin](https://www.cs.utexas.edu/~gdurrett/courses/online-course/materials.html)\n  - [CS 124 - From Languages to Information - Stanford University](https://www.youtube.com/channel/UC_48v322owNVtORXuMeRmpA/playlists?view=50&sort=dd&shelf_id=2)\n  - [CS 6340/5340 - Natural Language Processing - University of Utah - Spring 2024](https://utah-intro-nlp.github.io/) ([Youtube](https://www.youtube.com/playlist?list=PLbuogVdPnkCrPZ4Vc-GRnk730SLhC1L43))\n  - [CSE 447/517 - Natural Language Processing - University of Washington - Winter 2024](https://safe-fernleaf-26d.notion.site/Winter-24-CSE-447-517-Natural-Language-Processing-4142333a001143d2be5ecff1a535c4ab)\n  - [Neural Networks: Zero to Hero - Andrej Karpathy](https://karpathy.ai/zero-to-hero.html)\n  - [fast.ai Code-First Intro to Natural Language Processing](https://www.youtube.com/playlist?list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9) ([Github](https://github.com/fastai/course-nlp))\n  - [MOOC - Natural Language Processing - Coursera, University of Michigan](https://www.youtube.com/playlist?list=PLLssT5z_DsK8BdawOVCCaTCO99Ya58ryR)\n  - [Natural Language Processing at UT Austin (Greg Durrett)](https://www.youtube.com/playlist?list=PLofp2YXfp7Tbk88uH4jejfXPd2OpWuSLq)\n  - [CS224U: Natural Language Understanding - Spring 2019 - Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)\n  - [Deep Learning for Natural Language Processing, 2017 - Oxford University](https://github.com/oxford-cs-deepnlp-2017/lectures)\n  - [Natural Language Processing - IIT Bombay](https://nptel.ac.in/courses/106101007/)\n  - [CMU Advanced NLP Fall 2024](https://phontron.com/class/anlp-fall2024/schedule/) ([Lectures - Fall 2024](https://www.youtube.com/playlist?list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp)) ([Lectures - Fall 2021](https://www.youtube.com/playlist?list=PL8PYTP1V4I8AYSXn_GKVgwXVluCT9chJ6))\n  - [CMU Neural Nets for NLP 2021](https://www.youtube.com/playlist?list=PL8PYTP1V4I8AkaHEJ7lOOrlex-pcxS-XV)\n  - [Natural Language Processing - Michael Collins - Columbia University](https://www.youtube.com/playlist?list=PLA212ij5XG8OTDRl8IWFiJgHR9Ve2k9pv)\n  - [CMU CS11-711 - Advanced Natural Language Processing](https://cmu-l3.github.io/anlp-spring2025/) ([Lectures - Spring 2025](https://www.youtube.com/playlist?list=PLqC25OT8ZpD3WxQ0FwWMGPS_BcWdcKyZy))\n  - [CMU CS11-737 - Multilingual Natural Language Processing](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5)\n  - [UMass CS685: Advanced Natural Language Processing (Spring 2022)](https://www.youtube.com/playlist?list=PLWnsVgP6CzadI4-FT2Po4wsEK7MHCIQ-d)\n  - [Natural Language Processing (CMSC 470)](https://www.youtube.com/playlist?list=PLwrUPjGidcJ4UkSoi7_rmn-1kcedLqgdL)\n  - [Stanford CS25 - Transformers United 2023](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM)\n  - [Natural Language Processing (IN2361) - TUM](https://live.rbg.tum.de/?year=2019&term=W&slug=nlp&view=3)\n  - [CS 886: Recent Advances on Foundation Models Winter 2024 - University of Waterloo](https://cs.uwaterloo.ca/~wenhuche/teaching/cs886/)\n  - [UC Berkeley CS 194/294-196 Large Language Model Agents Fall 2024, by Dawn Song & Xinyun Chen](https://rdi.berkeley.edu/llm-agents/f24) ([YouTube playlist](https://www.youtube.com/playlist?list=PLS01nW3RtgopsNLeM936V4TNSsvvVglLc))\n  - [UC Berkeley CS 194/294-267 Understanding Large Language Models Foundations and Safety spring 2024, by Dawn Song & Dan Hendrycks](https://www.youtube.com/playlist?list=PLJ66BAXN6D8H_gRQJGjmbnS5qCWoxJNfe)\n  - [Introduction to Large Language Models (LLMs), IIT Delhi](https://www.youtube.com/playlist?list=PLqGkIjcOyrGnjyBHl4GE2S9kX47X96FH-)\n  - [Natural Language Processing (Spring 2024) - University of Utah](https://www.youtube.com/playlist?list=PLbuogVdPnkCrPZ4Vc-GRnk730SLhC1L43)\n  - [Multilingual NLP 2020 - CMU](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5)\n  - [Introduction to large language models - IIT Madras](https://www.youtube.com/playlist?list=PLZ2ps__7DhBbaMNZoyW2Hizl8DG6ikkjo)\n  - [Speech Technology - IIT Madras](https://www.youtube.com/playlist?list=PLZ2ps__7DhBaI_g3_V-CFrgFIf-0Yksiv)\n  \n- #### **Generative AI**\n  - [Stanford CS236: Deep Generative Models I 2023 I Stefano Ermon](https://www.youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8)\n  - [CS 6785 - Deep Generative Models - Cornell Tech, Spring 2023)](https://www.youtube.com/playlist?list=PL2UML_KCiC0UPzjW9BjO-IW6dqliu9O4B)\n  - [MIT 6.S184 Flow Matching and Diffusion Models, 2025](https://diffusion.csail.mit.edu)\n  \n- #### **Computer Vision**\n  - [CS 231n - Convolutional Neural Networks for Visual Recognition, Stanford University](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)\n  - [CS 198-126: Modern Computer Vision Fall 2022 (UC Berkeley)](https://www.youtube.com/playlist?list=PLzWRmD0Vi2KVsrCqA4VnztE4t71KnTnP5)\n  - [Machine Learning for Robotics and Computer Vision, WS 2013/2014 - TU M√ºnchen](https://vision.in.tum.de/teaching/ws2013/ml_ws13) ([YouTube](https://www.youtube.com/playlist?list=PLTBdjV_4f-EIiongKlS9OKrBEp8QR47Wl))\n  - [COGSCI 1 - Intro to Cognitive Science Summer 2022 - UC Berkeley](https://www.youtube.com/playlist?list=PLaMjLYzDGxvz1oT5gpFiY6rJZnlJ-1Xu-)\n  - [Informatics 1 - Cognitive Science 2015/16- University of Edinburgh](http://groups.inf.ed.ac.uk/vision/VIDEO/2015/inf1cs.htm)\n  - [Informatics 2A - Processing Formal and Natural Languages 2016-17 - University of Edinburgh](http://www.inf.ed.ac.uk/teaching/courses/inf2a/schedule.html)\n  - [NOC:Deep Learning For Visual Computing - IIT Kharagpur](https://nptel.ac.in/courses/108/105/108105103/)\n  - [Extreme Classification ](https://www.youtube.com/playlist?list=PLXtAHOcKKDTk43wjXud9GQS-l-QA5DQxH)\n  - [EECS 498/598 - Deep Learning for Computer Vision - University of Michigan - Fall 2019](https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2019/) ([Youtube](https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r))\n  - [Computer Vision - FAU Spring 2021](https://www.fau.tv/course/id/2306) ([Spring 2018](https://www.fau.tv/course/id/734))\n  - [CAP5415 Computer Vision - UCF Fall 2023](https://www.youtube.com/playlist?list=PLd3hlSJsX_InWyCQtwqQ7y6KnwhxNCgRf)\n  - [CAP6412 Advanced Computer Vision - UCF Spring 2024](https://www.crcv.ucf.edu/courses/cap6412-spring-2024/schedule/) ([Youtube](https://www.youtube.com/playlist?list=PLd3hlSJsX_IlSr0ua4v8WQezazAMXEJE4))\n  - [Advanced Deep Learning for Computer vision (ADL4CV) (IN2364) - TU Munich](https://dvl.in.tum.de/teaching/adl4cv-ss20/) ([Youtube](https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39))\n  - [Computer Vision III: Detection, Segmentation and Tracking (CV3DST) (IN2375) - TU Munich](https://www.youtube.com/playlist?list=PLog3nOPCjKBkamdw8F6Hw_4YbRiDRb2rb)\n  \n- #### **Time Series Analysis**\n  - [02417 Time Series Analysis](https://www.youtube.com/playlist?list=PLtiTxpFJ4k6TZ0g496fVcQpt_-XJRNkbi)\n  - [Applied Time Series Analysis](https://www.youtube.com/playlist?list=PLl0FT6O_WWDBm-4W-eoK34omYmEMseQDX)\n  \n- #### **Optimization**\n  - [Optimisation for Machine Learning: Theory and Implementation (Hindi) - IIT](https://www.youtube.com/playlist?list=PLyqSpQzTE6M-pmLzCoMu_ANU6atEFyyJl)\n  - [Rochester DSCC 435 Optimization for Machine Learning fall 2023, by Jiaming Liang](https://www.youtube.com/playlist?list=PLuJY91x7h5orCtyh6mChurVQ2ZZef9qPF)\n  - [Princeton ELE539/COS512 Optimization for Machine Learning spring 2021, by Chi Jin](https://sites.google.com/view/cjin/teaching/ece539cos512-2021-ver)\n  - [UT Dallas CS 7301 Advanced Topics in Optimization for Machine Learning spring 2021, by Rishabh Iyer](https://github.com/rishabhk108/AdvancedOptML) ([YouTube](https://www.youtube.com/playlist?list=PLGod0_zT9w92_evaYrf3-rE67AmgPJoUU))\n  - [Convex Analysis, Summer 2021 - TU Braunschweig](https://www.tu-braunschweig.de/index.php?eID=dumpFile&t=f&f=128341&token=3c40ee32c6c029df85f7e552522f4a87470e3401) ([YouTube](https://www.youtube.com/playlist?list=PLPomPKAI5ZlJBThiwc3bya7qngzw9-0QD))\n  - [EE364a: Convex Optimization I - Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rMJqxxviPa4AmDClvcbHi6h)\n  - [10-725 Convex Optimization, Spring 2015 - CMU](http://www.stat.cmu.edu/~ryantibs/convexopt-S15/)\n  - [10-725 Convex Optimization: Fall 2016 - CMU](http://www.stat.cmu.edu/~ryantibs/convexopt/)\n  - [10-725 Optimization Fall 2012 - CMU](http://www.cs.cmu.edu/~ggordon/10725-F12/schedule.html)\n  - [10-801 Advanced Optimization and Randomized Methods - CMU](http://www.cs.cmu.edu/~suvrit/teach/aopt.html) ([YouTube](https://www.youtube.com/playlist?list=PLjTcdlvIS6cjdA8WVXNIk56X_SjICxt0d))\n  - [AM 207 - Stochastic Methods for Data Analysis, Inference and Optimization, Harvard University](http://am207.github.io/2016/index.html)\n  - [MIT 6.S098 Applied Convex Optimization IAP 2022, by Alexandre Amice, Benoit Legat](https://alexandreamice.github.io/teaching/convex_optimization/) ([YouTube](https://www.youtube.com/playlist?list=PL5SG6ajT9NZKxdvM1jQOLXmeKO7MfyLxR))\n  - [University of Twente Discrete Optimization, by Marc Uetz](https://marcuetz.personalweb.utwente.nl/do/) ([Fall 2020](https://www.youtube.com/playlist?list=PLIygTcviGPKBUY9e1MCruRr5-I24LNm4g))\n  - [UC Davis MAT 168 Optimization winter 2024, by Matthias K√∂ppe](https://video.ucdavis.edu/channel/MAT+168+Optimization+%28Matthias+K%C3%B6ppe%3B+Winter+2024%29/329241352)\n  - [Purdue University CHE 597 Computational Optimization spring 2025, by Can Li](https://canli1.github.io/courses)\n  - [UCSD CS292F Convex Optimization Spring 2020, by Yu-Xiang Wang](https://cseweb.ucsd.edu/~yuxiangw/classes/CS292F-2020Spring/) ([Youtube](https://www.youtube.com/playlist?list=PLTN4aNO9NiB5VxYILKPBXoy9g1tUqmnBx))\n  - [UIUC ECE 490 Introduction to Optimization fall 2020, by Venugopal V. Veeravalli](https://courses.grainger.illinois.edu/ece490/fa2020/) ([YouTube](https://www.youtube.com/playlist?list=PLIygTcviGPKC5wSXtE6s2qdSYutRH1AUU))\n  - [University of Wisconsin-Madison CS/ECE/ISyE 524 Introduction to Optimization spring 2017-18, by Laurent Lessard](https://laurentlessard.com/teaching/524-intro-to-optimization/)\n  - [University of Wisconsin-Madison ISyE/Math/CS/Stat 525 Linear Optimization fall 2021, by Alberto Del Pia](https://www.youtube.com/playlist?list=PLeO_PhASIA0Ot69TqANAnNxoykHGOQp2Y)\n  - [University of Wisconsin-Madison ISyE/Math/CS 728 Integer Optimization (second part of the course) spring 2020](https://www.youtube.com/playlist?list=PLeO_PhASIA0NlDNF9y-SsgVEYcvAMj2CY)\n  - [Columbia IEOR E4007 Optimization Models and Methods 2005, by Garud Iyengar](https://www.youtube.com/playlist?list=PLIygTcviGPKCNQ2xHRwrLOxkEWv9OfGiF)\n \n- #### **Unsupervised Learning**\n  - [CS294 Deep Unsupervised Learning Spring 2024](https://sites.google.com/view/berkeley-cs294-158-sp24/home)\n  - [Deep Unsupervised Learning -- Berkeley Spring 2020](https://www.youtube.com/playlist?list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP)\n  - [CS294-158 Deep Unsupervised Learning SP19](https://www.youtube.com/channel/UCf4SX8kAZM_oGcZjMREsU9w/videos)\n  - [UC San Diego COGS 118A Supervised Machine Learning fall 2020, by Jason Fleischer](https://www.youtube.com/playlist?list=PLaaNbhBDEsoF_ad5N2mlOsvB-RwSTYUjQ)\n  - [UC San Diego COGS 118B Unsupervised Machine Learning winter 2024, by Jason Fleischer](https://www.youtube.com/playlist?list=PLaaNbhBDEsoEU9RRbwCqJWFAZH2LjNwBN)\n  - [UIUC STAT 437 Unsupervised Learning spring 2024, by Tori Ellison](https://www.youtube.com/playlist?list=PLIygTcviGPKB133Vh7zxsxFoblyfS4P5Y)\n  - [Johns Hopkins Unsupervised Learning spring 2017, by Rene Vidal](https://www.youtube.com/playlist?list=PLaBAmmD3yH4Nta9Y6g9hOV4dcnpTzeW4q)\n  - [Unsupervised Learning (STAT 841), Winter 2017](https://www.youtube.com/playlist?list=PLehuLRPyt1HzQoXEhtNuYTmd0aNQvtyAK)\n  \n- #### **Misc Machine Learning Topics**\n  - [Quantum Machine Learning | 2021 Qiskit Global Summer School](https://www.youtube.com/playlist?list=PLOFEBzvs-VvqJwybFxkTiDzhf5E11p8BI)\n  - [CS 6955 - Clustering, Spring 2015, University of Utah](https://www.youtube.com/playlist?list=PLbuogVdPnkCpRvi-qSMCdOwyn4UYoPxTI)\n  - [Info 290 - Analyzing Big Data with Twitter, UC Berkeley school of information](http://blogs.ischool.berkeley.edu/i290-abdt-s12/) ([YouTube](https://www.youtube.com/playlist?list=PLE8C1256A28C1487F))\n  - [CS224W Machine Learning with Graphs | Spring 2021 | Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn)\n  - [9.520 - Statistical Learning Theory and Applications, Fall 2015 - MIT](https://www.youtube.com/playlist?list=PLyGKBDfnk-iDj3FBd0Avr_dLbrU8VG73O)\n  - [Statistical Learning Theory, Spring 2019 - ETH Z√ºrich](https://video.ethz.ch/lectures/d-infk/2019/spring/252-0526-00L.html)\n  - [Course on the Statistical Learning Theory, University of S√£o Paulo, ICMC](https://www.youtube.com/playlist?list=PLKWX1jIoUZaVpVhMfevAE7iYNcDHPEJI_)\n  - [Reinforcement Learning - UCL](https://www.youtube.com/playlist?list=PLacBNHqv7n9gp9cBMrA6oDbzz_8JqhSKo)\n  - [Regularization Methods for Machine Learning 2016](http://academictorrents.com/details/493251615310f9b6ae1f483126292378137074cd) ([YouTube](https://www.youtube.com/playlist?list=PLbF0BXX_6CPJ20Gf_KbLFnPWjFTvvRwCO))\n  - [Statistical Inference in Big Data - University of Toronto](http://fields2015bigdata2inference.weebly.com/materials.html)\n  - [Reinforcement Learning - IIT Madras](https://nptel.ac.in/courses/106106143/)\n  - [Statistical Rethinking Winter 2015 - Richard McElreath](https://www.youtube.com/playlist?list=PLDcUM9US4XdMdZOhJWJJD4mDBMnbTWw_z)\n  - [Foundations of Machine Learning - Blmmoberg Edu](https://bloomberg.github.io/foml/#home)\n  - [Introduction to reinforcement learning - UCL](https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ)\n  - [Statistical Foundation of Reinforcement Learning - UCSD, by Yu-Xiang Wang, Spring 2021](https://cseweb.ucsd.edu/~yuxiangw/classes/RLCourse-2021Spring/) ([Youtube](https://www.youtube.com/playlist?list=PLTN4aNO9NiB5X8HkOBTkIfZ8VFSLH1W8W))\n  - [Web Information Retrieval (Proff. L. Becchetti - A. Vitaletti)](https://www.youtube.com/playlist?list=PLAQopGWlIcya-9yzQ8c8UtPOuCv0mFZkr)\n  - [Big Data Systems (WT 2019/20) - Prof. Dr. Tilmann Rabl - HPI](https://www.tele-task.de/series/1286/)\n  - [Distributed Data Analytics (WT 2017/18) - Dr. Thorsten Papenbrock - HPI](https://www.tele-task.de/series/1179/)\n  - [Introduction to Data-Centric AI - MIT](https://dcai.csail.mit.edu/)\n  - [Parallel Computing and Scientific Machine Learning](https://www.youtube.com/playlist?list=PLCAl7tjCwWyGjdzOOnlbGnVNZk0kB8VSa)\n  - [Machine Learning System Design - System Design Fight Club](https://www.youtube.com/playlist?list=PLlvnxKilk3aKx0oFua-HTtFf-d_inQ8Qn)\n  - [UT Austin ECE 381V Bandits and Online Learning fall 2021, by Sanjay Shakkottai](https://docs.google.com/document/d/1r6jXNd1DD9o8v4q4XqxShRXWYdhtLMjEXWDzuv0T6LU/edit)\n  - [UCSD MATH 273B Information Geometry and its Applications winter 2022, by Melvin Leok](https://www.youtube.com/playlist?list=PLHZhjPByiV3L94AeJ9FcK1yrnRDOt3Vit)\n  - [Cornell ECE 5545 Machine Learning Hardware and Systems Spring 2022, by Mohamed Abdelfattah](https://www.youtube.com/playlist?list=PL0mFAhrXqy9CuopJhAB8GVu_Oy7J0ery6)\n  - [High Dimensional Analysis: Random Matrices and Machine Learning by Roland Speicher](https://rolandspeicher.com/lectures/course-on-high-dimensional-analysis-random-matrices-and-machine-learning-summer-term-2023/)([Youtube](https://www.youtube.com/playlist?list=PLY11JnnnTUCabY4nc0hKptrd5qEWtLoo2))\n  - [ACP SUMMER SCHOOL 2023 on Machine Learning for Constraint Programming](https://www.youtube.com/playlist?list=PLcByDTr7vRTYJ2s6DL-3bzjGwtQif33y3)\n  - [EE512A - Advanced Inference in Graphical Models, Fall Quarter, 2014](https://people.ece.uw.edu/bilmes/classes/ee512/ee512_fall_2014/)\n  - [University of Wisconsin-Madison CS/ECE 561 - Probability and Information Theory in Machine Learning fall 2020, by Matthew Malley](https://mediaspace.wisc.edu/channel/CS_ECE%2B561%2B-%2BProbability%2Band%2BInfo%2BTheory%2Bin%2BMachine%2BLearning/191748913)\n  - [University of Maryland CMSC828U Algorithms in Machine Learning: Guarantees and Analyses fall 2020, by Furong Huang](https://www.cs.umd.edu/class/fall2020/cmsc828u//schedule/) ([YouTube playlist](https://www.youtube.com/playlist?list=PLM0SC1uXFSPo5TO_UN7fia1luj73yuHEC))\n  - [Statistical Physics of Machine Learning](https://www.youtube.com/playlist?list=PL04QVxpjcnjgzMr9ehyZUSkwu0Wr0cF_N)\n  - [11-755 - Machine Learning for Signal Processing, CMU](https://cmu-mlsp.github.io/mlspcourse/schedule/) ([YouTube-2024](https://www.youtube.com/playlist?list=PLWhigAi1mTpO3Rw-1D2b2AowYeIU5eRzD), [YouTube-2023](https://www.youtube.com/playlist?list=PLWhigAi1mTpPMV3hECmkEv3s8Lc8H_VUd))\n  - [Machine Learning for 3D Data, Fall 2023, KAIST](https://mhsung.github.io/kaist-cs479-fall-2023/)\n  - [Machine Learning for Physicists, Spring 2019, FAU](https://www.fau.tv/course/id/778) ([Spring 2017](https://www.fau.tv/course/id/574))\n  - [CSCE 585 - Machine Learning Systems, University of South Carolina](https://pooyanjamshidi.github.io/mls/lectures/) ([YouTube-2020](https://www.youtube.com/playlist?list=PLtkQf9LiEmLFS56WTpRJ3PZwwCYyi2Cdu))\n  - [CS-E4740 - Federated Learning, Spring 2023, Aalto University](https://www.youtube.com/playlist?list=PLrbn2dGrLJK8c6hCQXBVFoYsPXG-g_75c)\n\n\n------------------------------\n\n\n### Computer Networks\n\n- [CS 144 Introduction to Computer Networking - Stanford University, Fall 2013](http://www.scs.stanford.edu/10au-cs144/) ([Lecture videos](https://www.youtube.com/playlist?list=PL6RdenZrxrw9inR-IJv-erlOKRHjymxMN))\n- [Computer Networking: A Top-Down Approach](https://www.youtube.com/playlist?list=PLm556dMNleHc1MWN5BX9B2XkwkNE2Djiu)\n- [Computer Communication Networks, Rensselaer Polytechnic Institute - Fall 2001](https://www.ecse.rpi.edu/Homepages/koushik/shivkuma-teaching/video_index.html) ([Videos](https://www.ecse.rpi.edu/Homepages/koushik/shivkuma-teaching/video_index.html#ccn_video)) ([Slides](https://www.ecse.rpi.edu/Homepages/koushik/shivkuma-teaching/video_index.html#ccn_foils))\n- [Audio/Video Recordings and Podcasts of Professor Raj Jain's Lectures - Washington University in St. Louis](http://www.cse.wustl.edu/~jain/videos.htm) ([YouTube](https://www.youtube.com/user/ProfRajJain/playlists))\n- [Computer Networks, Tanenbaum, Wetherall Computer Networks 5e - Video Lectures](http://media.pearsoncmg.com/ph/streaming/esm/tanenbaum5e_videonotes/tanenbaum_videoNotes.html)\n- [CSEP 561 - PMP Network Systems, Fall 2013 - University of Washington](https://courses.cs.washington.edu/courses/csep561/13au/) ([Videos](https://courses.cs.washington.edu/courses/csep561/13au/video/))\n- [CSEP 561 ‚Äì Network Systems, Autumn 2008 - University of Washington](https://courses.cs.washington.edu/courses/csep561/08au/) ([Videos](https://courses.cs.washington.edu/courses/csep561/08au/lectures/))\n- [ECE/CS 438 - Communication Networks, Fall 2020 - UIUC](https://courses.physics.illinois.edu/cs438/fa2020/)\n- [Computer Networks - IIT Kharagpur](https://nptel.ac.in/courses/106105081/)\n- [Introduction to Data Communications 2013, Steven Gordon - Thammasat University, Thailand](https://www.youtube.com/playlist?list=PLvifRcqOOwF8u4iC7hFTMVC_WD6SEpnkx)\n- [Introduction to Complex Networks - RIT](https://www.youtube.com/playlist?list=PLE9AAD550EA21F3DC)\n- [Structural Analysis and Visualization of Networks](http://www.leonidzhukov.net/hse/2015/networks/)\n- [Columbia ELEN E4703 Wireless Communications spring 2006, by Angel Lozano](https://www.youtube.com/playlist?list=PLIygTcviGPKAaY0VGGjQ2whITq23AOjaR)\n- [Columbia COMS W4119 Computer Networks fall 2004, by Vishal Misra](https://www.youtube.com/playlist?list=PLIygTcviGPKCh6XgTHofe6zPK_LQ_nVW3)\n- [Columbia ELEN E4710 An Introduction to Network Engineering fall 2004, by Dan Rubenstein](https://www.cs.columbia.edu/~danr/courses/4710/Fall04/) ([Videos](https://www.youtube.com/playlist?list=PLIygTcviGPKClQelPKe2f05aReRMncyR7))\n- [Data Communication - IIT Kharagpur](https://nptel.ac.in/courses/106105082/)\n- [Error Correcting Codes - IISC Bangalore](https://nptel.ac.in/courses/117108044/)\n- [Information Theory and Coding - IIT Bombay](https://nptel.ac.in/courses/117101053/)\n- [Complex Network : Theory and Application - IIT Kharagpur](https://nptel.ac.in/courses/106105154/)\n- [Advanced 3G and 4G Wireless Mobile Communications - IIT Kanpur](https://nptel.ac.in/courses/117104099/)\n- [Broadband Networks: Concepts and Technology - IIT Bombay](https://nptel.ac.in/courses/117101050/)\n- [Coding Theory - IIT Madras](https://nptel.ac.in/courses/117106031/)\n- [Digital Communication - IIT Bombay](https://nptel.ac.in/courses/117101051/)\n- [Digital Voice & Picture Communication - IIT Kharagpur](https://nptel.ac.in/courses/117105081/)\n- [Wireless Ad Hoc and Sensor Networks - IIT Kharagpur](https://nptel.ac.in/courses/106105160/)\n- [Internetworking with TCP/IP by Prof. Dr. Christoph Meinel - HPI](https://www.youtube.com/playlist?list=PLoOmvuyo5UAfY5VrkObHTckZHwPsS1VCA)\n- [CS798: Mathematical Foundations of Computer Networking - University of Waterloo](https://www.youtube.com/playlist?list=PLFB088DB91845CA34)\n- [CS 168 Introduction to the Internet: Architecture and Protocols, Fall 2022 - UC Berkeley](https://fa22.cs168.io/) ([YouTube - Fall 2022](https://www.youtube.com/playlist?list=PLIygTcviGPKD4RbcpiXKeyXrIImw-mGd-)) ([Spring 2025](https://sp25.cs168.io/))\n- [Advanced Topics in Communication Networks, Fall 2022 - ETH Z√ºrich](https://video.ethz.ch/lectures/d-itet/2022/autumn/227-0575-00L.html)\n- [CS/ECE 438 Communication Networks [F23] - UIUC](https://rrc-uiuc.notion.site/Communication-Networks-F23-d37ef65a3d1b4b7ba3d49d929c03d546)\n\n------------------------------\n\n### Math for Computer Scientist\n\n- [Maths courses all topics covered - Khan Academy](https://www.khanacademy.org/math/)\n- **Calculus**\n  - [18.01 Single Variable Calculus, Fall 2006 - MIT OCW](https://ocw.mit.edu/courses/mathematics/18-01-single-variable-calculus-fall-2006/)\n  - [18.02 Multivariable Calculus, Fall 2007 - MIT OCW](https://ocw.mit.edu/courses/mathematics/18-02-multivariable-calculus-fall-2007/)\n  - [18.03 Differential Equations, Spring 2010 - MIT OCW](https://ocw.mit.edu/courses/mathematics/18-03-differential-equations-spring-2010/)\n  - [Highlights of Calculus - Gilbert Strang, MIT OCW](https://ocw.mit.edu/resources/res-18-005-highlights-of-calculus-spring-2010/)\n  - [MAT123 Introduction to Calculus (Fall 2015) - Stony Brook](https://www.math.stonybrook.edu/~scott/mat123.fall15/)\n  - [Vector Calculus for Engineers - HKUST](https://www.youtube.com/playlist?list=PLkZjai-2JcxnYmkg6fpzz4WFumGVl7MOa)\n- **Discrete Math**\n  - [6.042J - Mathematics for Computer Science, MIT OCW](https://ocw.mit.edu/courses/6-042j-mathematics-for-computer-science-fall-2010/video_galleries/video-lectures/) \n  - [Computer Science 70, 001 - Spring 2015](https://www.youtube.com/playlist?list=-XXv-cvA_iD8wQm8U0gG_Z1uHjImKXFy)\n  - [CSE 547 Discrete Mathematics, Prof Skiena, University of Stony Brook](http://www3.cs.stonybrook.edu/~algorith/math-video/)\n  - [Discrete Structures (Summer 2011) - Rutgers, The State University of New Jersey](https://itunes.apple.com/us/course/discrete-structures-summer/id698728837)\n  - [Discrete Mathematics and Mathematical Reasoning 2015/16 - University of Edinburgh](https://www.inf.ed.ac.uk/teaching/courses/dmmr/)\n  - [Discrete Mathematical Structures - IIT Madras](https://nptel.ac.in/courses/106106094/)\n  - [Discrete Structures - Pepperdine University](https://itunes.apple.com/us/course/discrete-structures/id546468789)\n  - [CMU 21 228 Discrete Mathematics spring 2021, by Po-Shen Loh](https://www.youtube.com/playlist?list=PLgTkKBA6LRqYuuQ-LboerRblBoD_q_eUM)\n  - [COMP2804: Discrete Structures II](https://cglab.ca/~morin/teaching/2804/)\n- **Probability & Statistics**\n  - [Statistics - CrashCourse](https://www.youtube.com/playlist?list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr)\n  - [6.041 Probabilistic Systems Analysis and Applied Probability - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041sc-probabilistic-systems-analysis-and-applied-probability-fall-2013/)\n  - [Stanford CS109 Introduction to Probability for Computer Scientists I 2022 I Chris Piech](https://www.youtube.com/playlist?list=PLoROMvodv4rOpr_A7B9SriE_iZmkanvUg)\n  - [MIT RES.6-012 Introduction to Probability, Spring 2018 - MIT](https://www.youtube.com/playlist?list=PLUl4u3cNGP60hI9ATjSFgLZpbNJ7myAg6)\n  - [Statistics 110 - Probability - Harvard University](https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo)\n  - [STAT 2.1x: Descriptive Statistics | UC Berkeley](https://www.youtube.com/playlist?list=PL_Ig1a5kxu56TfFnGlRlH2YpOBWGiYsQD)\n  - [STAT 2.2x: Probability | UC Berkeley](https://www.youtube.com/playlist?list=PL_Ig1a5kxu57qPZnHm-ie-D7vs9g7U-Cl)\n  - [MOOC - Statistics: Making Sense of Data, Coursera](http://academictorrents.com/details/a0cbaf3e03e0893085b6fbdc97cb6220896dddf2)\n  - [MOOC - Statistics One - Coursera](https://www.youtube.com/playlist?list=PLycnP7USbo1V3jlyjAzWUB201cLxPq4NP)\n  - [Probability and Random Processes - IIT Kharagpur](https://nptel.ac.in/courses/117105085/)\n  - [MOOC - Statistical Inference - Coursera](https://www.youtube.com/playlist?list=PLgIPpm6tJZoSvrYM54BUqJJ4CWrYeGO40)\n  - [131B - Introduction to Probability and Statistics, UCI](https://www.youtube.com/playlist?list=PLqOZ6FD_RQ7k-j-86QUC2_0nEu0QOP-Wy)\n  - [STATS 250 - Introduction to Statistics and Data Analysis, UMichigan](https://www.youtube.com/playlist?list=PL432AB57AF9F43D4F)\n  - [Sets, Counting and Probability - Harvard](http://matterhorn.dce.harvard.edu/engage/ui/index.html#/1999/01/82347)\n  - [Opinionated Lessons in Statistics](http://www.opinionatedlessons.org/) ([Youtube](https://www.youtube.com/playlist?list=PLUAHeOPjkJseXJKbuk9-hlOfZU9Wd6pS0))\n  - [Statistics - Brandon Foltz](https://www.youtube.com/user/BCFoltz/playlists)\n  - [Statistical Rethinking: A Bayesian Course Using R and Stan](https://github.com/rmcelreath/statrethinking_winter2019) ([Lectures](https://www.youtube.com/playlist?list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus)) ([Book](http://www.stat.columbia.edu/~gelman/book/))\n  - [02402 Introduction to Statistics E12 - Technical University of Denmark](https://www.youtube.com/playlist?list=PLMn2aW3wpAtPC8tZHQy6nwWsFG7P6sPqw) ([F17](https://www.youtube.com/playlist?list=PLgowegO9Se58_BnUNnaARajEE_bX-GJEz))\n  - [Engineering Probability (ECSE-2500) - RPI](https://www.youtube.com/playlist?list=PLuh62Q4Sv7BU1dN2G6ncyiMbML7OXh_Jx)\n  - [Purdue ECE302 Introduction to Probability for Data Science](https://www.youtube.com/playlist?list=PL4FSfq6xtSvyqsbgrYDeyV0WWXlXqwy2M)\n  - [Undergraduate Probability with Professor Roman Vershynin](https://www.math.uci.edu/~rvershyn/teaching/ugp/ugp.html)\n  - [High-Dimensional Probability](https://www.math.uci.edu/~rvershyn/teaching/hdp/hdp.html)\n  - [Mathematical Statistics - 2024](https://www.youtube.com/playlist?list=PLLyj1Zd4UWrPZH-fknPLak0tlUpUISBZR) ([YouTube-2020](https://www.youtube.com/playlist?list=PLLyj1Zd4UWrOk5-wIki_oOxHJnNj0_437))\n  - [Bayesian Data Analysis](https://www.youtube.com/playlist?list=PLBqnAso5Dy7O0IVoVn2b-WtetXQk5CDk6)\n  - [Bayesian Machine Learning and Information Processing](https://biaslab.github.io/teaching/bmlip/) ([YouTube-2021/22](https://www.youtube.com/playlist?list=PLkDDgjnfkmCELsBXiCKCVIHKHSjl-rpkJ)) ([YouTube-2020/21](https://www.youtube.com/playlist?list=PLkDDgjnfkmCH4zq9_ul-KaTsk-1j1EVEo))\n  - [Markov Processes - Spring 2023](https://www.youtube.com/playlist?list=PLLyj1Zd4UWrP3rME2XvFvE4Q5vI3H_7_Z)\n  - [Measure Theoretic Probability](https://www.youtube.com/playlist?list=PLLyj1Zd4UWrO6VtBSiQLsNlo9QBm30nxC)\n  - [Causal Inference Course - Brady Neal](https://www.youtube.com/playlist?list=PLoazKTcS0RzZ1SUgeOgc6SWt51gfT80N0)\n  - [Causal Inference -- Online Lectures (M.Sc/PhD Level)](https://www.youtube.com/playlist?list=PLyvUJLHD8IsJCB7ALqwjRG1BjL5JxE__H)\n  - [Machine Learning & Causal Inference: A Short Course](https://www.youtube.com/playlist?list=PLxq_lXOUlvQAoWZEqhRqHNezS30lI49G-)\n  - [Causal Inference Jonas Peters](https://www.youtube.com/playlist?list=PLzERW_Obpmv-_EXTV1zTmlv-Ab5Tfbp8X)\n  - [UIUC ECE 534 Random Processes fall 2020 - Ilan Shomorony](https://www.youtube.com/playlist?list=PL682UO4IMem-1IrJp1jTK_w1lh0qOwLx3)\n  - [ISyE 320 Simulation and Probabilistic Modeling spring 2022, by Qiaomin Xie - University of Wisconsin-Madison](https://www.youtube.com/playlist?list=PL682UO4IMem-7c512A5mwIn_J90z8Awgd)\n  - [Cambridge Principles of Statistics 2020, by Alberto J. Coca](https://www.youtube.com/playlist?list=PLn1JSlh3WT_YBwXFUfRAb1ZOXnPYDgVNa)\n  - [UC Berkeley STAT 150 Stochastic Processes spring 2021, by Brett Kolesnik](https://www.youtube.com/playlist?list=PL682UO4IMem_H6exlt8NMfBSc0137_wlo)\n  - [UIUC Math 564 Applied Stochastic Processes fall 2016, by Kay Kirkpatrick](https://www.youtube.com/playlist?list=PL682UO4IMem-5C_U0ml6O2kM1s1Yo-D9D)\n  - [CS/ECE 561 - Probability and Info Theory in Machine Learning](https://mediaspace.wisc.edu/channel/CS_ECE%2B561%2B-%2BProbability%2Band%2BInfo%2BTheory%2Bin%2BMachine%2BLearning/191748913)\n  - [UCLA Stats 10 Introduction to Statistical Reasoning summer 2022, by Miles Chen](https://www.youtube.com/playlist?list=PLIygTcviGPKCk7fc69zL_cOogOPQBzXhn)\n  - [UCLA Stats 101C Statistical Models and Data Mining summer 2022, by Miles Chen](https://www.youtube.com/playlist?list=PLIygTcviGPKAYdlamMMGkNGJuKFVYvYER)\n  - [UCLA Stats 102A Introduction to Computational Statistics with R winter 2024, by Miles Chen](https://www.youtube.com/playlist?list=PLIygTcviGPKCiE3kiMI7ofuQ3wmXQUcmx)\n  - [UCLA Stats 102B Computation and Optimization for Statistics spring 2024, by Miles Chen](https://www.youtube.com/playlist?list=PLIygTcviGPKD4XftRgjRlTITljOx792YN)\n  - [UCLA Stats 102C Introduction to Monte Carlo Methods fall 2023, by Miles Chen](https://www.youtube.com/playlist?list=PLIygTcviGPKDv0fZ7RxMGPuaa1Yqx_bzh)\n  - [UCLA Stats 200B Theoretical Statistics winter 2024, by Arash Amini](https://www.youtube.com/playlist?list=PLN_qg0-2-0SwfzKyD47bMBmwJnKeezZCW) ([Winter 2023](https://www.youtube.com/playlist?list=PLN_qg0-2-0Sw03Ffmuq8prIVSoTI3yVyR))\n  - [UCLA Stats 200C High-dimensional Statistics spring 2022, by Arash Amini](https://www.youtube.com/playlist?list=PLN_qg0-2-0SzyrvojbW4UZQjVG1CnBFMd) ([Spring 2021](https://www.youtube.com/playlist?list=PLN_qg0-2-0Sy-nbvOCLgt6uIQsOnmG-iV))\n  - [UCLA Stats 203 Large Sample Theory fall 2021, by Jingyi Jessica Li](https://www.youtube.com/playlist?list=PLAYxx7zX5F1P5GG-9U8eJPL_MIsl1_8Zh) ([Fall 2020](https://www.youtube.com/playlist?list=PLAYxx7zX5F1NKukTVwMADi1D5dbufWJkz))\n  - [UCSD Math 280 Probability Theory and Stochastic Processes, by Todd Kemp](https://mathweb.ucsd.edu/~tkemp/ProbabilityTube/) ([YouTube](https://www.youtube.com/@toddkemp-probability/playlists))\n  - [METU EE 531 Probability and Stochastic Processes, by Elif Uysal](https://ocw.metu.edu.tr/course/view.php?id=323)\n  - [6.262 Discrete Stochastic Processes - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-262-discrete-stochastic-processes-spring-2011/)\n  - [18.650 Statistics for Applications - MIT OCW](https://ocw.mit.edu/courses/mathematics/18-650-statistics-for-applications-fall-2016/lecture-videos/)\n  - [STAT240 - Robust Statistics - UC Berkeley](https://www.stat.berkeley.edu/~jsteinhardt/stat240/index.html)\n- **Linear Algebra**\n  - [Mathematical Foundations of Machine Learning (Fall 2021) - University of Chicago - Rebecca Willett](https://willett.psd.uchicago.edu/teaching/mathematical-foundations-of-machine-learning-fall-2021/)\n  - [18.06 - Linear Algebra, Prof. Gilbert Strang, MIT OCW](https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/)\n  - [18.065 Matrix Methods in Data Analysis, Signal Processing, and Machine Learning - MIT OCW](https://ocw.mit.edu/courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/video_galleries/video-lectures/)\n  - [University of Wisconsin-Madison ECE/CS/ME 532 Matrix Methods in Machine Learning fall 2017, by Laurent Lessard](https://laurentlessard.com/teaching/532-matrix-methods/)\n  - [Linear Algebra (Princeton University)](https://www.youtube.com/playlist?list=PLGqzsq0erqU7w7ZrTZ-pWWk4-AOkiGEGp)\n  - [MOOC: Coding the Matrix: Linear Algebra through Computer Science Applications - Coursera](http://academictorrents.com/details/54cd86f3038dfd446b037891406ba4e0b1200d5a)\n  - [CS 053 - Coding the Matrix - Brown University](http://cs.brown.edu/courses/cs053/current/lectures.htm) ([Fall 14 videos](https://cs.brown.edu/video/channels/coding-matrix-fall-2014/))\n  - [Linear Algebra Review - CMU](http://www.cs.cmu.edu/~zkolter/course/linalg/outline.html)\n  - [A first course in Linear Algebra - N J Wildberger - UNSW](https://www.youtube.com/playlist?list=PL44B6B54CBF6A72DF)\n  - [INTRODUCTION TO MATRIX ALGEBRA](http://ma.mathforcollege.com/youtube/index.html)\n  - [Computational Linear Algebra - fast.ai](https://www.youtube.com/playlist?list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY) ([Github](https://github.com/fastai/numerical-linear-algebra))\n  - [ENGR108: Introduction to Applied Linear Algebra‚ÄîVectors, Matrices, and Least Squares - Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rMz-WbFQtNUsUElIh2cPmN9)\n  - [MIT 18.S096 Matrix Calculus For Machine Learning And Beyond](https://www.youtube.com/playlist?list=PLUl4u3cNGP62EaLLH92E_VCN4izBKK6OE)\n  - [Cornell MATH 2940 Linear Algebra for Engineers spring 2009, by Andy Ruina](https://vod.video.cornell.edu/channel/MATH%2B2940%2B-%2BLinear%2BAlgebra%2Bfor%2BEngineers%2BSpring%2B2009/114208531)\n- [10-600 Math Background for ML - CMU](https://www.youtube.com/playlist?list=PL7y-1rk2cCsA339crwXMWUaBRuLBvPBCg)\n- [MIT 18.065 Matrix Methods in Data Analysis, Signal Processing, and Machine Learning](https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/video-lectures/)\n- [Direct Methods for Sparse Linear Systems - Prof Tim Davis - UFL](https://www.youtube.com/playlist?list=PL5EvFKC69QIyRLFuxWRnH6hIw6e1-bBXB)\n- [36-705 - Intermediate Statistics - Larry Wasserman, CMU](http://www.stat.cmu.edu/~larry/=stat705/) ([YouTube](https://www.youtube.com/playlist?list=PLcW8xNfZoh7eI7KSWneVWq-7wr8ffRtHF))\n- [Combinatorics - IISC Bangalore](https://nptel.ac.in/courses/106108051/)\n- [Advanced Engineering Mathematics - Notre Dame](https://www.youtube.com/playlist?list=PLd-PuDzW85Ae4pzlylMLzq_a-RHPx8ryA)\n- [Statistical Computing for Scientists and Engineers - Notre Dame](https://www.youtube.com/playlist?list=PLd-PuDzW85AeltIRcjDY7Z4q49NEAuMcA)\n- [Statistical Computing, Fall 2017 - Notre Dame](https://www.youtube.com/playlist?list=PLd-PuDzW85AcSgNGnT5TUHt85SrCljT3V)\n- [Statistics 243 Introduction to Statistical Computing, Fall 2015 - UC Berkeley](https://www.youtube.com/playlist?list=PLIygTcviGPKCJjCMep25BtbRwehuNTd-l) ([Notes-2015](https://github.com/berkeley-stat243/stat243-fall-2015)) ([YouTube-2014](https://www.youtube.com/playlist?list=PLIygTcviGPKDwAtmOYy_dY_tPuE_8Gc68)) ([Notes-2014](https://github.com/berkeley-stat243/stat243-fall-2014)) ([YouTube-2013](https://www.youtube.com/playlist?list=PLIygTcviGPKBj_b9jy_ZkQM3v4r9iLocO))\n- [Mathematics for Machine Learning, Lectures by Ulrike von Luxburg - T√ºbingen Machine Learning](https://www.youtube.com/playlist?list=PL05umP7R6ij1a6KdEy8PVE9zoCv6SlHRS)\n- [Essential Mathematics for Machine Learning- July 2018 - IIT Roorkee - YouTube Lectures](https://www.youtube.com/playlist?list=PLLy_2iUCG87D1CXFxE-SxCFZUiJzQ3IvE)\n- [Numerics of Machine Learning (Winter 2022/23) - T√ºbingen Machine Learning](https://www.youtube.com/playlist?list=PL05umP7R6ij2lwDdj7IkuHoP9vHlEcH0s)\n- [Nonlinear Dynamics and Chaos - Steven Strogatz, Cornell University](https://www.youtube.com/playlist?list=PLbN57C5Zdl6j_qJA-pARJnKsmROzPnO9V)\n- [Nonlinear Dynamics & Chaos - Virginia Tech](https://www.youtube.com/playlist?list=PLUeHTafWecAUqSh3Gy0NNr7H3OsXoC-aK)\n- [An introduction to Optimization on smooth manifolds (with book) - EPFL](https://www.nicolasboumal.net/book/)\n- [Math Modelling](https://www.youtube.com/playlist?list=PLXsDp0z6VWFT5ZM86xh8i1AMFYxnrefLk)\n- [Large-Scale Convex Optimization: Algorithms & Analyses via Monotone Operators by Ernest Ryu and Wotao Yin](https://www.youtube.com/@large-scaleconvexoptimizat2973/videos)\n- [An Overview of Variational Analysis  2021 by Tyrrell Rockafellar](https://www.youtube.com/playlist?list=PLIismQEEd55Fnzllb-HEYK6k8dMmz2ctj)\n- [UW AMATH 584 Applied Linear Algebra & Numerical Analysis by Nathan Kutz](https://faculty.washington.edu/kutz/am584/am584.html)\n- [UW AMATH 584 Applied Linear Algebra & Introductory Numerical Analysis fall 2005, by Loyce Adams](https://www.youtube.com/playlist?list=PL682UO4IMem-NKDk9uLzRaTOnHPpr4knp)\n- [Stanford CME 206 Introduction to Numerical Methods for Engineering spring 2005, by Charbel Farhat](https://www.youtube.com/playlist?list=PL682UO4IMem97Nk-jJCqUiYZmwpCxMuYF)\n- [Stanford CME 200 Linear Algebra with Application to Engineering Computations autumn 2004, by Margot Gerritsen](https://www.youtube.com/playlist?list=PL682UO4IMem-ZiiCDz7C6bVRjxJ5P35zk)\n- [Stanford CME 302 Numerical Linear Algebra autumn 2007, by Gene Golub](https://www.youtube.com/playlist?list=PL682UO4IMem-OlrG8LXfWQJ2kV_4mpAau)\n- [TUe Numerical Linear Algebra 2021, by Martijn Anthonissen](https://www.youtube.com/playlist?list=PLRb3xghOQGNKbUt8zIRpwrQ-SZ6aIZNvt)\n- [Numerical Linear Algebra fall 2018, by Jaegul Choo](https://www.youtube.com/playlist?list=PLep-kTP3NkcMdmrw07VsKFt87FT584Cpd)\n- [MIT 6.S955 Applied Numerical Algorithms fall 2023, by Justin Solomon](https://www.youtube.com/playlist?list=PLQ3UicqQtfNv_Io_NT1b0Nzr9YDqpK3Lb)\n- [UC Berkeley Math 54 Linear Algebra & Differential Equations spring 2022, by Alexander Paulin](https://math.berkeley.edu/~apaulin/54%20(Spring%202022).html) ([Summer 2021, by Peter Koroteev](https://math.berkeley.edu/~pkoroteev/math54.html)) ([Summer 2020, by Luvreet Sangha](https://www.youtube.com/playlist?list=PLShth7hrtLHO2U1XkrI6ZgMyuPHDxRcob)) ([Spring 2018, by Alexander Paulin](https://math.berkeley.edu/~apaulin/54_001(Spring2018).html))\n- [UC Berkeley Math 55 Discrete Mathematics fall 2021, by Nikhil Srivastava](https://www.youtube.com/playlist?list=PLaVBOvvdB5ctaLM6AmkUaODhd4JhyP_zC)\n- [UC Berkeley Math 56 Linear Algebra fall 2023, by Alexander Paulin](https://math.berkeley.edu/~apaulin/56%20(Fall%202023).html)\n- [Fundamental Mathematics for Robotics spring 2020, by Ken Tomiyama](https://www.youtube.com/@citqualityeducation803/videos)\n- [Short Course on Casual Inference, by Sanjay Shakkottai](https://www.youtube.com/playlist?list=PLcip-Gs_jEK_l2pNG8V_0UDK9jyPtLyuq)\n- [UCLA STAT 100C Linear Models spring 2023, by Arash Amini](https://www.youtube.com/playlist?list=PLN_qg0-2-0SzrzpEoojAa4anJdaKa49GM)\n- [MSU Math for Computing](https://www.youtube.com/playlist?list=PLZ-krWGO-UEyLqtyA2pACX_tXXBTLWkI1)\n- [Mathematics of Data Science - ETH Zurich](https://www.youtube.com/playlist?list=PLiud-28tsatIKUitdoH3EEUZL-9i516IL)\n- [Mathematical Data Science 1 - Spring 2021 - FAU](https://www.fau.tv/course/id/2297) ([Spring 2020](https://www.fau.tv/course/id/1234))\n- [Engineering Mathematics (UW ME564 and ME565) - Steve Brunton](https://www.youtube.com/playlist?list=PLMrJAkhIeNNR2W2sPWsYxfrxcASrUt_9j)\n- [Beginning Scientific Computing - Steve Brunton](https://www.youtube.com/playlist?list=PLMrJAkhIeNNRTVrHYDfjNyqzZ6Q6rsTyf)\n- [Jadavpur University: Foundation_Math_forML_Autumn23](https://www.youtube.com/playlist?list=PLcNLn_ApooUyoctc147F-49oHnfvuj3Yt)\n- [FAU: Inverse Problems Autumn21](https://www.fau.tv/course/id/2705)\n\n\n------------------------------\n\n### Web Programming and Internet Technologies\n- [CS50's Web Programming with Python and JavaScript](https://www.edx.org/course/cs50s-web-programming-with-python-and-javascript)\n- [Web Design Decal - HTML/CSS/JavaScript Course, University of California, Berkeley](http://wdd.io/)\n- [CS 75 Building Dynamic Websites - Harvard University](http://cs75.tv/2012/summer/)\n- [Internet Technology - IIT Kharagpur](https://nptel.ac.in/courses/106105084/)\n- [Introduction to Modern Application Development - IIT Madras](https://nptel.ac.in/courses/106106156/)\n- [CSE 199 - How the Internet Works, Fall 2016 - University of Buffalo](https://www.youtube.com/playlist?list=PLk97mPCd8nvbxGGfkYkBXrSEvpTc1xTF8)\n- [Open Sourced Elective: Database and Rails - Intro to Ruby on Rails, University of Texas](https://www.schneems.com/ut-rails) ([Lectures - Youtube](https://www.youtube.com/playlist?list=PL7A85FD7803A8CB1F))\n- [CSE154 - Web Programming, Spring 2020 - University of Washington](https://courses.cs.washington.edu/courses/cse154/20sp/) ([Videos](https://www.youtube.com/playlist?list=PLrE1feouzSWqcgK0Lvt3r_8AwN6UndaOD))\n- [CSEP545 - Transaction Processing for E-Commerce, Winter 2012 - University of Washington](https://courses.cs.washington.edu/courses/csep545/12wi/) ([Videos](https://courses.cs.washington.edu/courses/csep545/12wi/video/))\n- [CT 310 Web Development - Colorado State University](https://www.cs.colostate.edu/~ct310/yr2016sp/home_progress.php)\n- [Internet Technologies and Applications 2012, Steven Gordon - Thammasat University, Thailand](https://www.youtube.com/playlist?list=PLvifRcqOOwF9cfLMTE-42fiBsWvBsOEkS)\n- [CSCI 3110 Advanced Topics in Web Development, Fall 2011 - ETSU iTunes](https://itunes.apple.com/WebObjects/MZStore.woa/wa/viewPodcast?id=454017618)\n- [CSCI 5710 e-Commerce Implementation, Fall 2015 - ETSU iTunes](https://itunes.apple.com/us/itunes-u/e-commerce-implementation/id1020427670)\n- [MOOC - Web Development - Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPlLXUhUNt1wINWrrH9axjcI)\n- [Web Technologies Prof. Dr. Christoph Meinel - HPI](https://open.hpi.de/courses/webtech2015/items/4oqxq6euKfhXgHOMwFBxbn)\n\n------------------------------\n\n### Theoretical CS and Programming Languages\n\n- [MIT 18.404J Theory of Computation - Fall 2020 - Lecture Slides](https://ocw.mit.edu/courses/18-404j-theory-of-computation-fall-2020/pages/lecture-notes)\n- [MIT 18.404J Theory of Computation - Fall 2020 - Video Lectures](https://www.youtube.com/playlist?list=PLUl4u3cNGP60_JNv2MmK3wkOt9syvfQWY)\n- [MOOC - Compilers - Stanford University](https://archive.org/details/academictorrents_e31e54905c7b2669c81fe164de2859be4697013a)\n- [CS 6120: Advanced Compilers: The Self-Guided Online Course - Cornell University](https://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/)\n- [CS 164 Hack your language, UC Berkeley](https://sites.google.com/a/bodik.org/cs164/home) ([Lectures - Youtube](https://www.youtube.com/playlist?list=PLuhjguFxSeVLvKvWwTUIpVwXdLtZPX1ZS))\n- [Theory of computation - Shai Simonson](http://www.aduni.org/courses/theory/index.php?view=cw)\n- [CS 173 Programming Languages, Brown University](http://cs.brown.edu/courses/cs173/2012/Videos/) ([Book](http://cs.brown.edu/courses/cs173/2012/book/))\n- [CS Theory Toolkit at CMU 2020](https://www.youtube.com/playlist?list=PLm3J0oaFux3ZYpFLwwrlv_EHH9wtH6pnX)\n- [CS 421 - Programming Languages and Compilers, UIUC](https://courses.engr.illinois.edu/cs421/fa2014/)\n- [CSC 253 - CPython internals: A ten-hour codewalk through the Python interpreter source code, University of Rochester](https://www.youtube.com/playlist?list=PLzV58Zm8FuBL6OAv1Yu6AwXZrnsFbbR0S)\n- [CSE341 - Programming Languages, Dan Grossman, Spring 2013 - University of Washington](https://courses.cs.washington.edu/courses/cse341/13sp/)\n- [CSEP 501 - Compiler Construction, University of Washington](https://courses.cs.washington.edu/courses/csep501/09au/lectures/video.html) ([Lectures - Youtube](https://www.youtube.com/playlist?list=PLTPQEx-31JXhfAWGnGzwbfhB2zUB7Jd4C))\n- [CSEP 505 Programming Languages, Winter 2015 - University of Washington](https://courses.cs.washington.edu/courses/csep505/15wi/video/)\n- [DMFP - Discrete Mathematics and Functional Programming, Wheaton College](http://cs.wheaton.edu/~tvandrun/dmfp/)\n- [CS 374 - Algorithms & Models of Computation (Fall 2014), UIUC](https://courses.engr.illinois.edu/cs498374/fa2014/lectures.html) ([Lecture videos](https://www.youtube.com/playlist?list=PL0v718LJg-7_4Zwx3CE7kZ398mhlB2TqF473))\n- [6.045 Automata, Computability, and Complexity, MIT](https://stellar.mit.edu/S/course/6/sp15/6.045/materials.html) ([Lecture Videos](http://stellar.mit.edu/S/course/6/sp15/6.045/special/videos/index.html))\n- [MOOC - Automata - Jeffrey Ullman - Coursera](https://www.youtube.com/playlist?list=PL82C4B8475CAC3F95)\n- [CS581 Theory of Computation - Portland State University](http://web.cecs.pdx.edu/~harry/videos/) ([Lectures - Youtube](https://www.youtube.com/playlist?list=PLbtzT1TYeoMjNOGEiaRmm_vMIwUAidnQz))\n- [Theory of Computation - Fall 2011 UC Davis](https://www.youtube.com/playlist?list=PLslgisHe5tBM8UTCt1f66oMkpmjCblzkt)\n- [TDA555 Introduction to Functional Programming - Chalmers University of Technology](http://www.cse.chalmers.se/edu/course/TDA555/index.html) ([Lectures - YouTube](https://www.youtube.com/playlist?list=PLIQ9jYeUxhgqEnjey91yRTITaXqZQy3Ta))\n- [Ryan O'Donnell Theoretical Computer Science Talks](https://www.youtube.com/playlist?list=PLm3J0oaFux3bLpmu56cDd1PUTp-aJVaTo)\n- [Philip Wadler Haskell lecture recordings](https://www.youtube.com/playlist?list=PLtRG9GLtNcHBv4cuh2w1cz5VsgY6adoc3)\n- [Functional Programming (2021) - University of Nottingham](http://www.cs.nott.ac.uk/~pszgmh/pgp.html)\n- [Functional Programming - University of Edinburgh - 2016-17](http://www.inf.ed.ac.uk/teaching/courses/inf1/fp/)\n- [MOOC - Functional Programming Principles in Scala by Martin Odersky](https://www.youtube.com/user/afigfigueira/playlists?sort=dd&view=50&shelf_id=9)\n- [CS294 - Program Synthesis for Everyone](https://people.eecs.berkeley.edu/~bodik/cs294fa12)\n- [MOOC - Principles of Reactive Programming, Scala - Coursera](https://www.youtube.com/playlist?list=PLMhMDErmC1TdBMxd3KnRfYiBV2ELvLyxN)\n- [Category Theory for Programmers, 2014 - Bartosz Milewski](https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/) ([YouTube](https://www.youtube.com/playlist?list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_))\n- Oregon Programming Languages Summer School (Proof theory, type theory, category theory, verification)\n  - [2012 Lectures](https://www.cs.uoregon.edu/research/summerschool/summer12/curriculum.html)\n  - [2013 Lectures](https://www.cs.uoregon.edu/research/summerschool/summer13/curriculum.html)\n  - [2014 Lectures](https://www.cs.uoregon.edu/research/summerschool/summer14/curriculum.html)\n  - [2015 Lectures](https://www.cs.uoregon.edu/research/summerschool/summer15/curriculum.html)\n  - [2016 Lectures](https://www.cs.uoregon.edu/research/summerschool/summer16/curriculum.php)\n  - [ Latest YT playlists](https://www.youtube.com/@OPLSS/playlists)\n- [Inf1 - Computation and Logic 2015 - University of Edinburgh](http://www.inf.ed.ac.uk/teaching/courses/inf1/cl/)\n- [INFORMATICS 1 - FUNCTIONAL PROGRAMMING - University of Edinburgh](http://www.inf.ed.ac.uk/teaching/courses/inf1/fp/) ([Videos](http://groups.inf.ed.ac.uk/vision/VIDEO/2015/inf1fp.htm))\n- [Compiler Design - IISC Bangalore](https://nptel.ac.in/courses/106108052/)\n- [Compiler Design - IIT Kanpur](https://nptel.ac.in/courses/106104123/)\n- [Principles of Programming Languages - IIT Delhi](https://nptel.ac.in/courses/106102067/)\n- [Principles of Compiler Design - IISC Bangalore](https://nptel.ac.in/courses/106108113/)\n- [Functional Programming in Haskell - IIT Madras](https://nptel.ac.in/courses/106106137/)\n- [Theory of Computation - IIT Kanpur](https://nptel.ac.in/courses/106104148/)\n- [Theory of Automata, Formal Languages and Computation - IIT Madras](https://nptel.ac.in/courses/106106049/)\n- [Theory of Computation - IIT Kanpur](https://nptel.ac.in/courses/106104028/)\n- [Logic for CS - IIT Delhi](https://nptel.ac.in/courses/106102013/)\n- [Principles of Compiler Design - Swarthmore College](https://www.cs.swarthmore.edu/~jpolitz/cs75/s16/index.html)\n- [Undergrad Complexity Theory at CMU](https://www.youtube.com/playlist?list=PLm3J0oaFux3YL5vLXpzOyJiLtqLp6dCW2)\n- [Graduate Complexity Theory at CMU](https://www.youtube.com/playlist?list=PLm3J0oaFux3b8Gg1DdaJOzYNsaXYLAOKH)\n- [Great Ideas in Theoretical Computer Science at CMU](https://www.youtube.com/playlist?list=PLm3J0oaFux3aafQm568blS9blxtA_EWQv) \n  - [Another link](https://www.cs251.com/)\n- [Analysis of Boolean Functions at CMU](https://www.youtube.com/playlist?list=PLm3J0oaFux3YypJNaF6sRAf2zC1QzMuTA)\n- [Theoretical Computer Science (Bridging Course)(Tutorial) - SS 2015](http://ais.informatik.uni-freiburg.de/teaching/ss15/bridging/)\n- [Languages & Translators - UCLouvain LINFO2132](https://norswap.com/compilers/)\n- [Compiler Design by Sorav Bansal](https://www.youtube.com/playlist?list=PLf3ZkSCyj1tf3rPAkOKY5hUzDrDoekAc7)\n- [OCaml Programming: Correct + Efficient + Beautiful](https://www.youtube.com/playlist?list=PLre5AT9JnKShBOPeuiD9b-I4XROIJhkIU)\n- [Columbia IEOR E4004 Introduction to Operations Research: Deterministic Models summer 2005, by Jay Sethuraman](https://www.youtube.com/playlist?list=PLIygTcviGPKCVGq8cQ9MCBEm5wVXGsDpw)\n- [Columbia IEOR E4106 Introduction to Operations Research: Stochastic Models spring 2005, by Ward Whitt](https://www.youtube.com/playlist?list=PLIygTcviGPKDJMIOWQcnSSzKDFOG_dF4r)\n- [Columbia ELEN E6711 Stochastic Models in Information Systems fall 2005, by Yuliy Barsyhnikov](https://www.youtube.com/playlist?list=PL682UO4IMem9dvI-8vjxlPkM5onW9WoIp)\n- [Columbia ELEN E6717 Information Theory fall 2003, by Vittorio Castelli](https://www.youtube.com/playlist?list=PL682UO4IMem_IUZIFzlJi8vCTtS-Xi8eY)\n- [University of Washington EE514A/EE515A - Information Theory I/II fall 2013, by Jeff Bilmes](https://www.youtube.com/playlist?list=PLFze15KrfxbGsPDYxeLyeYorlHSBsTPv0)\n- [CMU 15 150 Principles of Functional Programming summer 2023, by Brandon Wu](https://www.youtube.com/playlist?list=PLsydD1kw8jng2t2G8USQNLz0faYZetPnH)\n- [CMU 21 738 Extremal Combinatorics spring 2020, by Po-Shen Loh](https://www.youtube.com/playlist?list=PLgTkKBA6LRqaGKITvQS1QuIBoEbOVwFTm)\n- [JHU Domain-Specific Languages (DSL) Class (Summer 2018)](https://www.youtube.com/playlist?list=PLW-6wqFEcgTqHMXV_8jI43QLkCv8VgqLk)\n- [Spring 2019 - Probabilistically Checkable and Interactive Proof Systems (Alessandro Chiesa)](https://www.youtube.com/playlist?list=PLkFD6_40KJIyWWtxCPBHwGsrutjvwM5_U)\n- [Algebraic Coding Theory - Stanford University](https://www.youtube.com/playlist?list=PLkvhuSoxwjI_UudECvFYArvG0cLbFlzSr)\n- [CS60094 Computational Number Theory](https://www.youtube.com/playlist?list=PLG63srgJBCAiOJ0hGikoiTq0CsUg_OGKu)\n\n------------------------------\n\n### Embedded Systems\n\n- [EE319K Embedded Systems - UT Austin](http://users.ece.utexas.edu/~valvano/Volume1/E-Book/VideoLinks.htm)\n- [EE445L Embedded Systems Design Lab, Fall 2015, UTexas](https://www.youtube.com/playlist?list=PLyg2vmIzGxXGBxFu8nvX3KBadSdsNAvbA)\n- [CS149 Introduction to Embedded Systems - Spring 2011 - UCBerkeley](https://youtube.com/playlist?list=PLu0nzW8Es1x0RIvuWdw1Diez2Clk8xAX5)\n- [CSE/ECE 474 Introduction to Embedded Systems - University of Washington](https://courses.cs.washington.edu/courses/cse474/23sp/) ([Lectures - YouTube-Spring 21](https://www.youtube.com/playlist?list=PLyB1_dMg8sy8W2EMtSUymI3KpAhXBQOlT))\n- [ECE 4760 Designing with Microcontrollers Fall 2016, Cornell University](http://people.ece.cornell.edu/land/courses/ece4760/) ([Lectures - Youtube](https://www.youtube.com/playlist?list=PLKcjQ_UFkrd4I5WOIxHEYZ7iY04lj15Ez))\n- [ECE 5760 - Advanced Microcontroller Design and system-on-chip, Spring 2016 - Cornell University](http://people.ece.cornell.edu/land/courses/ece5760/)\n- [Internet of Things by Prof. Dr.-Ing. Dietmar P. F. M√∂ller](https://video.tu-clausthal.de/vorlesung/408.html)\n- [CSE 351 - The Hardware/Software Interface, Spring 16 - University of Washington](https://courses.cs.washington.edu/courses/cse351/16sp/videos.html) ([Coursera](http://academictorrents.com/details/f1384286c8581bffba11e378fdb37608e649d82a))\n- [ECE 5030 - Electronic Bioinstrumentation, Spring 2014 - Cornell University](http://people.ece.cornell.edu/land/courses/ece5030/)\n- [ECE/CS 5780/6780 - Embedded Systems Design, Spring 14 - University of Utah](https://www.youtube.com/playlist?list=PLQefpK95HyFmao3zi-WDOMkeSev-Je5dE)\n- [EECS 373 - Introduction to Embedded System Design - University of Michigan](https://www.eecs.umich.edu/courses/eecs373/lectures.html) ([Lectures - YouTube-Fall 24](https://www.youtube.com/playlist?list=PLDe8F9fr1j_QULxa7xCozweLKYI4cXun4)) ([Lectures - YouTube-Fall 23](https://www.youtube.com/playlist?list=PLDe8F9fr1j_R2ljCeIq2FOLHaeZ6tBV_o))\n- [Embedded Systems Class - Version 1 - 2011 - UNCC](https://www.youtube.com/playlist?list=PLE4462C1C306E2EB2)\n- [Embedded Systems using the Renesas RX63N Processor - Version 3 - UNCC](https://www.youtube.com/playlist?list=PLPIqCiMhcdO5gxLJWt_hY5CPMzqg75IU5)\n- [Software Engineering for Embedded Systems (WS 2011/12) - HPI University of Potsdam](https://www.tele-task.de/series/864/)\n- [Embedded Software Testing - IIT Madras](https://nptel.ac.in/courses/117106112/)\n- [Embedded Systems - IIT Delhi](https://nptel.ac.in/courses/108102045/)\n- [Embedded Systems Design - IIT Kharagpur](https://nptel.ac.in/courses/106105159/)\n- [ARM Based Development - IIT Madras](https://nptel.ac.in/courses/117106111/)\n- [Software Engineering for Self Adaptive Systems - iTunes - HPI University of Potsdam](https://itunes.apple.com/us/itunes-u/software-engineering-for-self/id993578475)\n- [EE260 Embedded Systems by Robert Paz](https://www.youtube.com/playlist?list=PLnvE9iJk1wvib_pdUPdQGYZrkrmg9mf__)\n- [IoT Summer School](https://www.youtube.com/playlist?list=PLHih6DnKQaoYQ5PIT3Tp-UrqUguDYWYQu)\n- [ECSE 421 - Embedded Systems - McGill](http://www.cim.mcgill.ca/~jer/courses/es/)\n- [NOC:Advanced IOT Applications - IISc Bangalore](https://nptel.ac.in/courses/108/108/108108123/)\n- [NOC:Design for internet of things - IISc Bangalore](https://nptel.ac.in/courses/108/108/108108098/)\n\n------------------------------\n\n### Real time system evaluation\n\n- [Performance evaluation of Computer systems - IIT Madras](https://nptel.ac.in/courses/106/106/106106048/)\n- [Real Time systems - IIT Karaghpur](https://nptel.ac.in/courses/106/105/106105036/)\n- [EE 380 Colloquium on Computer Systems - Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rMWw6rRoeSpkiseTHzWj6vu)\n- [System storages - IISc Bangalore](https://nptel.ac.in/courses/106/108/106108058/)\n- [High Performance Computing - IISC Bangalore](https://www.youtube.com/playlist?list=PL2F82ECDF8BB71B0C)\n- [2023 High Performance Computing Course Prof Dr - Ing Morris Riedel](https://www.youtube.com/playlist?list=PLmJwSK7qduwUBwrFn3SY8vi4AYa2rVTWH) ([2022](https://www.youtube.com/playlist?list=PLmJwSK7qduwWyqcSEB45HOyxq--z8njix))\n- [High Performance Computing | Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPk8NaXIiFQXWK6VPnrtMRXC)\n- [UCLA Stats 205 Hierarchical Linear Models spring 2024, by Jingyi Jessica Li](https://www.youtube.com/playlist?list=PLAYxx7zX5F1O2HbRr4gORnscbM9EszYbK)\n- [UF EML 6934 Optimal Control spring 2012, by Anil V. Rao](https://www.youtube.com/playlist?list=PLIygTcviGPKBCJ9JyHfBi4ftc9FDCtaBc)\n- [Real-World Algorithms for IoT and Data Science - UIUC](https://rrc-uiuc.notion.site/Real-World-Algorithms-for-IoT-and-Data-Science-74d8f612f74a4c1689760dafa31ef93d)\n\n------------------------------\n\n### Computer Organization and Architecture\n\n- **Computer Organization**\n  - [How Computers Work - Aduni](http://aduni.org/courses/hcw/index.php?view=cw)\n  - [CS 61C - Machine Structures, UC Berkeley Spring 2015](http://www.infocobuild.com/education/audio-video-courses/computer-science/cs61c-spring2015-berkeley.html) \n  - [6.004 - Computation Structures Spring 2013, MIT](https://www.youtube.com/playlist?list=PLrRW1w6CGAcXbMtDFj205vALOGmiRc82-)\n  - [CS/ECE 3810 Computer Organization, Fall 2015, , University of Utah](http://www.cs.utah.edu/~rajeev/cs3810/) ([YouTube](https://www.youtube.com/playlist?list=PLm7BxCUdWqZzjZ-jRe73KUfj2GsSS2FPy))\n  - [Digital Computer Organization - IIT Kharagpur](https://nptel.ac.in/courses/117105078/)\n  - [Computer Organization - IIT Madras](https://nptel.ac.in/courses/106106092/)\n  - [CS-224 - Computer Organization, 2009-2010 Spring, Bilkent University](http://video.bilkent.edu.tr/course_videos.php?courseid=16) ([YouTube playlist](https://www.youtube.com/playlist?list=PLhwVAYxlh5dvB1MkZrcRZy6x_a2yORNAu))\n  - [INFORMATICS 2C - INTRODUCTION TO COMPUTER SYSTEMS (AUTUMN 2016) - University of Edinburgh](http://groups.inf.ed.ac.uk/vision/VIDEO/2014/inf2c-cs.htm)\n- **Computer Architecture**\n  - [18-447 - Introduction to Computer Architecture, CMU](http://www.ece.cmu.edu/~ece447/s15/doku.php?id=schedule) ([Lectures - YouTube - Fall 15](https://youtube.com/playlist?list=PL5PHm2jkkXmi5CxxI7b3JCL1TWybTDtKq))\n  - [CSEP 548 - Computer Architecture Autumn 2012 - University of Washington](https://courses.cs.washington.edu/courses/csep548/12au/video/index.html)\n  - [CS/ECE 6810 Computer Architecture, Spring 2016, University of Utah](http://www.cs.utah.edu/~rajeev/cs6810/) ([YouTube](https://www.youtube.com/playlist?list=PL8EC1756A7B1764F6))\n  - [MOOC - Computer Architecture, David Wentzlaff - Princeton University/Coursera](http://academictorrents.com/details/53bae6d22f3b6e692673f9335e0a0198c1618426)\n  - [Computer Architecture - ETH Z√ºrich - Fall 2019](https://safari.ethz.ch/architecture/fall2019/doku.php?id=schedule)\n  - [Digital Circuits and Computer Architecture - ETH Zurich - Spring 2017](https://www.youtube.com/playlist?list=PL5Q2soXY2Zi-IXWTT7xoNYpst5-zdZQ6y)\n  - [Computer Architecture - IIT Delhi](https://nptel.ac.in/courses/106102062/)\n  - [Computer Architecture - IIT Kanpur](https://nptel.ac.in/courses/106104122/)\n  - [Computer Architecture - IIT Madras](https://nptel.ac.in/courses/106106134/)\n  - [High Performance Computer Architecture - IIT Kharagpur](https://nptel.ac.in/courses/106105033/)\n  - [BE5B35APO - Computer Architectures, Spring 2022, CTU - FEE](https://cw.fel.cvut.cz/b212/courses/b35apo/en/lectures/start) ([YouTube - Spring 2022](https://www.youtube.com/playlist?list=PLQL6z4JeTTQnTrML7HgagbjdpCtvdyu0M)) ([RISC-V simulator - QtRvSim](https://comparch.edu.cvut.cz/))\n  - [CS773: Computer Architecture for Performance and Security - IIT Bombay](https://www.youtube.com/playlist?list=PLw6vmiIQrilQ-KhbMAMeh9_eddYjHRjb6)\n  - [COL718 - Architecture of High Performance Computers - IIT Delhi](https://www.cse.iitd.ac.in/~srsarangi/courses/2020/col_718_2020/index.html)\n  - [CS 695: Virtualization and Cloud Computing - IIT Bombay -Spring 2021](https://www.cse.iitb.ac.in/~cs695/)\n- **Parallel Computer Architecture**\n  - [15-418 - Parallel Computer Architecture and Programming, CMU](http://15418.courses.cs.cmu.edu/spring2015/) ([Lecture Videos](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22a5862643-2416-49ef-b46b-13465d1b6df0%22))\n  - [CS 267 Applications of Parallel Computers, Spring 18 - UC Berkeley](https://sites.google.com/lbl.gov/cs267-spr2018/) ([YouTube-Spring 18](https://www.youtube.com/playlist?list=PLkFD6_40KJIx1CL7aIN9BwFL_sttEzfQ7)) ([Notes-Spring 16](https://people.eecs.berkeley.edu/~demmel/cs267_Spr16/)) ([YouTube-Spring 16](https://www.youtube.com/playlist?list=PLkFD6_40KJIzSfxr35ZT59-LZcibZmfp2))\n  - [MOOC - Heterogeneous Parallel Programming - Coursera](http://academictorrents.com/details/8903d0871c652b96c7b29db738cea76902d65888)\n  - [ECE 498AL - Programming Massively Parallel Processors](https://nanohub.org/resources/7225)\n  - [Parallel Computing - IIT Delhi](https://nptel.ac.in/courses/106102114/)\n  - [Parallel Architectures 2012/13- University of Edinburgh](http://groups.inf.ed.ac.uk/vision/VIDEO/2012/pa.htm)\n- **Digital Systems Design**\n  - [ELEC2141 Digital Circuit Design, UNSW](https://www.youtube.com/playlist?list=PLB52B8F4E464CEEF7)\n  - [Digital Systems Design - IIT Kharagpur](https://nptel.ac.in/courses/117105080/)\n  - [Digital Design Course - 2015 - UNCC](https://www.youtube.com/playlist?list=PLPIqCiMhcdO7bBmieyG5u41x2Ogcn67Bs)\n- [CS1 - Higher Computing - Richard Buckland UNSW](https://www.youtube.com/playlist?list=PL6B940F08B9773B9F)\n- [MOOC - From NAND to Tetris - Building a Modern Computer From First Principles](https://www.nand2tetris.org/) ([YouTube](https://www.youtube.com/playlist?list=PLNMIACtpT9BfztU0P92qlw8Gd4vxvvfT1))\n- [System Validation, TU Delft](https://ocw.tudelft.nl/courses/system-validation/)\n- [High Performance Computing - IISC Bangalore](https://nptel.ac.in/courses/106108055/)\n- [Introduction to ARM - Open SecurityTraining](https://www.youtube.com/playlist?list=PLUFkSN0XLZ-n91t_AX5zO007Giz1INwPd)\n- [Intro x86 (32 bit) - Open SecurityTraining](https://www.youtube.com/playlist?list=PL038BE01D3BAEFDB0)\n- [Intermediate x86 (32 bit) - Open SecurityTraining](https://www.youtube.com/playlist?list=PL8F8D45D6C1FFD177)\n- [Design of Digital Circuits - ETH Z√ºrich - Spring 2019](https://www.youtube.com/playlist?list=PL5Q2soXY2Zi8J58xLKBNFQFHRO3GrXxA9)\n- [Onur Mutlu @ TU Wien 2019 - Memory Systems](https://www.youtube.com/playlist?list=PL5Q2soXY2Zi_gntM55VoMlKlw7YrXOhbl)\n- [Memory Systems Course - Technion, Summer 2018](https://www.youtube.com/playlist?list=PL5Q2soXY2Zi-IymxXpH_9vlZCOeA7Yfn9)\n- [UC Berkeley EECS16A Designing Information Devices and Systems I summer 2020, by Grace Kuo, Panos Zarkos, Urmita Sikder](https://www.youtube.com/playlist?list=PL682UO4IMem9_svw6nCsGOaDZaYSjpgcB)\n- [UC Berkeley EECS 16B Designing Information Devices and Systems II fall 2020, by Seth Sanders, Miki Lustig](https://www.youtube.com/playlist?list=PL682UO4IMem_QO6og7qXyvjMUHXNI7Hqs)\n- [EE 503 - Statistical Signal Processing and Modeling - Fall 2020 - METU](https://ocw.metu.edu.tr/course/view.php?id=350) ([YouTube](https://www.youtube.com/playlist?list=PLhAAV-jkgAdx8wIshnGR6GZeJSXXC6cxl))\n- [ELEN E4810 - DIGITAL SIGNAL PROCESSING - Fall 2013 - Columbia](https://www.ee.columbia.edu/~dpwe/e4810/outline.html)\n- [ELEN E4896 - MUSIC SIGNAL PROCESSING - Spring 2016 - Columbia](https://www.ee.columbia.edu/~dpwe/e4896/outline.html)\n- [Columbia ELEN E6820 Speech and Audio Processing spring 2006, by Dan Ellis](https://www.youtube.com/playlist?list=PL682UO4IMem8IpOKncIUSEFsYWoJyS5ks)\n- [CMU 11 751 / 18 781 Speech Recognition and Understanding fall 2023, by Shinji Watanabe](https://www.youtube.com/playlist?list=PLfVqr2l0FG-tW8d5ZSz-_tCgQed_F1ndb) ([Fall 2022](https://www.youtube.com/playlist?list=PLfVqr2l0FG-u7chWKPQMDoT0o-I2ejxeK))\n- [CMU 11 492 Speech Processing fall 2021, by Alan W. Black](https://www.youtube.com/playlist?list=PL682UO4IMem9InUp3CZHL4g7IwzfKXe3c)\n\n------------------------------\n\n### Security\n\n- [Internet Security (WT 2018/19) - HPI University of Potsdam](https://www.tele-task.de/series/1227/)\n- [6.1600 Foundations of Computer Security - MIT Fall 2023](https://61600.csail.mit.edu/2023/)\n- [6.858 Computer Systems Security - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-858-computer-systems-security-fall-2014/video_galleries/video-lectures/)\n- [CS 253 Web Security - Stanford University](https://www.youtube.com/playlist?list=PL1y1iaEtjSYiiSGVlL1cHsXN_kvJOOhu-)\n- [CS 161: Computer Security, UC Berkeley](https://fa23.cs161.org/) ([Videos](https://www.youtube.com/playlist?list=PLfBkt1-_BHX_VxOWlmstguFxojSN742vz)) ([Spring 2025](https://sp25.cs161.org/))\n- [6.875 - Cryptography - Fall 2021 - MIT](https://mit6875.github.io/fall2021.html) ([Spring 2018](https://www.youtube.com/playlist?list=PL6ogFv-ieghe8MOIcpD6UDtdK-UMHG8oH))\n- [CSEP590A - Practical Aspects of Modern Cryptography, Winter 2011 - University of Washington](https://courses.cs.washington.edu/courses/csep590a/11wi/) ([Videos](https://courses.cs.washington.edu/courses/csep590a/11wi/video/))\n- [CS461/ECE422 - Computer Security - University of Illinois at Urbana-Champaign](https://courses.engr.illinois.edu/cs461/sp2016/) ([Videos](https://recordings.engineering.illinois.edu:8443/ess/portal/section/8a560718-345a-417a-b665-6bd375a71ee2))\n- [Introduction to Cryptography, Christof Paar - Ruhr University Bochum, Germany](https://www.youtube.com/playlist?list=PLwJWuZfL_Ga2KJrTf9hOIgAQWkSpn9RNm)\n- [ECS235B Foundations of Computer and Information Security - UC Davis](https://itunes.apple.com/us/itunes-u/computer-science-foundations/id389259109)\n- [CIS 4930/ CIS 5930 - Offensive Computer Security, Florida State University](http://www.cs.fsu.edu/~redwood/OffensiveComputerSecurity/lectures.html)\n- [Introduction to Information Security I - IIT Madras](https://nptel.ac.in/courses/106106129/)\n- [Information Security - II - IIT Madras](https://nptel.ac.in/courses/106106141/)\n- [Introduction to Cryptology - IIT Roorkee](https://nptel.ac.in/courses/106107155/)\n- [Cryptography and Network Security - IIT Kharagpur](https://nptel.ac.in/courses/106105031/)\n- [18-636 Browser Security, Stanford](https://courseware.stanford.edu/pg/courses/334553/18636-spring-2013)\n- [Internet Security - Weaknesses and Targets (WT 2015/16)](https://www.tele-task.de/archive/series/overview/1084/) ([WT 2012/13](https://www.tele-task.de/archive/series/overview/921/) ([YouTube](https://www.youtube.com/playlist?list=PLVWVhkyKd-7taP50fB9PeZ2W_EPTOLD8o)))\n- [IT Security, Steven Gordon - Thammasat University, Thailand](https://www.youtube.com/playlist?list=PLvifRcqOOwF9-XSGfm-3uA9DfF7plasCF)\n- [Security and Cryptography, Steven Gordon - Thammasat University, Thailand](https://www.youtube.com/playlist?list=PLvifRcqOOwF-z2sfMb3w0uQzd7PfaLFlU)\n- [MOOC - Cryptography - Coursera](https://www.youtube.com/playlist?list=PL58C6Q25sEEHXvACYxiav_lC2DqSlC7Og)\n- [MOOC - Intro to Information Security - Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkG-z00NybuIyDqT4sRh3ak)\n- [ICS 444 - Computer & Network Security](https://www.youtube.com/playlist?list=PLciCszvvRCTV09wIXJwiPmYF7thHiq4En)\n- [Privacy and Security in Online Social Networks - IIT Madras](https://nptel.ac.in/courses/106106146/)\n- [Malware Dynamic Analysis - Open SecurityTraining](http://opensecuritytraining.info/MalwareDynamicAnalysis.html) ([YouTube](https://www.youtube.com/playlist?list=PLUFkSN0XLZ-kqYbGpY4Gt_VATd4ytQg-Z))\n- [CSN09112 - Network Security and Cryptography - Bill Buchanan - Edinburgh Napier](https://asecuritysite.com/csn09112)\n- [CSN10107 - Security Testing and Network Forensics - Bill Buchanan - Edinburgh Napier](https://asecuritysite.com/csn10107)\n- [CSN11123 - Advanced Cloud and Network Forensics - Bill Buchanan - Edinburgh Napier](https://asecuritysite.com/csn11123)\n- [CSN11117 - e-Security - Bill Buchanan - Edinburgh Napier](https://asecuritysite.com/csn11117)\n- [CSN08704 - Telecommunications - Bill Buchanan - Edinburgh Napier](https://asecuritysite.com/csn08704)\n- [CSN11128 - Incident Response and Malware Analysis - Bill Buchanan - Edinburgh Napier](https://asecuritysite.com/CSN11128)\n- [Internet Security for Beginners by Dr. Christoph Meinel - HPI](https://www.youtube.com/playlist?list=PLoOmvuyo5UAdsi-IacgZJQF1MRw0Ee-HH)\n- [Offensive Security and Reverse Engineering, Chaplain University by Ali Hadi](https://www.youtube.com/playlist?list=PLCS2zI95IiNybAAQ0HL88YzwRpLXje5y6)\n- [Computer Systems Security, Fall 2020, Vinod Ganapathy, IISc Bangalore](https://www.csa.iisc.ac.in/~vg/teaching/SecurityLectures/)\n- [UC Berkeley CS 161 Computer Security, Summer 2021, by Nicholas Ngai and Peyrin Kao](https://www.youtube.com/playlist?list=PLIygTcviGPKAPoe_0mUsXYaxZfsFyQyFE)\n- [UCSD CS291A Differential Privacy Fall 2021, by Yu-Xiang Wang](https://cseweb.ucsd.edu/~yuxiangw/classes/DPCourse-2021Fall/) ([Youtube](https://www.youtube.com/playlist?list=PLTN4aNO9NiB7UiBbSFznHRSkdieBc0-sk))\n- [Zero Knowledge Proofs MOOC, UC Berkeley RDI Center on Decentralization & AI](https://www.youtube.com/playlist?list=PLS01nW3Rtgor_yJmQsGBZAg5XM4TSGpPs)\n- [Multimedia Security, Fall 2017, FAU](https://www.fau.tv/course/id/786)\n\n------------------------------\n\n### Computer Graphics\n\n- [ECS 175 - Computer Graphics, Fall 2009 - UC Davis](https://itunes.apple.com/us/itunes-u/computer-graphics-fall-2009/id457893733?mt=10)\n- [6.837 - Computer Graphics - Spring 2017 - MIT](https://www.youtube.com/playlist?list=PLkHIj5SCfn3_PCotoqTetMpJc_jkpkgLt)\n- [6.838 - Shape Analysis - Spring 2017- MIT](https://www.youtube.com/playlist?list=PLkHIj5SCfn3-FeWqD3xeOZWP2kQYY654o)\n- [Introduction to Computer Graphics - IIT Delhi](https://nptel.ac.in/courses/106102065/)\n- [Computer Graphics - IIT Madras](https://nptel.ac.in/courses/106106090/)\n- [Computer Graphics 2012, Wolfgang Huerst, Utrecht University](https://www.youtube.com/playlist?list=PLDFA8FCF0017504DE)\n- [CS 5630/6630 - Visualization, Fall 2016, University of Utah](http://dataviscourse.net/2016/index.html) ([Lectures - Youtube](https://www.youtube.com/playlist?list=PLbuogVdPnkCpQY3miQpTJtnHgCLze2lr0))\n- [Advanced Visualization UC Davis](https://www.youtube.com/playlist?list=PLslgisHe5tBNnySlj9TlL-n-4jNEK-xgi)\n- [Computer Graphics Fall 2011, Barbara Hecker](https://www.youtube.com/playlist?list=PL9C949E9F19381E61)\n- [Ray Tracing for Global Illumination, UCDavis](https://www.youtube.com/playlist?list=PLslgisHe5tBPckSYyKoU3jEA4bqiFmNBJ)\n- [Rendering / Ray Tracing Course, SS 2015 - TU Wien](https://www.youtube.com/playlist?list=PLujxSBD-JXgnGmsn7gEyN28P1DnRZG7qi)\nintroduction/id389259246))\n- [Computational Geometry - IIT Delhi](https://nptel.ac.in/courses/106102011/)\n- [CS 468 - Differential Geometry for Computer Science - Stanford University](http://graphics.stanford.edu/courses/cs468-13-spring/schedule.html) ([Lecture videos](https://www.youtube.com/playlist?list=PL_deCdukpyu1rdH85XsEEREbpoqEauiJl))\n- [CMU 15-462/662: Computer Graphics](http://15462.courses.cs.cmu.edu/fall2020/)\n- [UC Berkeley CS184/284A Computer Graphics and Imaging Spring 2022, by Ren Ng](https://cs184.eecs.berkeley.edu/sp22) ([YouTube playlist](https://www.youtube.com/playlist?list=PLIygTcviGPKABEUa7EJzO8tgYRz120EpP))\n- [CS 15-458/858: Discrete Differential Geometry - Carnegie Mellon University - Spring 2021](https://brickisland.net/DDGSpring2021/)\n- [IN2124: Basic Mathematical Tools for Imaging and Visualization - TUM - Winter 2021](https://live.rbg.tum.de/?year=2021&term=W&slug=GMMfIuV&view=3)\n\n------------------------------\n\n### Image Processing and Computer Vision\n\n- [Digital Image Processing - IIT Kharagpur](https://nptel.ac.in/courses/117105079/)\n- [CS 543 - Computer Vision ‚Äì Spring 2017](https://courses.engr.illinois.edu/cs543/sp2017/) ([Recordings](https://echo360.org/section/283b0471-3d9f-4efb-9c51-bc00e778735e/home))\n- [CAP 5415 - Computer Vision - University of Central Florida](https://www.crcv.ucf.edu/courses/cap5415-fall-2012/)([Video Lectures](https://www.youtube.com/playlist?list=PLd3hlSJsX_ImKP68wfKZJVIPTd8Ie5u-9))\n- [EE637 - Digital Image Processing I - Purdue University](https://engineering.purdue.edu/~bouman/ece637/) ([Videos - Sp 2011](https://www.youtube.com/user/ModelBasedImaging),[Videos - Sp 2007](https://engineering.purdue.edu/~bouman/ece637/lectures/lectures07/))\n- [Computer Vision I: Variational Methods - TU M√ºnchen](https://vision.in.tum.de/teaching/ws2015/vmcv2015) ([YouTube](https://www.youtube.com/playlist?list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI))\n- [Computer Vision II: Multiple View Geometry (IN2228), SS 2016 - TU M√ºnchen](https://vision.in.tum.de/teaching/ss2016/mvg2016) ([YouTube](https://www.youtube.com/playlist?list=PLTBdjV_4f-EJn6udZ34tht9EVIW7lbeo4))\n- [EENG 512/CSCI 512 - Computer Vision - Colorado School of Mines](https://www.youtube.com/playlist?list=PL4B3F8D4A5CAD8DA3)\n- [Computer Vision for Visual Effects - RPI](https://www.ecse.rpi.edu/~rjradke/cvfxcourse.html) ([YouTube](https://www.youtube.com/playlist?list=PLuh62Q4Sv7BUJlKlt84HFqSWfW36MDd5a))\n- [Introduction to Image Processing - RPI](https://www.ecse.rpi.edu/~rjradke/improccourse.html) ([YouTube](https://www.youtube.com/playlist?list=PLuh62Q4Sv7BUf60vkjePfcOQc8sHxmnDX))\n- [CAP 6412 - Advanced Computer Vision - University of Central Florida](https://www.crcv.ucf.edu/cap6412-spring-2013/)([Video lectures](https://www.crcv.ucf.edu/cap6412-spring-2013/)) ([Spring 2018](https://www.youtube.com/playlist?list=PLd3hlSJsX_ImoNaeX5vFrxogGXTSmS993))\n- [Digital Signal Processing - RPI](https://www.ecse.rpi.edu/~rjradke/dspcourse.html)\n- [UC Berkeley EE 123 Digital Signal Processing fall 2003, by Avideh Zakhor](https://www.youtube.com/playlist?list=PLIygTcviGPKAVZtXnfoe689IBTJ2lNMmi)\n- [UC Berkeley EE 225B Digital Image Processing spring 2006, by Avideh Zakhor](https://www.youtube.com/playlist?list=PLIygTcviGPKAa5Vt6T6Noo8I0VaopzXuH)\n- [Advanced Vision 2014 - University of Edinburgh](http://homepages.inf.ed.ac.uk/rbf/AVINVERTED/main_av.htm)\n- [Photogrammetry Course - 2015/16 - University of Bonn, Germany](https://www.youtube.com/playlist?list=PLgnQpQtFTOGRsi5vzy9PiQpNWHjq-bKN1)\n- [MOOC - Introduction to Computer Vision - Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPnbDacyrK_kB_RUkuxQBlCm)\n- [ECSE-4540 - Intro to Digital Image Processing - Spring 2015 - RPI](https://www.youtube.com/playlist?list=PLuh62Q4Sv7BUf60vkjePfcOQc8sHxmnDX)\n- [Machine Learning for Computer Vision - Winter 2017-2018 - UniHeidelberg](https://www.youtube.com/playlist?list=PLuRaSnb3n4kSQFyt8VBldsQ9pO9Xtu8rY)\n- [High-Level Vision - CBCSL OSU](https://www.youtube.com/playlist?list=PLcXJymqaE9POZaT6UFAUUvrQiVQLfzCLN)\n- [Advanced Computer Vision - CBCSL OSU](https://www.youtube.com/playlist?list=PLcXJymqaE9POnU3bVmCVMmtSXzCpcj28T)\n- [Introduction to Image Processing & Computer Vision - CBCSL OSU](https://www.youtube.com/playlist?list=PLcXJymqaE9PMexHWGgXJVINpr6ajy5vuz)\n- [Machine Learning for Computer Vision - TU Munich](https://www.youtube.com/playlist?list=PLTBdjV_4f-EIiongKlS9OKrBEp8QR47Wl)\n- [Biometrics - IIT Kanpur](https://nptel.ac.in/courses/106104119/)\n- [Quantitative Big Imaging 2019 ETH Zurich](https://www.youtube.com/playlist?list=PLTWuXgjdOrnmXVVQG5DRkVeOIGOcTmCIw)\n- [Multiple View Geometry in Computer Vision](https://www.youtube.com/playlist?list=PLyH-5mHPFffFvCCZcbdWXAb_cTy4ZG3Dj)\n- [Modern C++ Course For CV (2020) - University of Bonn](https://www.ipb.uni-bonn.de/teaching/cpp-2020/lectures)\n- [Photogrammetry 1 Course ‚Äì 2020 - University of Bonn](https://www.ipb.uni-bonn.de/photo1-2020/)\n- [Photogrammetry II Course 2020/21 - University of Bonn](https://www.ipb.uni-bonn.de/photo2-2020/)\n- [3D Computer Vision - National University of Singapore](https://www.youtube.com/playlist?list=PLxg0CGqViygP47ERvqHw_v7FVnUovJeaz)\n- [Diagnostic Medical Image Processing - Fall 2014 - FAU](https://www.fau.tv/course/id/736) ([Fall 2011](https://fau.tv/course/id/123)) ([Fall 2010](https://www.fau.tv/course/id/52)) ([Fall 2009](https://www.fau.tv/course/id/13))\n- [Interventional Medical Image Processing - Spring 2016 - FAU](https://www.fau.tv/course/id/465) ([Spring 2015](https://www.fau.tv/course/id/354)) ([Spring 2012](https://www.fau.tv/course/id/151)) ([Spring 2011](https://www.fau.tv/course/id/105)) ([Spring 2009](https://www.fau.tv/course/id/3))\n- [Advances in Computer Vision - MIT](https://www.scenerepresentations.org/courses/2025/spring/advances-in-cv/)\n------------------------------\n\n### Computational Physics\n\n- [Statistics and Machine Learning for Astronomy](https://www.youtube.com/playlist?list=PLo4wAAMJnA1wDQ2ZmTJCaBYdrXqBWUwT5)\n- [Astronomical data analysis using Python 2021 - NRC IUCAA](https://www.youtube.com/playlist?list=PL3jLiVc5sr3P7Uov0VFsEfwPOEG1rF-FO)\n- [SPARC Workshop on Machine Learning in Solar Physics and Space Weather - CESSI IISER Kolkata](https://www.youtube.com/playlist?list=PLtxxbMktGS8pjURPBXJTAkClnXVE_ZNni)\n- [Data-Driven Methods and Machine Learning in Atmospheric Sciences - IISC](https://www.youtube.com/playlist?list=PLnUDCXHuQXBaGrYSbDMWi2inp7GSe3__8)\n- [Computational Astrophysics - AstroTwinCoLo, 2015](https://www.youtube.com/playlist?list=PLPdkBLbDPtqoHDcjUweIJqe6GKnOz0-Qw)\n- [Astroinformatics 2019 Conference - Caltech](https://m.youtube.com/playlist?list=PL8_xPU5epJdcv2L4MzpzNd6gPyq6glmjc)\n- [Space Science with Python - Astroniz](https://www.youtube.com/playlist?list=PLNvIBWkEdZ2iCc8G9dvx6MQvBruJG-TE8)\n- [Computational Physics Course in Python, Rutgers 2021](https://www.youtube.com/playlist?list=PLXmUYdQdC9IGv61Y1lhGBH0NsDQRdwcJE)\n- [Landau Computational Physics Course](https://www.youtube.com/playlist?list=PLnWQ_pnPVzmJnp794rQXIcwJIjwy7Nb2U)\n- [Statistical Methods and Machine Learning in High Energy Physics](https://www.youtube.com/playlist?list=PL04QVxpjcnjjKDki5FHlKQ8839TGHvj8y)\n- [Physics Informed Machine Learning by Steve Brunton](https://www.youtube.com/playlist?list=PLMrJAkhIeNNQ0BaKuBKY43k4xMo6NSbBa)\n- [Physics-informed machine learning meets engineering seminar series](https://www.youtube.com/playlist?list=PLuD_SqLtxSdW5aasHsFTNw_MrZrtu5tZ3)\n- [Physics Informed Machine Learning Workshop](https://www.youtube.com/playlist?list=PLWL3MaEZQ5I2LYm5BAdLYso5wGe9WMNby)\n- [Jake VanderPlas: Machine learning in Astronomy python tutorial](https://www.youtube.com/playlist?list=PLzWVyeIO6Cmt1cWrzwF2yqW-9j5TgyQaD)\n------------------------------\n\n### Computational Biology\n\n- [ECS 124 - Foundations of Algorithms for Bioinformatics - Dan Gusfield, UC Davis](http://web.cs.ucdavis.edu/~gusfield/cs124videos/videolist.html) ([YouTube](https://www.youtube.com/playlist?list=PL_w_qWAQZtAbh8bHfzXYpdnVKCGCDmmoL))\n- [CSE549 - Computational Biology - Steven Skiena - 2010 SBU](https://www.youtube.com/playlist?list=PLA48145CC64FE7990)\n- [7.32 Systems Biology, Fall 2014 - MIT OCW](https://ocw.mit.edu/courses/physics/8-591j-systems-biology-fall-2014/)\n- [6.802J/ 6.874J Foundations of Computational and Systems Biology - MIT OCW](https://ocw.mit.edu/courses/7-91j-foundations-of-computational-and-systems-biology-spring-2014/video_galleries/video-lectures/)\n- [6.S897 Machine Learning For Healthcare](https://ocw.mit.edu/courses/6-s897-machine-learning-for-healthcare-spring-2019/video_galleries/lecture-videos/)\n- [6.047/6.878 Machine Learning for Genomics Fall 2020 - MIT](https://www.youtube.com/playlist?list=PLypiXJdtIca6dEYlNoZJwBaz__CdsaoKJ)\n- [6.874 MIT Deep Learning in Life Sciences - Spring 2021 - MIT](https://www.youtube.com/playlist?list=PLypiXJdtIca5sxV7aE3-PS9fYX3vUdIOX)\n- [6.047/6.878 Public Lectures on Computational Biology: Genomes, Networks, Evolution - MIT](http://compbio.mit.edu/lectures.html)\n- [Bio 84 - Your Genes and Your Health, Stanford University](https://cmgm.stanford.edu/bio84/)\n- [BioMedical Informatics 231 Computational Molecular Biology, Stanford University](https://cmgm.stanford.edu/biochem218/)\n- [BioMedical Informatics 258 Genomics, Bioinformatics & Medicine, Stanford University](http://biochem158.stanford.edu/)\n- [03-251: Introduction to Computational Molecular Biology - Carnegie Mellon University](https://www.youtube.com/playlist?list=PLUKmtlUTHfBPoI70nVz3C-82N4nznc3Iz)\n- [03-712: Biological Modeling and Simulation - Carnegie Mellon University](https://www.youtube.com/playlist?list=PLUKmtlUTHfBOgpZFmTvsTwkUh2K1RAse-)\n- [MOOC - Bioinformatics Algorithms: An Active Learning Approach - UC San Diego/Coursera](http://bioinformaticsalgorithms.com/videos.htm)\n- [Neural Networks and Biological Modeling - Lecturer: Prof. Wulfram Gerstner - EPFL](http://www.klewel.com/conferences/epfl-neural-networks/)\n- [Video Lectures of Wulfram Gerstner: Computational Neuroscience - EPFL](http://lcn.epfl.ch/~gerstner/VideoLecturesGerstner.html)\n- [An Introduction To Systems Biology](http://www.weizmann.ac.il/mcb/UriAlon/introduction-systems-biology-design-principles-biological-circuits)\n- [Introduction to Bioinformatics, METUOpenCourseWare](https://www.youtube.com/playlist?list=PLuiPz6iU5SQ-PAjlyz4b3EIIQ6dpZ2DE_)\n- [MOOC - Algorithms for DNA Sequencing, Coursera](https://www.youtube.com/playlist?list=PL2mpR0RYFQsBiCWVJSvVAO3OJ2t7DzoHA)\n- [Frontiers of Biomedical Engineering with W. Mark Saltzman - Yale](https://www.youtube.com/playlist?list=PL27E877E8206F196B)\n- [NOC:Computational Systems Biology - IIT Madras](https://nptel.ac.in/courses/102/106/102106068/)\n- [NOC:BioInformatics:Algorithms and Applications - IIT Madras](https://nptel.ac.in/courses/102/106/102106065/)\n- [Data Science and AI for Neuroscience Summer School - Caltech Neuroscience](https://www.youtube.com/playlist?list=PLlPxFwLgTtnfDtq_AO3dd62s33RHtU4bp)\n- [Theoretical and Computational Neuroscience Summer School - 2024 - CNeuro](https://www.youtube.com/playlist?list=PLrAPN1qtMsr9XM_2MqXx2brXBpNit3whQ)\n- [Neuroscience 299: Computing with High-Dimensional Vectors - Fall 2021 - UC Berkeley](https://redwood.berkeley.edu/courses/computing-with-high-dimensional-vectors/)\n- [BIO410/510 Bioinformatics - California State University, Monterey Bay](https://www.youtube.com/playlist?list=PL17NIL2mko8mOPN9W0e4LOjJ2Dkome7ZH)\n- [BIO412: Comparative Genomics - California State University, Monterey Bay](https://www.youtube.com/playlist?list=PL17NIL2mko8nJ1RvfIwtaFnukoWICqS5B)\n- [CENG 465 - Introduction to Bioinformatics (Spring 2020-2021)](https://www.youtube.com/playlist?list=PL0X39D1PSBWPfCPbHb8GC7hoev8SG4Aye)\n- [UCLA Stats M254 Statistical Methods in Computational Biology spring 2024, by Jingyi Jessica Li](https://www.youtube.com/playlist?list=PLAYxx7zX5F1PieIIeSFc7asuKWRYm6nGy)\n- [Cell and Molecular Biology for Engineers  ETH Zurich](https://video.ethz.ch/lectures/d-itet/2011/autumn/227-0945-00L/8e6b12f7-d8cc-4f78-83b1-352876a266d0.html)\n- [Statistical Models in Computational Biology](https://video.ethz.ch/lectures/d-bsse/2018/spring/636-0702-00L/21c63925-cd10-4d56-bac1-b412ed6fe385.html)\n- [ETH Z√ºrich Statistical Models in Computational Biology spring 2018, by Niko Beerenwinkel](https://video.ethz.ch/lectures/d-bsse/2018/spring/636-0702-00L/21c63925-cd10-4d56-bac1-b412ed6fe385.html)\n- [UC Berkeley CS 198-96 Introduction to Neurotechnology fall 2020](https://github.com/neurotech-berkeley/neurotech-course)\n- [MLCB24 - Machine Learning in Computational Biology Fall 2024](https://www.youtube.com/playlist?list=PLypiXJdtIca4gtioEPLIExlAKvu64z7rc)\n- [Introduction to Neural Computation - MIT OCW](https://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-40-introduction-to-neural-computation-spring-2018/)\n- [Data Science for Biologists - Steve Brunton](https://www.youtube.com/playlist?list=PLMrJAkhIeNNQz4BMoGSsN8cbt8pHlokhV)\n- [Big Data and Biological Networks IIT Madras](https://www.youtube.com/playlist?list=PLZ2ps__7DhBapdXdBZInSjonWNAUL6Ycm)\n\n\n------------------------------\n\n### Quantum Computing\n\n- [15-859BB: Quantum Computation and Quantum Information 2018 - CMU](https://www.cs.cmu.edu/~odonnell/quantum18/) ([Youtube](https://www.youtube.com/playlist?list=PLm3J0oaFux3YL5qLskC6xQ24JpMwOAeJz))\n- [Quantum Computation and Information at CMU](https://www.youtube.com/playlist?list=PLm3J0oaFux3YL5qLskC6xQ24JpMwOAeJz)\n- [Ph/CS 219A Quantum Computation - Prof Preskill - Caltech](https://www.youtube.com/playlist?list=PL0ojjrEqIyPy-1RRD8cTD_lF1hflo89Iu)\n- [Quantum Mechanics and Quantum Computation - Umesh Vazirani](https://www.youtube.com/playlist?list=PL74Rel4IAsETUwZS_Se_P-fSEyEVQwni7)\n- [Introduction to quantum computing course 2022 - NYU](https://www.youtube.com/playlist?list=PLo0Vs5tDeRLRIPcJ83SN91M-asGuaa1AD)\n- [Phys 1470 - Foundations of Quantum Computing and Quantum Information - U of Pittsburgh](https://www.youtube.com/playlist?list=PL9KDUYiMK3D5etNeur9HocwcAcfcDtArw)\n- [Introduction to Quantum Computing From a Layperson to a Programmer in 30 Steps (EE225 SJSU)](https://www.youtube.com/playlist?list=PLnK6MrIqGXsJfcBdppW3CKJ858zR8P4eP)\n- [Quantum Computing Hardware and Architecture (EE274 SJSU)](https://www.youtube.com/playlist?list=PLnK6MrIqGXsL1KShnocSdwNSiKnBodpie)\n- [Quantum Physics for Non-Physicists 2021 - ETH Zurich](https://www.youtube.com/playlist?list=PLmE1-ewBrbkiOFq_vMXAww4GDMxDAB3pI) ([2020](https://www.youtube.com/playlist?list=PLmE1-ewBrbkiKoYQU4FawveQfhWU_4MkX))\n- [Introduction to Quantum Computing and Quantum Hardware - Qiskit](https://www.youtube.com/playlist?list=PLOFEBzvs-VvrXTMy5Y2IqmSaUjfnhvBHR)\n- [Understanding Quantum Information and Computation - Qiskit](https://www.youtube.com/playlist?list=PLOFEBzvs-VvqKKMXX4vbi4EB1uaErFMSO)\n- [Lectures in Quantum Computation and Quantum Information (IIT Madras)](https://www.youtube.com/playlist?list=PLqLyTdPNhQZwfLoL4QMeI6scnyH1c__tE)\n- [Quantum Information and Computing by Prof. D.K. Ghosh](https://www.youtube.com/playlist?list=PLq-Gm0yRYwThGmlypvSFQ-kT2rPaXKAZ5)\n- [Quantum Computing by Prof. Debabrata Goswami](https://www.youtube.com/playlist?list=PLq-Gm0yRYwTj7Fs6jyzYa83HErSrpXgPQ)\n- [The Building Blocks of a Quantum Computer: Part 1 - TU Delft](https://ocw.tudelft.nl/courses/building-blocks-quantum-computer-part-1/)\n- [The Building Blocks of a Quantum Computer: Part 2 - TU Delft](https://ocw.tudelft.nl/courses/building-blocks-quantum-computer-part-2/)\n- [Quantum Cryptography - TU Delft](https://ocw.tudelft.nl/courses/quantum-cryptography/)\n- [Introduction to Quantum Information](https://zhenyucai.com/post/intro_to_qi/)\n- [Quantum Computing for Everyone -- Part 1](https://www.youtube.com/playlist?list=PLfOgkuiMs5qApXtgIMREPicgbYIGjbf8e) ([Part 2](https://www.youtube.com/playlist?list=PLfOgkuiMs5qB-0J07mphWZ19j9Gll33ZU))\n- [Quantum Computer Systems ‚Äì UChicago](https://www.youtube.com/playlist?list=PLfOgkuiMs5qCa8BUrFMumyvPqeoOL-iu8)\n- [Quantum computing for the determined - Michael Nielsen](https://www.youtube.com/playlist?list=PL1826E60FD05B44E4)\n- [Quantum Computing](https://www.youtube.com/playlist?list=PLxP0p--aBHmIe--9rczWe4AZmw03e2bz0)\n- [Advanced Topics in Quantum Info Th.](https://www.youtube.com/playlist?list=PLmE1-ewBrbkicLl3pp14OmxRWSfdNYfmh)\n- [Theory of Quantum Communication - University of Waterloo - Fall 2020](https://www.math.uwaterloo.ca/~wcleung/co781-f2020.html)\n- [Intro to Quantum Computing - Nathan Wiebe](https://www.youtube.com/channel/UCYpyuTbBhQ2FvTmVLL6b3zA/videos)\n- [COMS 4281 - Introduction to Quantum Computing -Columbia University](http://www.henryyuen.net/classes/spring2021/)\n- [Introduction to Quantum Information Science](https://www.youtube.com/playlist?list=PLkespgaZN4gmu0nWNmfMflVRqw0VPkCGH) ([Online book](https://qubit.guide/using-the-e-book), [PDF](https://qubit.guide/qubit_guide.pdf))\n- [A practical introduction to Quantum Computing: from Qubits to Quantum Machine Learning: CERN](https://www.youtube.com/playlist?list=PLu0nzW8Es1x3gEeqUm_32QbhmGHHUXSVo)\n- [PSI 2018/2019 - Quantum Information Review (Gottesman)](https://pirsa.org/C19010)\n------------------------------\n\n### Robotics and Control\n\n- [ROB 101: Computational Linear Algebra - University of Michigan](https://github.com/michiganrobotics/rob101/tree/main/Fall%202021) ([Youtube - Fall 2021](https://www.youtube.com/playlist?list=PLdPQZLMHRjDJ5d_dE4FeOviv0gRe4UYsB))\n- [ROB 102: Introduction to AI and Programming - University of Michigan](https://robotics102.github.io/)\n- [ROB 311: How to Build Robots and Make Them Move - University of Michigan](https://www.youtube.com/playlist?list=PLdPQZLMHRjDIWDJDjiBKjFe7ETD_rssB9)\n- [ROB 320: Robot Operating Systems - University of Michigan](https://autorob.org/)\n- [ROB 501: Mathematics for Robotics - University of Michigan](https://github.com/michiganrobotics/rob501) ([Youtube](https://www.youtube.com/playlist?list=PLdPQZLMHRjDIzO99aE7yAtdOHSVHMXfYH))\n- [ROB 530 MOBILE ROBOTICS at U of Michigan - WINTER 2022 -- Instructor: Maani Ghaffari](https://www.youtube.com/playlist?list=PLdMorpQLjeXmbFaVku4JdjmQByHHqTd1F)\n- [Autorob Winter 2022 - University of Michigan](https://m.youtube.com/playlist?list=PLf_SmXJixhnWMMU6_xYW7iS08-7h9kENY)\n- [DeepRob Winter 2023 - University of Michigan](https://m.youtube.com/playlist?list=PLf_SmXJixhnXoMs0Qvxe500BrjfbIOwSg)\n- [CS 223A - Introduction to Robotics, Stanford University](https://see.stanford.edu/Course/CS223A)\n- [6.832 Underactuated Robotics - MIT OCW](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-832-underactuated-robotics-spring-2009/)\n- [CS287 Advanced Robotics at UC Berkeley Fall 2019 -- Instructor: Pieter Abbeel](https://www.youtube.com/playlist?list=PLwRJQ4m4UJjNBPJdt8WamRAt4XKc639wF)\n- [CS 287 - Advanced Robotics, Fall 2011, UC Berkeley](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa11/) ([Videos](http://rll.berkeley.edu/cs287/lecture_videos/))\n- [CMU 16-715 Robot Dynamics 2022 - CMU](https://www.youtube.com/playlist?list=PLZnJoM76RM6ItAfZIxJYNKdaR_BobleLY)\n- [CMU 16-745 Optimal Control 2024 - CMU](https://www.youtube.com/playlist?list=PLZnJoM76RM6Jv4f7E7RnzW4rijTUTPI4u) ([Lecture notebooks](https://github.com/Optimal-Control-16-745/lecture-notebooks)) ([YouTube-2023](https://www.youtube.com/playlist?list=PLZnJoM76RM6KugDT9sw5zhAmqKnGeoLRa)) ([YouTube-2022](https://www.youtube.com/playlist?list=PLZnJoM76RM6Iaf59ICcU9-DzztGZvK_52))\n- [CS235 - Applied Robot Design for Non-Robot-Designers - Stanford University](https://www.youtube.com/user/StanfordCS235/videos)\n- [Lecture: Visual Navigation for Flying Robots](https://vision.in.tum.de/teaching/ss2012/visnav2012) ([YouTube](https://www.youtube.com/playlist?list=PLTBdjV_4f-EKeki5ps2WHqJqyQvxls4ha))\n- [CS 205A: Mathematical Methods for Robotics, Vision, and Graphics (Fall 2013)](https://www.youtube.com/playlist?list=PLQ3UicqQtfNvQ_VzflHYKhAqZiTxOkSwi)\n- [Robotics 1, Prof. De Luca, Universit√† di Roma](http://www.dis.uniroma1.it/~deluca/rob1_en/material_rob1_en_2014-15.html) ([YouTube](https://www.youtube.com/playlist?list=PLAQopGWlIcyaqDBW1zSKx7lHfVcOmWSWt))\n- [Robotics 2, Prof. De Luca, Universit√† di Roma](http://www.diag.uniroma1.it/~deluca/rob2_en/material_rob2_en.html) ([YouTube](https://www.youtube.com/playlist?list=PLAQopGWlIcya6LnIF83QlJTqvpYmJXnDm))\n- [Robot Mechanics and Control, SNU](https://www.youtube.com/playlist?list=PLkjy3Accn-E7mlbuSF4aajcMMckG4wLvW)\n- [Introduction to Robotics Course - UNCC](https://www.youtube.com/playlist?list=PL4847E1D1C121292F)\n- [SLAM Lectures](https://www.youtube.com/playlist?list=PLpUPoM7Rgzi_7YWn14Va2FODh7LzADBSm)\n- [CSE 478 ‚Äì Autonomous Robotics ‚Äì Winter 2025 - University of Washington](https://courses.cs.washington.edu/courses/cse478/25wi/schedule/) ([Winter 2024](https://courses.cs.washington.edu/courses/cse478/24wi/schedule/))\n- [CSE 571 ‚Äì AI-Robotics ‚Äì Spring 2023 - University of Washington](https://courses.cs.washington.edu/courses/cse571/23sp/)\n- [EE 259 ‚Äì Principles of Sensing for Autonomy ‚Äì Spring 2023 - Stanford University](https://www.youtube.com/playlist?list=PLoROMvodv4rOhE007XQu707Dy52qXiZGV)\n- [ME 597 ‚Äì Autonomous Mobile Robotics ‚Äì Fall 2014](http://wavelab.uwaterloo.ca/index6ea9.html?page_id=267)\n- [ME 780 ‚Äì Perception For Autonomous Driving ‚Äì Spring 2017](http://wavelab.uwaterloo.ca/indexaef8.html?page_id=481)\n- [ME780 ‚Äì Nonlinear State Estimation for Robotics and Computer Vision ‚Äì Spring 2017](http://wavelab.uwaterloo.ca/indexe9a5.html?page_id=533)\n- [METR 4202/7202 -- Robotics & Automation - University of Queensland](http://robotics.itee.uq.edu.au/~metr4202/lectures.html)\n- [UIUC CS-588 Autonomous Vehicle System Engineering Outline](http://luthuli.cs.uiuc.edu/~daf/courses/MAAV-21/588-2021-records.html)\n- [Robotics - IIT Bombay](https://nptel.ac.in/courses/112101099/)\n- [Introduction to Machine Vision](https://www.youtube.com/playlist?list=PL1pxneANaikCO1-Z0XTaljLR3SE8tgRXY)\n- [6.834J Cognitive Robotics - MIT OCW](https://ocw.mit.edu/courses/aeronautics-and-astronautics/16-412j-cognitive-robotics-spring-2016/)\n- [Hello (Real) World with ROS ‚Äì Robot Operating System - TU Delft](https://ocw.tudelft.nl/courses/hello-real-world-ros-robot-operating-system/)\n- [Programming for Robotics (ROS) - ETH Zurich](https://www.youtube.com/playlist?list=PLE-BQwvVGf8HOvwXPgtDfWoxd4Cc6ghiP)\n- [Mechatronic System Design - TU Delft](https://ocw.tudelft.nl/courses/mechatronic-system-design/)\n- [CS 206 Evolutionary Robotics Course Spring 2020](https://www.youtube.com/playlist?list=PLAuiGdPEdw0inlKisMbjDypCbvcb_GBN9)\n- [Foundations of Robotics - UTEC 2018-I](https://www.youtube.com/playlist?list=PLoWGuY2dW-Acmc8V5NYSAXBxADMm1rE4p)\n- [Robotics and Control: Theory and Practice IIT Roorkee](https://www.youtube.com/playlist?list=PLLy_2iUCG87AjAXKbNMiKJZ2T9vvGpMB0)\n- [Mechatronics](https://www.youtube.com/playlist?list=PLtuwVtW88fOeTFS_szBWif0Mcc0lfNWaz)\n- [ME142 - Mechatronics Spring 2020 - UC Merced](https://www.youtube.com/playlist?list=PL-euleXgwWUNQ80DGq6qopHBmHcQyEyNQ)\n- [Mobile Sensing and Robotics - Bonn University](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQJXx-x0t23RmRbjp_yMb4v)\n- [MSR2 - Sensors and State Estimation Course (2020) - Bonn University](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQh_J16IMwDlji18SWQ2PZ6)\n- [SLAM Course (2013) - Bonn University](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN_)\n- [ENGR486 Robot Modeling and Control (2014W)](https://www.youtube.com/playlist?list=PLJzZfbLAMTelwaLxFXteeblbY2ytU2AxX)\n- [Robotics by Prof. D K Pratihar - IIT Kharagpur](https://www.youtube.com/playlist?list=PLbRMhDVUMngcdUbBySzyzcPiFTYWr4rV_)\n- [Introduction to Mobile Robotics - SS 2019 - Universit√§t Freiburg](http://ais.informatik.uni-freiburg.de/teaching/ss19/robotics/)\n- [Robot Mapping - WS 2018/19 - Universit√§t Freiburg](http://ais.informatik.uni-freiburg.de/teaching/ws18/mapping/)\n- [Mechanism and Robot Kinematics - IIT Kharagpur](https://nptel.ac.in/courses/112/105/112105236/)\n- [Self-Driving Cars - Cyrill Stachniss - Winter 2020/21 - University of Bonn)](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQo2Z_ogbonywTg8jxCI9pD)\n- [Aerial Robotics - University of Pennsylvania (UPenn)](https://www.youtube.com/playlist?list=PLblGgzWkqSqM7IWsgjDetdzZDS1NbkTnd)\n- [Modern Robotics - Northwestern University](https://www.youtube.com/playlist?list=PLggLP4f-rq02vX0OQQ5vrCxbJrzamYDfx)\n- [MIT 6.4210/6.4212 - Robotic Manipulation - MIT](https://manipulation.csail.mit.edu/Fall2022/index.html) ([Youtube](https://www.youtube.com/playlist?list=PLkx8KyIQkMfUSDs2hvTWzaq-cxGl8Ha69))\n- [Industrial Robotics and Automation - IIT (ISM) Dhanbad](https://www.youtube.com/playlist?list=PLXDsvE7qtfNdt9oYEhJ_LMXDUGu6bH-L6)\n- [MEE5114 Advanced Control for Robotics from Southern University of Science and Technology](https://www.youtube.com/playlist?list=PLYkCanigA7S4x-ExlnFsQN9WrNZREWEZd)\n- [Self-Driving Cars ‚Äî Andreas Geiger](https://www.youtube.com/playlist?list=PL05umP7R6ij321zzKXK6XCQXAaaYjQbzr)\n- [Signal Processing: An Introduction by Nathan Kutz](https://www.youtube.com/playlist?list=PL6Vi_EcJpt8E96_JTKoOKY3HYWVGjf6b4)\n- [UC Santa Barbara ME 269 Network Systems, Dynamics and Control fall 2021, by Francesco Bullo](https://www.youtube.com/playlist?list=PL7bpQ3f3TaeMsueY06FCmbNIEOOY-Ri2_)\n- [Cornell MAE 4710/5710 Applied Dynamics spring 2020, by Andy Ruina](https://cornell.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%229b14904e-5cd8-4ada-b0ff-ab4901537d09%22) ([Part 2](https://vod.video.cornell.edu/channel/MAE%2B4710_5710%2B%2BApplied%2BDynamis_%2BSpring%2B2020/248138383))\n- [Cornell MAE 4730/5730 Intermediate Dynamics fall 2020, by Andy Ruina](https://vod.video.cornell.edu/channel/MAE%2B4730_5730%2BIntermediate%2BDynamics%2BFall%2B2020%2B%2BRuina/247509122)\n- [CMU 16 299 Introduction to Feedback Control Systems spring 2022, by Chris Atkeson](http://www.cs.cmu.edu/~cga/controls-intro-22/)\n- [University of Wisconsin-Madison ECE 332 Feedback Control Systems fall 2021, by Steven Fredette](https://www.youtube.com/playlist?list=PLIygTcviGPKB7-l9W1KHtBFUMvbskh5iR)\n- [MAE 509 Linear Matrix Inequality Methods in Optimal and Robust Control, by Matthew M. Peet](https://www.youtube.com/playlist?list=PL5ebyVGQORm6n158o-I_liUZ7Q5Od43li)\n- [UIUC CS 588 Autonomous Vehicle System Engineering fall 2021, by David Forsyth](http://luthuli.cs.uiuc.edu/~daf/courses/MAAV-21/588-2021-records.html)\n- [UCCS ECE4590/ECE5590 Model Predictive Control, by M. Scott Trimboli](http://mocha-java.uccs.edu/ECE5590/index.html)\n- [EPFL ME 425 Model Predictive Control fall 2020, by Colin Jones](https://www.youtube.com/playlist?list=PLHmHXT53cpnkpbwLqlKae0iKexM8SXKDM)\n- [Robots That Learn - UC Berkeley CS 294-277](https://www.youtube.com/playlist?list=PLPaC96j0xdLcYLTSoSk9PO1Yg-1udJd-S)\n- [Data-Driven Dynamical Systems with Machine Learning - Steve Brunton](https://www.youtube.com/playlist?list=PLMrJAkhIeNNR6DzT17-MM1GHLkuYVjhyt)\n- [Data-Driven Control with Machine Learning - Steve Brunton](https://www.youtube.com/playlist?list=PLMrJAkhIeNNQkv98vuPjO2X2qJO_UPeWR)\n- [Wheeled Mobile Robots](https://www.youtube.com/playlist?list=PLyqSpQzTE6M9CXsZljkH_lCxRSiaXF566)\n- [Introduction to Mobile Robots and Robot Operating System (ROS), HSE 2021](https://www.youtube.com/playlist?list=PL2PmRem6srUn6jc7Q6ahjL8x2qJg150mZ)\n- [Surgical Robotics Lectures - Carleton University](https://www.youtube.com/playlist?list=PLY6RHB0yqJVasji1rwZAGYirD8zW1ipj-)\n- [Introduction to Mechatronic and Robotics - IIT Bombay](https://www.youtube.com/playlist?list=PL_uaeekrhGzJMZTb5etIdXasVO9-WVPVH)\n- [Robotics Fall 2020 - UIC](https://www.youtube.com/playlist?list=PLc7bpbeTIk741sSBpPzj5hl_L8Wlrn1u8)\n- [Introduction to Robotics @ Princeton](https://www.youtube.com/playlist?list=PLF8B1bJgOQK67xkgYz_Xtx0ShjcqfdXwE)\n- [Evolutionary robotics course. Spring 2025](https://www.youtube.com/@joshbongard3314/playlists)\n- [Robotics: Basics and Selected Advanced - IISC Bangalore](https://www.youtube.com/playlist?list=PLgMDNELGJ1CZT9pdEEkDylXFPLdcqxn0t)\n- [Nonlinear Control Design Jan 2024 - IIT Bombay](https://github.com/Developer-Y/cs-video-courses?tab=readme-ov-file)\n\n\n------------------------------\n\n### Computational Finance\n\n- [COMP510 - Computational Finance - Steven Skiena - 2007 HKUST](https://www.youtube.com/playlist?list=PL9E205B8FAAD530E1)\n- [Computational Finance Course - Prof Grzelak](https://www.youtube.com/playlist?list=PL6zzGYGhbWrPaI-op1UfNl0uDglxdkaOB)\n- [Financial Engineering Course: Interest Rates and xVA - Prof Grzelak](https://www.youtube.com/playlist?list=PL6zzGYGhbWrMpjEKDtnrHWyIj-oVLKCYD)\n- [MOOC - Mathematical Methods for Quantitative Finance, University of Washington/Coursera)](http://academictorrents.com/details/dfc1ddde962101f00ef9764b91181bd6bb5c9e93)\n- [18.S096 Topics in Mathematics with Applications in Finance, MIT OCW](https://ocw.mit.edu/courses/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/video_galleries/video-lectures/)\n- [Computational Finance - Universit√§t Leipzig](https://www.youtube.com/playlist?list=PL4i4aZbplv9J5jan6mDbDHtjfm7ghMWfj)\n- [Machine Learning for Trading | Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPnIRwl6rad_mYwEk4Gmj7Mx)\n- [ACT 460 / STA 2502 ‚Äì Stochastic Methods for Actuarial Science - University of Toronto](http://www.utstat.utoronto.ca/sjaimung/courses/sta2502/main.htm)\n- [MMF1928H / STA 2503F ‚Äì\nPricing Theory I / Applied Probability for Mathematical Finance - University of Toronto](http://www.utstat.toronto.edu/sjaimung/courses/mmf1928/content2013.htm)\n- [STA 4505H ‚Äì High Frequency & Algorithmic trading - University of Toronto](http://www.utstat.utoronto.ca/sjaimung/courses/sta4505/main-2014.htm)\n- [Mathematical Finance - IIT Guwahati](https://nptel.ac.in/courses/111/103/111103126/)\n- [Quantitative Finance - IIT Kanpur](https://nptel.ac.in/courses/110/104/110104066/)\n- [Financial Derivatives & Risk Management - IIT Roorkee](https://nptel.ac.in/courses/110/107/110107128/)\n- [Financial Mathematics - IIT Roorkee](https://nptel.ac.in/courses/112/107/112107260/)\n- [Harvard Economics 2355 Deep Learning for Economics spring 2023, by Melissa Dell](https://www.youtube.com/playlist?list=PLGTgQIsun7ueGTRzDlBWqgX6xBlMce-QC)\n- [UW ECON 484 Econometrics and Data Science spring 2020, by Gregory Duncan](https://www.youtube.com/playlist?list=PLrE1feouzSWobe0NxC_v3cw_OyZL5i-IV)\n- [MATH69122 Stochastic Control for Finance](https://appliedprobability.blog/category/math69122-stochastic-control-for-finance/page/2/)\n- [UC Davis MAT 133 Mathematical Finance Spring 2024, by Matthias K√∂ppe](https://video.ucdavis.edu/channel/MAT+133+%28Spring+2024%29/340365092) ([Spring 2021](https://video.ucdavis.edu/channel/channelid/231002963))\n\n------------------------------\n\n### Network Science\n\n- [Network Science, 2021 - HSE](https://www.youtube.com/playlist?list=PLriUvS7IljvkGesFRuYjqRz4lKgodJgh2)\n- [Network Science TU Graz](https://courses.isds.tugraz.at/dhelic/netsci/index.html)\n- [MATH/COMP 479 Network Science Macalester College](https://www.youtube.com/playlist?list=PLlWULwPzrppXKYVyRxFt0YsgIDXiBDPNR)\n- [ACM Winter School on Network Science _Dec 2023, Ahmedabad University](https://www.youtube.com/playlist?list=PLPeEbErKGwN2qqFieu1z7KZ1SXxrmyCKx)\n- [Network Science 2021/2022 (ENS Lyon)](https://www.youtube.com/playlist?list=PL6e66HEqjx1a1XHy4IIQHwPSRLU0bRoK1)\n\n------------------------------\n\n### Blockchain Development\n\n- **Blockchain and Cryptocurrencies**\n  - [Blockchain, Solidity, and Full Stack Web3 Development with JavaScript](https://youtu.be/gyMwXuJrbJQ) \n  - [Blockchain Fundamentals Decal 2018 - Berkeley DeCal](https://www.youtube.com/playlist?list=PLSONl1AVlZNU0QTGpbgEQXKHcmgYz-ddT)\n  - [Blockchain for Developers Decal - Spring 2018 - Berkeley DeCal](https://www.youtube.com/playlist?list=PLSONl1AVlZNUzp71_H1kb87PvIh8kIZU9)\n  - [Cryptocurrency Engineering and Design - Spring 2018 - MIT](https://ocw.mit.edu/courses/mas-s62-cryptocurrency-engineering-and-design-spring-2018/video_galleries/lecture-videos/)\n  - [15.S12 Blockchain and Money, Fall 2018 - MIT](https://www.youtube.com/playlist?list=PLUl4u3cNGP63UUkfL0onkxF6MYgVa04Fn)\n  - [Blockchain - Foundations and Use Cases](https://www.coursera.org/learn/blockchain-foundations-and-use-cases/home/welcome)\n- **Become Blockchain Developer**\n  - [Solidity for Beginners - Dapp University](https://www.youtube.com/playlist?list=PLS5SEs8ZftgUq-aMMYeKf8nPqHrNqa3Iu) \n  - [Master Solidity - Dapp University](https://www.youtube.com/playlist?list=PLS5SEs8ZftgVnWHv2_mkvJjn5HBOkde3g)\n  - [IPFS Inter Planetary File System  Dapp University](https://www.youtube.com/playlist?list=PLS5SEs8ZftgWggD3tKfgwsIPXuIhorXZk)\n  - [Solidity, Blockchain, and Smart Contract Course ‚Äì Beginner to Expert Python Tutorial - FreeCodingCamp](https://www.youtube.com/watch?v=M576WGiDBdQ)\n  - [Web 3.0 - Build Realtime Decentralized applications](https://www.youtube.com/playlist?list=PLS5SEs8ZftgVV6ah1fo2IvlHk1kTCy6un)\n\n------------------------------\n\n### Misc\n\n- **HCI**\n  - [CS147 - Introduction to Human-Computer Interaction Design - Stanford](https://hci.stanford.edu/courses/cs147/2015/au/calendar.php)\n  - [CSEP 510 - Human Computer Interaction](https://courses.cs.washington.edu/courses/csep510/04wi/)\n  - [Programming for Designers - COMP1400-T2 (2010) - UNSW](https://www.youtube.com/playlist?list=PL9444191613E018CC)\n  - [08-763 Intro to HCI for Technology Executives - Fall 2015 - CMU](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%228bb9f417-9f60-4e00-84f6-4ef8e7425ae1%22&maxResults=150)\n  - [05-600 HCI Pro Seminar - Fall 2015 - CMU](https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22d885fd87-1ba1-47a3-9bd2-c4bde55f9749%22&maxResults=150)\n- **Game Development**\n \t- [CS50's Introduction to Game Development](https://www.edx.org/course/cs50s-introduction-to-game-development)\n\t- [MIT CMS.611J Creating Video Games, Fall 2014](https://ocw.mit.edu/courses/comparative-media-studies-writing/cms-611j-creating-video-games-fall-2014/lecture-videos/)\n  - [MOOC - Beginning Game Programming with C# - Coursera](http://academictorrents.com/details/0a7ba7e62821e488a0061751fdb81f4298733bea)\n  - [Gatech ECE4795 GPU Programming for Video Games, Summer 2021](https://www.youtube.com/playlist?list=PLOunECWxELQQwayE8e3WjKPJsTGKknJ8w)\n- **Geospatial**\n  - [Introduction to Spatial Data Science, Autumn 2016, University of Chicago](https://www.youtube.com/playlist?list=PLzREt6r1Nenkr2vtYgbP4hs44HO_s_qEO)\n  - [Spatial Regression Analysis, Spring 2017, University of Chicago](https://www.youtube.com/playlist?list=PLzREt6r1Nenkk7x197-CKPFZ0BuAOCRGT)\n  - [Spatial Data Science, Autumn 2017, University of Chicago](https://www.youtube.com/playlist?list=PLzREt6r1Nenlu-MBaxCRL2KZNk62n7o1g)\n  - [Introduction to Geographic Information Systems - IIT Roorkee](https://nptel.ac.in/courses/105107155/)\n- [MOOC - Matlab - Coursera](https://youtu.be/6iN56l7dEMY)\n- [Computing for Computer Scientists - University of Michigan](https://c4cs.github.io)\n- [Linux System Administration Decal, Spring 2025, UC Berkeley](https://decal.ocf.berkeley.edu/)\n- [Linux Implementation/Administration Practicum - Redhat by Tulio Llosa](https://itunes.apple.com/us/itunes-u/linux-implementation-administration/id430673915)\n- [Innovative Computing - Harvard University](https://www.youtube.com/playlist?list=PLE3E96113F544495A)\n- [Linux Programming & Scripting - IIT Madras](https://nptel.ac.in/courses/117106113/)\n- [Model Checking - IIT Madras](https://nptel.ac.in/courses/106106136/)\n- [Virtual Reality - IIT Madras](https://nptel.ac.in/courses/106106138/)\n- [Dependable Systems (SS 2014) - HPI University of Potsdam](https://www.tele-task.de/series/1005/)\n- [Business Process Compliance (WT 2013/14) - HPI University of Potsdam](https://www.tele-task.de/series/979/)\n- [Design Thinking for Digital Engineering (SS 2018) - Dr. Julia von Thienen - HPI](https://www.tele-task.de/series/1206/)\n- [CS224w ‚Äì Social Network Analysis ‚Äì Autumn 2017 - Stanford University](http://snap.stanford.edu/class/cs224w-videos-2017/)\n- [The Missing Semester of Your CS Education](https://missing.csail.mit.edu/)\n- [University of Crete, Computer Science video lectures (mostly Greek language lectures, very few 100% English-speaking courses). Very popular CS destination for European Erasmus students](https://opencourses.uoc.gr/courses/course/index.php?categoryid=28)\n- [Stanford EE274 I Data Compression: Theory and Applications I 2023](https://www.youtube.com/playlist?list=PLoROMvodv4rPj4uhbgUAaEKwNNak8xgkz)\n- [Probabilistic Methods - University of Waterloo](https://www.youtube.com/playlist?list=PL2BdWtDKMS6nRF72s3TOGyBqXwMVHYiLU)\n- [Free Probability Theory and Ramanujan Graphs - Spring 2024](https://www.youtube.com/playlist?list=PL-FpbJb6Ix_Npx7GSSxnD2BLrLtwkdwt4)\n- [Asymptotics and perturbation methods - Prof. Steven Strogatz](https://www.youtube.com/playlist?list=PL5EH0ZJ7V0jV7kMYvPcZ7F9oaf_YAlfbI)\n- [ETH Z√ºrich AI in the Sciences and Engineering](https://www.youtube.com/playlist?list=PLJkYEExhe7rYFkBIB2U5pf_RWzYnFLj7r)\n- [Introduction to GIS Programming (Fall 2024) - Open Geospatial Solutions](https://www.youtube.com/playlist?list=PLAxJ4-o7ZoPfb18kNe2luWX9xKg1233i9)\n- [Gatech Guitar Amplification and Effects, by Aaron Lanterman](https://www.youtube.com/playlist?list=PLOunECWxELQS7JV_KeeTJJpgGjOftoaAH)\n- [Gatech ECE3084 Signals and Systems summer 2020, by Aaron Lanterman](https://www.youtube.com/playlist?list=PLOunECWxELQRYwsuj4BL4Hu1nvj9dxRQ6)\n- [Gatech ECE4450 Analog Circuits for Music Synthesis spring 2021, by Aaron Lanterman](https://www.youtube.com/playlist?list=PLOunECWxELQS5bMdWo9VhmZtsCjhjYNcV)\n- [UC Berkeley EE 120 Signals and Systems spring 2019, by Murat Arcak](https://www.youtube.com/playlist?list=PLIygTcviGPKCFASN_5cR04KUST-G97bb-)\n- [Stanford EE 102 spring 1999, Introduction to Signals and Systems, by Stephen Boyd](https://www.youtube.com/playlist?list=PLpGHT1n4-mAvjbBio7D_qpIN4bZqOOOST)\n- [Stanford EE 376a winter 2011, Information Theory, by Thomas Cover](https://www.youtube.com/user/classxteam/playlists)\n- [MIT RES.6.007 Signals and Systems, 1987 - MIT](https://www.youtube.com/playlist?list=PL41692B571DD0AF9B)\n- [MIT 9.19 Computational Psycholinguistics, 2023 - MIT](https://rlevy.github.io/9.19-syllabus/syllabus.html) ([YouTube](https://www.youtube.com/playlist?list=PLlp18pgkl6U_Dfv59jF-NlAW6dwqYKZim))\n- [UCCS ECE4510/ECE5510 Feedback Control Systems, by Gregory Plett](http://mocha-java.uccs.edu/ECE4510/index.html)\n- [UCCS ECE4520/ECE5520 Multivariable Control Systems I, by Gregory Plett](http://mocha-java.uccs.edu/ECE5520/index.html)\n- [UCCS ECE4530/ECE5530 Multivariable Control Systems II, by Gregory Plett](http://mocha-java.uccs.edu/ECE5530/index.html)\n- [UCCS ECE4540/ECE5540 Digital Control Systems, by Gregory Plett](http://mocha-java.uccs.edu/ECE5540/index.html)\n- [UCCS ECE4550/ECE5550 Applied Kalman Filtering, by Gregory Plett](http://mocha-java.uccs.edu/ECE5550/index.html)\n- [UCCS ECE4560/ECE5560 System Identification, by Gregory Plett](http://mocha-java.uccs.edu/ECE5560/index.html)\n- [UCCS ECE4570/ECE5570 Optimization for Systems and Control, by M. Scott Trimboli](http://mocha-java.uccs.edu/ECE5570-NEW/index.html)\n- [UCCS ECE4580/ECE5580 Multivariable Control in the Frequency Domain, by M. Scott Trimboli](http://mocha-java.uccs.edu/ECE5580/index.html)\n- [UCCS ECE4710/ECE5710 Modeling, Simulation, and Identification of Battery Dynamics, by Gregory Plett](http://mocha-java.uccs.edu/ECE5710/index.html)\n- [UCCS ECE4720/ECE5720 Battery Management and Control, by Gregory Plett](http://mocha-java.uccs.edu/ECE5720/index.html)\n- [Purdue ME 597 Distributed Energy Resources Spring 2024, by Kevin J. Kircher](https://www.youtube.com/playlist?list=PLcZDMdEnS08l_z5LVDQrEcyFrBsHlKVXd)\n- [Stanford AA228V/CS238V Validation of Safety Critical Systems Winter 2025, by Sydney Michelle Katz](https://www.youtube.com/playlist?list=PLoROMvodv4rOq1LMLI8U7djzDb8--xpaC)\n\n",
         "AI_DataScience"
        ],
        [
         "4",
         "MDEwOlJlcG9zaXRvcnkxMTU0Nzg4MjA=",
         "[![Logo](/logo.png)](http://awesome-scalability.com/)\n\nAn updated and organized reading list for illustrating the patterns of scalable, reliable, and performant large-scale systems. Concepts are explained in the articles of prominent engineers and credible references. Case studies are taken from battle-tested systems that serve millions to billions of users.\n\n#### If your system goes slow\n> Understand your problems: scalability problem (fast for a single user but slow under heavy load) or performance problem (slow for a single user) by reviewing some [design principles](#principle) and checking how [scalability](#scalability) and [performance](#performance) problems are solved at tech companies. The section of [intelligence](#intelligence) are created for those who work with data and machine learning at big (data) and deep (learning) scale.\n\n#### If your system goes down\n> \"Even if you lose all one day, you can build all over again if you retain your calm!\" - Thuan Pham, former CTO of Uber. So, keep calm and mind the [availability](#availability) and [stability](#stability) matters! \n\n#### If you are having a system design interview\n> Look at some [interview notes](#interview) and [real-world architectures with completed diagrams](#architecture) to get a comprehensive view before designing your system on whiteboard. You can check some [talks](#talk) of engineers from tech giants to know how they build, scale, and optimize their systems. Good luck!\n\n#### If you are building your dream team\n> The goal of scaling team is not growing team size but increasing team output and value. You can find out how tech companies reach that goal in various aspects: hiring, management, organization, culture, and communication in the [organization](#organization) section.\n\n#### Community power\n\n> Contributions are greatly welcome! You may want to take a look at the [contribution guidelines](CONTRIBUTING.md). If you see a link here that is no longer maintained or is not a good fit, please submit a pull request!\n\n> Many long hours of hard work have gone into this project. If you find it helpful, please share on Facebook, [on Twitter](https://ctt.ec/V8B2p), [on Weibo](http://t.cn/RnjFLCB), or on your chat groups! Knowledge is power, knowledge shared is power multiplied. Thank you!\n\n## Content\n- [Principle](#principle)\n- [Scalability](#scalability)\n- [Availability](#availability)\n- [Stability](#stability)\n- [Performance](#performance)\n- [Intelligence](#intelligence)\n- [Architecture](#architecture)\n- [Interview](#interview)\n- [Organization](#organization)\n- [Talk](#talk)\n- [Book](#book)\n\n## Principle\n* [Lessons from Giant-Scale Services - Eric Brewer, UC Berkeley & Google](https://people.eecs.berkeley.edu/~brewer/papers/GiantScale-IEEE.pdf)\n* [Designs, Lessons and Advice from Building Large Distributed Systems - Jeff Dean, Google](https://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf)\n* [How to Design a Good API & Why it Matters - Joshua Bloch, CMU & Google](https://www.infoq.com/presentations/effective-api-design)\n* [On Efficiency, Reliability, Scaling - James Hamilton, VP at AWS](http://mvdirona.com/jrh/work/)\n* [Principles of Chaos Engineering](https://www.usenix.org/conference/srecon17americas/program/presentation/rosenthal)\n* [Finding the Order in Chaos](https://www.usenix.org/conference/srecon16/program/presentation/lueder)\n* [The Twelve-Factor App](https://12factor.net/)\n* [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)\n* [High Cohesion and Low Coupling](http://www.math-cs.gordon.edu/courses/cs211/lectures-2009/Cohesion,Coupling,MVC.pdf)\n* [Monoliths and Microservices](https://medium.com/@SkyscannerEng/monoliths-and-microservices-8c65708c3dbf)\n* [CAP Theorem and Trade-offs](http://robertgreiner.com/2014/08/cap-theorem-revisited/)\n* [CP Databases and AP Databases](https://blog.andyet.com/2014/10/01/right-database)\n* [Stateless vs Stateful Scalability](http://ithare.com/scaling-stateful-objects/)\t\n* [Scale Up vs Scale Out: Hidden Costs](https://blog.codinghorror.com/scaling-up-vs-scaling-out-hidden-costs/)\n* [ACID and BASE](https://neo4j.com/blog/acid-vs-base-consistency-models-explained/)\n* [Blocking/Non-Blocking and Sync/Async](https://blogs.msdn.microsoft.com/csliu/2009/08/27/io-concept-blockingnon-blocking-vs-syncasync/)\n* [Performance and Scalability of Databases](https://use-the-index-luke.com/sql/testing-scalability)\n* [Database Isolation Levels and Effects on Performance and Scalability](http://highscalability.com/blog/2011/2/10/database-isolation-levels-and-their-effects-on-performance-a.html)\n* [The Probability of Data Loss in Large Clusters](https://martin.kleppmann.com/2017/01/26/data-loss-in-large-clusters.html)\n* [Data Access for Highly-Scalable Solutions: Using SQL, NoSQL, and Polyglot Persistence](https://docs.microsoft.com/en-us/previous-versions/msp-n-p/dn271399(v=pandp.10))\n* [SQL vs NoSQL](https://www.upwork.com/hiring/data/sql-vs-nosql-databases-whats-the-difference/)\n* [SQL vs NoSQL - Lesson Learned at Salesforce](https://engineering.salesforce.com/sql-or-nosql-9eaf1d92545b)\n* [NoSQL Databases: Survey and Decision Guidance](https://medium.baqend.com/nosql-databases-a-survey-and-decision-guidance-ea7823a822d)\n* [How Sharding Works](https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6)\n* [Consistent Hashing](http://www.tom-e-white.com/2007/11/consistent-hashing.html)\n* [Consistent Hashing: Algorithmic Tradeoffs](https://medium.com/@dgryski/consistent-hashing-algorithmic-tradeoffs-ef6b8e2fcae8)\n* [Don‚Äôt be tricked by the Hashing Trick](https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087)\n* [Uniform Consistent Hashing at Netflix](https://medium.com/netflix-techblog/distributing-content-to-open-connect-3e3e391d4dc9)\n* [Eventually Consistent - Werner Vogels, CTO at Amazon](https://www.allthingsdistributed.com/2008/12/eventually_consistent.html)\n* [Cache is King](https://www.stevesouders.com/blog/2012/10/11/cache-is-king/)\n* [Anti-Caching](https://www.the-paper-trail.org/post/2014-06-06-paper-notes-anti-caching/)\n* [Understand Latency](http://highscalability.com/latency-everywhere-and-it-costs-you-sales-how-crush-it)\n* [Latency Numbers Every Programmer Should Know](http://norvig.com/21-days.html#answers)\n* [The Calculus of Service Availability](https://queue.acm.org/detail.cfm?id=3096459&__s=dnkxuaws9pogqdnxmx8i)\n* [Architecture Issues When Scaling Web Applications: Bottlenecks, Database, CPU, IO](http://highscalability.com/blog/2014/5/12/4-architecture-issues-when-scaling-web-applications-bottlene.html)\t\n* [Common Bottlenecks](http://highscalability.com/blog/2012/5/16/big-list-of-20-common-bottlenecks.html)\n* [Life Beyond Distributed Transactions](https://queue.acm.org/detail.cfm?id=3025012)\n* [Relying on Software to Redirect Traffic Reliably at Various Layers](https://www.usenix.org/conference/srecon15/program/presentation/taveira)\n* [Breaking Things on Purpose](https://www.usenix.org/conference/srecon17americas/program/presentation/andrus)\n* [Avoid Over Engineering](https://medium.com/@rdsubhas/10-modern-software-engineering-mistakes-bc67fbef4fc8)\n* [Scalability Worst Practices](https://www.infoq.com/articles/scalability-worst-practices)\n* [Use Solid Technologies - Don‚Äôt Re-invent the Wheel - Keep It Simple!](https://medium.com/@DataStax/instagram-engineerings-3-rules-to-a-scalable-cloud-application-architecture-c44afed31406)\n* [Simplicity by Distributing Complexity](https://engineering.zalando.com/posts/2018/01/simplicity-by-distributing-complexity.html)\n* [Why Over-Reusing is Bad](http://tech.transferwise.com/why-over-reusing-is-bad/)\n* [Performance is a Feature](https://blog.codinghorror.com/performance-is-a-feature/)\n* [Make Performance Part of Your Workflow](https://codeascraft.com/2014/12/11/make-performance-part-of-your-workflow/)\n* [The Benefits of Server Side Rendering over Client Side Rendering](https://medium.com/walmartlabs/the-benefits-of-server-side-rendering-over-client-side-rendering-5d07ff2cefe8)\n* [Automate and Abstract: Lessons at Facebook](https://architecht.io/lessons-from-facebook-on-engineering-for-scale-f5716f0afc7a)\n* [AWS Do's and Don'ts](https://8thlight.com/blog/sarah-sunday/2017/09/15/aws-dos-and-donts.html)\n* [(UI) Design Doesn‚Äôt Scale - Stanley Wood, Design Director at Spotify](https://medium.com/@hellostanley/design-doesnt-scale-4d81e12cbc3e)\n* [Linux Performance](http://www.brendangregg.com/linuxperf.html)\n* [Building Fast and Resilient Web Applications - Ilya Grigorik](https://www.igvita.com/2016/05/20/building-fast-and-resilient-web-applications/)\n* [Accept Partial Failures, Minimize Service Loss](https://www.usenix.org/conference/srecon17asia/program/presentation/wang_daxin)\n* [Design for Resiliency](http://highscalability.com/blog/2012/12/31/designing-for-resiliency-will-be-so-2013.html)\n* [Design for Self-healing](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/self-healing)\n* [Design for Scaling Out](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/scale-out)\t\n* [Design for Evolution](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/design-for-evolution)\n* [Learn from Mistakes](http://highscalability.com/blog/2013/8/26/reddit-lessons-learned-from-mistakes-made-scaling-to-1-billi.html)\n\n## Scalability\n* [Microservices and Orchestration](https://martinfowler.com/microservices/)\n\t* [Domain-Oriented Microservice Architecture at Uber](https://eng.uber.com/microservice-architecture/)\n\t* [Service Architecture (3 parts: Domain Gateways, Value-Added Services, BFF) at SoundCloud](https://developers.soundcloud.com/blog/service-architecture-3)\n\t* [Container (8 parts) at Riot Games](https://engineering.riotgames.com/news/thinking-inside-container)\n\t* [Containerization at Pinterest](https://medium.com/@Pinterest_Engineering/containerization-at-pinterest-92295347f2f3)\n\t* [Evolution of Container Usage at Netflix](https://medium.com/netflix-techblog/the-evolution-of-container-usage-at-netflix-3abfc096781b)\n\t* [Dockerizing MySQL at Uber](https://eng.uber.com/dockerizing-mysql/)\n\t* [Testing of Microservices at Spotify](https://labs.spotify.com/2018/01/11/testing-of-microservices/)\n\t* [Docker in Production at Treehouse](https://medium.com/treehouse-engineering/lessons-learned-running-docker-in-production-5dce99ece770)\n\t* [Microservice at SoundCloud](https://developers.soundcloud.com/blog/inside-a-soundcloud-microservice)\n\t* [Operate Kubernetes Reliably at Stripe](https://stripe.com/blog/operating-kubernetes)\n\t* [Cross-Cluster Traffic Mirroring with Istio at Trivago](https://tech.trivago.com/2020/06/10/cross-cluster-traffic-mirroring-with-istio/)\n\t* [Agrarian-Scale Kubernetes (3 parts) at New York Times](https://open.nytimes.com/agrarian-scale-kubernetes-part-3-ee459887ed7e)\n\t* [Nanoservices at BBC](https://medium.com/bbc-design-engineering/powering-bbc-online-with-nanoservices-727840ba015b)\n\t* [PowerfulSeal: Testing Tool for Kubernetes Clusters at Bloomberg](https://www.techatbloomberg.com/blog/powerfulseal-testing-tool-kubernetes-clusters/)\n\t* [Conductor: Microservices Orchestrator at Netflix](https://medium.com/netflix-techblog/netflix-conductor-a-microservices-orchestrator-2e8d4771bf40)\n\t* [Docker Containers that Power Over 100.000 Online Shops at Shopify](https://shopifyengineering.myshopify.com/blogs/engineering/docker-at-shopify-how-we-built-containers-that-power-over-100-000-online-shops)\n\t* [Microservice Architecture at Medium](https://medium.engineering/microservice-architecture-at-medium-9c33805eb74f)\n\t* [From bare-metal to Kubernetes at Betabrand](https://boxunix.com/post/bare_metal_to_kube/)\n\t* [Kubernetes at Tinder](https://medium.com/tinder-engineering/tinders-move-to-kubernetes-cda2a6372f44)\n\t* [Kubernetes at Quora](https://www.quora.com/q/quoraengineering/Adopting-Kubernetes-at-Quora)\t\n\t* [Kubernetes Platform at Pinterest](https://medium.com/pinterest-engineering/building-a-kubernetes-platform-at-pinterest-fb3d9571c948)\n\t* [Microservices at Nubank](https://medium.com/building-nubank/microservices-at-nubank-an-overview-2ebcb336c64d)\n\t* [Payment Transaction Management in Microservices at Mercari](https://engineering.mercari.com/en/blog/entry/20210831-2019-06-07-155849/)\n\t* [Service Mesh at Snap](https://eng.snap.com/monolith-to-multicloud-microservices-snap-service-mesh)\n\t* [GRIT: Protocol for Distributed Transactions across Microservices at eBay](https://tech.ebayinc.com/engineering/grit-a-protocol-for-distributed-transactions-across-microservices/)\n\t* [Rubix: Kubernetes at Palantir](https://medium.com/palantir/introducing-rubix-kubernetes-at-palantir-ab0ce16ea42e)\n\t* [CRISP: Critical Path Analysis for Microservice Architectures at Uber](https://eng.uber.com/crisp-critical-path-analysis-for-microservice-architectures/)\n* [Distributed Caching](https://www.wix.engineering/post/scaling-to-100m-to-cache-or-not-to-cache)\n\t* [EVCache: Distributed In-memory Caching at Netflix](https://medium.com/netflix-techblog/caching-for-a-global-netflix-7bcc457012f1)\n\t* [EVCache Cache Warmer Infrastructure at Netflix](https://medium.com/netflix-techblog/cache-warming-agility-for-a-stateful-service-2d3b1da82642)\n\t* [Memsniff: Robust Memcache Traffic Analyzer at Box](https://blog.box.com/blog/introducing-memsniff-robust-memcache-traffic-analyzer/)\n\t* [Caching with Consistent Hashing and Cache Smearing at Etsy](https://codeascraft.com/2017/11/30/how-etsy-caches/)\n\t* [Analysis of Photo Caching at Facebook](https://code.facebook.com/posts/220956754772273/an-analysis-of-facebook-photo-caching/)\n\t* [Cache Efficiency Exercise at Facebook](https://code.facebook.com/posts/964122680272229/web-performance-cache-efficiency-exercise/)\n\t* [tCache: Scalable Data-aware Java Caching at Trivago](http://tech.trivago.com/2015/10/15/tcache/)\n\t* [Pycache: In-process Caching at Quora](https://engineering.quora.com/Pycache-lightning-fast-in-process-caching)\t\n\t* [Reduce Memcached Memory Usage by 50% at Trivago](http://tech.trivago.com/2017/12/19/how-trivago-reduced-memcached-memory-usage-by-50/)\n\t* [Caching Internal Service Calls at Yelp](https://engineeringblog.yelp.com/2018/03/caching-internal-service-calls-at-yelp.html)\n\t* [Estimating the Cache Efficiency using Big Data at Allegro](https://allegro.tech/2017/01/estimating-the-cache-efficiency-using-big-data.html)\n\t* [Distributed Cache at Zalando](https://engineering.zalando.com/posts/2018/04/distributed-cache-akka-kubernetes.html)\n\t* [Distributed Cache for S3 at ClickHouse](https://clickhouse.com/blog/building-a-distributed-cache-for-s3)\n\t* [Application Data Caching from RAM to SSD at NetFlix](https://medium.com/netflix-techblog/evolution-of-application-data-caching-from-ram-to-ssd-a33d6fa7a690)\n\t* [Tradeoffs of Replicated Cache at Skyscanner](https://medium.com/@SkyscannerEng/the-tradeoffs-of-a-replicated-cache-b6680c722f58)\n\t* [Location Caching with Quadtrees at Yext](http://engblog.yext.com/post/geolocation-caching)\n\t* [Video Metadata Caching at Vimeo](https://medium.com/vimeo-engineering-blog/video-metadata-caching-at-vimeo-a54b25f0b304)\n\t* [Scaling Redis at Twitter](http://highscalability.com/blog/2014/9/8/how-twitter-uses-redis-to-scale-105tb-ram-39mm-qps-10000-ins.html)\n\t* [Scaling Job Queue with Redis at Slack](https://slack.engineering/scaling-slacks-job-queue-687222e9d100)\n\t* [Moving persistent data out of Redis at Github](https://githubengineering.com/moving-persistent-data-out-of-redis/)\n\t* [Storing Hundreds of Millions of Simple Key-Value Pairs in Redis at Instagram](https://engineering.instagram.com/storing-hundreds-of-millions-of-simple-key-value-pairs-in-redis-1091ae80f74c)\n\t* [Redis at Trivago](http://tech.trivago.com/2017/01/25/learn-redis-the-hard-way-in-production/)\n\t* [Optimizing Redis Storage at Deliveroo](https://deliveroo.engineering/2017/01/19/optimising-membership-queries.html)\n\t* [Memory Optimization in Redis at Wattpad](http://engineering.wattpad.com/post/23244724794/store-more-stuff-memory-optimization-in-redis)\n\t* [Redis Fleet at Heroku](https://blog.heroku.com/rolling-redis-fleet)\n\t* [Solving Remote Build Cache Misses (2 parts) at SoundCloud](https://developers.soundcloud.com/blog/gradle-remote-build-cache-misses-part-2)\n\t* [Ratings & Reviews (2 parts) at Flipkart](https://blog.flipkart.tech/ratings-reviews-flipkart-part-2-574ab08e75cf)\n\t* [Prefetch Caching of Items at eBay](https://tech.ebayinc.com/engineering/prefetch-caching-of-ebay-items/)\n\t* [Cross-Region Caching Library at Wix](https://www.wix.engineering/post/how-we-built-a-cross-region-caching-library)\n\t* [Improving Distributed Caching Performance and Efficiency at Pinterest](https://medium.com/pinterest-engineering/improving-distributed-caching-performance-and-efficiency-at-pinterest-92484b5fe39b)\n\t* [Standardize and Improve Microservices Caching at DoorDash](https://doordash.engineering/2023/10/19/how-doordash-standardized-and-improved-microservices-caching/)\n    * [HTTP Caching and CDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching)\n        * [Zynga Geo Proxy: Reducing Mobile Game Latency at Zynga](https://www.zynga.com/blogs/engineering/zynga-geo-proxy-reducing-mobile-game-latency)\n        * [Google AMP at Cond√© Nast](https://technology.condenast.com/story/the-why-and-how-of-google-amp-at-conde-nast)\n        * [A/B Tests on Hosting Infrastructure (CDNs) at Deliveroo](https://deliveroo.engineering/2016/09/19/ab-testing-cdns.html)\n        * [HAProxy with Kubernetes for User-facing Traffic at SoundCloud](https://developers.soundcloud.com/blog/how-soundcloud-uses-haproxy-with-kubernetes-for-user-facing-traffic)\n        * [Bandaid: Service Proxy at Dropbox](https://blogs.dropbox.com/tech/2018/03/meet-bandaid-the-dropbox-service-proxy/)\n\t\t* [Service Workers at Slack](https://slack.engineering/service-workers-at-slack-our-quest-for-faster-boot-times-and-offline-support-3492cf79c88)\n\t\t* [CDN Services at Spotify](https://labs.spotify.com/2020/02/24/how-spotify-aligned-cdn-services-for-a-lightning-fast-streaming-experience/)\n* [Distributed Locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)\n\t* [Chubby: Lock Service for Loosely Coupled Distributed Systems at Google](https://blog.acolyer.org/2015/02/13/the-chubby-lock-service-for-loosely-coupled-distributed-systems/)\n\t* [Distributed Locking at Uber](https://www.youtube.com/watch?v=MDuagr729aU)\n\t* [Distributed Locks using Redis at GoSquared](https://engineering.gosquared.com/distributed-locks-using-redis)\n\t* [ZooKeeper at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/zookeeper-at-twitter.html)\n\t* [Eliminating Duplicate Queries using Distributed Locking at Chartio](https://chartio.com/blog/eliminating-duplicate-queries-using-distributed-locking/)\n* [Distributed Tracking, Tracing, and Measuring](https://www.oreilly.com/ideas/understanding-the-value-of-distributed-tracing)\n\t* [Zipkin: Distributed Systems Tracing at Twitter](https://blog.twitter.com/engineering/en_us/a/2012/distributed-systems-tracing-with-zipkin.html)\n\t* [Improve Zipkin Traces using Kubernetes Pod Metadata at SoundCloud](https://developers.soundcloud.com/blog/using-kubernetes-pod-metadata-to-improve-zipkin-traces)\n\t* [Canopy: Scalable Distributed Tracing & Analysis at Facebook](https://www.infoq.com/presentations/canopy-scalable-tracing-analytics-facebook)\n\t* [Pintrace: Distributed Tracing at Pinterest](https://medium.com/@Pinterest_Engineering/distributed-tracing-at-pinterest-with-new-open-source-tools-a4f8a5562f6b)\n\t* [XCMetrics: All-in-One Tool for Tracking Xcode Build Metrics at Spotify](https://engineering.atspotify.com/2021/01/20/introducing-xcmetrics-our-all-in-one-tool-for-tracking-xcode-build-metrics/)\n\t* [Real-time Distributed Tracing at LinkedIn](https://engineering.linkedin.com/distributed-service-call-graph/real-time-distributed-tracing-website-performance-and-efficiency)\t\n\t* [Tracking Service Infrastructure at Scale at Shopify](https://www.usenix.org/conference/srecon17americas/program/presentation/arthorne)\t\n\t* [Distributed Tracing at HelloFresh](https://engineering.hellofresh.com/scaling-hellofresh-distributed-tracing-7b182928247d)\n\t* [Analyzing Distributed Trace Data at Pinterest](https://medium.com/@Pinterest_Engineering/analyzing-distributed-trace-data-6aae58919949)\n\t* [Distributed Tracing at Uber](https://eng.uber.com/distributed-tracing/)\n\t* [JVM Profiler: Tracing Distributed JVM Applications at Uber](https://eng.uber.com/jvm-profiler/)\n\t* [Data Checking at Dropbox](https://www.usenix.org/conference/srecon17asia/program/presentation/mah)\n\t* [Tracing Distributed Systems at Showmax](https://tech.showmax.com/2016/10/tracing-distributed-systems-at-showmax/)\n\t* [osquery Across the Enterprise at Palantir](https://medium.com/@palantir/osquery-across-the-enterprise-3c3c9d13ec55)\n\t* [StatsD at Etsy](https://codeascraft.com/2011/02/15/measure-anything-measure-everything/)\n* [Distributed Scheduling](https://www.csee.umbc.edu/courses/graduate/CMSC621/fall02/lectures/ch11.pdf)\n\t* [Distributed Task Scheduling (3 parts) at PagerDuty](https://www.pagerduty.com/eng/distributed-task-scheduling-3/)\n    * [Building Cron at Google](https://landing.google.com/sre/sre-book/chapters/distributed-periodic-scheduling/)\n    * [Distributed Cron Architecture at Quora](https://engineering.quora.com/Quoras-Distributed-Cron-Architecture)\n    * [Chronos: A Replacement for Cron at Airbnb](https://medium.com/airbnb-engineering/chronos-a-replacement-for-cron-f05d7d986a9d)\n    * [Scheduler at Nextdoor](https://engblog.nextdoor.com/we-don-t-run-cron-jobs-at-nextdoor-6f7f9cc62040)\n    * [Peloton: Unified Resource Scheduler for Diverse Cluster Workloads at Uber](https://eng.uber.com/peloton/)\n    * [Fenzo: OSS Scheduler for Apache Mesos Frameworks at Netflix](https://medium.com/netflix-techblog/fenzo-oss-scheduler-for-apache-mesos-frameworks-5c340e77e543)\n    * [Airflow - Workflow Orchestration](https://airflow.apache.org/)\n\t\t* [Airflow at Airbnb](https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8)\n\t\t* [Airflow at Adyen](https://www.adyen.com/knowledge-hub/apache-airflow-at-adyen)\n\t\t* [Airflow at Pandora](https://engineering.pandora.com/apache-airflow-at-pandora-1d7a844d68ee)\n        * [Airflow at Robinhood](https://medium.com/robinhood-engineering/why-robinhood-uses-airflow-aed13a9a90c8)\n        * [Airflow at Lyft](https://eng.lyft.com/running-apache-airflow-at-lyft-6e53bb8fccff)\n        * [Airflow at Drivy](https://drivy.engineering/airflow-architecture/)\n\t\t* [Airflow at Grab](https://engineering.grab.com/experimentation-platform-data-pipeline)\n\t\t* [Airflow at Adobe](https://medium.com/adobetech/adobe-experience-platform-orchestration-service-with-apache-airflow-952203723c0b)\n        * [Auditing Airflow Job Runs at Walmart](https://medium.com/walmartlabs/auditing-airflow-batch-jobs-73b45100045)\n        * [MaaT: DAG-based Distributed Task Scheduler at Alibaba](https://hackernoon.com/meet-maat-alibabas-dag-based-distributed-task-scheduler-7c9cf0c83438)\n        * [boundary-layer: Declarative Airflow Workflows at Etsy](https://www.etsy.com/codeascraft/boundary-layer-declarative-airflow-workflows)\n* [Distributed Monitoring and Alerting](https://www.oreilly.com/ideas/monitoring-distributed-systems)\n\t* [Unicorn: Remediation System at eBay](https://www.ebayinc.com/stories/blogs/tech/unicorn-rheos-remediation-center/)\n\t* [M3: Metrics and Monitoring Platform at Uber](https://eng.uber.com/optimizing-m3/)\n\t* [Athena: Automated Build Health Management System at Dropbox](https://blogs.dropbox.com/tech/2019/05/athena-our-automated-build-health-management-system/)\n\t* [Vortex: Monitoring Server Applications at Dropbox](https://blogs.dropbox.com/tech/2019/11/monitoring-server-applications-with-vortex/)\t\n\t* [Nuage: Cloud Management Service at LinkedIn](https://engineering.linkedin.com/blog/2019/solving-manageability-challenges-with-nuage)\n\t* [Telltale: Application Monitoring at Netflix](https://netflixtechblog.com/telltale-netflix-application-monitoring-simplified-5c08bfa780ba)\n\t* [ThirdEye: Monitoring Platform at LinkedIn](https://engineering.linkedin.com/blog/2019/06/smart-alerts-in-thirdeye--linkedins-real-time-monitoring-platfor)\n\t* [Periskop: Exception Monitoring Service at SoundCloud](https://developers.soundcloud.com/blog/periskop-exception-monitoring-service)\n    * [Securitybot: Distributed Alerting Bot at Dropbox](https://blogs.dropbox.com/tech/2017/02/meet-securitybot-open-sourcing-automated-security-at-scale/)\t\n    * [Monitoring System at Alibaba](https://www.usenix.org/conference/srecon18asia/presentation/xinchi)\n    * [Real User Monitoring at Dailymotion](https://medium.com/dailymotion/real-user-monitoring-1948375f8be5)\n    * [Alerting Ecosystem at Uber](https://eng.uber.com/observability-at-scale/)\n\t* [Alerting Framework at Airbnb](https://medium.com/airbnb-engineering/alerting-framework-at-airbnb-35ba48df894f)\n\t* [Alerting on Service-Level Objectives (SLOs) at SoundCloud](https://developers.soundcloud.com/blog/alerting-on-slos)\n    * [Job-based Forecasting Workflow for Observability Anomaly Detection at Uber](https://eng.uber.com/observability-anomaly-detection/)\n\t* [Monitoring and Alert System using Graphite and Cabot at HackerEarth](http://engineering.hackerearth.com/2017/03/21/monitoring-and-alert-system-using-graphite-and-cabot/)\n    * [Observability (2 parts) at Twitter](https://blog.twitter.com/engineering/en_us/a/2016/observability-at-twitter-technical-overview-part-ii.html)\n    * [Distributed Security Alerting at Slack](https://slack.engineering/distributed-security-alerting-c89414c992d6)\n    * [Real-Time News Alerting at Bloomberg](https://www.infoq.com/presentations/news-alerting-bloomberg)\n\t* [Data Pipeline Monitoring System at LinkedIn](https://engineering.linkedin.com/blog/2019/an-inside-look-at-linkedins-data-pipeline-monitoring-system-)\n\t* [Monitoring and Observability at Picnic](https://blog.picnic.nl/monitoring-and-observability-at-picnic-684cefd845c4)\n* [Distributed Security](https://msdn.microsoft.com/en-us/library/cc767123.aspx)\n\t* [Approach to Security at Scale at Dropbox](https://blogs.dropbox.com/tech/2018/02/security-at-scale-the-dropbox-approach/)\n\t* [Aardvark and Repokid: AWS Least Privilege for Distributed, High-Velocity Development at Netflix](https://medium.com/netflix-techblog/introducing-aardvark-and-repokid-53b081bf3a7e)\t\n\t* [LISA: Distributed Firewall at LinkedIn](https://www.slideshare.net/MikeSvoboda/2017-lisa-linkedins-distributed-firewall-dfw)\n\t* [Secure Infrastructure To Store Bitcoin In The Cloud at Coinbase](https://engineering.coinbase.com/how-coinbase-builds-secure-infrastructure-to-store-bitcoin-in-the-cloud-30a6504e40ba)\n\t* [BinaryAlert: Real-time Serverless Malware Detection at Airbnb](https://medium.com/airbnb-engineering/binaryalert-real-time-serverless-malware-detection-ca44370c1b90)\n\t* [Scalable IAM Architecture to Secure Access to 100 AWS Accounts at Segment](https://segment.com/blog/secure-access-to-100-aws-accounts/)\n\t* [OAuth Audit Toolbox at Indeed](http://engineering.indeedblog.com/blog/2018/04/oaudit-toolbox/)\n\t* [Active Directory Password Blacklisting at Yelp](https://engineeringblog.yelp.com/2018/04/ad-password-blacklisting.html)\t\n\t* [Syscall Auditing at Scale at Slack](https://slack.engineering/syscall-auditing-at-scale-e6a3ca8ac1b8)\n\t* [Athenz: Fine-Grained, Role-Based Access Control at Yahoo](https://yahooeng.tumblr.com/post/160481899076/open-sourcing-athenz-fine-grained-role-based)\n\t* [WebAuthn Support for Secure Sign In at Dropbox](https://blogs.dropbox.com/tech/2018/05/introducing-webauthn-support-for-secure-dropbox-sign-in/)\n\t* [Security Development Lifecycle at Slack](https://slack.engineering/moving-fast-and-securing-things-540e6c5ae58a)\n\t* [Unprivileged Container Builds at Kinvolk](https://kinvolk.io/blog/2018/04/towards-unprivileged-container-builds/)\n\t* [Diffy: Differencing Engine for Digital Forensics in the Cloud at Netflix](https://medium.com/netflix-techblog/netflix-sirt-releases-diffy-a-differencing-engine-for-digital-forensics-in-the-cloud-37b71abd2698)\n\t* [Detecting Credential Compromise in AWS at Netflix](https://medium.com/netflix-techblog/netflix-cloud-security-detecting-credential-compromise-in-aws-9493d6fd373a)\n\t* [Scalable User Privacy at Spotify](https://labs.spotify.com/2018/09/18/scalable-user-privacy/)\n\t* [AVA: Audit Web Applications at Indeed](https://engineering.indeedblog.com/blog/2018/09/application-scanning/)\n\t* [TTL as a Service: Automatic Revocation of Stale Privileges at Yelp](https://engineeringblog.yelp.com/2018/11/ttl-as-a-service.html)\n\t* [Enterprise Key Management at Slack](https://slack.engineering/engineering-dive-into-slack-enterprise-key-management-1fce471b178c)\t\n\t* [Scalability and Authentication at Twitch](https://blog.twitch.tv/en/2019/03/15/how-twitch-addresses-scalability-and-authentication/)\n\t* [Edge Authentication and Token-Agnostic Identity Propagation at Netflix](https://netflixtechblog.com/edge-authentication-and-token-agnostic-identity-propagation-514e47e0b602)\n\t* [Hardening Kubernetes Infrastructure with Cilium at Palantir](https://blog.palantir.com/hardening-palantirs-kubernetes-infrastructure-with-cilium-1c40d4c7ef0)\n\t* [Improving Web Vulnerability Management through Automation at Lyft](https://eng.lyft.com/improving-web-vulnerability-management-through-automation-2631570d8415)\n\t* [Clock Skew when Syncing Password Payloads at Drobbox](https://dropbox.tech/application/dropbox-passwords-clock-skew-payload-sync-merge)\n* [Distributed Messaging, Queuing, and Event Streaming](https://arxiv.org/pdf/1704.00411.pdf)\n\t* [Cape: Event Stream Processing Framework at Dropbox](https://blogs.dropbox.com/tech/2017/05/introducing-cape/)\n\t* [Brooklin: Distributed Service for Near Real-Time Data Streaming at LinkedIn](https://engineering.linkedin.com/blog/2019/brooklin-open-source)\n\t* [Samza: Stream Processing System for Latency Insighs at LinkedIn](https://engineering.linkedin.com/blog/2018/04/samza-aeon--latency-insights-for-asynchronous-one-way-flows)\t\n\t* [Bullet: Forward-Looking Query Engine for Streaming Data at Yahoo](https://yahooeng.tumblr.com/post/161855616651/open-sourcing-bullet-yahoos-forward-looking)\n\t* [EventHorizon: Tool for Watching Events Streaming at Etsy](https://codeascraft.com/2018/05/29/the-eventhorizon-saga/)\n\t* [Qmessage: Distributed, Asynchronous Task Queue at Quora](https://engineering.quora.com/Qmessage-Handling-Billions-of-Tasks-Per-Day)\n\t* [Cherami: Message Queue System for Transporting Async Tasks at Uber](https://eng.uber.com/cherami/)\n\t* [Dynein: Distributed Delayed Job Queueing System at Airbnb](https://medium.com/airbnb-engineering/dynein-building-a-distributed-delayed-job-queueing-system-93ab10f05f99)\n\t* [Timestone: Queueing System for Non-Parallelizable Workloads at Netflix](https://netflixtechblog.com/timestone-netflixs-high-throughput-low-latency-priority-queueing-system-with-built-in-support-1abf249ba95f)\n\t* [Messaging Service at Riot Games](https://engineering.riotgames.com/news/riot-messaging-service)\n\t* [Messaging System Model at Dropbox](https://dropbox.tech/infrastructure/infrastructure-messaging-system-model-async-platform-evolution)\n\t* [Debugging Production with Event Logging at Zillow](https://www.zillow.com/engineering/debugging-production-event-logging/)\n\t* [Cross-platform In-app Messaging Orchestration Service at Netflix](https://medium.com/netflix-techblog/building-a-cross-platform-in-app-messaging-orchestration-service-86ba614f92d8)\n\t* [Video Gatekeeper at Netflix](https://medium.com/netflix-techblog/re-architecting-the-video-gatekeeper-f7b0ac2f6b00)\n\t* [Scaling Push Messaging for Millions of Devices at Netflix](https://www.infoq.com/presentations/neflix-push-messaging-scale)\n\t* [Delaying Asynchronous Message Processing with RabbitMQ at Indeed](http://engineering.indeedblog.com/blog/2017/06/delaying-messages/)\t\n\t* [Benchmarking Streaming Computation Engines at Yahoo](https://yahooeng.tumblr.com/post/135321837876/benchmarking-streaming-computation-engines-at)\n\t* [Improving Stream Data Quality With Protobuf Schema Validation at Deliveroo](https://deliveroo.engineering/2019/02/05/improving-stream-data-quality-with-protobuf-schema-validation.html)\n\t* [Scaling Email Infrastructure at Medium](https://medium.engineering/scaling-email-infrastructure-for-medium-digest-254223c883b8)\n\t* [Real-time Messaging at Slack](https://slack.engineering/real-time-messaging/)\n\t* [Event Stream Database at Nike](https://medium.com/nikeengineering/moving-faster-with-aws-by-creating-an-event-stream-database-dedec8ca3eeb)\n\t* [Event Tracking System at Udemy](https://medium.com/udemy-engineering/designing-the-new-event-tracking-system-at-udemy-a45e502216fd)\n    * [Event-Driven Messaging](https://martinfowler.com/articles/201701-event-driven.html)\n        * [Domain-Driven Design at Alibaba](https://medium.com/swlh/creating-coding-excellence-with-domain-driven-design-88f73d2232c3)\n        * [Domain-Driven Design at Weebly](https://medium.com/weebly-engineering/how-to-organize-your-monolith-before-breaking-it-into-services-69cbdb9248b0)\n        * [Domain-Driven Design at Moonpig](https://engineering.moonpig.com/development/modelling-for-domain-driven-design)\n        * [Scaling Event Sourcing for Netflix Downloads](https://www.infoq.com/presentations/netflix-scale-event-sourcing)\n        * [Scaling Event-Sourcing at Jet.com](https://medium.com/@eulerfx/scaling-event-sourcing-at-jet-9c873cac33b8)\n        * [Event Sourcing (2 parts) at eBay](https://www.ebayinc.com/stories/blogs/tech/event-sourcing-in-action-with-ebays-continuous-delivery-team/)\n\t\t* [Event Sourcing at FREE NOW](https://medium.com/inside-freenow/event-sourcing-an-evolutionary-perspective-31e7387aa6f1)\n\t\t* [Scalable content feed using Event Sourcing and CQRS patterns at Brainly](https://medium.com/engineering-brainly/scalable-content-feed-using-event-sourcing-and-cqrs-patterns-e09df98bf977)\n    * [Pub-Sub Messaging](https://aws.amazon.com/pub-sub-messaging/)\n\t\t* [Pulsar: Pub-Sub Messaging at Scale at Yahoo](https://yahooeng.tumblr.com/post/150078336821/open-sourcing-pulsar-pub-sub-messaging-at-scale)\n\t\t* [Wormhole: Pub-Sub System at Facebook](https://code.facebook.com/posts/188966771280871/wormhole-pub-sub-system-moving-data-through-space-and-time/)\n\t\t* [MemQ: Cloud Native Pub-Sub System at Pinterest](https://medium.com/pinterest-engineering/memq-an-efficient-scalable-cloud-native-pubsub-system-4402695dd4e7)\n\t\t* [Pub-Sub in Microservices at Netflix](https://medium.com/netflix-techblog/how-netflix-microservices-tackle-dataset-pub-sub-4a068adcc9a)\n\t* [Kafka - Message Broker](https://martin.kleppmann.com/papers/kafka-debull15.pdf)\t\n\t\t* [Kafka at LinkedIn](https://engineering.linkedin.com/kafka/running-kafka-scale)\n\t\t* [Kafka at Pinterest](https://medium.com/pinterest-engineering/how-pinterest-runs-kafka-at-scale-ff9c6f735be)\n\t\t* [Kafka at Trello](https://tech.trello.com/why-we-chose-kafka/)\t\n\t\t* [Kafka at Salesforce](https://engineering.salesforce.com/how-apache-kafka-inspired-our-platform-events-architecture-2f351fe4cf63)\n\t\t* [Kafka at The New York Times](https://open.nytimes.com/publishing-with-apache-kafka-at-the-new-york-times-7f0e3b7d2077)\n\t\t* [Kafka at Yelp](https://engineeringblog.yelp.com/2016/07/billions-of-messages-a-day-yelps-real-time-data-pipeline.html)\n\t\t* [Kafka at Criteo](https://medium.com/criteo-labs/upgrading-kafka-on-a-large-infra-3ee99f56e970)\n\t\t* [Kafka on Kubernetes at Shopify](https://shopifyengineering.myshopify.com/blogs/engineering/running-apache-kafka-on-kubernetes-at-shopify)\n\t\t* [Kafka on PaaSTA: Running Kafka on Kubernetes at Yelp (2 parts)](https://engineeringblog.yelp.com/2022/03/kafka-on-paasta-part-two.html)\n\t\t* [Migrating Kafka's Zookeeper with No Downtime at Yelp](https://engineeringblog.yelp.com/2019/01/migrating-kafkas-zookeeper-with-no-downtime.html)\n\t\t* [Reprocessing and Dead Letter Queues with Kafka at Uber](https://eng.uber.com/reliable-reprocessing/)\n\t\t* [Chaperone: Audit Kafka End-to-End at Uber](https://eng.uber.com/chaperone/)\n\t\t* [Finding Kafka throughput limit in infrastructure at Dropbox](https://blogs.dropbox.com/tech/2019/01/finding-kafkas-throughput-limit-in-dropbox-infrastructure/)\n\t\t* [Cost Orchestration at Walmart](https://medium.com/walmartlabs/cost-orchestration-at-walmart-f34918af67c4)\n\t\t* [InfluxDB and Kafka to Scale to Over 1 Million Metrics a Second at Hulu](https://medium.com/hulu-tech-blog/how-hulu-uses-influxdb-and-kafka-to-scale-to-over-1-million-metrics-a-second-1721476aaff5)\n\t\t* [Scaling Kafka to Support Data Growth at PayPal](https://medium.com/paypal-tech/scaling-kafka-to-support-paypals-data-growth-a0b4da420fab)\n\t* [Stream Data Deduplication](https://en.wikipedia.org/wiki/Data_deduplication)\n\t\t* [Exactly-once Semantics with Kafka](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/)\n\t\t* [Real-time Deduping at Tapjoy](http://eng.tapjoy.com/blog-list/real-time-deduping-at-scale)\n\t\t* [Deduplication at Segment](https://segment.com/blog/exactly-once-delivery/)\n\t\t* [Deduplication at Mail.Ru](https://medium.com/@andrewsumin/efficient-storage-how-we-went-down-from-50-pb-to-32-pb-99f9c61bf6b4)\n\t\t* [Petabyte Scale Data Deduplication at Mixpanel](https://medium.com/mixpaneleng/petabyte-scale-data-deduplication-mixpanel-engineering-e808c70c99f8)\n* [Distributed Logging](https://blog.codinghorror.com/the-problem-with-logging/)\n\t* [Logging at LinkedIn](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)\n\t* [Scalable and Reliable Log Ingestion at Pinterest](https://medium.com/@Pinterest_Engineering/scalable-and-reliable-data-ingestion-at-pinterest-b921c2ee8754)\n\t* [High-performance Replicated Log Service at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2015/building-distributedlog-twitter-s-high-performance-replicated-log-servic.html)\n\t* [Logging Service with Spark at CERN Accelerator](https://databricks.com/blog/2017/12/14/the-architecture-of-the-next-cern-accelerator-logging-service.html)\n\t* [Logging and Aggregation at Quora](https://engineering.quora.com/Logging-and-Aggregation-at-Quora)\n\t* [Collection and Analysis of Daemon Logs at Badoo](https://badoo.com/techblog/blog/2016/06/06/collection-and-analysis-of-daemon-logs-at-badoo/)\n\t* [Log Parsing with Static Code Analysis at Palantir](https://medium.com/palantir/using-static-code-analysis-to-improve-log-parsing-18f0d1843965)\t\t\n\t* [Centralized Application Logging at eBay](https://tech.ebayinc.com/engineering/low-latency-and-high-throughput-cal-ingress/)\n\t* [Enrich VPC Flow Logs at Hyper Scale to provide Network Insight at Netflix](https://netflixtechblog.com/hyper-scale-vpc-flow-logs-enrichment-to-provide-network-insight-e5f1db02910d)\t\n\t* [BookKeeper: Distributed Log Storage at Yahoo](https://yahooeng.tumblr.com/post/109908973316/bookkeeper-yahoos-distributed-log-storage-is)\n\t* [LogDevice: Distributed Data Store for Logs at Facebook](https://code.facebook.com/posts/357056558062811/logdevice-a-distributed-data-store-for-logs/)\n\t* [LogFeeder: Log Collection System at Yelp](https://engineeringblog.yelp.com/2018/03/introducing-logfeeder.html)\n\t* [DBLog: Generic Change-Data-Capture Framework at Netflix](https://medium.com/netflix-techblog/dblog-a-generic-change-data-capture-framework-69351fb9099b)\t\n* [Distributed Searching](http://nwds.cs.washington.edu/files/nwds/pdf/Distributed-WR.pdf)\n\t* [Search Architecture at Instagram](https://instagram-engineering.com/search-architecture-eeb34a936d3a)\n\t* [Search Architecture at eBay](http://www.cs.otago.ac.nz/homepages/andrew/papers/2017-8.pdf)\n\t* [Search Architecture at Box](https://medium.com/box-tech-blog/scaling-box-search-using-lumos-22d9e0cb4175)\n\t* [Search Discovery Indexing Platform at Coupang](https://medium.com/coupang-tech/the-evolution-of-search-discovery-indexing-platform-fa43e41305f9)\n\t* [Universal Search System at Pinterest](https://medium.com/pinterest-engineering/building-a-universal-search-system-for-pinterest-e4cb03a898d4)\n\t* [Improving Search Engine Efficiency by over 25% at eBay](https://www.ebayinc.com/stories/blogs/tech/making-e-commerce-search-faster/)\t\n\t* [Indexing and Querying Telemetry Logs with Lucene at Palantir](https://medium.com/palantir/indexing-and-querying-telemetry-logs-with-lucene-234c5ce3e5f3)\n\t* [Query Understanding at TripAdvisor](https://www.tripadvisor.com/engineering/query-understanding-at-tripadvisor/)\n\t* [Search Federation Architecture at LinkedIn (2018)](https://engineering.linkedin.com/blog/2018/03/search-federation-architecture-at-linkedin)\n\t* [Search at Slack](https://slack.engineering/search-at-slack-431f8c80619e)\n\t* [Search Engine at DoorDash](https://careersatdoordash.com/blog/introducing-doordashs-in-house-search-engine/)\n\t* [Stability and Scalability for Search at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2022/stability-and-scalability-for-search)\n\t* [Search Service at Twitter (2014)](https://blog.twitter.com/engineering/en_us/a/2014/building-a-complete-tweet-index.html)\n\t* [Autocomplete Search (2 parts) at Traveloka](https://medium.com/traveloka-engineering/high-quality-autocomplete-search-part-2-d5b15bb0dadf)\n\t* [Data-Driven Autocorrection System at Canva](https://product.canva.com/building-a-data-driven-autocorrection-system/)\n\t* [Adapting Search to Indian Phonetics at Flipkart](https://blog.flipkart.tech/adapting-search-to-indian-phonetics-cdbe65259686)\n\t* [Nautilus: Search Engine at Dropbox](https://blogs.dropbox.com/tech/2018/09/architecture-of-nautilus-the-new-dropbox-search-engine/)\n\t* [Galene: Search Architecture of LinkedIn](https://engineering.linkedin.com/search/did-you-mean-galene)\n\t* [Manas: High Performing Customized Search System at Pinterest](https://medium.com/@Pinterest_Engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f)\n\t* [Sherlock: Near Real Time Search Indexing at Flipkart](https://blog.flipkart.tech/sherlock-near-real-time-search-indexing-95519783859d)\n\t* [Nebula: Storage Platform to Build Search Backends at Airbnb](https://medium.com/airbnb-engineering/nebula-as-a-storage-platform-to-build-airbnbs-search-backends-ecc577b05f06)\n\t* [ELK (Elasticsearch, Logstash, Kibana) Stack](https://logz.io/blog/15-tech-companies-chose-elk-stack/)\n\t\t* [Predictions in Real Time with ELK at Uber](https://eng.uber.com/elk/)\n\t\t* [Building a scalable ELK stack at Envato](https://webuild.envato.com/blog/building-a-scalable-elk-stack/)\n\t\t* [ELK at Robinhood](https://robinhood.engineering/taming-elk-4e1349f077c3)\n\t\t* [Scaling Elasticsearch Clusters at Uber](https://www.infoq.com/presentations/uber-elasticsearch-clusters?utm_source=presentations_about_Case_Study&utm_medium=link&utm_campaign=Case_Study)\n\t\t* [Elasticsearch Performance Tuning Practice at eBay](https://www.ebayinc.com/stories/blogs/tech/elasticsearch-performance-tuning-practice-at-ebay/)\n\t\t* [Improve Performance using Elasticsearch Plugins (2 parts) at Tinder](https://medium.com/tinder-engineering/how-we-improved-our-performance-using-elasticsearch-plugins-part-2-b051da2ee85b)\n\t\t* [Elasticsearch at Kickstarter](https://kickstarter.engineering/elasticsearch-at-kickstarter-db3c487887fc)\n\t\t* [Log Parsing with Logstash and Google Protocol Buffers at Trivago](https://tech.trivago.com/2016/01/19/logstash_protobuf_codec/)\n\t\t* [Fast Order Search using Data Pipeline and Elasticsearch at Yelp](https://engineeringblog.yelp.com/2018/06/fast-order-search.html)\n\t\t* [Moving Core Business Search to Elasticsearch at Yelp](https://engineeringblog.yelp.com/2017/06/moving-yelps-core-business-search-to-elasticsearch.html)\n\t\t* [Sharding out Elasticsearch at Vinted](http://engineering.vinted.com/2017/06/05/sharding-out-elasticsearch/)\n\t\t* [Self-Ranking Search with Elasticsearch at Wattpad](http://engineering.wattpad.com/post/146216619727/self-ranking-search-with-elasticsearch-at-wattpad)\n\t\t* [Vulcanizer: a library for operating Elasticsearch at Github](https://github.blog/2019-03-05-vulcanizer-a-library-for-operating-elasticsearch/)\t\n* [Distributed Storage](http://highscalability.com/blog/2011/11/1/finding-the-right-data-solution-for-your-application-in-the.html)\n\t* [In-memory Storage](https://medium.com/@denisanikin/what-an-in-memory-database-is-and-how-it-persists-data-efficiently-f43868cff4c1)\n\t\t* [MemSQL Architecture - The Fast (MVCC, InMem, LockFree, CodeGen) And Familiar (SQL)](http://highscalability.com/blog/2012/8/14/memsql-architecture-the-fast-mvcc-inmem-lockfree-codegen-and.html)\n\t\t* [Optimizing Memcached Efficiency at Quora](https://engineering.quora.com/Optimizing-Memcached-Efficiency)\n\t\t* [Real-Time Data Warehouse with MemSQL on Cisco UCS](https://blogs.cisco.com/datacenter/memsql)\n\t\t* [Moving to MemSQL at Tapjoy](http://eng.tapjoy.com/blog-list/moving-to-memsql)\n\t\t* [MemSQL and Kinesis for Real-time Insights at Disney](https://conferences.oreilly.com/strata/strata-ca/public/schedule/detail/68131)\n\t\t* [MemSQL to Query Hundreds of Billions of Rows in a Dashboard at Pandora](https://engineering.pandora.com/using-memsql-at-pandora-79a86cb09b57)\n\t* [Object Storage](http://www.datacenterknowledge.com/archives/2013/10/04/object-storage-the-future-of-scale-out)\n\t\t* [Scaling HDFS at Uber](https://eng.uber.com/scaling-hdfs/)\n\t\t* [Reasons for Choosing S3 over HDFS at Databricks](https://databricks.com/blog/2017/05/31/top-5-reasons-for-choosing-s3-over-hdfs.html)\n\t\t* [File System on Amazon S3 at Quantcast](https://www.quantcast.com/blog/quantcast-file-system-on-amazon-s3/)\n\t\t* [Image Recovery at Scale Using S3 Versioning at Trivago](https://tech.trivago.com/2018/09/03/efficient-image-recovery-at-scale-using-amazon-s3-versioning/)\n\t\t* [Cloud Object Store at Yahoo](https://yahooeng.tumblr.com/post/116391291701/yahoo-cloud-object-store-object-storage-at)\n\t\t* [Ambry: Distributed Immutable Object Store at LinkedIn](https://www.usenix.org/conference/srecon17americas/program/presentation/shenoy)\n\t\t* [Dynamometer: Scale Testing HDFS on Minimal Hardware with Maximum Fidelity at LinkedIn](https://engineering.linkedin.com/blog/2018/02/dynamometer--scale-testing-hdfs-on-minimal-hardware-with-maximum)\n\t\t* [Hammerspace: Persistent, Concurrent, Off-heap Storage at Airbnb](https://medium.com/airbnb-engineering/hammerspace-persistent-concurrent-off-heap-storage-3db39bb04472)\n\t\t* [MezzFS: Mounting Object Storage in Media Processing Platform at Netflix](https://medium.com/netflix-techblog/mezzfs-mounting-object-storage-in-netflixs-media-processing-platform-cda01c446ba)\t\n\t\t* [Magic Pocket: In-house Multi-exabyte Storage System at Dropbox](https://blogs.dropbox.com/tech/2016/05/inside-the-magic-pocket/)\n* [Relational Databases](https://www.mysql.com/products/cluster/scalability.html)\n\t* [MySQL at Uber](https://www.uber.com/en-SG/blog/mysql-at-uber/)\n\t* [MySQL at Pinterest](https://medium.com/@Pinterest_Engineering/learn-to-stop-using-shiny-new-things-and-love-mysql-3e1613c2ce14)\n\t* [PostgreSQL at Twitch](https://blog.twitch.tv/en/2016/10/11/how-twitch-uses-postgresql-c34aa9e56f58)\n\t* [Scaling MySQL-based Financial Reporting System at Airbnb](https://medium.com/airbnb-engineering/tracking-the-money-scaling-financial-reporting-at-airbnb-6d742b80f040)\n\t* [Scaling MySQL at Wix](https://www.wix.engineering/post/scaling-to-100m-mysql-is-a-better-nosql)\n\t* [Building and Deploying MySQL Raft at Meta](https://engineering.fb.com/2023/05/16/data-infrastructure/mysql-raft-meta/)\n\t* [MaxScale (MySQL) Database Proxy at Airbnb](https://medium.com/airbnb-engineering/unlocking-horizontal-scalability-in-our-web-serving-tier-d907449cdbcf)\n\t* [Switching from Postgres to MySQL at Uber](https://www.uber.com/en-NL/blog/postgres-to-mysql-migration/)\n\t* [Handling Growth with Postgres at Instagram](https://engineering.instagram.com/handling-growth-with-postgres-5-tips-from-instagram-d5d7e7ffdfcb)\n\t* [Scaling the Analytics Database (Postgres) at TransferWise](http://tech.transferwise.com/scaling-our-analytics-database/)\n\t* [Updating a 50 Terabyte PostgreSQL Database at Adyen](https://medium.com/adyen/updating-a-50-terabyte-postgresql-database-f64384b799e7)\n\t* [Scaling Database Access for 100s of Billions of Queries per Day at PayPal](https://medium.com/paypal-engineering/scaling-database-access-for-100s-of-billions-of-queries-per-day-paypal-introducing-hera-e192adacda54)\n\t* [Minimizing Read-Write MySQL Downtime at Yelp](https://engineeringblog.yelp.com/2020/11/minimizing-read-write-mysql-downtime.html)\n\t* [Migrating MySQL from 5.6 to 8.0 at Facebook](https://engineering.fb.com/2021/07/22/data-infrastructure/mysql/)\n\t* [Migration from HBase to MyRocks at Quora](https://quoraengineering.quora.com/Migration-from-HBase-to-MyRocks-at-Quora)\n\t* [Replication](https://docs.microsoft.com/en-us/sql/relational-databases/replication/types-of-replication)\n\t\t* [MySQL Parallel Replication (4 parts) at Booking.com](https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-4-annex-under-the-hood-eb456cf8b2fb)\n\t\t* [Mitigating MySQL Replication Lag and Reducing Read Load at Github](https://githubengineering.com/mitigating-replication-lag-and-reducing-read-load-with-freno/)\n\t\t* [Read Consistency with Database Replicas at Shopify](https://shopify.engineering/read-consistency-database-replicas)\n\t\t* [Black-Box Auditing: Verifying End-to-End Replication Integrity between MySQL and Redshift at Yelp](https://engineeringblog.yelp.com/2018/04/black-box-auditing.html)\n\t\t* [Partitioning Main MySQL Database at Airbnb](https://medium.com/airbnb-engineering/how-we-partitioned-airbnb-s-main-database-in-two-weeks-55f7e006ff21)\n\t\t* [Herb: Multi-DC Replication Engine for Schemaless Datastore at Uber](https://eng.uber.com/herb-datacenter-replication/)\n\t* [Sharding](https://quabase.sei.cmu.edu/mediawiki/index.php/Shard_data_set_across_multiple_servers_(Range-based))\n\t\t* [Sharding MySQL at Pinterest](https://medium.com/@Pinterest_Engineering/sharding-pinterest-how-we-scaled-our-mysql-fleet-3f341e96ca6f)\n\t\t* [Sharding MySQL at Twilio](https://www.twilio.com/engineering/2014/06/26/how-we-replaced-our-data-pipeline-with-zero-downtime)\n\t\t* [Sharding MySQL at Square](https://medium.com/square-corner-blog/sharding-cash-10280fa3ef3b)\n\t\t* [Sharding MySQL at Quora](https://www.quora.com/q/quoraengineering/MySQL-sharding-at-Quora)\n\t\t* [Sharding Layer of Schemaless Datastore at Uber](https://eng.uber.com/schemaless-rewrite/)\n\t\t* [Sharding & IDs at Instagram](https://instagram-engineering.com/sharding-ids-at-instagram-1cf5a71e5a5c)\n\t\t* [Sharding Postgres at Notion](https://www.notion.so/blog/sharding-postgres-at-notion)\n\t\t* [Sharding Postgres at Figma](https://www.figma.com/blog/how-figmas-databases-team-lived-to-tell-the-scale/)\n\t\t* [Solr: Improving Performance for Batch Indexing at Box](https://blog.box.com/blog/solr-improving-performance-batch-indexing/)\t\n\t\t* [Geosharded Recommendations (3 parts) at Tinder](https://medium.com/tinder-engineering/geosharded-recommendations-part-3-consistency-2d2cb2f0594b)\n\t\t* [Scaling Services with Shard Manager at Facebook](https://engineering.fb.com/production-engineering/scaling-services-with-shard-manager/)\n\t* [Presto the Distributed SQL Query Engine](https://research.fb.com/wp-content/uploads/2019/03/Presto-SQL-on-Everything.pdf?)\n\t\t* [Presto at Pinterest](https://medium.com/@Pinterest_Engineering/presto-at-pinterest-a8bda7515e52)\n\t\t* [Presto Infrastructure at Lyft](https://eng.lyft.com/presto-infrastructure-at-lyft-b10adb9db01)\n\t\t* [Presto at Grab](https://engineering.grab.com/scaling-like-a-boss-with-presto)\n\t\t* [Engineering Data Analytics with Presto and Apache Parquet at Uber](https://eng.uber.com/presto/)\n\t\t* [Data Wrangling at Slack](https://slack.engineering/data-wrangling-at-slack-f2e0ff633b69)\n\t\t* [Presto in Big Data Platform on AWS at Netflix](https://medium.com/netflix-techblog/using-presto-in-our-big-data-platform-on-aws-938035909fd4)\n\t\t* [Presto Auto Scaling at Eventbrite](https://www.eventbrite.com/engineering/big-data-workloads-presto-auto-scaling/)\n\t\t* [Speed Up Presto with Alluxio Local Cache at Uber](https://www.uber.com/en-MY/blog/speed-up-presto-with-alluxio-local-cache/)\n* [NoSQL Databases](https://www.thoughtworks.com/insights/blog/nosql-databases-overview)\n\t* [Key-Value Databases](http://www.cs.ucsb.edu/~agrawal/fall2009/dynamo.pdf)\n\t\t* [DynamoDB at Nike](https://medium.com/nikeengineering/becoming-a-nimble-giant-how-dynamo-db-serves-nike-at-scale-4cc375dbb18e)\n\t\t* [DynamoDB at Segment](https://segment.com/blog/the-million-dollar-eng-problem/)\n\t\t* [DynamoDB at Mapbox](https://blog.mapbox.com/scaling-mapbox-infrastructure-with-dynamodb-streams-d53eabc5e972)\n\t\t* [Manhattan: Distributed Key-Value Database at Twitter](https://blog.twitter.com/engineering/en_us/a/2014/manhattan-our-real-time-multi-tenant-distributed-database-for-twitter-scale.html)\n\t\t* [Sherpa: Distributed NoSQL Key-Value Store at Yahoo](https://yahooeng.tumblr.com/post/120730204806/sherpa-scales-new-heights)\n\t\t* [HaloDB: Embedded Key-Value Storage Engine at Yahoo](https://yahooeng.tumblr.com/post/178262468576/introducing-halodb-a-fast-embedded-key-value)\n\t\t* [MPH: Fast and Compact Immutable Key-Value Stores at Indeed](http://engineering.indeedblog.com/blog/2018/02/indeed-mph/)\n\t\t* [Venice: Distributed Key-Value Database at Linkedin](https://engineering.linkedin.com/blog/2017/02/building-venice-with-apache-helix)\n\t* [Columnar Databases](https://aws.amazon.com/nosql/columnar/)\n\t\t* [Cassandra](http://www.cs.cornell.edu/projects/ladis2009/papers/lakshman-ladis2009.pdf)\n\t\t\t* [Cassandra at Instagram](https://www.slideshare.net/DataStax/cassandra-at-instagram-2016)\n\t\t\t* [Storing Images in Cassandra at Walmart](https://medium.com/walmartlabs/building-object-store-storing-images-in-cassandra-walmart-scale-a6b9c02af593)\n\t\t\t* [Storing Messages with Cassandra at Discord](https://blog.discordapp.com/how-discord-stores-billions-of-messages-7fa6ec7ee4c7)\n\t\t\t* [Scaling Cassandra Cluster at Walmart](https://medium.com/walmartlabs/avoid-pitfalls-in-scaling-your-cassandra-cluster-lessons-and-remedies-a71ca01f8c04)\n\t\t\t* [Scaling Ad Analytics with Cassandra at Yelp](https://engineeringblog.yelp.com/2016/08/how-we-scaled-our-ad-analytics-with-cassandra.html)\n\t\t\t* [Scaling to 100+ Million Reads/Writes using Spark and Cassandra at Dream11](https://medium.com/dream11-tech-blog/leaderboard-dream11-4efc6f93c23e)\t\t\n\t\t\t* [Moving Food Feed from Redis to Cassandra at Zomato](https://www.zomato.com/blog/how-we-moved-our-food-feed-from-redis-to-cassandra)\n\t\t\t* [Benchmarking Cassandra Scalability on AWS at Netflix](https://medium.com/netflix-techblog/benchmarking-cassandra-scalability-on-aws-over-a-million-writes-per-second-39f45f066c9e)\n\t\t\t* [Service Decomposition at Scale with Cassandra at Intuit QuickBooks](https://quickbooks-engineering.intuit.com/service-decomposition-at-scale-70405ac2f637)\n\t\t\t* [Cassandra for Keeping Counts In Sync at SoundCloud](https://developers.soundcloud.com/blog/keeping-counts-in-sync)\n\t\t\t* [Cassandra Driver Configuration for Improved Performance and Load Balancing at Glassdoor](https://medium.com/glassdoor-engineering/cassandra-driver-configuration-for-improved-performance-and-load-balancing-1b0106ce12bb)\n\t\t\t* [cstar: Cassandra Orchestration Tool at Spotify](https://labs.spotify.com/2018/09/04/introducing-cstar-the-spotify-cassandra-orchestration-tool-now-open-source/)\n\t\t* [HBase](https://hbase.apache.org/)\n\t\t\t* [HBase at Salesforce](https://engineering.salesforce.com/investing-in-big-data-apache-hbase-b9d98661a66b)\n\t\t\t* [HBase in Facebook Messages](https://www.facebook.com/notes/facebook-engineering/the-underlying-technology-of-messages/454991608919/)\n\t\t\t* [HBase in Imgur Notification](https://blog.imgur.com/2015/09/15/tech-tuesday-imgur-notifications-from-mysql-to-hbase/)\n\t\t\t* [Improving HBase Backup Efficiency at Pinterest](https://medium.com/@Pinterest_Engineering/improving-hbase-backup-efficiency-at-pinterest-86159da4b954)\n\t\t\t* [HBase at Xiaomi](https://www.slideshare.net/HBaseCon/hbase-practice-at-xiaomi)\n\t\t* [Redshift](https://www.allthingsdistributed.com/2018/11/amazon-redshift-performance-optimization.html)\n\t\t\t* [Redshift at GIPHY](https://engineering.giphy.com/scaling-redshift-without-scaling-costs/)\n\t\t\t* [Redshift at Hudl](https://www.hudl.com/bits/the-low-hanging-fruit-of-redshift-performance)\n\t\t\t* [Redshift at Drivy](https://drivy.engineering/redshift_tips_ticks_part_1/)\n\t* [Document Databases](https://msdn.microsoft.com/en-us/magazine/hh547103.aspx)\n\t\t* [eBay: Building Mission-Critical Multi-Data Center Applications with MongoDB](https://www.mongodb.com/blog/post/ebay-building-mission-critical-multi-data-center-applications-with-mongodb)\n\t\t* [MongoDB at Baidu: Multi-Tenant Cluster Storing 200+ Billion Documents across 160 Shards](https://www.mongodb.com/blog/post/mongodb-at-baidu-powering-100-apps-across-600-nodes-at-pb-scale)\n\t\t* [Migrating Mongo Data at Addepar](https://medium.com/build-addepar/migrating-mountains-of-mongo-data-63e530539952)\n\t\t* [The AWS and MongoDB Infrastructure of Parse (acquired by Facebook)](https://medium.baqend.com/parse-is-gone-a-few-secrets-about-their-infrastructure-91b3ab2fcf71)\n\t\t* [Migrating Mountains of Mongo Data at Addepar](https://medium.com/build-addepar/migrating-mountains-of-mongo-data-63e530539952)\n\t\t* [Couchbase Ecosystem at LinkedIn](https://engineering.linkedin.com/blog/2017/12/couchbase-ecosystem-at-linkedin)\n\t\t* [SimpleDB at Zendesk](https://medium.com/zendesk-engineering/resurrecting-amazon-simpledb-9404034ec506)\n\t\t* [Espresso: Distributed Document Store at LinkedIn](https://engineering.linkedin.com/espresso/introducing-espresso-linkedins-hot-new-distributed-document-store)\n\t* [Graph Databases](https://www.eecs.harvard.edu/margo/papers/systor13-bench/)\n\t\t* [FlockDB: Distributed Graph Database at Twitter](https://blog.twitter.com/engineering/en_us/a/2010/introducing-flockdb.html)\n\t\t* [TAO: Distributed Data Store for the Social Graph at Facebook](https://www.cs.cmu.edu/~pavlo/courses/fall2013/static/papers/11730-atc13-bronson.pdf)\n\t\t* [Akutan: Distributed Knowledge Graph Store at eBay](https://tech.ebayinc.com/engineering/akutan-a-distributed-knowledge-graph-store/)\n* [Time Series Databases](https://www.influxdata.com/time-series-database/)\n\t* [Beringei: High-performance Time Series Storage Engine at Facebook](https://code.facebook.com/posts/952820474848503/beringei-a-high-performance-time-series-storage-engine/)\n\t* [MetricsDB: TimeSeries Database for storing metrics at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2019/metricsdb.html)\t\n\t* [Atlas: In-memory Dimensional Time Series Database at Netflix](https://medium.com/netflix-techblog/introducing-atlas-netflixs-primary-telemetry-platform-bd31f4d8ed9a)\n\t* [Heroic: Time Series Database at Spotify](https://labs.spotify.com/2015/11/17/monitoring-at-spotify-introducing-heroic/)\n\t* [Roshi: Distributed Storage System for Time-Series Event at SoundCloud](https://developers.soundcloud.com/blog/roshi-a-crdt-system-for-timestamped-events)\n\t* [Goku: Time Series Database at Pinterest](https://medium.com/@Pinterest_Engineering/goku-building-a-scalable-and-high-performant-time-series-database-system-a8ff5758a181)\n\t* [Scaling Time Series Data Storage (2 parts) at Netflix](https://medium.com/netflix-techblog/scaling-time-series-data-storage-part-ii-d67939655586)\n\t* [Time Series Data Abstraction Layer at Netflix](https://netflixtechblog.com/introducing-netflix-timeseries-data-abstraction-layer-31552f6326f8)\n\t* [Druid - Real-time Analytics Database](https://druid.apache.org/)\n\t\t* [Druid at Airbnb](https://medium.com/airbnb-engineering/druid-airbnb-data-platform-601c312f2a4c)\n\t\t* [Druid at Walmart](https://medium.com/walmartlabs/event-stream-analytics-at-walmart-with-druid-dcf1a37ceda7)\n\t\t* [Druid at eBay](https://tech.ebayinc.com/engineering/monitoring-at-ebay-with-druid/)\n\t\t* [Druid at Netflix](https://netflixtechblog.com/how-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06)\n* [Distributed Repositories, Dependencies, and Configurations Management](https://betterexplained.com/articles/intro-to-distributed-version-control-illustrated/)\n\t* [DGit: Distributed Git at Github](https://githubengineering.com/introducing-dgit/)\n\t* [Stemma: Distributed Git Server at Palantir](https://medium.com/@palantir/stemma-distributed-git-server-70afbca0fc29)\n\t* [Configuration Management for Distributed Systems at Flickr](https://code.flickr.net/2016/03/24/configuration-management-for-distributed-systems-using-github-and-cfg4j/)\n\t* [Git Repository at Microsoft](https://blogs.msdn.microsoft.com/bharry/2017/05/24/the-largest-git-repo-on-the-planet/)\n\t* [Solve Git Problem with Large Repositories at Microsoft](https://www.infoq.com/news/2017/02/GVFS)\t\n\t* [Single Repository at Google](https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext)\t\n\t* [Scaling Infrastructure and (Git) Workflow at Adyen](https://medium.com/adyen/from-0-100-billion-scaling-infrastructure-and-workflow-at-adyen-7b63b690dfb6)\t\n\t* [Dotfiles Distribution at Booking.com](https://medium.com/booking-com-infrastructure/dotfiles-distribution-dedb69c66a75)\n\t* [Secret Detector: Preventing Secrets in Source Code at Yelp](https://engineeringblog.yelp.com/2018/06/yelps-secret-detector.html)\n\t* [Managing Software Dependency at Scale at LinkedIn](https://engineering.linkedin.com/blog/2018/09/managing-software-dependency-at-scale)\n\t* [Merging Code in High-velocity Repositories at LinkedIn](https://engineering.linkedin.com/blog/2020/continuous-integration)\n\t* [Dynamic Configuration at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2018/dynamic-configuration-at-twitter.html)\n\t* [Dynamic Configuration at Mixpanel](https://medium.com/mixpaneleng/dynamic-configuration-at-mixpanel-94bfcf97d6b8)\n\t* [Dynamic Configuration at GoDaddy](https://sg.godaddy.com/engineering/2019/03/06/dynamic-configuration-for-nodejs/)\n\t* [Fleet Management (3 parts) at Spotify](https://engineering.atspotify.com/2023/5/fleet-management-at-spotify-part-3-fleet-wide-refactoring)\n* [Scaling Continuous Integration and Continuous Delivery](https://www.synopsys.com/blogs/software-security/agile-cicd-devops-glossary/)\n\t* [Continuous Integration Stack at Facebook](https://code.fb.com/web/rapid-release-at-massive-scale/)\n\t* [Continuous Integration with Distributed Repositories and Dependencies at Netflix](https://medium.com/netflix-techblog/towards-true-continuous-integration-distributed-repositories-and-dependencies-2a2e3108c051)\n\t* [Continuous Integration and Deployment with Bazel at Dropbox](https://blogs.dropbox.com/tech/2019/12/continuous-integration-and-deployment-with-bazel/)\n\t* [Adopting Bazel for Web at Airbnb](https://medium.com/airbnb-engineering/adopting-bazel-for-web-at-scale-a784b2dbe325)\n\t* [Continuous Deployments at BuzzFeed](https://tech.buzzfeed.com/continuous-deployments-at-buzzfeed-d171f76c1ac4)\n\t* [Screwdriver: Continuous Delivery Build System for Dynamic Infrastructure at Yahoo](https://yahooeng.tumblr.com/post/155765242061/open-sourcing-screwdriver-yahoos-continuous)\n\t* [CI/CD at Betterment](https://www.betterment.com/resources/ci-cd-shortening-the-feedback-loop/)\n\t* [CI/CD at Brainly](https://medium.com/engineering-brainly/ci-cd-at-scale-fdfb0f49e031)\n\t* [Scaling iOS CI with Anka at Shopify](https://engineering.shopify.com/blogs/engineering/scaling-ios-ci-with-anka)\n\t* [Scaling Jira Server at Yelp](https://engineeringblog.yelp.com/2019/04/Scaling-Jira-Server-Administration-For-The-Enterprise.html)\n\t* [Auto-scaling CI/CD cluster at Flexport](https://flexport.engineering/how-flexport-halved-testing-costs-with-an-auto-scaling-ci-cd-cluster-8304297222f)\n\n## Availability\n* [Resilience Engineering: Learning to Embrace Failure](https://queue.acm.org/detail.cfm?id=2371297)\t\n\t* [Resilience Engineering with Project Waterbear at LinkedIn](https://engineering.linkedin.com/blog/2017/11/resilience-engineering-at-linkedin-with-project-waterbear)\n\t* [Resiliency against Traffic Oversaturation at iHeartRadio](https://tech.iheart.com/resiliency-against-traffic-oversaturation-77c5ed92a5fb)\n\t* [Resiliency in Distributed Systems at GO-JEK](https://blog.gojekengineering.com/resiliency-in-distributed-systems-efd30f74baf4)\n\t* [Practical NoSQL Resilience Design Pattern for the Enterprise at eBay](https://www.ebayinc.com/stories/blogs/tech/practical-nosql-resilience-design-pattern-for-the-enterprise/)\n\t* [Ensuring Resilience to Disaster at Quora](https://engineering.quora.com/Ensuring-Quoras-Resilience-to-Disaster)\n\t* [Site Resiliency at Expedia](https://www.infoq.com/presentations/expedia-website-resiliency?utm_source=presentations_about_Case_Study&utm_medium=link&utm_campaign=Case_Study)\n\t* [Resiliency and Disaster Recovery with Kafka at eBay](https://tech.ebayinc.com/engineering/resiliency-and-disaster-recovery-with-kafka/)\n\t* [Disaster Recovery for Multi-Region Kafka at Uber](https://eng.uber.com/kafka/)\n* [Failover](http://cloudpatterns.org/mechanisms/failover_system)\n\t* [The Evolution of Global Traffic Routing and Failover](https://www.usenix.org/conference/srecon16/program/presentation/heady)\n\t* [Testing for Disaster Recovery Failover Testing](https://www.usenix.org/conference/srecon17asia/program/presentation/liu_zehua)\n\t* [Designing a Microservices Architecture for Failure](https://blog.risingstack.com/designing-microservices-architecture-for-failure/)\n\t* [ELB for Automatic Failover at GoSquared](https://engineering.gosquared.com/use-elb-automatic-failover)\n\t* [Eliminate the Database for Higher Availability at American Express](http://americanexpress.io/eliminate-the-database-for-higher-availability/)\n\t* [Failover with Redis Sentinel at Vinted](http://engineering.vinted.com/2015/09/03/failover-with-redis-sentinel/)\n\t* [High-availability SaaS Infrastructure at FreeAgent](http://engineering.freeagent.com/2017/02/06/ha-infrastructure-without-breaking-the-bank/)\n\t* [MySQL High Availability at GitHub](https://github.blog/2018-06-20-mysql-high-availability-at-github/)\n\t* [MySQL High Availability at Eventbrite](https://www.eventbrite.com/engineering/mysql-high-availability-at-eventbrite/)\n\t* [Business Continuity & Disaster Recovery at Walmart](https://medium.com/walmartlabs/business-continuity-disaster-recovery-in-the-microservices-world-ef2adca363df)\n* [Load Balancing](https://blog.vivekpanyam.com/scaling-a-web-service-load-balancing/)\n\t* [Introduction to Modern Network Load Balancing and Proxying](https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236)\n\t* [Top Five (Load Balancing) Scalability Patterns](https://www.f5.com/company/blog/top-five-scalability-patterns)\n\t* [Load Balancing infrastructure to support more than 1.3 billion users at Facebook](https://www.usenix.org/conference/srecon15europe/program/presentation/shuff)\n\t* [DHCPLB: DHCP Load Balancer at Facebook](https://code.facebook.com/posts/1734309626831603/dhcplb-an-open-source-load-balancer/)\n\t* [Katran: Scalable Network Load Balancer at Facebook](https://code.facebook.com/posts/1906146702752923/open-sourcing-katran-a-scalable-network-load-balancer/)\n\t* [Deterministic Aperture: A Distributed, Load Balancing Algorithm at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2019/daperture-load-balancer.html)\t\n\t* [Load Balancing with Eureka at Netflix](https://medium.com/netflix-techblog/netflix-shares-cloud-load-balancing-and-failover-tool-eureka-c10647ef95e5)\n\t* [Edge Load Balancing at Netflix](https://medium.com/netflix-techblog/netflix-edge-load-balancing-695308b5548c)\n\t* [Zuul 2: Cloud Gateway at Netflix](https://medium.com/netflix-techblog/open-sourcing-zuul-2-82ea476cb2b3)\n\t* [Load Balancing at Yelp](https://engineeringblog.yelp.com/2017/05/taking-zero-downtime-load-balancing-even-further.html)\n\t* [Load Balancing at Github](https://githubengineering.com/introducing-glb/)\n\t* [Consistent Hashing to Improve Load Balancing at Vimeo](https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed)\n\t* [UDP Load Balancing at 500 pixel](https://developers.500px.com/udp-load-balancing-with-keepalived-167382d7ad08)\n\t* [QALM: QoS Load Management Framework at Uber](https://eng.uber.com/qalm/)\t\n\t* [Traffic Steering using Rum DNS at LinkedIn](https://www.usenix.org/conference/srecon17europe/program/presentation/rastogi)\n\t* [Traffic Infrastructure (Edge Network) at Dropbox](https://blogs.dropbox.com/tech/2018/10/dropbox-traffic-infrastructure-edge-network/)\n\t* [Intelligent DNS based load balancing at Dropbox](https://blogs.dropbox.com/tech/2020/01/intelligent-dns-based-load-balancing-at-dropbox/)\n\t* [Monitor DNS systems at Stripe](https://stripe.com/en-sg/blog/secret-life-of-dns)\n\t* [Multi-DNS Architecture (3 parts) at Monday](https://medium.com/monday-engineering/how-and-why-we-migrated-our-dns-from-cloudflare-to-a-multi-dns-architecture-part-3-584a470f4062)\n\t* [Dynamic Anycast DNS Infrastructure at Hulu](https://medium.com/hulu-tech-blog/building-hulus-dynamic-anycast-dns-infrastructure-985a7a11fd30)\n* [Rate Limiting](https://www.keycdn.com/support/rate-limiting/)\n\t* [Rate Limiting for Scaling to Millions of Domains at Cloudflare](https://blog.cloudflare.com/counting-things-a-lot-of-different-things/)\n\t* [Cloud Bouncer: Distributed Rate Limiting at Yahoo](https://yahooeng.tumblr.com/post/111288877956/cloud-bouncer-distributed-rate-limiting-at-yahoo)\n\t* [Scaling API with Rate Limiters at Stripe](https://stripe.com/blog/rate-limiters)\n\t* [Distributed Rate Limiting at Allegro](https://allegro.tech/2017/04/hermes-max-rate.html)\n\t* [Ratequeue: Core Queueing-And-Rate-Limiting System at Twilio](https://www.twilio.com/blog/2017/11/chaos-engineering-ratequeue-ha.html)\n\t* [Quotas Service at Grab](https://engineering.grab.com/quotas-service)\n\t* [Rate Limiting at Figma](https://medium.com/figma-design/an-alternative-approach-to-rate-limiting-f8a06cf7c94c)\t\n* [Autoscaling](https://medium.com/@BotmetricHQ/top-11-hard-won-lessons-learned-about-aws-auto-scaling-5bfe56da755f)\n\t* [Autoscaling Pinterest](https://medium.com/@Pinterest_Engineering/auto-scaling-pinterest-df1d2beb4d64)\n\t* [Autoscaling Based on Request Queuing at Square](https://medium.com/square-corner-blog/autoscaling-based-on-request-queuing-c4c0f57f860f)\n\t* [Autoscaling Jenkins at Trivago](http://tech.trivago.com/2017/02/17/your-definite-guide-for-autoscaling-jenkins/)\n\t* [Autoscaling Pub-Sub Consumers at Spotify](https://labs.spotify.com/2017/11/20/autoscaling-pub-sub-consumers/)\n\t* [Autoscaling Bigtable Clusters based on CPU Load at Spotify](https://labs.spotify.com/2018/12/18/bigtable-autoscaler-saving-money-and-time-using-managed-storage/)\n\t* [Autoscaling AWS Step Functions Activities at Yelp](https://engineeringblog.yelp.com/2019/06/autoscaling-aws-step-functions-activities.html)\n\t* [Scryer: Predictive Auto Scaling Engine at Netflix](https://medium.com/netflix-techblog/scryer-netflixs-predictive-auto-scaling-engine-a3f8fc922270)\t\n\t* [Bouncer: Simple AWS Auto Scaling Rollovers at Palantir](https://medium.com/palantir/bouncer-simple-aws-auto-scaling-rollovers-c5af601d65d4)\n\t* [Clusterman: Autoscaling Mesos Clusters at Yelp](https://engineeringblog.yelp.com/2019/02/autoscaling-mesos-clusters-with-clusterman.html)\n* [Availability in Globally Distributed Storage Systems at Google](http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/36737.pdf)\t\n* [NodeJS High Availability at Yahoo](https://yahooeng.tumblr.com/post/68823943185/nodejs-high-availability)\n* [Operations (11 parts) at LinkedIn](https://www.linkedin.com/pulse/introduction-every-day-monday-operations-benjamin-purgason)\n* [Monitoring Powers High Availability for LinkedIn Feed](https://www.usenix.org/conference/srecon17americas/program/presentation/barot)\n* [Supporting Global Events at Facebook](https://code.facebook.com/posts/166966743929963/how-production-engineers-support-global-events-on-facebook/)\n* [High Availability at BlaBlaCar](https://medium.com/blablacar-tech/the-expendables-backends-high-availability-at-blablacar-8cea3b95b26b)\n* [High Availability at Netflix](https://medium.com/@NetflixTechBlog/tips-for-high-availability-be0472f2599c)\n* [High Availability Cloud Infrastructure at Twilio](https://www.twilio.com/engineering/2011/12/12/scaling-high-availablity-infrastructure-in-cloud)\n* [Automating Datacenter Operations at Dropbox](https://blogs.dropbox.com/tech/2019/01/automating-datacenter-operations-at-dropbox/)\n* [Globalizing Player Accounts at Riot Games](https://technology.riotgames.com/news/globalizing-player-accounts)\n\n## Stability\n* [Circuit Breaker](https://martinfowler.com/bliki/CircuitBreaker.html)\n\t* [Circuit Breaking in Distributed Systems](https://www.infoq.com/presentations/circuit-breaking-distributed-systems)\n\t* [Circuit Breaker for Scaling Containers](https://f5.com/about-us/blog/articles/the-art-of-scaling-containers-circuit-breakers-28919)\n\t* [Lessons in Resilience at SoundCloud](https://developers.soundcloud.com/blog/lessons-in-resilience-at-SoundCloud)\n\t* [Protector: Circuit Breaker for Time Series Databases at Trivago](http://tech.trivago.com/2016/02/23/protector/)\n\t* [Improved Production Stability with Circuit Breakers at Heroku](https://blog.heroku.com/improved-production-stability-with-circuit-breakers)\n\t* [Circuit Breaker at Zendesk](https://medium.com/zendesk-engineering/the-joys-of-circuit-breaking-ee6584acd687)\n\t* [Circuit Breaker at Traveloka](https://medium.com/traveloka-engineering/circuit-breakers-dont-let-your-dependencies-bring-you-down-5ba1c5cf1eec)\n\t* [Circuit Breaker at Shopify](https://shopify.engineering/circuit-breaker-misconfigured)\n* [Timeouts](https://www.javaworld.com/article/2824163/application-performance/stability-patterns-applied-in-a-restful-architecture.html)\n\t* [Fault Tolerance (Timeouts and Retries, Thread Separation, Semaphores, Circuit Breakers) at Netflix](https://medium.com/netflix-techblog/fault-tolerance-in-a-high-volume-distributed-system-91ab4faae74a)\n\t* [Enforce Timeout: A Reliability Methodology at DoorDash](https://doordash.engineering/2018/12/21/enforce-timeout-a-doordash-reliability-methodology/)\n\t* [Troubleshooting a Connection Timeout Issue with tcp_tw_recycle Enabled at eBay](https://www.ebayinc.com/stories/blogs/tech/a-vip-connection-timeout-issue-caused-by-snat-and-tcp-tw-recycle/)\n* [Crash-safe Replication for MySQL at Booking.com](https://medium.com/booking-com-infrastructure/better-crash-safe-replication-for-mysql-a336a69b317f)\n* [Bulkheads: Partition and Tolerate Failure in One Part](https://skife.org/architecture/fault-tolerance/2009/12/31/bulkheads.html)\n* [Steady State: Always Put Logs on Separate Disk](https://docs.microsoft.com/en-us/sql/relational-databases/policy-based-management/place-data-and-log-files-on-separate-drives)\n* [Throttling: Maintain a Steady Pace](http://www.sosp.org/2001/papers/welsh.pdf)\n* [Multi-Clustering: Improving Resiliency and Stability of a Large-scale Monolithic API Service at LinkedIn](https://engineering.linkedin.com/blog/2017/11/improving-resiliency-and-stability-of-a-large-scale-api)\n* [Determinism (4 parts) in League of Legends Server](https://engineering.riotgames.com/news/determinism-league-legends-fixing-divergences)\n\n## Performance\n* [Performance Optimization on OS, Storage, Database, Network](https://stackify.com/application-performance-metrics/)\n\t* [Improving Performance with Background Data Prefetching at Instagram](https://engineering.instagram.com/improving-performance-with-background-data-prefetching-b191acb39898)\n\t* [Fixing Linux filesystem performance regressions at LinkedIn](https://engineering.linkedin.com/blog/2020/fixing-linux-filesystem-performance-regressions)\n\t* [Compression Techniques to Solve Network I/O Bottlenecks at eBay](https://www.ebayinc.com/stories/blogs/tech/how-ebays-shopping-cart-used-compression-techniques-to-solve-network-io-bottlenecks/)\n\t* [Optimizing Web Servers for High Throughput and Low Latency at Dropbox](https://blogs.dropbox.com/tech/2017/09/optimizing-web-servers-for-high-throughput-and-low-latency/)\n\t* [Linux Performance Analysis in 60.000 Milliseconds at Netflix](https://medium.com/netflix-techblog/linux-performance-analysis-in-60-000-milliseconds-accc10403c55)\n\t* [Live Downsizing Google Cloud Persistent Disks (PD-SSD) at Mixpanel](https://engineering.mixpanel.com/2018/07/31/live-downsizing-google-cloud-pds-for-fun-and-profit/)\n\t* [Decreasing RAM Usage by 40% Using jemalloc with Python & Celery at Zapier](https://zapier.com/engineering/celery-python-jemalloc/)\n\t* [Reducing Memory Footprint at Slack](https://slack.engineering/reducing-slacks-memory-footprint-4480fec7e8eb)\n\t* [Continuous Load Testing at Slack](https://slack.engineering/continuous-load-testing/)\n\t* [Performance Improvements at Pinterest](https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7)\n\t* [Server Side Rendering at Wix](https://www.youtube.com/watch?v=f9xI2jR71Ms)\n\t* [30x Performance Improvements on MySQLStreamer at Yelp](https://engineeringblog.yelp.com/2018/02/making-30x-performance-improvements-on-yelps-mysqlstreamer.html)\n\t* [Optimizing APIs at Netflix](https://medium.com/netflix-techblog/optimizing-the-netflix-api-5c9ac715cf19)\n\t* [Performance Monitoring with Riemann and Clojure at Walmart](https://medium.com/walmartlabs/performance-monitoring-with-riemann-and-clojure-eafc07fcd375)\n\t* [Performance Tracking Dashboard for Live Games at Zynga](https://www.zynga.com/blogs/engineering/live-games-have-evolving-performance)\n\t* [Optimizing CAL Report Hadoop MapReduce Jobs at eBay](https://www.ebayinc.com/stories/blogs/tech/optimization-of-cal-report-hadoop-mapreduce-job/)\n\t* [Performance Tuning on Quartz Scheduler at eBay](https://www.ebayinc.com/stories/blogs/tech/performance-tuning-on-quartz-scheduler/)\n\t* [Profiling C++ (Part 1: Optimization, Part 2: Measurement and Analysis) at Riot Games](https://engineering.riotgames.com/news/profiling-optimisation)\n\t* [Profiling React Server-Side Rendering at HomeAway](https://medium.com/homeaway-tech-blog/profiling-react-server-side-rendering-to-free-the-node-js-event-loop-7f0fe455a901)\n\t* [Hardware-Assisted Video Transcoding at Dailymotion](https://medium.com/dailymotion-engineering/hardware-assisted-video-transcoding-at-dailymotion-66cd2db448ae)\n\t* [Cross Shard Transactions at 10 Million RPS at Dropbox](https://blogs.dropbox.com/tech/2018/11/cross-shard-transactions-at-10-million-requests-per-second/)\n\t* [API Profiling at Pinterest](https://medium.com/@Pinterest_Engineering/api-profiling-at-pinterest-6fa9333b4961)\n\t* [Pagelets Parallelize Server-side Processing at Yelp](https://engineeringblog.yelp.com/2017/07/generating-web-pages-in-parallel-with-pagelets.html)\n\t* [Improving key expiration in Redis at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2019/improving-key-expiration-in-redis.html)\n\t* [Ad Delivery Network Performance Optimization with Flame Graphs at MindGeek](https://medium.com/mindgeek-engineering-blog/ad-delivery-network-performance-optimization-with-flame-graphs-bc550cf59cf7)\n\t* [Predictive CPU isolation of containers at Netflix](https://medium.com/netflix-techblog/predictive-cpu-isolation-of-containers-at-netflix-91f014d856c7)\n\t* [Improving HDFS I/O Utilization for Efficiency at Uber](https://eng.uber.com/improving-hdfs-i-o-utilization-for-efficiency/)\n\t* [Cloud Jewels: Estimating kWh in the Cloud at Etsy](https://codeascraft.com/2020/04/23/cloud-jewels-estimating-kwh-in-the-cloud/)\n\t* [Unthrottled: Fixing CPU Limits in the Cloud (2 parts) at Indeed](https://engineering.indeedblog.com/blog/2019/12/unthrottled-fixing-cpu-limits-in-the-cloud/)\n* [Performance Optimization by Tuning Garbage Collection](https://confluence.atlassian.com/enterprise/garbage-collection-gc-tuning-guide-461504616.html)\n\t* [Garbage Collection in Java Applications at LinkedIn](https://engineering.linkedin.com/garbage-collection/garbage-collection-optimization-high-throughput-and-low-latency-java-applications)\n\t* [Garbage Collection in High-Throughput, Low-Latency Machine Learning Services at Adobe](https://medium.com/adobetech/engineering-high-throughput-low-latency-machine-learning-services-7d45edac0271)\n\t* [Garbage Collection in Redux Applications at SoundCloud](https://developers.soundcloud.com/blog/garbage-collection-in-redux-applications)\n\t* [Garbage Collection in Go Application at Twitch](https://blog.twitch.tv/go-memory-ballast-how-i-learnt-to-stop-worrying-and-love-the-heap-26c2462549a2)\n\t* [Analyzing V8 Garbage Collection Logs at Alibaba](https://www.linux.com/blog/can-nodejs-scale-ask-team-alibaba)\n\t* [Python Garbage Collection for Dropping 50% Memory Growth Per Request at Instagram](https://instagram-engineering.com/copy-on-write-friendly-python-garbage-collection-ad6ed5233ddf)\n\t* [Performance Impact of Removing Out of Band Garbage Collector (OOBGC) at Github](https://githubengineering.com/removing-oobgc/)\n\t* [Debugging Java Memory Leaks at Allegro](https://allegro.tech/2018/05/a-comedy-of-errors-debugging-java-memory-leaks.html)\n\t* [Optimizing JVM at Alibaba](https://www.youtube.com/watch?v=X4tmr3nhZRg)\n\t* [Tuning JVM Memory for Large-scale Services at Uber](https://eng.uber.com/jvm-tuning-garbage-collection/)\n\t* [Solr Performance Tuning at Walmart](https://medium.com/walmartglobaltech/solr-performance-tuning-beb7d0d0f8d9)\n\t* [Memory Tuning a High Throughput Microservice at Flipkart](https://blog.flipkart.tech/memory-tuning-a-high-throughput-microservice-ed57b3e60997)\n* [Performance Optimization on Image, Video, Page Load](https://developers.google.com/web/fundamentals/performance/why-performance-matters/)\n\t* [Optimizing 360 Photos at Scale at Facebook](https://code.facebook.com/posts/129055711052260/optimizing-360-photos-at-scale/)\n\t* [Reducing Image File Size in the Photos Infrastructure at Etsy](https://codeascraft.com/2017/05/30/reducing-image-file-size-at-etsy/)\n\t* [Improving GIF Performance at Pinterest](https://medium.com/@Pinterest_Engineering/improving-gif-performance-on-pinterest-8dad74bf92f1)\n\t* [Optimizing Video Playback Performance at Pinterest](https://medium.com/@Pinterest_Engineering/optimizing-video-playback-performance-caf55ce310d1)\n\t* [Optimizing Video Stream for Low Bandwidth with Dynamic Optimizer at Netflix](https://medium.com/netflix-techblog/optimized-shot-based-encodes-now-streaming-4b9464204830)\n\t* [Adaptive Video Streaming at YouTube](https://youtube-eng.googleblog.com/2018/04/making-high-quality-video-efficient.html)\n    * [Reducing Video Loading Time at Dailymotion](https://medium.com/dailymotion/reducing-video-loading-time-fa9c997a2294)\n\t* [Improving Homepage Performance at Zillow](https://www.zillow.com/engineering/improving-homepage-performance/)\n\t* [The Process of Optimizing for Client Performance at Expedia](https://medium.com/expedia-engineering/go-fast-or-go-home-the-process-of-optimizing-for-client-performance-57bb497402e)\n\t* [Web Performance at BBC](https://medium.com/bbc-design-engineering/bbc-world-service-web-performance-26b08f7abfcc)\n* [Performance Optimization by Brotli Compression](https://blogs.akamai.com/2016/02/understanding-brotlis-potential.html)\n\t* [Boosting Site Speed Using Brotli Compression at LinkedIn](https://engineering.linkedin.com/blog/2017/05/boosting-site-speed-using-brotli-compression)\t\n\t* [Brotli at Booking.com](https://medium.com/booking-com-development/bookings-journey-with-brotli-978b249d34f3)\n\t* [Brotli at Treebo](https://tech.treebo.com/a-tale-of-brotli-compression-bcb071d9780a)\n\t* [Deploying Brotli for Static Content at Dropbox](https://dropbox.tech/infrastructure/deploying-brotli-for-static-content)\n\t* [Progressive Enhancement with Brotli at Yelp](https://engineeringblog.yelp.com/2017/07/progressive-enhancement-with-brotli.html)\n\t* [Speeding Up Redis with Compression at DoorDash](https://doordash.engineering/2019/01/02/speeding-up-redis-with-compression/)\n* [Performance Optimization on Languages and Frameworks](https://www.techempower.com/benchmarks/)\n\t* [Python at Netflix](https://netflixtechblog.com/python-at-netflix-bba45dae649e)\n\t* [Python at scale (3 parts) at Instagram](https://instagram-engineering.com/python-at-scale-strict-modules-c0bb9245c834)\n\t* [OCaml best practices (2 parts) at Issuu](https://engineering.issuu.com/2018/12/10/our-current-ocaml-best-practices-part-2)\n\t* [PHP at Slack](https://slack.engineering/taking-php-seriously-cf7a60065329)\n\t* [Go at Trivago](https://tech.trivago.com/2020/03/02/why-we-chose-go/)\n\t* [TypeScript at Etsy](https://codeascraft.com/2021/11/08/etsys-journey-to-typescript/)\n\t* [Kotlin for taming state at Etsy](https://www.etsy.com/sg-en/codeascraft/sealed-classes-opened-my-mind)\n\t* [Kotlin at DoorDash](https://doordash.engineering/2022/03/22/how-to-leverage-functional-programming-in-kotlin-to-write-better-cleaner-code/)\n\t* [BPF and Go at Bumble](https://medium.com/bumble-tech/bpf-and-go-modern-forms-of-introspection-in-linux-6b9802682223)\n\t* [Ruby on Rails at GitLab](https://medium.com/gitlab-magazine/why-we-use-ruby-on-rails-to-build-gitlab-601dce4a7a38)\n\t* [Rust in production at Figma](https://medium.com/figma-design/rust-in-production-at-figma-e10a0ec31929)\n\t* [Choosing a Language Stack at WeWork](https://engineering.wework.com/choosing-a-language-stack-cac3726928f6)\n\t* [Switching from Go to Rust at Discord](https://blog.discord.com/why-discord-is-switching-from-go-to-rust-a190bbca2b1f)\n\t* [ASP.NET Core Performance Optimization at Agoda](https://medium.com/agoda-engineering/happy-asp-net-core-performance-optimization-4e21a383d299)\n\t* [Data Race Patterns in Go at Uber](https://eng.uber.com/data-race-patterns-in-go/)\n\t* [Java 21 Virtual Threads at Netflix](https://netflixtechblog.com/java-21-virtual-threads-dude-wheres-my-lock-3052540e231d)\t\n    \n## Intelligence\n* [Big Data](https://insights.sei.cmu.edu/sei_blog/2017/05/reference-architectures-for-big-data-systems.html)\t\n\t* [Data Platform at Uber](https://eng.uber.com/uber-big-data-platform/)\n\t* [Data Platform at BMW](https://www.unibw.de/code/events-u/jt-2018-workshops/ws3_bigdata_vortrag_widmann.pdf)\n\t* [Data Platform at Netflix](https://www.youtube.com/watch?v=CSDIThSwA7s)\n\t* [Data Platform at Flipkart](https://blog.flipkart.tech/overview-of-flipkart-data-platform-20c6d3e9a196)\n\t* [Data Platform at Coupang](https://medium.com/coupang-tech/evolving-the-coupang-data-platform-308e305a9c45)\n\t* [Data Platform at DoorDash](https://doordash.engineering/2020/09/25/how-doordash-is-scaling-its-data-platform/)\n\t* [Data Platform at Khan Academy](http://engineering.khanacademy.org/posts/khanalytics.htm)\n\t* [Data Infrastructure at Airbnb](https://medium.com/airbnb-engineering/data-infrastructure-at-airbnb-8adfb34f169c)\n\t* [Data Infrastructure at LinkedIn](https://www.infoq.com/presentations/big-data-infrastructure-linkedin)\n\t* [Data Infrastructure at GO-JEK](https://blog.gojekengineering.com/data-infrastructure-at-go-jek-cd4dc8cbd929)\n\t* [Data Ingestion Infrastructure at Pinterest](https://medium.com/@Pinterest_Engineering/scalable-and-reliable-data-ingestion-at-pinterest-b921c2ee8754)\n\t* [Data Analytics Architecture at Pinterest](https://medium.com/@Pinterest_Engineering/behind-the-pins-building-analytics-f7b508cdacab)\n\t* [Data Orchestration Service at Spotify](https://engineering.atspotify.com/2022/03/why-we-switched-our-data-orchestration-service/)\n\t* [Big Data Processing (2 parts) at Spotify](https://labs.spotify.com/2017/10/23/big-data-processing-at-spotify-the-road-to-scio-part-2/)\n\t* [Big Data Processing at Uber](https://cdn.oreillystatic.com/en/assets/1/event/160/Big%20data%20processing%20with%20Hadoop%20and%20Spark%2C%20the%20Uber%20way%20Presentation.pdf)\n\t* [Analytics Pipeline at Lyft](https://cdn.oreillystatic.com/en/assets/1/event/269/Lyft_s%20analytics%20pipeline_%20From%20Redshift%20to%20Apache%20Hive%20and%20Presto%20Presentation.pdf)\n\t* [Analytics Pipeline at Grammarly](https://tech.grammarly.com/blog/building-a-versatile-analytics-pipeline-on-top-of-apache-spark)\n\t* [Analytics Pipeline at Teads](https://medium.com/teads-engineering/give-meaning-to-100-billion-analytics-events-a-day-d6ba09aa8f44)\n\t* [ML Data Pipelines for Real-Time Fraud Prevention at PayPal](https://www.infoq.com/presentations/paypal-ml-fraud-prevention-2018)\n\t* [Big Data Analytics and ML Techniques at LinkedIn](https://cdn.oreillystatic.com/en/assets/1/event/269/Big%20data%20analytics%20and%20machine%20learning%20techniques%20to%20drive%20and%20grow%20business%20Presentation%201.pdf)\n\t* [Self-Serve Reporting Platform on Hadoop at LinkedIn](https://cdn.oreillystatic.com/en/assets/1/event/137/Building%20a%20self-serve%20real-time%20reporting%20platform%20at%20LinkedIn%20Presentation%201.pdf)\n\t* [Privacy-Preserving Analytics and Reporting at LinkedIn](https://engineering.linkedin.com/blog/2019/04/privacy-preserving-analytics-and-reporting-at-linkedin)\n\t* [Analytics Platform for Tracking Item Availability at Walmart](https://medium.com/walmartlabs/how-we-build-a-robust-analytics-platform-using-spark-kafka-and-cassandra-lambda-architecture-70c2d1bc8981)\n\t* [Real-Time Analytics for Mobile App Crashes using Apache Pinot at Uber](https://www.uber.com/en-SG/blog/real-time-analytics-for-mobile-app-crashes/)\n\t* [HALO: Hardware Analytics and Lifecycle Optimization at Facebook](https://code.fb.com/data-center-engineering/hardware-analytics-and-lifecycle-optimization-halo-at-facebook/)\n\t* [RBEA: Real-time Analytics Platform at King](https://techblog.king.com/rbea-scalable-real-time-analytics-king/)\n\t* [AresDB: GPU-Powered Real-time Analytics Engine at Uber](https://eng.uber.com/aresdb/)\n\t* [AthenaX: Streaming Analytics Platform at Uber](https://eng.uber.com/athenax/)\n\t* [Jupiter: Config Driven Adtech Batch Ingestion Platform at Uber](https://www.uber.com/en-SG/blog/jupiter-batch-ingestion-platform/)\n\t* [Delta: Data Synchronization and Enrichment Platform at Netflix](https://medium.com/netflix-techblog/delta-a-data-synchronization-and-enrichment-platform-e82c36a79aee)\n\t* [Keystone: Real-time Stream Processing Platform at Netflix](https://medium.com/netflix-techblog/keystone-real-time-stream-processing-platform-a3ee651812a)\n\t* [Databook: Turning Big Data into Knowledge with Metadata at Uber](https://eng.uber.com/databook/)\n\t* [Amundsen: Data Discovery & Metadata Engine at Lyft](https://eng.lyft.com/amundsen-lyfts-data-discovery-metadata-engine-62d27254fbb9)\n\t* [Maze: Funnel Visualization Platform at Uber](https://eng.uber.com/maze/)\n\t* [Metacat: Making Big Data Discoverable and Meaningful at Netflix](https://medium.com/netflix-techblog/metacat-making-big-data-discoverable-and-meaningful-at-netflix-56fb36a53520)\n\t* [SpinalTap: Change Data Capture System at Airbnb](https://medium.com/airbnb-engineering/capturing-data-evolution-in-a-service-oriented-architecture-72f7c643ee6f)\n\t* [Accelerator: Fast Data Processing Framework at eBay](https://www.ebayinc.com/stories/blogs/tech/announcing-the-accelerator-processing-1-000-000-000-lines-per-second-on-a-single-computer/)\n\t* [Omid: Transaction Processing Platform at Yahoo](https://yahooeng.tumblr.com/post/180867271141/a-new-chapter-for-omid)\n\t* [TensorFlowOnSpark: Distributed Deep Learning on Big Data Clusters at Yahoo](https://yahooeng.tumblr.com/post/157196488076/open-sourcing-tensorflowonspark-distributed-deep)\n\t* [CaffeOnSpark: Distributed Deep Learning on Big Data Clusters at Yahoo](https://yahooeng.tumblr.com/post/139916828451/caffeonspark-open-sourced-for-distributed-deep)\n\t* [Spark on Scala: Analytics Reference Architecture at Adobe](https://medium.com/adobetech/spark-on-scala-adobe-analytics-reference-architecture-7457f5614b4c)\n\t* [Experimentation Platform (2 parts) at Spotify](https://engineering.atspotify.com/2020/11/02/spotifys-new-experimentation-platform-part-2/)\n\t* [Experimentation Platform at Airbnb](https://medium.com/airbnb-engineering/https-medium-com-jonathan-parks-scaling-erf-23fd17c91166)\n\t* [Smart Product Platform at Zalando](https://engineering.zalando.com/posts/2017/10/zalando-smart-product-platform.html)\n\t* [Log Analysis Platform at LINE](https://www.slideshare.net/wyukawa/strata2017-sg)\n\t* [Data Visualisation Platform at Myntra](https://medium.com/myntra-engineering/universal-dashboarding-platform-udp-data-visualisation-platform-at-myntra-5f2522fcf72d)\n\t* [Building and Scaling Data Lineage at Netflix](https://medium.com/netflix-techblog/building-and-scaling-data-lineage-at-netflix-to-improve-data-infrastructure-reliability-and-1a52526a7977)\n\t* [Building a scalable data management system for computer vision tasks at Pinterest](https://medium.com/@Pinterest_Engineering/building-a-scalable-data-management-system-for-computer-vision-tasks-a6dee8f1c580)\n\t* [Structured Data at Etsy](https://codeascraft.com/2019/07/31/an-introduction-to-structured-data-at-etsy/)\n\t* [Scaling a Mature Data Pipeline - Managing Overhead at Airbnb](https://medium.com/airbnb-engineering/scaling-a-mature-data-pipeline-managing-overhead-f34835cbc866)\n\t* [Spark Partitioning Strategies at Airbnb](https://medium.com/airbnb-engineering/on-spark-hive-and-small-files-an-in-depth-look-at-spark-partitioning-strategies-a9a364f908)\n\t* [Scaling the Hadoop Distributed File System at LinkedIn](https://engineering.linkedin.com/blog/2021/the-exabyte-club--linkedin-s-journey-of-scaling-the-hadoop-distr)\n\t* [Scaling Hadoop YARN cluster beyond 10,000 nodes at LinkedIn](https://engineering.linkedin.com/blog/2021/scaling-linkedin-s-hadoop-yarn-cluster-beyond-10-000-nodes)\n\t* [Scaling Big Data Access Controls at Pinterest](https://medium.com/pinterest-engineering/securely-scaling-big-data-access-controls-at-pinterest-bbc3406a1695)\n* [Distributed Machine Learning](https://www.csie.ntu.edu.tw/~cjlin/talks/bigdata-bilbao.pdf)\n\t* [Machine Learning Platform at Yelp](https://engineeringblog.yelp.com/2020/07/ML-platform-overview.html)\n\t* [Machine Learning Platform at Etsy](https://codeascraft.com/2021/12/21/redesigning-etsys-machine-learning-platform/)\n\t* [Machine Learning Platform at Zalando](https://engineering.zalando.com/posts/2022/04/zalando-machine-learning-platform.html)\n\t* [Scaling AI/ML Infrastructure at Uber](https://www.uber.com/en-SG/blog/scaling-ai-ml-infrastructure-at-uber/)\n\t* [Recommendation System at Lyft](https://eng.lyft.com/the-recommendation-system-at-lyft-67bc9dcc1793)\n\t* [Reinforcement Learning Platform at Lyft](https://eng.lyft.com/lyfts-reinforcement-learning-platform-670f77ff46ec)\n\t* [Platform for Serving Recommendations at Etsy](https://www.etsy.com/sg-en/codeascraft/building-a-platform-for-serving-recommendations-at-etsy)\n\t* [Infrastructure to Run User Forecasts at Spotify](https://engineering.atspotify.com/2022/06/how-we-built-infrastructure-to-run-user-forecasts-at-spotify/)\n\t* [Aroma: Using ML for Code Recommendation at Facebook](https://code.fb.com/developer-tools/aroma/)\n\t* [Flyte: Cloud Native Machine Learning and Data Processing Platform at Lyft](https://eng.lyft.com/introducing-flyte-cloud-native-machine-learning-and-data-processing-platform-fb2bb3046a59)\n\t* [LyftLearn: ML Model Training Infrastructure built on Kubernetes at Lyft](https://eng.lyft.com/lyftlearn-ml-model-training-infrastructure-built-on-kubernetes-aef8218842bb)\n\t* [Horovod: Open Source Distributed Deep Learning Framework for TensorFlow at Uber](https://eng.uber.com/horovod/)\n\t* [Genie: Gen AI On-Call Copilot at Uber](https://www.uber.com/blog/genie-ubers-gen-ai-on-call-copilot/)\n\t* [COTA: Improving Customer Care with NLP & Machine Learning at Uber](https://eng.uber.com/cota/)\n\t* [Manifold: Model-Agnostic Visual Debugging Tool for Machine Learning at Uber](https://eng.uber.com/manifold/)\t\n\t* [Repo-Topix: Topic Extraction Framework at Github](https://githubengineering.com/topics/)\n\t* [Concourse: Generating Personalized Content Notifications in Near-Real-Time at LinkedIn](https://engineering.linkedin.com/blog/2018/05/concourse--generating-personalized-content-notifications-in-near)\n\t* [Altus Care: Applying a Chatbot to Platform Engineering at eBay](https://www.ebayinc.com/stories/blogs/tech/altus-care-apply-chatbot-to-ebay-platform-engineering/)\n\t* [PyKrylov: Accelerating Machine Learning Research at eBay](https://tech.ebayinc.com/engineering/pykrylov-accelerating-machine-learning-research-at-ebay/)\n\t* [Box Graph: Spontaneous Social Network at Box](https://blog.box.com/blog/box-graph-how-we-built-spontaneous-social-network/)\n\t* [PricingNet: Pricing Modelling with Neural Networks at Skyscanner](https://hackernoon.com/pricingnet-modelling-the-global-airline-industry-with-neural-networks-833844d20ea6)\n\t* [PinText: Multitask Text Embedding System at Pinterest](https://medium.com/pinterest-engineering/pintext-a-multitask-text-embedding-system-in-pinterest-b80ece364555)\n\t* [SearchSage: Learning Search Query Representations at Pinterest](https://medium.com/pinterest-engineering/searchsage-learning-search-query-representations-at-pinterest-654f2bb887fc)\n\t* [Cannes: ML saves $1.7M a year on document previews at Dropbox](https://dropbox.tech/machine-learning/cannes--how-ml-saves-us--1-7m-a-year-on-document-previews)\n\t* [Scaling Gradient Boosted Trees for Click-Through-Rate Prediction at Yelp](https://engineeringblog.yelp.com/2018/01/building-a-distributed-ml-pipeline-part1.html)\t\n\t* [Learning with Privacy at Scale at Apple](https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html)\n\t* [Deep Learning for Image Classification Experiment at Mercari](https://medium.com/mercari-engineering/mercaris-image-classification-experiment-using-deep-learning-9b4e994a18ec)\n\t* [Deep Learning for Frame Detection in Product Images at Allegro](https://allegro.tech/2016/12/deep-learning-for-frame-detection.html)\n\t* [Content-based Video Relevance Prediction at Hulu](https://medium.com/hulu-tech-blog/content-based-video-relevance-prediction-b2c448e14752)\n\t* [Moderating Inappropriate Video Content at Yelp](https://engineeringblog.yelp.com/2024/03/moderating-inappropriate-video-content-at-yelp.html)\n\t* [Improving Photo Selection With Deep Learning at TripAdvisor](http://engineering.tripadvisor.com/improving-tripadvisor-photo-selection-deep-learning/)\n\t* [Personalized Recommendations for Experiences Using Deep Learning at TripAdvisor](https://www.tripadvisor.com/engineering/personalized-recommendations-for-experiences-using-deep-learning/)\n\t* [Personalised Recommender Systems at BBC](https://medium.com/bbc-design-engineering/developing-personalised-recommender-systems-at-the-bbc-e26c5e0c4216)\n\t* [Machine Learning (2 parts) at Cond√© Nast](https://technology.condenast.com/story/handbag-brand-and-color-detection)\n\t* [Natural Language Processing and Content Analysis (2 parts) at Cond√© Nast](https://technology.condenast.com/story/natural-language-processing-and-content-analysis-at-conde-nast-part-2-system-architecture)\n\t* [Mapping the World of Music Using Machine Learning (2 parts) at iHeartRadio](https://tech.iheart.com/mapping-the-world-of-music-using-machine-learning-part-2-aa50b6a0304c)\n\t* [Machine Learning to Improve Streaming Quality at Netflix](https://medium.com/netflix-techblog/using-machine-learning-to-improve-streaming-quality-at-netflix-9651263ef09f)\n\t* [Machine Learning to Match Drivers & Riders at GO-JEK](https://blog.gojekengineering.com/how-we-use-machine-learning-to-match-drivers-riders-b06d617b9e5)\n\t* [Improving Video Thumbnails with Deep Neural Nets at YouTube](https://youtube-eng.googleblog.com/2015/10/improving-youtube-video-thumbnails-with_8.html)\n\t* [Quantile Regression for Delivering On Time at Instacart](https://tech.instacart.com/how-instacart-delivers-on-time-using-quantile-regression-2383e2e03edb)\n\t* [Cross-Lingual End-to-End Product Search with Deep Learning at Zalando](https://engineering.zalando.com/posts/2018/02/search-deep-neural-network.html)\n\t* [Machine Learning at Jane Street](https://blog.janestreet.com/real-world-machine-learning-part-1/)\n\t* [Machine Learning for Ranking Answers End-to-End at Quora](https://engineering.quora.com/A-Machine-Learning-Approach-to-Ranking-Answers-on-Quora)\n\t* [Clustering Similar Stories Using LDA at Flipboard](http://engineering.flipboard.com/2017/02/storyclustering)\n\t* [Similarity Search at Flickr](https://code.flickr.net/2017/03/07/introducing-similarity-search-at-flickr/)\n\t* [Large-Scale Machine Learning Pipeline for Job Recommendations at Indeed](http://engineering.indeedblog.com/blog/2016/04/building-a-large-scale-machine-learning-pipeline-for-job-recommendations/)\n\t* [Deep Learning from Prototype to Production at Taboola](http://engineering.taboola.com/deep-learning-from-prototype-to-production/)\n\t* [Atom Smashing using Machine Learning at CERN](https://cdn.oreillystatic.com/en/assets/1/event/144/Atom%20smashing%20using%20machine%20learning%20at%20CERN%20Presentation.pdf)\n\t* [Mapping Tags at Medium](https://medium.engineering/mapping-mediums-tags-1b9a78d77cf0)\n\t* [Clustering with the Dirichlet Process Mixture Model in Scala at Monsanto](http://engineering.monsanto.com/2015/11/23/chinese-restaurant-process/)\n\t* [Map Pins with DBSCAN & Random Forests at Foursquare](https://engineering.foursquare.com/you-are-probably-here-better-map-pins-with-dbscan-random-forests-9d51e8c1964d)\n\t* [Forecasting at Uber](https://eng.uber.com/forecasting-introduction/)\n\t* [Financial Forecasting at Uber](https://eng.uber.com/transforming-financial-forecasting-machine-learning/)\n\t* [Productionizing ML with Workflows at Twitter](https://blog.twitter.com/engineering/en_us/topics/insights/2018/ml-workflows.html)\n\t* [GUI Testing Powered by Deep Learning at eBay](https://www.ebayinc.com/stories/blogs/tech/gui-testing-powered-by-deep-learning/)\n\t* [Scaling Machine Learning to Recommend Driving Routes at Pivotal](http://engineering.pivotal.io/post/scaling-machine-learning-to-recommend-driving-routes/)\n\t* [Real-Time Predictions at DoorDash](https://www.infoq.com/presentations/doordash-real-time-predictions)\n\t* [Machine Intelligence at Dropbox](https://blogs.dropbox.com/tech/2018/09/machine-intelligence-at-dropbox-an-update-from-our-dbxi-team/)\n\t* [Machine Learning for Indexing Text from Billions of Images at Dropbox](https://blogs.dropbox.com/tech/2018/10/using-machine-learning-to-index-text-from-billions-of-images/)\n\t* [Modeling User Journeys via Semantic Embeddings at Etsy](https://codeascraft.com/2018/07/12/modeling-user-journey-via-semantic-embeddings/)\n\t* [Automated Fake Account Detection at LinkedIn](https://engineering.linkedin.com/blog/2018/09/automated-fake-account-detection-at-linkedin)\n\t* [Building Knowledge Graph at Airbnb](https://medium.com/airbnb-engineering/contextualizing-airbnb-by-building-knowledge-graph-b7077e268d5a)\n\t* [Core Modeling at Instagram](https://instagram-engineering.com/core-modeling-at-instagram-a51e0158aa48)\n\t* [Neural Architecture Search (NAS) for Prohibited Item Detection at Mercari](https://tech.mercari.com/entry/2019/04/26/163000)\n\t* [Computer Vision at Airbnb](https://medium.com/airbnb-engineering/amenity-detection-and-beyond-new-frontiers-of-computer-vision-at-airbnb-144a4441b72e)\n\t* [3D Home Backend Algorithms at Zillow](https://www.zillow.com/engineering/behind-zillow-3d-home-backend-algorithms/)\n\t* [Long-term Forecasts at Lyft](https://eng.lyft.com/making-long-term-forecasts-at-lyft-fac475b3ba52)\n\t* [Discovering Popular Dishes with Deep Learning at Yelp](https://engineeringblog.yelp.com/2019/10/discovering-popular-dishes-with-deep-learning.html)\n\t* [SplitNet Architecture for Ad Candidate Ranking at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2019/splitnet-architecture-for-ad-candidate-ranking.html)\n\t* [Jobs Filter at Indeed](https://engineering.indeedblog.com/blog/2019/09/jobs-filter/)\n\t* [Architecting Restaurant Wait Time Predictions at Yelp](https://engineeringblog.yelp.com/2019/12/architecting-wait-time-estimations.html)\n\t* [Music Personalization at Spotify](https://labs.spotify.com/2016/08/07/commodity-music-ml-services/)\n\t* [Deep Learning for Domain Name Valuation at GoDaddy](https://sg.godaddy.com/engineering/2019/07/26/domain-name-valuation/)\n\t* [Similarity Clustering to Catch Fraud Rings at Stripe](https://stripe.com/blog/similarity-clustering)\n\t* [Personalized Search at Etsy](https://codeascraft.com/2020/10/29/bringing-personalized-search-to-etsy/)\n\t* [ML Feature Serving Infrastructure at Lyft](https://eng.lyft.com/ml-feature-serving-infrastructure-at-lyft-d30bf2d3c32a)\n\t* [Context-Specific Bidding System at Etsy](https://codeascraft.com/2021/03/23/how-we-built-a-context-specific-bidding-system-for-etsy-ads/)\n\t* [Moderating Promotional Spam and Inappropriate Content in Photos at Scale at Yelp](https://engineeringblog.yelp.com/2021/05/moderating-promotional-spam-and-inappropriate-content-in-photos-at-scale-at-yelp.html)\n\t* [Optimizing Payments with Machine Learning at Dropbox](https://dropbox.tech/machine-learning/optimizing-payments-with-machine-learning)\n\t* [Scaling Media Machine Learning at Netflix](https://netflixtechblog.com/scaling-media-machine-learning-at-netflix-f19b400243)\n\t* [Similarity Engine at eBay](https://tech.ebayinc.com/engineering/ebays-blazingly-fast-billion-scale-vector-similarity-engine/)\n\t* [Machine Learning in Content Moderation at Etsy](https://www.etsy.com/codeascraft/machine-learning-in-content-moderation-at-etsy)\n\n## Architecture\n* [Tech Stack at Medium](https://medium.engineering/the-stack-that-helped-medium-drive-2-6-millennia-of-reading-time-e56801f7c492)\n* [Tech Stack at Shopify](https://engineering.shopify.com/blogs/engineering/e-commerce-at-scale-inside-shopifys-tech-stack)\n* [Building Services (4 parts) at Airbnb](https://medium.com/airbnb-engineering/building-services-at-airbnb-part-4-23c95e428064)\n* [Architecture of Evernote](https://evernote.com/blog/a-digest-of-evernotes-architecture/)\n* [Architecture of Chat Service (3 parts) at Riot Games](https://engineering.riotgames.com/news/chat-service-architecture-persistence)\n* [Architecture of League of Legends Client Update](https://technology.riotgames.com/news/architecture-league-client-update)\n* [Architecture of Ad Platform at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2020/building-twitters-ad-platform-architecture-for-the-future.html)\n* [Architecture of API Gateway at Uber](https://eng.uber.com/architecture-api-gateway/)\n* [Architecture of API Gateway at Tinder](https://medium.com/tinder/how-we-built-the-tinder-api-gateway-831c6ca5ceca)\n* [Basic Architecture of Slack](https://slack.engineering/how-slack-built-shared-channels-8d42c895b19f)\n* [Lightweight Distributed Architecture to Handle Thousands of Library Releases at eBay](https://tech.ebayinc.com/engineering/a-lightweight-distributed-architecture-to-handle-thousands-of-library-releases-at-ebay/)\n* [Back-end at LinkedIn](https://engineering.linkedin.com/architecture/brief-history-scaling-linkedin)\n* [Back-end at Flickr](https://yahooeng.tumblr.com/post/157200523046/introducing-tripod-flickrs-backend-refactored)\n* [Infrastructure (3 parts) at Zendesk](https://medium.com/zendesk-engineering/the-history-of-infrastructure-at-zendesk-part-3-foundation-team-forming-and-evolving-9859e40f5390)\n* [Cloud Infrastructure at Grubhub](https://bytes.grubhub.com/cloud-infrastructure-at-grubhub-94db998a898a)\n* [Real-time Presence Platform at LinkedIn](https://engineering.linkedin.com/blog/2018/01/now-you-see-me--now-you-dont--linkedins-real-time-presence-platf)\n* [Settings Platform at LinkedIn](https://engineering.linkedin.com/blog/2019/05/building-member-trust-through-a-centralized-and-scalable-setting)\n* [Nearline System for Scale and Performance (2 parts) at Glassdoor](https://medium.com/glassdoor-engineering/building-a-nearline-system-for-scale-and-performance-part-ii-9e01bf51b23d)\n* [Real-time User Action Counting System for Ads at Pinterest](https://medium.com/@Pinterest_Engineering/building-a-real-time-user-action-counting-system-for-ads-88a60d9c9a)\n* [API Platform at Riot Games](https://engineering.riotgames.com/news/riot-games-api-deep-dive)\n* [Games Platform at The New York Times](https://open.nytimes.com/play-by-play-moving-the-nyt-games-platform-to-gcp-with-zero-downtime-cf425898d569)\n* [Kabootar: Communication Platform at Swiggy](https://bytes.swiggy.com/kabootar-swiggys-communication-platform-e5a43cc25629)\n* [Simone: Distributed Simulation Service at Netflix](https://medium.com/netflix-techblog/https-medium-com-netflix-techblog-simone-a-distributed-simulation-service-b2c85131ca1b)\n* [Seagull: Distributed System that Helps Running > 20 Million Tests Per Day at Yelp](https://engineeringblog.yelp.com/2017/04/how-yelp-runs-millions-of-tests-every-day.html)\n* [PriceAggregator: Intelligent System for Hotel Price Fetching (3 parts) at Agoda](https://medium.com/agoda-engineering/priceaggregator-an-intelligent-system-for-hotel-price-fetching-part-3-52acfc705081)\n* [Phoenix: Testing Platform (3 parts) at Tinder](https://medium.com/tinder-engineering/phoenix-tinders-testing-platform-part-iii-520728b9537)\n* [Hexagonal Architecture at Netflix](https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749)\n* [Architecture of Sticker Services at LINE](https://www.slideshare.net/linecorp/architecture-sustaining-line-sticker-services)\n* [Stack Overflow Enterprise at Palantir](https://medium.com/@palantir/terraforming-stack-overflow-enterprise-in-aws-47ee431e6be7)\n* [Architecture of Following Feed, Interest Feed, and Picked For You at Pinterest](https://medium.com/@Pinterest_Engineering/building-a-dynamic-and-responsive-pinterest-7d410e99f0a9)\n* [API Specification Workflow at WeWork](https://engineering.wework.com/our-api-specification-workflow-9337448d6ee6)\n* [Media Database at Netflix](https://medium.com/netflix-techblog/implementing-the-netflix-media-database-53b5a840b42a)\n* [Member Transaction History Architecture at Walmart](https://medium.com/walmartlabs/member-transaction-history-architecture-8b6e34b87c21)\n* [Sync Engine (2 parts) at Dropbox](https://dropbox.tech/infrastructure/-testing-our-new-sync-engine)\n* [Ads Pacing Service at Twitter](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2021/how-we-built-twitter-s-highly-reliable-ads-pacing-service)\n* [Rapid Event Notification System at Netflix](https://netflixtechblog.com/rapid-event-notification-system-at-netflix-6deb1d2b57d1)\n* [Architectures of Finance, Banking, and Payment Systems](https://www.redhat.com/architect/portfolio/detail/12-integrating-a-modern-payments-architecture)\n\t* [Bank Backend at Monzo](https://monzo.com/blog/2016/09/19/building-a-modern-bank-backend/)\n\t* [Trading Platform for Scale at Wealthsimple](https://medium.com/@Wealthsimple/engineering-at-wealthsimple-reinventing-our-trading-platform-for-scale-17e332241b6c)\n\t* [Core Banking System at Margo Bank](https://medium.com/margobank/choosing-an-architecture-85750e1e5a03)\n\t* [Architecture of Nubank](https://www.infoq.com/presentations/nubank-architecture)\n\t* [Tech Stack at TransferWise](http://tech.transferwise.com/the-transferwise-stack-heartbeat-of-our-little-revolution/)\n\t* [Tech Stack at Addepar](https://medium.com/build-addepar/our-tech-stack-a4f55dab4b0d)\n\t* [Avoiding Double Payments in a Distributed Payments System at Airbnb](https://medium.com/airbnb-engineering/avoiding-double-payments-in-a-distributed-payments-system-2981f6b070bb)\n\t* [Scaling Payments (3 parts) at Etsy](https://www.etsy.com/sg-en/codeascraft/scaling-etsy-payments-with-vitess-part-3--reducing-cutover-risk)\n\t* [Handles Millions of Digital Transactions Safely Everyday at Paytm](https://paytm.com/blog/engineering/how-paytm-handles-millions-of-digital-transactions-safely-everyday/)\n\t* [Billing and Payment Platform at Grammarly](https://www.grammarly.com/blog/engineering/billing-and-payments-platform/)\n\n## Interview\n* [Designing Large-Scale Systems](https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/)\n\t* [My Scaling Hero - Jeff Atwood (a dose of Endorphins before your interview, JK)](https://blog.codinghorror.com/my-scaling-hero/)\n\t* [Software Engineering Advice from Building Large-Scale Distributed Systems - Jeff Dean](https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf)\n\t* [Introduction to Architecting Systems for Scale](https://lethain.com/introduction-to-architecting-systems-for-scale/)\n\t* [Anatomy of a System Design Interview](https://hackernoon.com/anatomy-of-a-system-design-interview-4cb57d75a53f)\n\t* [8 Things You Need to Know Before a System Design Interview](http://blog.gainlo.co/index.php/2015/10/22/8-things-you-need-to-know-before-system-design-interviews/)\n\t* [Top 10 System Design Interview Questions ](https://hackernoon.com/top-10-system-design-interview-questions-for-software-engineers-8561290f0444)\n\t* [Top 10 Common Large-Scale Software Architectural Patterns in a Nutshell](https://towardsdatascience.com/10-common-software-architectural-patterns-in-a-nutshell-a0b47a1e9013)\n\t* [Cloud Big Data Design Patterns - Lynn Langit](https://lynnlangit.com/2017/03/14/beyond-relational/)\t\n\t* [How NOT to design Netflix in your 45-minute System Design Interview?](https://hackernoon.com/how-not-to-design-netflix-in-your-45-minute-system-design-interview-64953391a054)\n\t* [API Best Practices: Webhooks, Deprecation, and Design](https://zapier.com/engineering/api-best-practices/)\n* [Explaining Low-Level Systems (OS, Network/Protocol, Database, Storage)](https://www.cse.wustl.edu/~jain/cse567-06/ftp/os_monitors/index.html)\n\t* [The Precise Meaning of I/O Wait Time in Linux](http://veithen.github.io/2013/11/18/iowait-linux.html)\n\t* [Paxos Made Live ‚Äì An Engineering Perspective](https://research.google.com/archive/paxos_made_live.html)\n\t* [How to do Distributed Locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)\n\t* [SQL Transaction Isolation Levels Explained](http://elliot.land/post/sql-transaction-isolation-levels-explained)\n* [\"What Happens When... and How\" Questions](https://www.glassdoor.com/Interview/What-happens-when-you-type-www-google-com-in-your-browser-QTN_56396.htm)\n\t* [Netflix: What Happens When You Press Play?](http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html)\n\t* [Monzo: How Peer-To-Peer Payments Work](https://monzo.com/blog/2018/04/05/how-monzo-to-monzo-payments-work/)\n\t* [Transit and Peering: How Your Requests Reach GitHub](https://githubengineering.com/transit-and-peering-how-your-requests-reach-github/)\n\t* [How Spotify Streams Music](https://labs.spotify.com/2018/08/31/smoother-streaming-with-bbr/)\n\n## Organization\n* [Engineering Levels at SoundCloud](https://developers.soundcloud.com/blog/engineering-levels)\n* [Engineering Roles at Palantir](https://medium.com/palantir/dev-versus-delta-demystifying-engineering-roles-at-palantir-ad44c2a6e87)\n* [Engineering Career Framework at Dropbox](https://dropbox.tech/culture/our-updated-engineering-career-framework)\n* [Scaling Engineering Teams at Twitter](https://www.youtube.com/watch?v=-PXi_7Ld5kU)\n* [Scaling Decision-Making Across Teams at LinkedIn](https://engineering.linkedin.com/blog/2018/03/scaling-decision-making-across-teams-within-linkedin-engineering)\n* [Scaling Data Science Team at GOJEK](https://blog.gojekengineering.com/the-dynamics-of-scaling-an-organisation-cb96dbe8aecd)\n* [Scaling Agile at Zalando](https://engineering.zalando.com/posts/2018/05/scaling-agile-zalando.html)\n* [Scaling Agile at bol.com](https://hackernoon.com/how-we-run-bol-com-with-60-autonomous-teams-fe7a98c0759)\n* [Lessons Learned from Scaling a Product Team at Intercom](https://blog.intercom.com/how-we-build-software/)\n* [Hiring, Managing, and Scaling Engineering Teams at Typeform](https://medium.com/@eleonorazucconi/toby-oliver-cto-typeform-on-hiring-managing-and-scaling-engineering-teams-86bef9e5a708)\t\n* [Scaling the Datagram Team at Instagram](https://instagram-engineering.com/scaling-the-datagram-team-fc67bcf9b721)\n* [Scaling the Design Team at Flexport](https://medium.com/flexport-design/designing-a-design-team-a9a066bc48a5)\n* [Team Model for Scaling a Design System at Salesforce](https://medium.com/salesforce-ux/the-salesforce-team-model-for-scaling-a-design-system-d89c2a2d404b)\n* [Building Analytics Team (4 parts) at Wish](https://medium.com/wish-engineering/scaling-the-analytics-team-at-wish-part-4-recruiting-2a9823b9f5a)\n* [From 2 Founders to 1000 Employees at Transferwise](https://medium.com/transferwise-ideas/from-2-founders-to-1000-employees-how-a-small-scale-startup-grew-into-a-global-community-9f26371a551b)\n* [Lessons Learned Growing a UX Team from 10 to 170 at Adobe](https://medium.com/thinking-design/lessons-learned-growing-a-ux-team-from-10-to-170-f7b47be02262)\n* [Five Lessons from Scaling at Pinterest](https://medium.com/@sarahtavel/five-lessons-from-scaling-pinterest-6a699a889b08)\n* [Approach Engineering at Vinted](http://engineering.vinted.com/2018/09/04/how-we-approach-engineering-at-vinted/)\n* [Using Metrics to Improve the Development Process (and Coach People) at Indeed](https://engineering.indeedblog.com/blog/2018/10/using-metrics-to-improve-the-development-process-and-coach-people/)\n* [Mistakes to Avoid while Creating an Internal Product at Skyscanner](https://medium.com/@SkyscannerEng/9-mistakes-to-avoid-while-creating-an-internal-product-63d579b00b1a)\n* [RACI (Responsible, Accountable, Consulted, Informed) at Etsy](https://codeascraft.com/2018/01/04/selecting-a-cloud-provider/)\n* [Four Pillars of Leading People (Empathy, Inspiration, Trust, Honesty) at Zalando](https://engineering.zalando.com/posts/2018/10/four-pillars-leadership.html)\n* [Pair Programming at Shopify](https://engineering.shopify.com/blogs/engineering/pair-programming-explained)\n* [Distributed Responsibility at Asana](https://blog.asana.com/2017/12/distributed-responsibility-engineering-manager/)\n* [Rotating Engineers at Zalando](https://engineering.zalando.com/posts/2019/03/rotating-engineers-at-zalando.html)\n* [Experiment Idea Review at Pinterest](https://medium.com/pinterest-engineering/how-pinterest-supercharged-its-growth-team-with-experiment-idea-review-fd6571a02fb8)\n* [Tech Migrations at Spotify](https://engineering.atspotify.com/2020/06/25/tech-migrations-the-spotify-way/)\n* [Improving Code Ownership at Yelp](https://engineeringblog.yelp.com/2021/01/whose-code-is-it-anyway.html)\n* [Agile Code Base at eBay](https://tech.ebayinc.com/engineering/how-creating-an-agile-code-base-helped-ebay-pivot-for-apple-silicon/)\n* [Agile Data Engineering at Miro](https://medium.com/miro-engineering/agile-data-engineering-at-miro-ec2dcc8a3fcb)\n* [Automated Incident Management through Slack at Airbnb](https://medium.com/airbnb-engineering/incident-management-ae863dc5d47f)\n* [Refactor Organization at BBC](https://medium.com/bbc-product-technology/refactor-organisation-80e4e171d922)\n* [Code Review](https://ai.google/research/pubs/pub47025)\n\t* [Code Review at Palantir](https://medium.com/@palantir/code-review-best-practices-19e02780015f)\n\t* [Code Review at LINE](https://engineering.linecorp.com/en/blog/effective-code-review/)\n\t* [Code Reviews at Medium](https://medium.engineering/code-reviews-at-medium-bed2c0dce13a)\n\t* [Code Review at LinkedIn](https://engineering.linkedin.com/blog/2018/06/scaling-collective-code-ownership-with-code-reviews)\n\t* [Code Review at Disney](https://medium.com/disney-streaming/the-secret-to-better-code-reviews-c14c7884b9ac)\n\t* [Code Review at Netlify](https://www.netlify.com/blog/2020/03/05/feedback-ladders-how-we-encode-code-reviews-at-netlify/)\n\n## Talk\n* [Distributed Systems in One Lesson - Tim Berglund, Senior Director of Developer Experience at Confluent](https://www.youtube.com/watch?v=Y6Ev8GIlbxc)\n* [Building Real Time Infrastructure at Facebook - Jeff Barber and Shie Erlich, Software Engineer at Facebook](https://www.usenix.org/conference/srecon17americas/program/presentation/erlich)\n* [Building Reliable Social Infrastructure for Google - Marc Alvidrez, Senior Manager at Google](https://www.usenix.org/conference/srecon16/program/presentation/alvidrez)\n* [Building a Distributed Build System at Google Scale - Aysylu Greenberg, SDE at Google](https://www.youtube.com/watch?v=K8YuavUy6Qc)\n* [Site Reliability Engineering at Dropbox - Tammy Butow, Site Reliability Engineering Manager at Dropbox](https://www.youtube.com/watch?v=ggizCjUCCqE)\n* [How Google Does Planet-Scale for Planet-Scale Infra - Melissa Binde, SRE Director for Google Cloud Platform](https://www.youtube.com/watch?v=H4vMcD7zKM0)\n* [Netflix Guide to Microservices - Josh Evans, Director of Operations Engineering at Netflix](https://www.youtube.com/watch?v=CZ3wIuvmHeM&t=2837s)\n* [Achieving Rapid Response Times in Large Online Services - Jeff Dean, Google Senior Fellow](https://www.youtube.com/watch?v=1-3Ahy7Fxsc)\n* [Architecture to Handle 80K RPS Celebrity Sales at Shopify - Simon Eskildsen, Engineering Lead at Shopify](https://www.youtube.com/watch?v=N8NWDHgWA28)\n* [Lessons of Scale at Facebook - Bobby Johnson, Director of Engineering at Facebook](https://www.youtube.com/watch?v=QCHiNEw73AU)\n* [Performance Optimization for the Greater China Region at Salesforce - Jeff Cheng, Enterprise Architect at Salesforce](https://www.salesforce.com/video/1757880/)\n* [How GIPHY Delivers a GIF to 300 Millions Users - Alex Hoang and Nima Khoshini, Services Engineers at GIPHY](https://vimeo.com/252367076)\n* [High Performance Packet Processing Platform at Alibaba - Haiyong Wang, Senior Director at Alibaba](https://www.youtube.com/watch?v=wzsxJqeVIhY&list=PLMu8-hpCxIVENuAue7bd0eCAglLGY_8AW&index=7)\n* [Solving Large-scale Data Center and Cloud Interconnection Problems -  Ihab Tarazi, CTO at Equinix](https://atscaleconference.com/videos/solving-large-scale-data-center-and-cloud-interconnection-problems/)\n* [Scaling Dropbox - Kevin Modzelewski, Back-end Engineer at Dropbox](https://www.youtube.com/watch?v=PE4gwstWhmc)\n* [Scaling Reliability at Dropbox - Sat Kriya Khalsa, SRE at Dropbox](https://www.youtube.com/watch?v=IhGWOaD5BYQ)\n* [Scaling with Performance at Facebook - Bill Jia, VP of Infrastructure at Facebook](https://atscaleconference.com/videos/performance-scale-2018-opening-remarks/)\n* [Scaling Live Videos to a Billion Users at Facebook - Sachin Kulkarni, Director of Engineering at Facebook](https://www.youtube.com/watch?v=IO4teCbHvZw)\n* [Scaling Infrastructure at Instagram - Lisa Guo, Instagram Engineering](https://www.youtube.com/watch?v=hnpzNAPiC0E)\n* [Scaling Infrastructure at Twitter - Yao Yue, Staff Software Engineer at Twitter](https://www.youtube.com/watch?v=6OvrFkLSoZ0)\n* [Scaling Infrastructure at Etsy - Bethany Macri, Engineering Manager at Etsy](https://www.youtube.com/watch?v=LfqyhM1LeIU)\n* [Scaling Real-time Infrastructure at Alibaba for Global Shopping Holiday - Xiaowei Jiang, Senior Director at Alibaba](https://atscaleconference.com/videos/scaling-alibabas-real-time-infrastructure-for-global-shopping-holiday/)\n* [Scaling Data Infrastructure at Spotify - Matti (Lepist√∂) Pehrs, Spotify](https://www.youtube.com/watch?v=cdsfRXr9pJU)\n* [Scaling Pinterest - Marty Weiner, Pinterest‚Äôs founding engineer](https://www.youtube.com/watch?v=jQNCuD_hxdQ&list=RDhnpzNAPiC0E&index=11)\n* [Scaling Slack - Bing Wei, Software Engineer (Infrastructure) at Slack](https://www.infoq.com/presentations/slack-scalability)\n* [Scaling Backend at Youtube - Sugu Sougoumarane, SDE at Youtube](https://www.youtube.com/watch?v=5yDO-tmIoXY&feature=youtu.be)\n* [Scaling Backend at Uber - Matt Ranney, Chief Systems Architect at Uber](https://www.youtube.com/watch?v=nuiLcWE8sPA)\n* [Scaling Global CDN at Netflix - Dave Temkin, Director of Global Networks at Netflix](https://www.youtube.com/watch?v=tbqcsHg-Q_o)\n* [Scaling Load Balancing Infra to Support 1.3 Billion Users at Facebook - Patrick Shuff, Production Engineer at Facebook](https://www.youtube.com/watch?v=bxhYNfFeVF4)\n* [Scaling (a NSFW site) to 200 Million Views A Day And Beyond - Eric Pickup, Lead Platform Developer at MindGeek](https://www.youtube.com/watch?v=RlkCdM_f3p4)\n* [Scaling Counting Infrastructure at Quora - Chun-Ho Hung and Nikhil Gar, SEs at Quora](https://www.infoq.com/presentations/quora-analytics)\n* [Scaling Git at Microsoft - Saeed Noursalehi, Principal Program Manager at Microsoft](https://www.youtube.com/watch?v=g_MPGU_m01s)\n* [Scaling Multitenant Architecture Across Multiple Data Centres at Shopify - Weingarten, Engineering Lead at Shopify](https://www.youtube.com/watch?v=F-f0-k46WVk)\n\n## A Piece of Cake\nRoses are red. Violets are blue. [Binh](https://nguyenquocbinh.org/) likes sweet. [Treat Binh a tiramisu?](https://paypal.me/binhnguyennus) :cake:\n",
         "AI_DataScience"
        ],
        [
         "5",
         "MDEwOlJlcG9zaXRvcnkzMzAxNTU4Mw==",
         "# Keras 3: Deep Learning for Humans\n\nKeras 3 is a multi-backend deep learning framework, with support for JAX, TensorFlow, PyTorch, and OpenVINO (for inference-only).\nEffortlessly build and train models for computer vision, natural language processing, audio processing,\ntimeseries forecasting, recommender systems, etc.\n\n- **Accelerated model development**: Ship deep learning solutions faster thanks to the high-level UX of Keras\nand the availability of easy-to-debug runtimes like PyTorch or JAX eager execution.\n- **State-of-the-art performance**: By picking the backend that is the fastest for your model architecture (often JAX!),\nleverage speedups ranging from 20% to 350% compared to other frameworks. [Benchmark here](https://keras.io/getting_started/benchmarks/).\n- **Datacenter-scale training**: Scale confidently from your laptop to large clusters of GPUs or TPUs.\n\nJoin nearly three million developers, from burgeoning startups to global enterprises, in harnessing the power of Keras 3.\n\n\n## Installation\n\n### Install with pip\n\nKeras 3 is available on PyPI as `keras`. Note that Keras 2 remains available as the `tf-keras` package.\n\n1. Install `keras`:\n\n```\npip install keras --upgrade\n```\n\n2. Install backend package(s).\n\nTo use `keras`, you should also install the backend of choice: `tensorflow`, `jax`, or `torch`.\nNote that `tensorflow` is required for using certain Keras 3 features: certain preprocessing layers\nas well as `tf.data` pipelines.\n\n### Local installation\n\n#### Minimal installation\n\nKeras 3 is compatible with Linux and macOS systems. For Windows users, we recommend using WSL2 to run Keras.\nTo install a local development version:\n\n1. Install dependencies:\n\n```\npip install -r requirements.txt\n```\n\n2. Run installation command from the root directory.\n\n```\npython pip_build.py --install\n```\n\n3. Run API generation script when creating PRs that update `keras_export` public APIs:\n\n```\n./shell/api_gen.sh\n```\n\n#### Adding GPU support\n\nThe `requirements.txt` file will install a CPU-only version of TensorFlow, JAX, and PyTorch. For GPU support, we also\nprovide a separate `requirements-{backend}-cuda.txt` for TensorFlow, JAX, and PyTorch. These install all CUDA\ndependencies via `pip` and expect a NVIDIA driver to be pre-installed. We recommend a clean Python environment for each\nbackend to avoid CUDA version mismatches. As an example, here is how to create a JAX GPU environment with `conda`:\n\n```shell\nconda create -y -n keras-jax python=3.10\nconda activate keras-jax\npip install -r requirements-jax-cuda.txt\npython pip_build.py --install\n```\n\n## Configuring your backend\n\nYou can export the environment variable `KERAS_BACKEND` or you can edit your local config file at `~/.keras/keras.json`\nto configure your backend. Available backend options are: `\"tensorflow\"`, `\"jax\"`, `\"torch\"`, `\"openvino\"`. Example:\n\n```\nexport KERAS_BACKEND=\"jax\"\n```\n\nIn Colab, you can do:\n\n```python\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n\nimport keras\n```\n\n**Note:** The backend must be configured before importing `keras`, and the backend cannot be changed after\nthe package has been imported.\n\n**Note:** The OpenVINO backend is an inference-only backend, meaning it is designed only for running model\npredictions using `model.predict()` method.\n\n## Backwards compatibility\n\nKeras 3 is intended to work as a drop-in replacement for `tf.keras` (when using the TensorFlow backend). Just take your\nexisting `tf.keras` code, make sure that your calls to `model.save()` are using the up-to-date `.keras` format, and you're\ndone.\n\nIf your `tf.keras` model does not include custom components, you can start running it on top of JAX or PyTorch immediately.\n\nIf it does include custom components (e.g. custom layers or a custom `train_step()`), it is usually possible to convert it\nto a backend-agnostic implementation in just a few minutes.\n\nIn addition, Keras models can consume datasets in any format, regardless of the backend you're using:\nyou can train your models with your existing `tf.data.Dataset` pipelines or PyTorch `DataLoaders`.\n\n## Why use Keras 3?\n\n- Run your high-level Keras workflows on top of any framework -- benefiting at will from the advantages of each framework,\ne.g. the scalability and performance of JAX or the production ecosystem options of TensorFlow.\n- Write custom components (e.g. layers, models, metrics) that you can use in low-level workflows in any framework.\n    - You can take a Keras model and train it in a training loop written from scratch in native TF, JAX, or PyTorch.\n    - You can take a Keras model and use it as part of a PyTorch-native `Module` or as part of a JAX-native model function.\n- Make your ML code future-proof by avoiding framework lock-in.\n- As a PyTorch user: get access to power and usability of Keras, at last!\n- As a JAX user: get access to a fully-featured, battle-tested, well-documented modeling and training library.\n\n\nRead more in the [Keras 3 release announcement](https://keras.io/keras_3/).\n",
         "AI_DataScience"
        ],
        [
         "6",
         "MDEwOlJlcG9zaXRvcnkyOTAwOTE5NDg=",
         "[![Twitter](https://img.shields.io/twitter/follow/labmlai?style=social)](https://twitter.com/labmlai)\n\n# [labml.ai Deep Learning Paper Implementations](https://nn.labml.ai/index.html)\n\nThis is a collection of simple PyTorch implementations of\nneural networks and related algorithms.\nThese implementations are documented with explanations,\n\n[The website](https://nn.labml.ai/index.html)\nrenders these as side-by-side formatted notes.\nWe believe these would help you understand these algorithms better.\n\n![Screenshot](https://nn.labml.ai/dqn-light.png)\n\nWe are actively maintaining this repo and adding new \nimplementations almost weekly.\n[![Twitter](https://img.shields.io/twitter/follow/labmlai?style=social)](https://twitter.com/labmlai) for updates.\n\n## Paper Implementations\n\n#### ‚ú® [Transformers](https://nn.labml.ai/transformers/index.html)\n\n* [Multi-headed attention](https://nn.labml.ai/transformers/mha.html)\n* [Triton Flash Attention](https://nn.labml.ai/transformers/flash/index.html)\n* [Transformer building blocks](https://nn.labml.ai/transformers/models.html) \n* [Transformer XL](https://nn.labml.ai/transformers/xl/index.html)\n    * [Relative multi-headed attention](https://nn.labml.ai/transformers/xl/relative_mha.html)\n* [Rotary Positional Embeddings](https://nn.labml.ai/transformers/rope/index.html)\n* [Attention with Linear Biases (ALiBi)](https://nn.labml.ai/transformers/alibi/index.html)\n* [RETRO](https://nn.labml.ai/transformers/retro/index.html)\n* [Compressive Transformer](https://nn.labml.ai/transformers/compressive/index.html)\n* [GPT Architecture](https://nn.labml.ai/transformers/gpt/index.html)\n* [GLU Variants](https://nn.labml.ai/transformers/glu_variants/simple.html)\n* [kNN-LM: Generalization through Memorization](https://nn.labml.ai/transformers/knn)\n* [Feedback Transformer](https://nn.labml.ai/transformers/feedback/index.html)\n* [Switch Transformer](https://nn.labml.ai/transformers/switch/index.html)\n* [Fast Weights Transformer](https://nn.labml.ai/transformers/fast_weights/index.html)\n* [FNet](https://nn.labml.ai/transformers/fnet/index.html)\n* [Attention Free Transformer](https://nn.labml.ai/transformers/aft/index.html)\n* [Masked Language Model](https://nn.labml.ai/transformers/mlm/index.html)\n* [MLP-Mixer: An all-MLP Architecture for Vision](https://nn.labml.ai/transformers/mlp_mixer/index.html)\n* [Pay Attention to MLPs (gMLP)](https://nn.labml.ai/transformers/gmlp/index.html)\n* [Vision Transformer (ViT)](https://nn.labml.ai/transformers/vit/index.html)\n* [Primer EZ](https://nn.labml.ai/transformers/primer_ez/index.html)\n* [Hourglass](https://nn.labml.ai/transformers/hour_glass/index.html)\n\n#### ‚ú® [Low-Rank Adaptation (LoRA)](https://nn.labml.ai/lora/index.html)\n\n#### ‚ú® [Eleuther GPT-NeoX](https://nn.labml.ai/neox/index.html)\n* [Generate on a 48GB GPU](https://nn.labml.ai/neox/samples/generate.html)\n* [Finetune on two 48GB GPUs](https://nn.labml.ai/neox/samples/finetune.html)\n* [LLM.int8()](https://nn.labml.ai/neox/utils/llm_int8.html)\n\n#### ‚ú® [Diffusion models](https://nn.labml.ai/diffusion/index.html)\n\n* [Denoising Diffusion Probabilistic Models (DDPM)](https://nn.labml.ai/diffusion/ddpm/index.html)\n* [Denoising Diffusion Implicit Models (DDIM)](https://nn.labml.ai/diffusion/stable_diffusion/sampler/ddim.html)\n* [Latent Diffusion Models](https://nn.labml.ai/diffusion/stable_diffusion/latent_diffusion.html)\n* [Stable Diffusion](https://nn.labml.ai/diffusion/stable_diffusion/index.html)\n\n#### ‚ú® [Generative Adversarial Networks](https://nn.labml.ai/gan/index.html)\n* [Original GAN](https://nn.labml.ai/gan/original/index.html)\n* [GAN with deep convolutional network](https://nn.labml.ai/gan/dcgan/index.html)\n* [Cycle GAN](https://nn.labml.ai/gan/cycle_gan/index.html)\n* [Wasserstein GAN](https://nn.labml.ai/gan/wasserstein/index.html)\n* [Wasserstein GAN with Gradient Penalty](https://nn.labml.ai/gan/wasserstein/gradient_penalty/index.html)\n* [StyleGAN 2](https://nn.labml.ai/gan/stylegan/index.html)\n\n#### ‚ú® [Recurrent Highway Networks](https://nn.labml.ai/recurrent_highway_networks/index.html)\n\n#### ‚ú® [LSTM](https://nn.labml.ai/lstm/index.html)\n\n#### ‚ú® [HyperNetworks - HyperLSTM](https://nn.labml.ai/hypernetworks/hyper_lstm.html)\n\n#### ‚ú® [ResNet](https://nn.labml.ai/resnet/index.html)\n\n#### ‚ú® [ConvMixer](https://nn.labml.ai/conv_mixer/index.html)\n\n#### ‚ú® [Capsule Networks](https://nn.labml.ai/capsule_networks/index.html)\n\n#### ‚ú® [U-Net](https://nn.labml.ai/unet/index.html)\n\n#### ‚ú® [Sketch RNN](https://nn.labml.ai/sketch_rnn/index.html)\n\n#### ‚ú® Graph Neural Networks\n\n* [Graph Attention Networks (GAT)](https://nn.labml.ai/graphs/gat/index.html)\n* [Graph Attention Networks v2 (GATv2)](https://nn.labml.ai/graphs/gatv2/index.html)\n\n#### ‚ú® [Counterfactual Regret Minimization (CFR)](https://nn.labml.ai/cfr/index.html)\n\nSolving games with incomplete information such as poker with CFR.\n\n* [Kuhn Poker](https://nn.labml.ai/cfr/kuhn/index.html)\n\n#### ‚ú® [Reinforcement Learning](https://nn.labml.ai/rl/index.html)\n* [Proximal Policy Optimization](https://nn.labml.ai/rl/ppo/index.html) with\n [Generalized Advantage Estimation](https://nn.labml.ai/rl/ppo/gae.html)\n* [Deep Q Networks](https://nn.labml.ai/rl/dqn/index.html) with\n with [Dueling Network](https://nn.labml.ai/rl/dqn/model.html),\n [Prioritized Replay](https://nn.labml.ai/rl/dqn/replay_buffer.html)\n and Double Q Network.\n\n#### ‚ú® [Optimizers](https://nn.labml.ai/optimizers/index.html)\n* [Adam](https://nn.labml.ai/optimizers/adam.html)\n* [AMSGrad](https://nn.labml.ai/optimizers/amsgrad.html)\n* [Adam Optimizer with warmup](https://nn.labml.ai/optimizers/adam_warmup.html)\n* [Noam Optimizer](https://nn.labml.ai/optimizers/noam.html)\n* [Rectified Adam Optimizer](https://nn.labml.ai/optimizers/radam.html)\n* [AdaBelief Optimizer](https://nn.labml.ai/optimizers/ada_belief.html)\n* [Sophia-G Optimizer](https://nn.labml.ai/optimizers/sophia.html)\n\n#### ‚ú® [Normalization Layers](https://nn.labml.ai/normalization/index.html)\n* [Batch Normalization](https://nn.labml.ai/normalization/batch_norm/index.html)\n* [Layer Normalization](https://nn.labml.ai/normalization/layer_norm/index.html)\n* [Instance Normalization](https://nn.labml.ai/normalization/instance_norm/index.html)\n* [Group Normalization](https://nn.labml.ai/normalization/group_norm/index.html)\n* [Weight Standardization](https://nn.labml.ai/normalization/weight_standardization/index.html)\n* [Batch-Channel Normalization](https://nn.labml.ai/normalization/batch_channel_norm/index.html)\n* [DeepNorm](https://nn.labml.ai/normalization/deep_norm/index.html)\n\n#### ‚ú® [Distillation](https://nn.labml.ai/distillation/index.html)\n\n#### ‚ú® [Adaptive Computation](https://nn.labml.ai/adaptive_computation/index.html)\n\n* [PonderNet](https://nn.labml.ai/adaptive_computation/ponder_net/index.html)\n\n#### ‚ú® [Uncertainty](https://nn.labml.ai/uncertainty/index.html)\n\n* [Evidential Deep Learning to Quantify Classification Uncertainty](https://nn.labml.ai/uncertainty/evidence/index.html)\n\n#### ‚ú® [Activations](https://nn.labml.ai/activations/index.html)\n\n* [Fuzzy Tiling Activations](https://nn.labml.ai/activations/fta/index.html)\n\n#### ‚ú® [Langauge Model Sampling Techniques](https://nn.labml.ai/sampling/index.html)\n* [Greedy Sampling](https://nn.labml.ai/sampling/greedy.html)\n* [Temperature Sampling](https://nn.labml.ai/sampling/temperature.html)\n* [Top-k Sampling](https://nn.labml.ai/sampling/top_k.html)\n* [Nucleus Sampling](https://nn.labml.ai/sampling/nucleus.html)\n\n#### ‚ú® [Scalable Training/Inference](https://nn.labml.ai/scaling/index.html)\n* [Zero3 memory optimizations](https://nn.labml.ai/scaling/zero3/index.html)\n\n### Installation\n\n```bash\npip install labml-nn\n```\n",
         "AI_DataScience"
        ],
        [
         "7",
         "MDEwOlJlcG9zaXRvcnk4Mzg0NDcyMA==",
         "# Face Recognition\n\n_You can also read a translated version of this file [in Chinese ÁÆÄ‰Ωì‰∏≠ÊñáÁâà](https://github.com/ageitgey/face_recognition/blob/master/README_Simplified_Chinese.md) or [in Korean ÌïúÍµ≠Ïñ¥](https://github.com/ageitgey/face_recognition/blob/master/README_Korean.md) or [in Japanese Êó•Êú¨Ë™û](https://github.com/m-i-k-i/face_recognition/blob/master/README_Japanese.md)._\n\nRecognize and manipulate faces from Python or from the command line with\nthe world's simplest face recognition library.\n\nBuilt using [dlib](http://dlib.net/)'s state-of-the-art face recognition\nbuilt with deep learning. The model has an accuracy of 99.38% on the\n[Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/) benchmark.\n\nThis also provides a simple `face_recognition` command line tool that lets\nyou do face recognition on a folder of images from the command line!\n\n\n[![PyPI](https://img.shields.io/pypi/v/face_recognition.svg)](https://pypi.python.org/pypi/face_recognition)\n[![Build Status](https://github.com/ageitgey/face_recognition/workflows/CI/badge.svg?branch=master&event=push)](https://github.com/ageitgey/face_recognition/actions?query=workflow%3ACI)\n[![Documentation Status](https://readthedocs.org/projects/face-recognition/badge/?version=latest)](http://face-recognition.readthedocs.io/en/latest/?badge=latest)\n\n## Features\n\n#### Find faces in pictures\n\nFind all the faces that appear in a picture:\n\n![](https://cloud.githubusercontent.com/assets/896692/23625227/42c65360-025d-11e7-94ea-b12f28cb34b4.png)\n\n```python\nimport face_recognition\nimage = face_recognition.load_image_file(\"your_file.jpg\")\nface_locations = face_recognition.face_locations(image)\n```\n\n#### Find and manipulate facial features in pictures\n\nGet the locations and outlines of each person's eyes, nose, mouth and chin.\n\n![](https://cloud.githubusercontent.com/assets/896692/23625282/7f2d79dc-025d-11e7-8728-d8924596f8fa.png)\n\n```python\nimport face_recognition\nimage = face_recognition.load_image_file(\"your_file.jpg\")\nface_landmarks_list = face_recognition.face_landmarks(image)\n```\n\nFinding facial features is super useful for lots of important stuff. But you can also use it for really stupid stuff\nlike applying [digital make-up](https://github.com/ageitgey/face_recognition/blob/master/examples/digital_makeup.py) (think 'Meitu'):\n\n![](https://cloud.githubusercontent.com/assets/896692/23625283/80638760-025d-11e7-80a2-1d2779f7ccab.png)\n\n#### Identify faces in pictures\n\nRecognize who appears in each photo.\n\n![](https://cloud.githubusercontent.com/assets/896692/23625229/45e049b6-025d-11e7-89cc-8a71cf89e713.png)\n\n```python\nimport face_recognition\nknown_image = face_recognition.load_image_file(\"biden.jpg\")\nunknown_image = face_recognition.load_image_file(\"unknown.jpg\")\n\nbiden_encoding = face_recognition.face_encodings(known_image)[0]\nunknown_encoding = face_recognition.face_encodings(unknown_image)[0]\n\nresults = face_recognition.compare_faces([biden_encoding], unknown_encoding)\n```\n\nYou can even use this library with other Python libraries to do real-time face recognition:\n\n![](https://cloud.githubusercontent.com/assets/896692/24430398/36f0e3f0-13cb-11e7-8258-4d0c9ce1e419.gif)\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py) for the code.\n\n## Online Demos\n\nUser-contributed shared Jupyter notebook demo (not officially supported): [![Deepnote](https://beta.deepnote.org/buttons/try-in-a-jupyter-notebook.svg)](https://beta.deepnote.org/launch?template=face_recognition)\n\n## Installation\n\n### Requirements\n\n  * Python 3.3+ or Python 2.7\n  * macOS or Linux (Windows not officially supported, but might work)\n\n### Installation Options:\n\n#### Installing on Mac or Linux\n\nFirst, make sure you have dlib already installed with Python bindings:\n\n  * [How to install dlib from source on macOS or Ubuntu](https://gist.github.com/ageitgey/629d75c1baac34dfa5ca2a1928a7aeaf)\n  \nThen, make sure you have cmake installed:  \n \n```brew install cmake```\n\nFinally, install this module from pypi using `pip3` (or `pip2` for Python 2):\n\n```bash\npip3 install face_recognition\n```\n\nAlternatively, you can try this library with [Docker](https://www.docker.com/), see [this section](#deployment).\n\nIf you are having trouble with installation, you can also try out a\n[pre-configured VM](https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b).\n\n#### Installing on an Nvidia Jetson Nano board\n\n * [Jetson Nano installation instructions](https://medium.com/@ageitgey/build-a-hardware-based-face-recognition-system-for-150-with-the-nvidia-jetson-nano-and-python-a25cb8c891fd)\n   * Please follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don't follow the instructions in the article to comment out a line in dlib and recompile it.\n\n#### Installing on Raspberry Pi 2+\n\n  * [Raspberry Pi 2+ installation instructions](https://gist.github.com/ageitgey/1ac8dbe8572f3f533df6269dab35df65)\n\n#### Installing on FreeBSD\n\n```bash\npkg install graphics/py-face_recognition\n```\n\n#### Installing on Windows\n\nWhile Windows isn't officially supported, helpful users have posted instructions on how to install this library:\n\n  * [@masoudr's Windows 10 installation guide (dlib + face_recognition)](https://github.com/ageitgey/face_recognition/issues/175#issue-257710508)\n\n#### Installing a pre-configured Virtual Machine image\n\n  * [Download the pre-configured VM image](https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b) (for VMware Player or VirtualBox).\n\n## Usage\n\n### Command-Line Interface\n\nWhen you install `face_recognition`, you get two simple command-line \nprograms:\n\n* `face_recognition` - Recognize faces in a photograph or folder full for \n   photographs.\n* `face_detection` - Find faces in a photograph or folder full for photographs.\n\n#### `face_recognition` command line tool\n\nThe `face_recognition` command lets you recognize faces in a photograph or \nfolder full  for photographs.\n\nFirst, you need to provide a folder with one picture of each person you\nalready know. There should be one image file for each person with the\nfiles named according to who is in the picture:\n\n![known](https://cloud.githubusercontent.com/assets/896692/23582466/8324810e-00df-11e7-82cf-41515eba704d.png)\n\nNext, you need a second folder with the files you want to identify:\n\n![unknown](https://cloud.githubusercontent.com/assets/896692/23582465/81f422f8-00df-11e7-8b0d-75364f641f58.png)\n\nThen in you simply run the command `face_recognition`, passing in\nthe folder of known people and the folder (or single image) with unknown\npeople and it tells you who is in each image:\n\n```bash\n$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/\n\n/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person\n```\n\nThere's one line in the output for each face. The data is comma-separated\nwith the filename and the name of the person found.\n\nAn `unknown_person` is a face in the image that didn't match anyone in\nyour folder of known people.\n\n#### `face_detection` command line tool\n\nThe `face_detection` command lets you find the location (pixel coordinatates) \nof any faces in an image.\n\nJust run the command `face_detection`, passing in a folder of images \nto check (or a single image):\n\n```bash\n$ face_detection  ./folder_with_pictures/\n\nexamples/image1.jpg,65,215,169,112\nexamples/image2.jpg,62,394,211,244\nexamples/image2.jpg,95,941,244,792\n```\n\nIt prints one line for each face that was detected. The coordinates\nreported are the top, right, bottom and left coordinates of the face (in pixels).\n \n##### Adjusting Tolerance / Sensitivity\n\nIf you are getting multiple matches for the same person, it might be that\nthe people in your photos look very similar and a lower tolerance value\nis needed to make face comparisons more strict.\n\nYou can do that with the `--tolerance` parameter. The default tolerance\nvalue is 0.6 and lower numbers make face comparisons more strict:\n\n```bash\n$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures/\n\n/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person\n```\n\nIf you want to see the face distance calculated for each match in order\nto adjust the tolerance setting, you can use `--show-distance true`:\n\n```bash\n$ face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures/\n\n/unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,None\n```\n\n##### More Examples\n\nIf you simply want to know the names of the people in each photograph but don't\ncare about file names, you could do this:\n\n```bash\n$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ | cut -d ',' -f2\n\nBarack Obama\nunknown_person\n```\n\n##### Speeding up Face Recognition\n\nFace recognition can be done in parallel if you have a computer with\nmultiple CPU cores. For example, if your system has 4 CPU cores, you can\nprocess about 4 times as many images in the same amount of time by using\nall your CPU cores in parallel.\n\nIf you are using Python 3.4 or newer, pass in a `--cpus <number_of_cpu_cores_to_use>` parameter:\n\n```bash\n$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/\n```\n\nYou can also pass in `--cpus -1` to use all CPU cores in your system.\n\n#### Python Module\n\nYou can import the `face_recognition` module and then easily manipulate\nfaces with just a couple of lines of code. It's super easy!\n\nAPI Docs: [https://face-recognition.readthedocs.io](https://face-recognition.readthedocs.io/en/latest/face_recognition.html).\n\n##### Automatically find all the faces in an image\n\n```python\nimport face_recognition\n\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_locations = face_recognition.face_locations(image)\n\n# face_locations is now an array listing the co-ordinates of each face!\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture.py)\n to try it out.\n\nYou can also opt-in to a somewhat more accurate deep-learning-based face detection model.\n\nNote: GPU acceleration (via NVidia's CUDA library) is required for good\nperformance with this model. You'll also want to enable CUDA support\nwhen compliling `dlib`.\n\n```python\nimport face_recognition\n\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_locations = face_recognition.face_locations(image, model=\"cnn\")\n\n# face_locations is now an array listing the co-ordinates of each face!\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture_cnn.py)\n to try it out.\n\nIf you have a lot of images and a GPU, you can also\n[find faces in batches](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_batches.py).\n\n##### Automatically locate the facial features of a person in an image\n\n```python\nimport face_recognition\n\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_landmarks_list = face_recognition.face_landmarks(image)\n\n# face_landmarks_list is now an array with the locations of each facial feature in each face.\n# face_landmarks_list[0]['left_eye'] would be the location and outline of the first person's left eye.\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/find_facial_features_in_picture.py)\n to try it out.\n\n##### Recognize faces in images and identify who they are\n\n```python\nimport face_recognition\n\npicture_of_me = face_recognition.load_image_file(\"me.jpg\")\nmy_face_encoding = face_recognition.face_encodings(picture_of_me)[0]\n\n# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!\n\nunknown_picture = face_recognition.load_image_file(\"unknown.jpg\")\nunknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]\n\n# Now we can see the two face encodings are of the same person with `compare_faces`!\n\nresults = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)\n\nif results[0] == True:\n    print(\"It's a picture of me!\")\nelse:\n    print(\"It's not a picture of me!\")\n```\n\nSee [this example](https://github.com/ageitgey/face_recognition/blob/master/examples/recognize_faces_in_pictures.py)\n to try it out.\n\n## Python Code Examples\n\nAll the examples are available [here](https://github.com/ageitgey/face_recognition/tree/master/examples).\n\n\n#### Face Detection\n\n* [Find faces in a photograph](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture.py)\n* [Find faces in a photograph (using deep learning)](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_picture_cnn.py)\n* [Find faces in batches of images w/ GPU (using deep learning)](https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_batches.py)\n* [Blur all the faces in a live video using your webcam (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/blur_faces_on_webcam.py)\n\n#### Facial Features\n\n* [Identify specific facial features in a photograph](https://github.com/ageitgey/face_recognition/blob/master/examples/find_facial_features_in_picture.py)\n* [Apply (horribly ugly) digital make-up](https://github.com/ageitgey/face_recognition/blob/master/examples/digital_makeup.py)\n\n#### Facial Recognition\n\n* [Find and recognize unknown faces in a photograph based on photographs of known people](https://github.com/ageitgey/face_recognition/blob/master/examples/recognize_faces_in_pictures.py)\n* [Identify and draw boxes around each person in a photo](https://github.com/ageitgey/face_recognition/blob/master/examples/identify_and_draw_boxes_on_faces.py)\n* [Compare faces by numeric face distance instead of only True/False matches](https://github.com/ageitgey/face_recognition/blob/master/examples/face_distance.py)\n* [Recognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam.py)\n* [Recognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py)\n* [Recognize faces in a video file and write out new video file (Requires OpenCV to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_video_file.py)\n* [Recognize faces on a Raspberry Pi w/ camera](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_on_raspberry_pi.py)\n* [Run a web service to recognize faces via HTTP (Requires Flask to be installed)](https://github.com/ageitgey/face_recognition/blob/master/examples/web_service_example.py)\n* [Recognize faces with a K-nearest neighbors classifier](https://github.com/ageitgey/face_recognition/blob/master/examples/face_recognition_knn.py)\n* [Train multiple images per person then recognize faces using a SVM](https://github.com/ageitgey/face_recognition/blob/master/examples/face_recognition_svm.py)\n\n## Creating a Standalone Executable\nIf you want to create a standalone executable that can run without the need to install `python` or `face_recognition`, you can use [PyInstaller](https://github.com/pyinstaller/pyinstaller). However, it requires some custom configuration to work with this library. See [this issue](https://github.com/ageitgey/face_recognition/issues/357) for how to do it.\n\n## Articles and Guides that cover `face_recognition`\n\n- My article on how Face Recognition works: [Modern Face Recognition with Deep Learning](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78)\n  - Covers the algorithms and how they generally work\n- [Face recognition with OpenCV, Python, and deep learning](https://www.pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/) by Adrian Rosebrock\n  - Covers how to use face recognition in practice\n- [Raspberry Pi Face Recognition](https://www.pyimagesearch.com/2018/06/25/raspberry-pi-face-recognition/) by Adrian Rosebrock\n  - Covers how to use this on a Raspberry Pi\n- [Face clustering with Python](https://www.pyimagesearch.com/2018/07/09/face-clustering-with-python/) by Adrian Rosebrock\n  - Covers how to automatically cluster photos based on who appears in each photo using unsupervised learning\n\n## How Face Recognition Works\n\nIf you want to learn how face location and recognition work instead of\ndepending on a black box library, [read my article](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78).\n\n## Caveats\n\n* The face recognition model is trained on adults and does not work very well on children. It tends to mix\n  up children quite easy using the default comparison threshold of 0.6.\n* Accuracy may vary between ethnic groups. Please see [this wiki page](https://github.com/ageitgey/face_recognition/wiki/Face-Recognition-Accuracy-Problems#question-face-recognition-works-well-with-european-individuals-but-overall-accuracy-is-lower-with-asian-individuals) for more details.\n\n## <a name=\"deployment\">Deployment to Cloud Hosts (Heroku, AWS, etc)</a>\n\nSince `face_recognition` depends on `dlib` which is written in C++, it can be tricky to deploy an app\nusing it to a cloud hosting provider like Heroku or AWS.\n\nTo make things easier, there's an example Dockerfile in this repo that shows how to run an app built with\n`face_recognition` in a [Docker](https://www.docker.com/) container. With that, you should be able to deploy\nto any service that supports Docker images.\n\nYou can try the Docker image locally by running: `docker-compose up --build`\n\nThere are also [several prebuilt Docker images.](docker/README.md)\n\nLinux users with a GPU (drivers >= 384.81) and [Nvidia-Docker](https://github.com/NVIDIA/nvidia-docker) installed can run the example on the GPU: Open the [docker-compose.yml](docker-compose.yml) file and uncomment the `dockerfile: Dockerfile.gpu` and `runtime: nvidia` lines.\n\n## Having problems?\n\nIf you run into problems, please read the [Common Errors](https://github.com/ageitgey/face_recognition/wiki/Common-Errors) section of the wiki before filing a github issue.\n\n## Thanks\n\n* Many, many thanks to [Davis King](https://github.com/davisking) ([@nulhom](https://twitter.com/nulhom))\n  for creating dlib and for providing the trained facial feature detection and face encoding models\n  used in this library. For more information on the ResNet that powers the face encodings, check out\n  his [blog post](http://blog.dlib.net/2017/02/high-quality-face-recognition-with-deep.html).\n* Thanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image,\n  pillow, etc, etc that makes this kind of stuff so easy and fun in Python.\n* Thanks to [Cookiecutter](https://github.com/audreyr/cookiecutter) and the\n  [audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage) project template\n  for making Python project packaging way more tolerable.\n",
         "AI_DataScience"
        ],
        [
         "8",
         "MDEwOlJlcG9zaXRvcnkxMTQ3NDcyMjY=",
         "# deepfakes_faceswap\n\n### Important information for **Patreon** and **PayPal** supporters. Please see this forum post: https://forum.faceswap.dev/viewtopic.php?f=14&t=3120\n\n<p align=\"center\">\n  <a href=\"https://faceswap.dev\"><img src=\"https://i.imgur.com/zHvjHnb.png\"></img></a>\n<br />FaceSwap is a tool that utilizes deep learning to recognize and swap faces in pictures and videos.\n</p>\n<p align=\"center\">\n<img src = \"https://i.imgur.com/nWHFLDf.jpg\"></img>\n</p>\n\n<p align=\"center\">\n<a href=\"https://www.patreon.com/bePatron?u=23238350\"><img src=\"https://c5.patreon.com/external/logo/become_a_patron_button.png\"></img></a>\n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"https://discord.gg/FC54sYg\"><img src=\"https://i.imgur.com/gIpztkv.png\"></img></a></p>\n\n<p align=\"center\">\n  <a href=\"https://www.dailymotion.com/video/x810mot\"><img src=\"https://user-images.githubusercontent.com/36920800/178301720-b69841bb-a1ca-4c20-91db-a2a10f5692ca.png\"></img></a>\n<br />Emma Stone/Scarlett Johansson FaceSwap using the Phaze-A model\n</p>\n\n<p align=\"center\">\n  <a href=\"https://www.youtube.com/watch?v=r1jng79a5xc\"><img src=\"https://img.youtube.com/vi/r1jng79a5xc/0.jpg\"></img></a>\n<br />Jennifer Lawrence/Steve Buscemi FaceSwap using the Villain model\n</p>\n\n\n![Build Status](https://github.com/deepfakes/faceswap/actions/workflows/pytest.yml/badge.svg) [![Documentation Status](https://readthedocs.org/projects/faceswap/badge/?version=latest)](https://faceswap.readthedocs.io/en/latest/?badge=latest)\n\nMake sure you check out [INSTALL.md](INSTALL.md) before getting started.\n\n- [deepfakes\\_faceswap](#deepfakes_faceswap)\n    - [Important information for **Patreon** and **PayPal** supporters. Please see this forum post: https://forum.faceswap.dev/viewtopic.php?f=14\\&t=3120](#important-information-for-patreon-and-paypal-supporters-please-see-this-forum-post-httpsforumfaceswapdevviewtopicphpf14t3120)\n- [Manifesto](#manifesto)\n  - [FaceSwap has ethical uses.](#faceswap-has-ethical-uses)\n- [How To setup and run the project](#how-to-setup-and-run-the-project)\n- [Overview](#overview)\n  - [Extract](#extract)\n  - [Train](#train)\n  - [Convert](#convert)\n  - [GUI](#gui)\n- [General notes:](#general-notes)\n- [Help I need support!](#help-i-need-support)\n  - [Discord Server](#discord-server)\n  - [FaceSwap Forum](#faceswap-forum)\n- [Donate](#donate)\n  - [Patreon](#patreon)\n  - [One time Donations](#one-time-donations)\n    - [@torzdf](#torzdf)\n    - [@andenixa](#andenixa)\n- [How to contribute](#how-to-contribute)\n  - [For people interested in the generative models](#for-people-interested-in-the-generative-models)\n  - [For devs](#for-devs)\n  - [For non-dev advanced users](#for-non-dev-advanced-users)\n  - [For end-users](#for-end-users)\n- [About machine learning](#about-machine-learning)\n  - [How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?](#how-does-a-computer-know-how-to-recognizeshape-faces-how-does-machine-learning-work-what-is-a-neural-network)\n\n# Manifesto\n\n## FaceSwap has ethical uses.\n\nWhen faceswapping was first developed and published, the technology was groundbreaking, it was a huge step in AI development. It was also completely ignored outside of academia because the code was confusing and fragmentary. It required a thorough understanding of complicated AI techniques and took a lot of effort to figure it out. Until one individual brought it together into a single, cohesive collection. It ran, it worked, and as is so often the way with new technology emerging on the internet, it was immediately used to create inappropriate content. Despite the inappropriate uses the software was given originally, it was the first AI code that anyone could download, run and learn by experimentation without having a Ph.D. in math, computer theory, psychology, and more. Before \"deepfakes\" these techniques were like black magic, only practiced by those who could understand all of the inner workings as described in esoteric and endlessly complicated books and papers.\n\n\"Deepfakes\" changed all that and anyone could participate in AI development. To us, developers, the release of this code opened up a fantastic learning opportunity. It allowed us to build on ideas developed by others, collaborate with a variety of skilled coders, experiment with AI whilst learning new skills and ultimately contribute towards an emerging technology which will only see more mainstream use as it progresses.\n\nAre there some out there doing horrible things with similar software? Yes. And because of this, the developers have been following strict ethical standards. Many of us don't even use it to create videos, we just tinker with the code to see what it does. Sadly, the media concentrates only on the unethical uses of this software. That is, unfortunately, the nature of how it was first exposed to the public, but it is not representative of why it was created, how we use it now, or what we see in its future. Like any technology, it can be used for good or it can be abused. It is our intention to develop FaceSwap in a way that its potential for abuse is minimized whilst maximizing its potential as a tool for learning, experimenting and, yes, for legitimate faceswapping.\n\nWe are not trying to denigrate celebrities or to demean anyone. We are programmers, we are engineers, we are Hollywood VFX artists, we are activists, we are hobbyists, we are human beings. To this end, we feel that it's time to come out with a standard statement of what this software is and isn't as far as us developers are concerned.\n\n- FaceSwap is not for creating inappropriate content.\n- FaceSwap is not for changing faces without consent or with the intent of hiding its use.\n- FaceSwap is not for any illicit, unethical, or questionable purposes.\n- FaceSwap exists to experiment and discover AI techniques, for social or political commentary, for movies, and for any number of ethical and reasonable uses.\n\nWe are very troubled by the fact that FaceSwap can be used for unethical and disreputable things. However, we support the development of tools and techniques that can be used ethically as well as provide education and experience in AI for anyone who wants to learn it hands-on. We will take a zero tolerance approach to anyone using this software for any unethical purposes and will actively discourage any such uses.\n\n# How To setup and run the project\nFaceSwap is a Python program that will run on multiple Operating Systems including Windows, Linux, and MacOS.\n\nSee [INSTALL.md](INSTALL.md) for full installation instructions. You will need a modern GPU with CUDA support for best performance. Many AMD GPUs are supported through DirectML (Windows) and ROCm (Linux).\n\n# Overview\nThe project has multiple entry points. You will have to:\n - Gather photos and/or videos\n - **Extract** faces from your raw photos\n - **Train** a model on the faces extracted from the photos/videos\n - **Convert** your sources with the model\n\nCheck out [USAGE.md](USAGE.md) for more detailed instructions.\n\n## Extract\nFrom your setup folder, run `python faceswap.py extract`. This will take photos from `src` folder and extract faces into `extract` folder.\n\n## Train\nFrom your setup folder, run `python faceswap.py train`. This will take photos from two folders containing pictures of both faces and train a model that will be saved inside the `models` folder.\n\n## Convert\nFrom your setup folder, run `python faceswap.py convert`. This will take photos from `original` folder and apply new faces into `modified` folder.\n\n## GUI\nAlternatively, you can run the GUI by running `python faceswap.py gui`\n\n# General notes:\n- All of the scripts mentioned have `-h`/`--help` options with arguments that they will accept. You're smart, you can figure out how this works, right?!\n\nNB: there is a conversion tool for video. This can be accessed by running `python tools.py effmpeg -h`. Alternatively, you can use [ffmpeg](https://www.ffmpeg.org) to convert video into photos, process images, and convert images back to the video.\n\n\n**Some tips:**\n\nReusing existing models will train much faster than starting from nothing.\nIf there is not enough training data, start with someone who looks similar, then switch the data.\n\n# Help I need support!\n## Discord Server\nYour best bet is to join the [FaceSwap Discord server](https://discord.gg/FC54sYg) where there are plenty of users willing to help. Please note that, like this repo, this is a SFW Server!\n\n## FaceSwap Forum\nAlternatively, you can post questions in the [FaceSwap Forum](https://faceswap.dev/forum). Please do not post general support questions in this repo as they are liable to be deleted without response.\n\n# Donate\nThe developers work tirelessly to improve and develop FaceSwap. Many hours have been put in to provide the software as it is today, but this is an extremely time-consuming process with no financial reward. If you enjoy using the software, please consider donating to the devs, so they can spend more time implementing improvements.\n\n## Patreon\nThe best way to support us is through our Patreon page:\n\n[![become-a-patron](https://c5.patreon.com/external/logo/become_a_patron_button.png)](https://www.patreon.com/bePatron?u=23238350)\n\n## One time Donations\nAlternatively you can give a one off donation to any of our Devs:\n### @torzdf\n There is very little FaceSwap code that hasn't been touched by torzdf. He is responsible for implementing the GUI, FAN aligner, MTCNN detector and porting the Villain, DFL-H128 and DFaker models to FaceSwap, as well as significantly improving many areas of the code.\n\n**Bitcoin:** bc1qpm22suz59ylzk0j7qk5e4c7cnkjmve2rmtrnc6\n\n**Ethereum:** 0xd3e954dC241B87C4E8E1A801ada485DC1d530F01\n\n**Monero:** 45dLrtQZ2pkHizBpt3P3yyJKkhcFHnhfNYPMSnz3yVEbdWm3Hj6Kr5TgmGAn3Far8LVaQf1th2n3DJVTRkfeB5ZkHxWozSX\n\n**Paypal:** [![torzdf](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=JZ8PP3YE9J62L)\n\n### @andenixa\nCreator of the Unbalanced and OHR models, as well as expanding various capabilities within the training process. Andenixa is currently working on new models and will take requests for donations.\n\n**Paypal:** [![andenixa](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_SM.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=NRVLQYGS6NWTU)\n\n# How to contribute\n\n## For people interested in the generative models\n - Go to the 'faceswap-model' to discuss/suggest/commit alternatives to the current algorithm.\n\n## For devs\n - Read this README entirely\n - Fork the repo\n - Play with it\n - Check issues with the 'dev' tag\n - For devs more interested in computer vision and openCV, look at issues with the 'opencv' tag. Also feel free to add your own alternatives/improvements\n\n## For non-dev advanced users\n - Read this README entirely\n - Clone the repo\n - Play with it\n - Check issues with the 'advuser' tag\n - Also go to the '[faceswap Forum](https://faceswap.dev/forum)' and help others.\n\n## For end-users\n - Get the code here and play with it if you can\n - You can also go to the [faceswap Forum](https://faceswap.dev/forum) and help or get help from others.\n - Be patient. This is a relatively new technology for developers as well. Much effort is already being put into making this program easy to use for the average user. It just takes time!\n - **Notice** Any issue related to running the code has to be opened in the [faceswap Forum](https://faceswap.dev/forum)!\n\n# About machine learning\n\n## How does a computer know how to recognize/shape faces? How does machine learning work? What is a neural network?\nIt's complicated. Here's a good video that makes the process understandable:\n[![How Machines Learn](https://img.youtube.com/vi/R9OHn5ZF4Uo/0.jpg)](https://www.youtube.com/watch?v=R9OHn5ZF4Uo)\n\nHere's a slightly more in depth video that tries to explain the basic functioning of a neural network:\n[![How Machines Learn](https://img.youtube.com/vi/aircAruvnKk/0.jpg)](https://www.youtube.com/watch?v=aircAruvnKk)\n\ntl;dr: training data + trial and error\n",
         "AI_DataScience"
        ],
        [
         "9",
         "MDEwOlJlcG9zaXRvcnkxNjQ0MTk2",
         "<a name=\"logo\"/>\n<div align=\"center\">\n<a href=\"https://julialang.org/\" target=\"_blank\">\n<img src=\"doc/src/assets/logo.svg\" alt=\"Julia Logo\" width=\"210\" height=\"142\"></img>\n</a>\n</div>\n\n<table>\n    <!-- Docs -->\n    <tr>\n        <td>Documentation</td>\n        <td>\n            <a href=\"https://docs.julialang.org\"><img src='https://img.shields.io/badge/docs-v1-blue.svg'/></a>\n        </td>\n    </tr>\n    <!-- Continuous integration\n    To change the badge to point to a different pipeline, it is not sufficient to simply change the `?branch=` part.\n    You need to go to the Buildkite website and get the SVG URL for the correct pipeline. -->\n    <tr>\n        <td>Continuous integration</td>\n        <td>\n            <a href=\"https://buildkite.com/julialang/julia-master\"><img src='https://badge.buildkite.com/f28e0d28b345f9fad5856ce6a8d64fffc7c70df8f4f2685cd8.svg?branch=master'/></a>\n        </td>\n    </tr>\n    <!-- Coverage -->\n    <tr>\n        <td>Code coverage</td>\n        <td>\n            <a href='https://coveralls.io/github/JuliaLang/julia?branch=master'><img src='https://coveralls.io/repos/github/JuliaLang/julia/badge.svg?branch=master' alt='Coverage Status'/></a>\n            <a href=\"https://codecov.io/gh/JuliaLang/julia\"><img src=\"https://codecov.io/gh/JuliaLang/julia/branch/master/graph/badge.svg?token=TckCRxc7HS\"/></a>\n        </td>\n    </tr>\n</table>\n\n## The Julia Language\n\nJulia is a high-level, high-performance dynamic language for technical\ncomputing. The main homepage for Julia can be found at\n[julialang.org](https://julialang.org/). This is the GitHub\nrepository of Julia source code, including instructions for compiling\nand installing Julia, below.\n\n## Resources\n\n- **Homepage:** <https://julialang.org>\n- **Install:** <https://julialang.org/install/>\n- **Source code:** <https://github.com/JuliaLang/julia>\n- **Documentation:** <https://docs.julialang.org>\n- **Packages:** <https://julialang.org/packages/>\n- **Discussion forum:** <https://discourse.julialang.org>\n- **Zulip:** <https://julialang.zulipchat.com/>\n- **Slack:** <https://julialang.slack.com> (get an invite from <https://julialang.org/slack/>)\n- **YouTube:** <https://www.youtube.com/user/JuliaLanguage>\n- **Code coverage:** <https://coveralls.io/r/JuliaLang/julia>\n\nNew developers may find the notes in\n[CONTRIBUTING](https://github.com/JuliaLang/julia/blob/master/CONTRIBUTING.md)\nhelpful to start contributing to the Julia codebase.\n\n### Learning Julia\n\n- [**Learning resources**](https://julialang.org/learning/)\n\n## Binary Installation\n\nThe recommended way of installing Julia is to use `juliaup` which will install\nthe latest stable `julia` for you and help keep it up to date. It can also let\nyou install and run different Julia versions simultaneously. Instructions for\nthis can be found [here](https://julialang.org/install/). If you want to manually\ndownload specific Julia binaries, you can find those on the [downloads\npage](https://julialang.org/downloads/). The downloads page also provides\ndetails on the [different tiers of\nsupport](https://julialang.org/downloads/#supported_platforms) for OS and\nplatform combinations.\n\nIf everything works correctly, you will get a `julia` program and when you run\nit in a terminal or command prompt, you will see a Julia banner and an\ninteractive prompt into which you can enter expressions for evaluation. You can\nread about [getting\nstarted](https://docs.julialang.org/en/v1/manual/getting-started/) in the\nmanual.\n\n**Note**: Although some OS package managers provide Julia, such\ninstallations are neither maintained nor endorsed by the Julia\nproject. They may be outdated, broken and/or unmaintained. We\nrecommend you use the official Julia binaries instead.\n\n## Building Julia\n\nFirst, make sure you have all the [required\ndependencies](https://github.com/JuliaLang/julia/blob/master/doc/src/devdocs/build/build.md#required-build-tools-and-external-libraries) installed.\nThen, acquire the source code by cloning the git repository:\n\n    git clone https://github.com/JuliaLang/julia.git\n\nand then use the command prompt to change into the resulting julia directory. By default, you will be building the latest unstable version of\nJulia. However, most users should use the [most recent stable version](https://github.com/JuliaLang/julia/releases)\nof Julia. You can get this version by running:\n\n    git checkout v1.11.7\n\nTo build the `julia` executable, run `make` from within the julia directory.\n\nBuilding Julia requires 2GiB of disk space and approximately 4GiB of virtual memory.\n\n**Note:** The build process will fail badly if any of the build directory's parent directories have spaces or other shell meta-characters such as `$` or `:` in their names (this is due to a limitation in GNU make).\n\nOnce it is built, you can run the `julia` executable. From within the julia directory, run\n\n    ./julia\n\nYour first test of Julia determines whether your build is working\nproperly. From the julia\ndirectory, type `make testall`. You should see output that\nlists a series of running tests; if they complete without error, you\nshould be in good shape to start using Julia.\n\nYou can read about [getting\nstarted](https://docs.julialang.org/en/v1/manual/getting-started/)\nin the manual.\n\nDetailed build instructions, should they be necessary,\nare included in the [build documentation](https://github.com/JuliaLang/julia/blob/master/doc/src/devdocs/build/build.md).\n\n### Uninstalling Julia\n\nBy default, Julia does not install anything outside the directory it was cloned\ninto and `~/.julia`. Julia and the vast majority of Julia packages can be\ncompletely uninstalled by deleting these two directories.\n\n## Source Code Organization\n\nThe Julia source code is organized as follows:\n\n| Directory         | Contents                                                           |\n| -                 | -                                                                  |\n| `base/`           | source code for the Base module (part of Julia's standard library) |\n| `cli/`            | source for the command line interface/REPL                         |\n| `contrib/`        | miscellaneous scripts                                              |\n| `deps/`           | external dependencies                                              |\n| `doc/src/`        | source for the user manual                                         |\n| `etc/`            | contains `startup.jl`                                              |\n| `src/`            | source for Julia language core                                     |\n| `stdlib/`         | source code for other standard library packages                    |\n| `test/`           | test suites                                                        |\n\n## Terminal, Editors and IDEs\n\nThe Julia REPL is quite powerful. See the section in the manual on\n[the Julia REPL](https://docs.julialang.org/en/v1/stdlib/REPL/)\nfor more details.\n\nOn Windows, we highly recommend running Julia in a modern terminal,\nsuch as [Windows Terminal from the Microsoft Store](https://aka.ms/terminal).\n\nSupport for editing Julia is available for many\n[widely used editors](https://github.com/JuliaEditorSupport):\n[Emacs](https://github.com/JuliaEditorSupport/julia-emacs),\n[Vim](https://github.com/JuliaEditorSupport/julia-vim),\n[Sublime Text](https://github.com/JuliaEditorSupport/Julia-sublime), and many\nothers.\n\nFor users who prefer IDEs, we recommend using VS Code with the\n[julia-vscode](https://www.julia-vscode.org/) plugin.\\\nFor notebook users, [Jupyter](https://jupyter.org/) notebook support is available through the\n[IJulia](https://github.com/JuliaLang/IJulia.jl) package, and\nthe [Pluto.jl](https://github.com/fonsp/Pluto.jl) package provides Pluto notebooks.\n",
         "AI_DataScience"
        ],
        [
         "10",
         "MDEwOlJlcG9zaXRvcnk0NTk4NjE2Mg==",
         "# TensorFlow Examples\n\nThis tutorial was designed for easily diving into TensorFlow, through examples. For readability, it includes both notebooks and source codes with explanation, for both TF v1 & v2.\n\nIt is suitable for beginners who want to find clear and concise examples about TensorFlow. Besides the traditional 'raw' TensorFlow implementations, you can also find the latest TensorFlow API practices (such as `layers`, `estimator`, `dataset`, ...).\n\n**Update (05/16/2020):** Moving all default examples to TF2. For TF v1 examples: [check here](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1).\n\n## Tutorial index\n\n#### 0 - Prerequisite\n- [Introduction to Machine Learning](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/0_Prerequisite/ml_introduction.ipynb).\n- [Introduction to MNIST Dataset](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/0_Prerequisite/mnist_dataset_intro.ipynb).\n\n#### 1 - Introduction\n- **Hello World** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/1_Introduction/helloworld.ipynb)). Very simple example to learn how to print \"hello world\" using TensorFlow 2.0+.\n- **Basic Operations** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/1_Introduction/basic_operations.ipynb)). A simple example that cover TensorFlow 2.0+ basic operations.\n\n#### 2 - Basic Models\n- **Linear Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/linear_regression.ipynb)). Implement a Linear Regression with TensorFlow 2.0+.\n- **Logistic Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/logistic_regression.ipynb)). Implement a Logistic Regression with TensorFlow 2.0+.\n- **Word2Vec (Word Embedding)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/word2vec.ipynb)). Build a Word Embedding Model (Word2Vec) from Wikipedia data, with TensorFlow 2.0+.\n- **GBDT (Gradient Boosted Decision Trees)** ([notebooks](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/2_BasicModels/gradient_boosted_trees.ipynb)). Implement a Gradient Boosted Decision Trees with TensorFlow 2.0+ to predict house value using Boston Housing dataset.\n\n#### 3 - Neural Networks\n##### Supervised\n\n- **Simple Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/neural_network.ipynb)). Use TensorFlow 2.0 'layers' and 'model' API to build a simple neural network to classify MNIST digits dataset.\n- **Simple Neural Network (low-level)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/neural_network_raw.ipynb)). Raw implementation of a simple neural network to classify MNIST digits dataset.\n- **Convolutional Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/convolutional_network.ipynb)). Use TensorFlow 2.0+ 'layers' and 'model' API to build a convolutional neural network to classify MNIST digits dataset.\n- **Convolutional Neural Network (low-level)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/convolutional_network_raw.ipynb)). Raw implementation of a convolutional neural network to classify MNIST digits dataset.\n- **Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/recurrent_network.ipynb)). Build a recurrent neural network (LSTM) to classify MNIST digits dataset, using TensorFlow 2.0 'layers' and 'model' API.\n- **Bi-directional Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/bidirectional_rnn.ipynb)). Build a bi-directional recurrent neural network (LSTM) to classify MNIST digits dataset, using TensorFlow 2.0+ 'layers' and 'model' API.\n- **Dynamic Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/dynamic_rnn.ipynb)). Build a recurrent neural network (LSTM) that performs dynamic calculation to classify sequences of variable length, using TensorFlow 2.0+ 'layers' and 'model' API.\n\n##### Unsupervised\n- **Auto-Encoder** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/autoencoder.ipynb)). Build an auto-encoder to encode an image to a lower dimension and re-construct it.\n- **DCGAN (Deep Convolutional Generative Adversarial Networks)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/dcgan.ipynb)). Build a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images from noise.\n\n#### 4 - Utilities\n- **Save and Restore a model** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/4_Utils/save_restore_model.ipynb)). Save and Restore a model with TensorFlow 2.0+.\n- **Build Custom Layers & Modules** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/4_Utils/build_custom_layers.ipynb)). Learn how to build your own layers / modules and integrate them into TensorFlow 2.0+ Models.\n- **Tensorboard** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/4_Utils/tensorboard.ipynb)). Track and visualize neural network computation graph, metrics, weights and more using TensorFlow 2.0+ tensorboard.\n\n#### 5 - Data Management\n- **Load and Parse data** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/5_DataManagement/load_data.ipynb)). Build efficient data pipeline with TensorFlow 2.0 (Numpy arrays, Images, CSV files, custom data, ...).\n- **Build and Load TFRecords** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/5_DataManagement/tfrecords.ipynb)). Convert data into TFRecords format, and load them with TensorFlow 2.0+.\n- **Image Transformation (i.e. Image Augmentation)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/5_DataManagement/image_transformation.ipynb)). Apply various image augmentation techniques with TensorFlow 2.0+, to generate distorted images for training.\n\n#### 6 - Hardware\n- **Multi-GPU Training** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/6_Hardware/multigpu_training.ipynb)). Train a convolutional neural network with multiple GPUs on CIFAR-10 dataset.\n\n## TensorFlow v1\n\nThe tutorial index for TF v1 is available here: [TensorFlow v1.15 Examples](tensorflow_v1). Or see below for a list of the examples.\n\n## Dataset\nSome examples require MNIST dataset for training and testing. Don't worry, this dataset will automatically be downloaded when running examples.\nMNIST is a database of handwritten digits, for a quick description of that dataset, you can check [this notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/0_Prerequisite/mnist_dataset_intro.ipynb).\n\nOfficial Website: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).\n\n## Installation\n\nTo download all the examples, simply clone this repository:\n```\ngit clone https://github.com/aymericdamien/TensorFlow-Examples\n```\n\nTo run them, you also need the latest version of TensorFlow. To install it:\n```\npip install tensorflow\n```\n\nor (with GPU support):\n```\npip install tensorflow_gpu\n```\n\nFor more details about TensorFlow installation, you can check [TensorFlow Installation Guide](https://www.tensorflow.org/install/)\n\n\n## TensorFlow v1 Examples - Index\n\nThe tutorial index for TF v1 is available here: [TensorFlow v1.15 Examples](tensorflow_v1).\n\n#### 0 - Prerequisite\n- [Introduction to Machine Learning](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/0_Prerequisite/ml_introduction.ipynb).\n- [Introduction to MNIST Dataset](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/0_Prerequisite/mnist_dataset_intro.ipynb).\n\n#### 1 - Introduction\n- **Hello World** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/1_Introduction/helloworld.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/1_Introduction/helloworld.py)). Very simple example to learn how to print \"hello world\" using TensorFlow.\n- **Basic Operations** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/tensorflow_v1/1_Introduction/basic_operations.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-examples/Examples/blob/master/tensorflow_v1/1_Introduction/basic_operations.py)). A simple example that cover TensorFlow basic operations.\n- **TensorFlow Eager API basics** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/1_Introduction/basic_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/1_Introduction/basic_eager_api.py)). Get started with TensorFlow's Eager API.\n\n#### 2 - Basic Models\n- **Linear Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/linear_regression.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/linear_regression.py)). Implement a Linear Regression with TensorFlow.\n- **Linear Regression (eager api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/linear_regression_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/linear_regression_eager_api.py)). Implement a Linear Regression using TensorFlow's Eager API.\n- **Logistic Regression** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/logistic_regression.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/logistic_regression.py)). Implement a Logistic Regression with TensorFlow.\n- **Logistic Regression (eager api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/logistic_regression_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/logistic_regression_eager_api.py)). Implement a Logistic Regression using TensorFlow's Eager API.\n- **Nearest Neighbor** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/nearest_neighbor.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/nearest_neighbor.py)). Implement Nearest Neighbor algorithm with TensorFlow.\n- **K-Means** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/kmeans.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/kmeans.py)). Build a K-Means classifier with TensorFlow.\n- **Random Forest** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/random_forest.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/random_forest.py)). Build a Random Forest classifier with TensorFlow.\n- **Gradient Boosted Decision Tree (GBDT)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/gradient_boosted_decision_tree.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/gradient_boosted_decision_tree.py)). Build a Gradient Boosted Decision Tree (GBDT) with TensorFlow.\n- **Word2Vec (Word Embedding)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/2_BasicModels/word2vec.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/2_BasicModels/word2vec.py)). Build a Word Embedding Model (Word2Vec) from Wikipedia data, with TensorFlow.\n\n#### 3 - Neural Networks\n##### Supervised\n\n- **Simple Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/3_NeuralNetworks/notebooks/neural_network_raw.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/neural_network_raw.py)). Build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset. Raw TensorFlow implementation.\n- **Simple Neural Network (tf.layers/estimator api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/neural_network.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/neural_network.py)). Use TensorFlow 'layers' and 'estimator' API to build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset.\n- **Simple Neural Network (eager api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/neural_network_eager_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/neural_network_eager_api.py)). Use TensorFlow Eager API to build a simple neural network (a.k.a Multi-layer Perceptron) to classify MNIST digits dataset.\n- **Convolutional Neural Network** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/convolutional_network_raw.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/convolutional_network_raw.py)). Build a convolutional neural network to classify MNIST digits dataset. Raw TensorFlow implementation.\n- **Convolutional Neural Network (tf.layers/estimator api)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/convolutional_network.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/convolutional_network.py)). Use TensorFlow 'layers' and 'estimator' API to build a convolutional neural network to classify MNIST digits dataset.\n- **Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/recurrent_network.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/recurrent_network.py)). Build a recurrent neural network (LSTM) to classify MNIST digits dataset.\n- **Bi-directional Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/bidirectional_rnn.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/bidirectional_rnn.py)). Build a bi-directional recurrent neural network (LSTM) to classify MNIST digits dataset.\n- **Dynamic Recurrent Neural Network (LSTM)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/dynamic_rnn.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/dynamic_rnn.py)). Build a recurrent neural network (LSTM) that performs dynamic calculation to classify sequences of different length.\n\n##### Unsupervised\n- **Auto-Encoder** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/autoencoder.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/autoencoder.py)). Build an auto-encoder to encode an image to a lower dimension and re-construct it.\n- **Variational Auto-Encoder** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/variational_autoencoder.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/variational_autoencoder.py)). Build a variational auto-encoder (VAE), to encode and generate images from noise.\n- **GAN (Generative Adversarial Networks)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/gan.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/gan.py)). Build a Generative Adversarial Network (GAN) to generate images from noise.\n- **DCGAN (Deep Convolutional Generative Adversarial Networks)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/3_NeuralNetworks/dcgan.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/3_NeuralNetworks/dcgan.py)). Build a Deep Convolutional Generative Adversarial Network (DCGAN) to generate images from noise.\n\n#### 4 - Utilities\n- **Save and Restore a model** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/4_Utils/save_restore_model.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/4_Utils/save_restore_model.py)). Save and Restore a model with TensorFlow.\n- **Tensorboard - Graph and loss visualization** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/4_Utils/tensorboard_basic.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/4_Utils/tensorboard_basic.py)). Use Tensorboard to visualize the computation Graph and plot the loss.\n- **Tensorboard - Advanced visualization** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/4_Utils/tensorboard_advanced.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/4_Utils/tensorboard_advanced.py)). Going deeper into Tensorboard; visualize the variables, gradients, and more...\n\n#### 5 - Data Management\n- **Build an image dataset** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/build_an_image_dataset.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/5_DataManagement/build_an_image_dataset.py)). Build your own images dataset with TensorFlow data queues, from image folders or a dataset file.\n- **TensorFlow Dataset API** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/tensorflow_dataset_api.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/5_DataManagement/tensorflow_dataset_api.py)). Introducing TensorFlow Dataset API for optimizing the input data pipeline.\n- **Load and Parse data** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/load_data.ipynb)). Build efficient data pipeline (Numpy arrays, Images, CSV files, custom data, ...).\n- **Build and Load TFRecords** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/tfrecords.ipynb)). Convert data into TFRecords format, and load them.\n- **Image Transformation (i.e. Image Augmentation)** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/5_DataManagement/image_transformation.ipynb)). Apply various image augmentation techniques, to generate distorted images for training.\n\n#### 6 - Multi GPU\n- **Basic Operations on multi-GPU** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/6_MultiGPU/multigpu_basics.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/6_MultiGPU/multigpu_basics.py)). A simple example to introduce multi-GPU in TensorFlow.\n- **Train a Neural Network on multi-GPU** ([notebook](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/notebooks/6_MultiGPU/multigpu_cnn.ipynb)) ([code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v1/examples/6_MultiGPU/multigpu_cnn.py)). A clear and simple TensorFlow implementation to train a convolutional neural network on multiple GPUs.\n\n## More Examples\nThe following examples are coming from [TFLearn](https://github.com/tflearn/tflearn), a library that provides a simplified interface for TensorFlow. You can have a look, there are many [examples](https://github.com/tflearn/tflearn/tree/master/examples) and [pre-built operations and layers](http://tflearn.org/doc_index/#api).\n\n### Tutorials\n- [TFLearn Quickstart](https://github.com/tflearn/tflearn/blob/master/tutorials/intro/quickstart.md). Learn the basics of TFLearn through a concrete machine learning task. Build and train a deep neural network classifier.\n\n### Examples\n- [TFLearn Examples](https://github.com/tflearn/tflearn/blob/master/examples). A large collection of examples using TFLearn.\n\n",
         "AI_DataScience"
        ],
        [
         "11",
         "MDEwOlJlcG9zaXRvcnkxNTYxNTcwNTU=",
         "<div align=\"center\">\n<h1><img width=\"30\" src=\"https://madewithml.com/static/images/rounded_logo.png\">&nbsp;<a href=\"https://madewithml.com/\">Made With ML</a></h1>\nDesign ¬∑ Develop ¬∑ Deploy ¬∑ Iterate\n<br>\nJoin 40K+ developers in learning how to responsibly deliver value with ML.\n    <br>\n</div>\n\n<br>\n\n<div align=\"center\">\n    <a target=\"_blank\" href=\"https://madewithml.com/\"><img src=\"https://img.shields.io/badge/Subscribe-40K-brightgreen\"></a>&nbsp;\n    <a target=\"_blank\" href=\"https://github.com/GokuMohandas/Made-With-ML\"><img src=\"https://img.shields.io/github/stars/GokuMohandas/Made-With-ML.svg?style=social&label=Star\"></a>&nbsp;\n    <a target=\"_blank\" href=\"https://www.linkedin.com/in/goku\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>&nbsp;\n    <a target=\"_blank\" href=\"https://twitter.com/GokuMohandas\"><img src=\"https://img.shields.io/twitter/follow/GokuMohandas.svg?label=Follow&style=social\"></a>\n    <br>\n    üî•&nbsp; Among the <a href=\"https://github.com/GokuMohandas/Made-With-ML\" target=\"_blank\">top ML repositories</a> on GitHub\n</div>\n\n<br>\n<hr>\n\n## Lessons\n\nLearn how to combine machine learning with software engineering to design, develop, deploy and iterate on production-grade ML applications.\n\n- Lessons: https://madewithml.com/\n- Code: [GokuMohandas/Made-With-ML](https://github.com/GokuMohandas/Made-With-ML)\n\n<a href=\"https://madewithml.com/#course\">\n  <img src=\"https://madewithml.com/static/images/lessons.png\" alt=\"lessons\">\n</a>\n\n## Overview\n\nIn this course, we'll go from experimentation (design + development) to production (deployment + iteration). We'll do this iteratively by motivating the components that will enable us to build a *reliable* production system.\n\n<blockquote>\n  <img width=20 src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/YouTube_full-color_icon_%282017%29.svg/640px-YouTube_full-color_icon_%282017%29.svg.png\">&nbsp; Be sure to watch the video below for a quick overview of what we'll be building.\n</blockquote>\n\n<div align=\"center\">\n  <a href=\"https://youtu.be/AWgkt8H8yVo\"><img src=\"https://img.youtube.com/vi/AWgkt8H8yVo/0.jpg\" alt=\"Course overview video\"></a>\n</div>\n\n<br>\n\n- **üí° First principles**: before we jump straight into the code, we develop a first principles understanding for every machine learning concept.\n- **üíª Best practices**: implement software engineering best practices as we develop and deploy our machine learning models.\n- **üìà Scale**: easily scale ML workloads (data, train, tune, serve) in Python without having to learn completely new languages.\n- **‚öôÔ∏è MLOps**: connect MLOps components (tracking, testing, serving, orchestration, etc.) as we build an end-to-end machine learning system.\n- **üöÄ Dev to Prod**: learn how to quickly and reliably go from development to production without any changes to our code or infra management.\n- **üêô CI/CD**: learn how to create mature CI/CD workflows to continuously train and deploy better models in a modular way that integrates with any stack.\n\n## Audience\n\nMachine learning is not a separate industry, instead, it's a powerful way of thinking about data that's not reserved for any one type of person.\n\n- **üë©‚Äçüíª All developers**: whether software/infra engineer or data scientist, ML is increasingly becoming a key part of the products that you'll be developing.\n- **üë©‚Äçüéì College graduates**: learn the practical skills required for industry and bridge gap between the university curriculum and what industry expects.\n- **üë©‚Äçüíº Product/Leadership**: who want to develop a technical foundation so that they can build amazing (and reliable) products powered by machine learning.\n\n## Set up\n\nBe sure to go through the [course](https://madewithml/#course) for a much more detailed walkthrough of the content on this repository. We will have instructions for both local laptop and Anyscale clusters for the sections below, so be sure to toggle the ‚ñ∫ dropdown based on what you're using (Anyscale instructions will be toggled on by default). If you do want to run this course with Anyscale, where we'll provide the **structure**, **compute (GPUs)** and **community** to learn everything in one day, join our next upcoming live cohort ‚Üí [sign up here](https://4190urw86oh.typeform.com/madewithml)!\n\n### Cluster\n\nWe'll start by setting up our cluster with the environment and compute configurations.\n\n<details>\n  <summary>Local</summary><br>\n  Your personal laptop (single machine) will act as the cluster, where one CPU will be the head node and some of the remaining CPU will be the worker nodes. All of the code in this course will work in any personal laptop though it will be slower than executing the same workloads on a larger cluster.\n</details>\n\n<details open>\n  <summary>Anyscale</summary><br>\n\n  We can create an [Anyscale Workspace](https://docs.anyscale.com/develop/workspaces/get-started) using the [webpage UI](https://console.anyscale.com/o/madewithml/workspaces/add/blank).\n\n  ```md\n  - Workspace name: `madewithml`\n  - Project: `madewithml`\n  - Cluster environment name: `madewithml-cluster-env`\n  # Toggle `Select from saved configurations`\n  - Compute config: `madewithml-cluster-compute-g5.4xlarge`\n  ```\n\n  > Alternatively, we can use the [CLI](https://docs.anyscale.com/reference/anyscale-cli) to create the workspace via `anyscale workspace create ...`\n\n</details>\n\n<details>\n  <summary>Other (cloud platforms, K8s, on-prem)</summary><br>\n\n  If you don't want to do this course locally or via Anyscale, you have the following options:\n\n  - On [AWS and GCP](https://docs.ray.io/en/latest/cluster/vms/index.html#cloud-vm-index). Community-supported Azure and Aliyun integrations also exist.\n  - On [Kubernetes](https://docs.ray.io/en/latest/cluster/kubernetes/index.html#kuberay-index), via the officially supported KubeRay project.\n  - Deploy Ray manually [on-prem](https://docs.ray.io/en/latest/cluster/vms/user-guides/launching-clusters/on-premises.html#on-prem) or onto platforms [not listed here](https://docs.ray.io/en/latest/cluster/vms/user-guides/community/index.html#ref-cluster-setup).\n\n</details>\n\n### Git setup\n\nCreate a repository by following these instructions: [Create a new repository](https://github.com/new) ‚Üí name it `Made-With-ML` ‚Üí Toggle `Add a README file` (**very important** as this creates a `main` branch) ‚Üí Click `Create repository` (scroll down)\n\nNow we're ready to clone the repository that has all of our code:\n\n```bash\ngit clone https://github.com/GokuMohandas/Made-With-ML.git .\n```\n\n### Credentials\n\n```bash\ntouch .env\n```\n```bash\n# Inside .env\nGITHUB_USERNAME=\"CHANGE_THIS_TO_YOUR_USERNAME\"  # ‚Üê CHANGE THIS\n```\n```bash\nsource .env\n```\n\n### Virtual environment\n\n<details>\n  <summary>Local</summary><br>\n\n  ```bash\n  export PYTHONPATH=$PYTHONPATH:$PWD\n  python3 -m venv venv  # recommend using Python 3.10\n  source venv/bin/activate  # on Windows: venv\\Scripts\\activate\n  python3 -m pip install --upgrade pip setuptools wheel\n  python3 -m pip install -r requirements.txt\n  pre-commit install\n  pre-commit autoupdate\n  ```\n\n  > Highly recommend using Python `3.10` and using [pyenv](https://github.com/pyenv/pyenv) (mac) or [pyenv-win](https://github.com/pyenv-win/pyenv-win) (windows).\n\n</details>\n\n<details open>\n  <summary>Anyscale</summary><br>\n\n  Our environment with the appropriate Python version and libraries is already all set for us through the cluster environment we used when setting up our Anyscale Workspace. So we just need to run these commands:\n  ```bash\n  export PYTHONPATH=$PYTHONPATH:$PWD\n  pre-commit install\n  pre-commit autoupdate\n  ```\n\n</details>\n\n## Notebook\n\nStart by exploring the [jupyter notebook](notebooks/madewithml.ipynb) to interactively walkthrough the core machine learning workloads.\n\n<div align=\"center\">\n  <img src=\"https://madewithml.com/static/images/mlops/systems-design/workloads.png\">\n</div>\n\n<details>\n  <summary>Local</summary><br>\n\n  ```bash\n  # Start notebook\n  jupyter lab notebooks/madewithml.ipynb\n```\n\n</details>\n\n<details open>\n  <summary>Anyscale</summary><br>\n\n  Click on the Jupyter icon &nbsp;<img width=15 src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Jupyter_logo.svg/1200px-Jupyter_logo.svg.png\">&nbsp; at the top right corner of our Anyscale Workspace page and this will open up our JupyterLab instance in a new tab. Then navigate to the `notebooks` directory and open up the `madewithml.ipynb` notebook.\n\n</details>\n\n\n## Scripts\n\nNow we'll execute the same workloads using the clean Python scripts following software engineering best practices (testing, documentation, logging, serving, versioning, etc.) The code we've implemented in our notebook will be refactored into the following scripts:\n\n```bash\nmadewithml\n‚îú‚îÄ‚îÄ config.py\n‚îú‚îÄ‚îÄ data.py\n‚îú‚îÄ‚îÄ evaluate.py\n‚îú‚îÄ‚îÄ models.py\n‚îú‚îÄ‚îÄ predict.py\n‚îú‚îÄ‚îÄ serve.py\n‚îú‚îÄ‚îÄ train.py\n‚îú‚îÄ‚îÄ tune.py\n‚îî‚îÄ‚îÄ utils.py\n```\n\n**Note**: Change the `--num-workers`, `--cpu-per-worker`, and `--gpu-per-worker` input argument values below based on your system's resources. For example, if you're on a local laptop, a reasonable configuration would be `--num-workers 6 --cpu-per-worker 1 --gpu-per-worker 0`.\n\n### Training\n```bash\nexport EXPERIMENT_NAME=\"llm\"\nexport DATASET_LOC=\"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/dataset.csv\"\nexport TRAIN_LOOP_CONFIG='{\"dropout_p\": 0.5, \"lr\": 1e-4, \"lr_factor\": 0.8, \"lr_patience\": 3}'\npython madewithml/train.py \\\n    --experiment-name \"$EXPERIMENT_NAME\" \\\n    --dataset-loc \"$DATASET_LOC\" \\\n    --train-loop-config \"$TRAIN_LOOP_CONFIG\" \\\n    --num-workers 1 \\\n    --cpu-per-worker 3 \\\n    --gpu-per-worker 1 \\\n    --num-epochs 10 \\\n    --batch-size 256 \\\n    --results-fp results/training_results.json\n```\n\n### Tuning\n```bash\nexport EXPERIMENT_NAME=\"llm\"\nexport DATASET_LOC=\"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/dataset.csv\"\nexport TRAIN_LOOP_CONFIG='{\"dropout_p\": 0.5, \"lr\": 1e-4, \"lr_factor\": 0.8, \"lr_patience\": 3}'\nexport INITIAL_PARAMS=\"[{\\\"train_loop_config\\\": $TRAIN_LOOP_CONFIG}]\"\npython madewithml/tune.py \\\n    --experiment-name \"$EXPERIMENT_NAME\" \\\n    --dataset-loc \"$DATASET_LOC\" \\\n    --initial-params \"$INITIAL_PARAMS\" \\\n    --num-runs 2 \\\n    --num-workers 1 \\\n    --cpu-per-worker 3 \\\n    --gpu-per-worker 1 \\\n    --num-epochs 10 \\\n    --batch-size 256 \\\n    --results-fp results/tuning_results.json\n```\n\n### Experiment tracking\n\nWe'll use [MLflow](https://mlflow.org/) to track our experiments and store our models and the [MLflow Tracking UI](https://www.mlflow.org/docs/latest/tracking.html#tracking-ui) to view our experiments. We have been saving our experiments to a local directory but note that in an actual production setting, we would have a central location to store all of our experiments. It's easy/inexpensive to spin up your own MLflow server for all of your team members to track their experiments on or use a managed solution like [Weights & Biases](https://wandb.ai/site), [Comet](https://www.comet.ml/), etc.\n\n```bash\nexport MODEL_REGISTRY=$(python -c \"from madewithml import config; print(config.MODEL_REGISTRY)\")\nmlflow server -h 0.0.0.0 -p 8080 --backend-store-uri $MODEL_REGISTRY\n```\n\n<details>\n  <summary>Local</summary><br>\n\n  If you're running this notebook on your local laptop then head on over to <a href=\"http://localhost:8080/\" target=\"_blank\">http://localhost:8080/</a> to view your MLflow dashboard.\n\n</details>\n\n<details open>\n  <summary>Anyscale</summary><br>\n\n  If you're on <a href=\"https://docs.anyscale.com/develop/workspaces/get-started\" target=\"_blank\">Anyscale Workspaces</a>, then we need to first expose the port of the MLflow server. Run the following command on your Anyscale Workspace terminal to generate the public URL to your MLflow server.\n\n  ```bash\n  APP_PORT=8080\n  echo https://$APP_PORT-port-$ANYSCALE_SESSION_DOMAIN\n  ```\n\n</details>\n\n### Evaluation\n```bash\nexport EXPERIMENT_NAME=\"llm\"\nexport RUN_ID=$(python madewithml/predict.py get-best-run-id --experiment-name $EXPERIMENT_NAME --metric val_loss --mode ASC)\nexport HOLDOUT_LOC=\"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/holdout.csv\"\npython madewithml/evaluate.py \\\n    --run-id $RUN_ID \\\n    --dataset-loc $HOLDOUT_LOC \\\n    --results-fp results/evaluation_results.json\n```\n```json\n{\n  \"timestamp\": \"June 09, 2023 09:26:18 AM\",\n  \"run_id\": \"6149e3fec8d24f1492d4a4cabd5c06f6\",\n  \"overall\": {\n    \"precision\": 0.9076136428670714,\n    \"recall\": 0.9057591623036649,\n    \"f1\": 0.9046792827719773,\n    \"num_samples\": 191.0\n  },\n...\n```\n\n### Inference\n```bash\nexport EXPERIMENT_NAME=\"llm\"\nexport RUN_ID=$(python madewithml/predict.py get-best-run-id --experiment-name $EXPERIMENT_NAME --metric val_loss --mode ASC)\npython madewithml/predict.py predict \\\n    --run-id $RUN_ID \\\n    --title \"Transfer learning with transformers\" \\\n    --description \"Using transformers for transfer learning on text classification tasks.\"\n```\n```json\n[{\n  \"prediction\": [\n    \"natural-language-processing\"\n  ],\n  \"probabilities\": {\n    \"computer-vision\": 0.0009767753,\n    \"mlops\": 0.0008223939,\n    \"natural-language-processing\": 0.99762577,\n    \"other\": 0.000575123\n  }\n}]\n```\n\n### Serving\n\n<details>\n  <summary>Local</summary><br>\n\n  ```bash\n  # Start\n  ray start --head\n  ```\n\n  ```bash\n  # Set up\n  export EXPERIMENT_NAME=\"llm\"\n  export RUN_ID=$(python madewithml/predict.py get-best-run-id --experiment-name $EXPERIMENT_NAME --metric val_loss --mode ASC)\n  python madewithml/serve.py --run_id $RUN_ID\n  ```\n\n  Once the application is running, we can use it via cURL, Python, etc.:\n\n  ```python\n  # via Python\n  import json\n  import requests\n  title = \"Transfer learning with transformers\"\n  description = \"Using transformers for transfer learning on text classification tasks.\"\n  json_data = json.dumps({\"title\": title, \"description\": description})\n  requests.post(\"http://127.0.0.1:8000/predict\", data=json_data).json()\n  ```\n\n  ```bash\n  ray stop  # shutdown\n  ```\n\n</details>\n\n<details open>\n  <summary>Anyscale</summary><br>\n\n  In Anyscale Workspaces, Ray is already running so we don't have to manually start/shutdown like we have to do locally.\n\n  ```bash\n  # Set up\n  export EXPERIMENT_NAME=\"llm\"\n  export RUN_ID=$(python madewithml/predict.py get-best-run-id --experiment-name $EXPERIMENT_NAME --metric val_loss --mode ASC)\n  python madewithml/serve.py --run_id $RUN_ID\n  ```\n\n  Once the application is running, we can use it via cURL, Python, etc.:\n\n  ```python\n  # via Python\n  import json\n  import requests\n  title = \"Transfer learning with transformers\"\n  description = \"Using transformers for transfer learning on text classification tasks.\"\n  json_data = json.dumps({\"title\": title, \"description\": description})\n  requests.post(\"http://127.0.0.1:8000/predict\", data=json_data).json()\n  ```\n\n</details>\n\n### Testing\n```bash\n# Code\npython3 -m pytest tests/code --verbose --disable-warnings\n\n# Data\nexport DATASET_LOC=\"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/dataset.csv\"\npytest --dataset-loc=$DATASET_LOC tests/data --verbose --disable-warnings\n\n# Model\nexport EXPERIMENT_NAME=\"llm\"\nexport RUN_ID=$(python madewithml/predict.py get-best-run-id --experiment-name $EXPERIMENT_NAME --metric val_loss --mode ASC)\npytest --run-id=$RUN_ID tests/model --verbose --disable-warnings\n\n# Coverage\npython3 -m pytest tests/code --cov madewithml --cov-report html --disable-warnings  # html report\npython3 -m pytest tests/code --cov madewithml --cov-report term --disable-warnings  # terminal report\n```\n\n## Production\n\nFrom this point onwards, in order to deploy our application into production, we'll need to either be on Anyscale or on a [cloud VM](https://docs.ray.io/en/latest/cluster/vms/index.html#cloud-vm-index) / [on-prem](https://docs.ray.io/en/latest/cluster/vms/user-guides/launching-clusters/on-premises.html#on-prem) cluster you manage yourself (w/ Ray). If not on Anyscale, the commands will be [slightly different](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html) but the concepts will be the same.\n\n> If you don't want to set up all of this yourself, we highly recommend joining our [upcoming live cohort](https://4190urw86oh.typeform.com/madewithml){:target=\"_blank\"} where we'll provide an environment with all of this infrastructure already set up for you so that you just focused on the machine learning.\n\n<div align=\"center\">\n  <img src=\"https://madewithml.com/static/images/mlops/jobs_and_services/manual.png\">\n</div>\n\n### Authentication\n\nThese credentials below are **automatically** set for us if we're using Anyscale Workspaces. We **do not** need to set these credentials explicitly on Workspaces but we do if we're running this locally or on a cluster outside of where our Anyscale Jobs and Services are configured to run.\n\n``` bash\nexport ANYSCALE_HOST=https://console.anyscale.com\nexport ANYSCALE_CLI_TOKEN=$YOUR_CLI_TOKEN  # retrieved from Anyscale credentials page\n```\n\n### Cluster environment\n\nThe cluster environment determines **where** our workloads will be executed (OS, dependencies, etc.) We've already created this [cluster environment](./deploy/cluster_env.yaml) for us but this is how we can create/update one ourselves.\n\n```bash\nexport CLUSTER_ENV_NAME=\"madewithml-cluster-env\"\nanyscale cluster-env build deploy/cluster_env.yaml --name $CLUSTER_ENV_NAME\n```\n\n### Compute configuration\n\nThe compute configuration determines **what** resources our workloads will be executes on. We've already created this [compute configuration](./deploy/cluster_compute.yaml) for us but this is how we can create it ourselves.\n\n```bash\nexport CLUSTER_COMPUTE_NAME=\"madewithml-cluster-compute-g5.4xlarge\"\nanyscale cluster-compute create deploy/cluster_compute.yaml --name $CLUSTER_COMPUTE_NAME\n```\n\n### Anyscale jobs\n\nNow we're ready to execute our ML workloads. We've decided to combine them all together into one [job](./deploy/jobs/workloads.yaml) but we could have also created separate jobs for each workload (train, evaluate, etc.) We'll start by editing the `$GITHUB_USERNAME` slots inside our [`workloads.yaml`](./deploy/jobs/workloads.yaml) file:\n```yaml\nruntime_env:\n  working_dir: .\n  upload_path: s3://madewithml/$GITHUB_USERNAME/jobs  # <--- CHANGE USERNAME (case-sensitive)\n  env_vars:\n    GITHUB_USERNAME: $GITHUB_USERNAME  # <--- CHANGE USERNAME (case-sensitive)\n```\n\nThe `runtime_env` here specifies that we should upload our current `working_dir` to an S3 bucket so that all of our workers when we execute an Anyscale Job have access to the code to use. The `GITHUB_USERNAME` is used later to save results from our workloads to S3 so that we can retrieve them later (ex. for serving).\n\nNow we're ready to submit our job to execute our ML workloads:\n```bash\nanyscale job submit deploy/jobs/workloads.yaml\n```\n\n### Anyscale Services\n\nAnd after our ML workloads have been executed, we're ready to launch our serve our model to production. Similar to our Anyscale Jobs configs, be sure to change the `$GITHUB_USERNAME` in [`serve_model.yaml`](./deploy/services/serve_model.yaml).\n\n```yaml\nray_serve_config:\n  import_path: deploy.services.serve_model:entrypoint\n  runtime_env:\n    working_dir: .\n    upload_path: s3://madewithml/$GITHUB_USERNAME/services  # <--- CHANGE USERNAME (case-sensitive)\n    env_vars:\n      GITHUB_USERNAME: $GITHUB_USERNAME  # <--- CHANGE USERNAME (case-sensitive)\n```\n\nNow we're ready to launch our service:\n```bash\n# Rollout service\nanyscale service rollout -f deploy/services/serve_model.yaml\n\n# Query\ncurl -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer $SECRET_TOKEN\" -d '{\n  \"title\": \"Transfer learning with transformers\",\n  \"description\": \"Using transformers for transfer learning on text classification tasks.\"\n}' $SERVICE_ENDPOINT/predict/\n\n# Rollback (to previous version of the Service)\nanyscale service rollback -f $SERVICE_CONFIG --name $SERVICE_NAME\n\n# Terminate\nanyscale service terminate --name $SERVICE_NAME\n```\n\n### CI/CD\n\nWe're not going to manually deploy our application every time we make a change. Instead, we'll automate this process using GitHub Actions!\n\n<div align=\"center\">\n  <img src=\"https://madewithml.com/static/images/mlops/cicd/cicd.png\">\n</div>\n\n1. Create a new github branch to save our changes to and execute CI/CD workloads:\n```bash\ngit remote set-url origin https://github.com/$GITHUB_USERNAME/Made-With-ML.git  # <-- CHANGE THIS to your username\ngit checkout -b dev\n```\n\n2. We'll start by adding the necessary credentials to the [`/settings/secrets/actions`](https://github.com/GokuMohandas/Made-With-ML/settings/secrets/actions) page of our GitHub repository.\n\n``` bash\nexport ANYSCALE_HOST=https://console.anyscale.com\nexport ANYSCALE_CLI_TOKEN=$YOUR_CLI_TOKEN  # retrieved from https://console.anyscale.com/o/madewithml/credentials\n```\n\n3. Now we can make changes to our code (not on `main` branch) and push them to GitHub. But in order to push our code to GitHub, we'll need to first authenticate with our credentials before pushing to our repository:\n\n```bash\ngit config --global user.name $GITHUB_USERNAME  # <-- CHANGE THIS to your username\ngit config --global user.email you@example.com  # <-- CHANGE THIS to your email\ngit add .\ngit commit -m \"\"  # <-- CHANGE THIS to your message\ngit push origin dev\n```\n\nNow you will be prompted to enter your username and password (personal access token). Follow these steps to get personal access token: [New GitHub personal access token](https://github.com/settings/tokens/new) ‚Üí Add a name ‚Üí Toggle `repo` and `workflow` ‚Üí Click `Generate token` (scroll down) ‚Üí Copy the token and paste it when prompted for your password.\n\n4. Now we can start a PR from this branch to our `main` branch and this will trigger the [workloads workflow](/.github/workflows/workloads.yaml). If the workflow (Anyscale Jobs) succeeds, this will produce comments with the training and evaluation results directly on the PR.\n\n<div align=\"center\">\n  <img src=\"https://madewithml.com/static/images/mlops/cicd/comments.png\">\n</div>\n\n5. If we like the results, we can merge the PR into the `main` branch. This will trigger the [serve workflow](/.github/workflows/serve.yaml) which will rollout our new service to production!\n\n### Continual learning\n\nWith our CI/CD workflow in place to deploy our application, we can now focus on continually improving our model. It becomes really easy to extend on this foundation to connect to scheduled runs (cron), [data pipelines](https://madewithml.com/courses/mlops/data-engineering/), drift detected through [monitoring](https://madewithml.com/courses/mlops/monitoring/), [online evaluation](https://madewithml.com/courses/mlops/evaluation/#online-evaluation), etc. And we can easily add additional context such as comparing any experiment with what's currently in production (directly in the PR even), etc.\n\n<div align=\"center\">\n  <img src=\"https://madewithml.com/static/images/mlops/cicd/continual.png\">\n</div>\n\n## FAQ\n\n### Jupyter notebook kernels\n\nIssues with configuring the notebooks with jupyter? By default, jupyter will use the kernel with our virtual environment but we can also manually add it to jupyter:\n```bash\npython3 -m ipykernel install --user --name=venv\n```\nNow we can open up a notebook ‚Üí Kernel (top menu bar) ‚Üí Change Kernel ‚Üí `venv`. To ever delete this kernel, we can do the following:\n```bash\njupyter kernelspec list\njupyter kernelspec uninstall venv\n```\n",
         "AI_DataScience"
        ],
        [
         "12",
         "MDEwOlJlcG9zaXRvcnkzMzg4NDg5MQ==",
         "<!--\n Licensed to the Apache Software Foundation (ASF) under one\n or more contributor license agreements.  See the NOTICE file\n distributed with this work for additional information\n regarding copyright ownership.  The ASF licenses this file\n to you under the Apache License, Version 2.0 (the\n \"License\"); you may not use this file except in compliance\n with the License.  You may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing,\n software distributed under the License is distributed on an\n \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n KIND, either express or implied.  See the License for the\n specific language governing permissions and limitations\n under the License.\n-->\n\n<!-- START Apache Airflow, please keep comment here to allow auto update of PyPI readme.md -->\n# Apache Airflow\n\n| Badges     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n|------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| License    | [![License](https://img.shields.io/:license-Apache%202-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0.txt)                                                                                                                                                                                                                                                                                                                                               |\n| PyPI       | [![PyPI version](https://badge.fury.io/py/apache-airflow.svg)](https://badge.fury.io/py/apache-airflow) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/apache-airflow.svg)](https://pypi.org/project/apache-airflow/) [![PyPI - Downloads](https://img.shields.io/pypi/dm/apache-airflow)](https://pypi.org/project/apache-airflow/)                                                                                                           |\n| Containers | [![Docker Pulls](https://img.shields.io/docker/pulls/apache/airflow.svg)](https://hub.docker.com/r/apache/airflow) [![Docker Stars](https://img.shields.io/docker/stars/apache/airflow.svg)](https://hub.docker.com/r/apache/airflow) [![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/apache-airflow)](https://artifacthub.io/packages/search?repo=apache-airflow)                                                  |\n| Community  | [![Contributors](https://img.shields.io/github/contributors/apache/airflow)](https://github.com/apache/airflow/graphs/contributors) [![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://s.apache.org/airflow-slack) ![Commit Activity](https://img.shields.io/github/commit-activity/m/apache/airflow) [![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=apache-airflow)](https://insights.linuxfoundation.org/project/apache-airflow) |\n\n\n\n| Version | Build Status                                                                                                                                                                                                                                                                                                            |\n|---------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Main    | [![GitHub Build main](https://github.com/apache/airflow/actions/workflows/ci-amd.yml/badge.svg)](https://github.com/apache/airflow/actions) [![GitHub Build main](https://github.com/apache/airflow/actions/workflows/ci-arm.yml/badge.svg)](https://github.com/apache/airflow/actions)                                 |\n| 3.x     | [![GitHub Build 3.1](https://github.com/apache/airflow/actions/workflows/ci-amd.yml/badge.svg?branch=v3-1-test)](https://github.com/apache/airflow/actions) [![GitHub Build 3.1](https://github.com/apache/airflow/actions/workflows/ci-arm.yml/badge.svg?branch=v3-1-test)](https://github.com/apache/airflow/actions) |\n| 2.x     | [![GitHub Build 2.11](https://github.com/apache/airflow/actions/workflows/ci.yml/badge.svg?branch=v2-11-test)](https://github.com/apache/airflow/actions)                                                                                                                                                               |\n\n\n\n<picture width=\"500\">\n  <img\n    src=\"https://github.com/apache/airflow/blob/19ebcac2395ef9a6b6ded3a2faa29dc960c1e635/docs/apache-airflow/img/logos/wordmark_1.png?raw=true\"\n    alt=\"Apache Airflow logo\"\n  />\n</picture>\n\n[Apache Airflow](https://airflow.apache.org/docs/apache-airflow/stable/) (or simply Airflow) is a platform to programmatically author, schedule, and monitor workflows.\n\nWhen workflows are defined as code, they become more maintainable, versionable, testable, and collaborative.\n\nUse Airflow to author workflows (Dags) that orchestrate tasks. The Airflow scheduler executes your tasks on an array of workers while following the specified dependencies. Rich command line utilities make performing complex surgeries on DAGs a snap. The rich user interface makes it easy to visualize pipelines running in production, monitor progress, and troubleshoot issues when needed.\n\n<!-- END Apache Airflow, please keep comment here to allow auto update of PyPI readme.md -->\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n**Table of contents**\n\n- [Project Focus](#project-focus)\n- [Principles](#principles)\n- [Requirements](#requirements)\n- [Getting started](#getting-started)\n- [Installing from PyPI](#installing-from-pypi)\n- [Installation](#installation)\n- [Official source code](#official-source-code)\n- [Convenience packages](#convenience-packages)\n- [User Interface](#user-interface)\n- [Semantic versioning](#semantic-versioning)\n- [Version Life Cycle](#version-life-cycle)\n- [Support for Python and Kubernetes versions](#support-for-python-and-kubernetes-versions)\n- [Base OS support for reference Airflow images](#base-os-support-for-reference-airflow-images)\n- [Approach to dependencies of Airflow](#approach-to-dependencies-of-airflow)\n- [Contributing](#contributing)\n- [Voting Policy](#voting-policy)\n- [Who uses Apache Airflow?](#who-uses-apache-airflow)\n- [Who maintains Apache Airflow?](#who-maintains-apache-airflow)\n- [What goes into the next release?](#what-goes-into-the-next-release)\n- [Can I use the Apache Airflow logo in my presentation?](#can-i-use-the-apache-airflow-logo-in-my-presentation)\n- [Links](#links)\n- [Sponsors](#sponsors)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## Project Focus\n\nAirflow works best with workflows that are mostly static and slowly changing. When the DAG structure is similar from one run to the next, it clarifies the unit of work and continuity. Other similar projects include [Luigi](https://github.com/spotify/luigi), [Oozie](https://oozie.apache.org/) and [Azkaban](https://azkaban.github.io/).\n\nAirflow is commonly used to process data, but has the opinion that tasks should ideally be idempotent (i.e., results of the task will be the same, and will not create duplicated data in a destination system), and should not pass large quantities of data from one task to the next (though tasks can pass metadata using Airflow's [XCom feature](https://airflow.apache.org/docs/apache-airflow/stable/concepts/xcoms.html)). For high-volume, data-intensive tasks, a best practice is to delegate to external services specializing in that type of work.\n\nAirflow is not a streaming solution, but it is often used to process real-time data, pulling data off streams in batches.\n\n## Principles\n\n- **Dynamic**: Pipelines are defined in code, enabling dynamic dag generation and parameterization.\n- **Extensible**: The Airflow framework includes a wide range of built-in operators and can be extended to fit your needs.\n- **Flexible**: Airflow leverages the [**Jinja**](https://jinja.palletsprojects.com) templating engine, allowing rich customizations.\n\n<!-- START Requirements, please keep comment here to allow auto update of PyPI readme.md -->\n## Requirements\n\nApache Airflow is tested with:\n\n|            | Main version (dev)           | Stable version (3.1.0) |\n|------------|------------------------------|------------------------|\n| Python     | 3.10, 3.11, 3.12, 3.13       | 3.9, 3.10, 3.11, 3.12  |\n| Platform   | AMD64/ARM64(\\*)              | AMD64/ARM64(\\*)        |\n| Kubernetes | 1.30, 1.31, 1.32, 1.33, 1.34 | 1.30, 1.31, 1.32, 1.33 |\n| PostgreSQL | 13, 14, 15, 16, 17           | 13, 14, 15, 16, 17     |\n| MySQL      | 8.0, 8.4, Innovation         | 8.0, 8.4, Innovation   |\n| SQLite     | 3.15.0+                      | 3.15.0+                |\n\n\\* Experimental\n\n**Note**: MariaDB is not tested/recommended.\n\n**Note**: SQLite is used in Airflow tests. Do not use it in production. We recommend\nusing the latest stable version of SQLite for local development.\n\n**Note**: Airflow currently can be run on POSIX-compliant Operating Systems. For development, it is regularly\ntested on fairly modern Linux Distros and recent versions of macOS.\nOn Windows you can run it via WSL2 (Windows Subsystem for Linux 2) or via Linux Containers.\nThe work to add Windows support is tracked via [#10388](https://github.com/apache/airflow/issues/10388), but\nit is not a high priority. You should only use Linux-based distros as \"Production\" execution environment\nas this is the only environment that is supported. The only distro that is used in our CI tests and that\nis used in the [Community managed DockerHub image](https://hub.docker.com/p/apache/airflow) is\n`Debian Bookworm`.\n\n<!-- END Requirements, please keep comment here to allow auto update of PyPI readme.md -->\n<!-- START Getting started, please keep comment here to allow auto update of PyPI readme.md -->\n## Getting started\n\nVisit the official Airflow website documentation (latest **stable** release) for help with\n[installing Airflow](https://airflow.apache.org/docs/apache-airflow/stable/installation/),\n[getting started](https://airflow.apache.org/docs/apache-airflow/stable/start.html), or walking\nthrough a more complete [tutorial](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/).\n\n> Note: If you're looking for documentation for the main branch (latest development branch): you can find it on [s.apache.org/airflow-docs](https://s.apache.org/airflow-docs/).\n\nFor more information on Airflow Improvement Proposals (AIPs), visit\nthe [Airflow Wiki](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals).\n\nDocumentation for dependent projects like provider distributions, Docker image, Helm Chart, you'll find it in [the documentation index](https://airflow.apache.org/docs/).\n\n<!-- END Getting started, please keep comment here to allow auto update of PyPI readme.md -->\n<!-- START Installing from PyPI, please keep comment here to allow auto update of PyPI readme.md -->\n\n## Installing from PyPI\n\nWe publish Apache Airflow as `apache-airflow` package in PyPI. Installing it however might be sometimes tricky\nbecause Airflow is a bit of both a library and application. Libraries usually keep their dependencies open, and\napplications usually pin them, but we should do neither and both simultaneously. We decided to keep\nour dependencies as open as possible (in `pyproject.toml`) so users can install different versions of libraries\nif needed. This means that `pip install apache-airflow` will not work from time to time or will\nproduce unusable Airflow installation.\n\nTo have repeatable installation, however, we keep a set of \"known-to-be-working\" constraint\nfiles in the orphan `constraints-main` and `constraints-2-0` branches. We keep those \"known-to-be-working\"\nconstraints files separately per major/minor Python version.\nYou can use them as constraint files when installing Airflow from PyPI. Note that you have to specify\ncorrect Airflow tag/version/branch and Python versions in the URL.\n\n1. Installing just Airflow:\n\n> Note: Only `pip` installation is currently officially supported.\n\nWhile it is possible to install Airflow with tools like [Poetry](https://python-poetry.org) or\n[pip-tools](https://pypi.org/project/pip-tools), they do not share the same workflow as\n`pip` - especially when it comes to constraint vs. requirements management.\nInstalling via `Poetry` or `pip-tools` is not currently supported.\n\nThere are known issues with ``bazel`` that might lead to circular dependencies when using it to install\nAirflow. Please switch to ``pip`` if you encounter such problems. ``Bazel`` community works on fixing\nthe problem in `this PR <https://github.com/bazelbuild/rules_python/pull/1166>`_ so it might be that\nnewer versions of ``bazel`` will handle it.\n\nIf you wish to install Airflow using those tools, you should use the constraint files and convert\nthem to the appropriate format and workflow that your tool requires.\n\n\n```bash\npip install 'apache-airflow==3.1.0' \\\n --constraint \"https://raw.githubusercontent.com/apache/airflow/constraints-3.1.0/constraints-3.10.txt\"\n```\n\n2. Installing with extras (i.e., postgres, google)\n\n```bash\npip install 'apache-airflow[postgres,google]==3.1.0' \\\n --constraint \"https://raw.githubusercontent.com/apache/airflow/constraints-3.1.0/constraints-3.10.txt\"\n```\n\nFor information on installing provider distributions, check\n[providers](http://airflow.apache.org/docs/apache-airflow-providers/index.html).\n\n<!-- END Installing from PyPI, please keep comment here to allow auto update of PyPI readme.md -->\n\n## Installation\n\nFor comprehensive instructions on setting up your local development environment and installing Apache Airflow, please refer to the [INSTALLING.md](INSTALLING.md) file.\n\n<!-- START Official source code, please keep comment here to allow auto update of PyPI readme.md -->\n## Official source code\n\nApache Airflow is an [Apache Software Foundation](https://www.apache.org) (ASF) project,\nand our official source code releases:\n\n- Follow the [ASF Release Policy](https://www.apache.org/legal/release-policy.html)\n- Can be downloaded from [the ASF Distribution Directory](https://downloads.apache.org/airflow)\n- Are cryptographically signed by the release manager\n- Are officially voted on by the PMC members during the\n  [Release Approval Process](https://www.apache.org/legal/release-policy.html#release-approval)\n\nFollowing the ASF rules, the source packages released must be sufficient for a user to build and test the\nrelease provided they have access to the appropriate platform and tools.\n\n<!-- END Official source code, please keep comment here to allow auto update of PyPI readme.md -->\n## Convenience packages\n\nThere are other ways of installing and using Airflow. Those are \"convenience\" methods - they are\nnot \"official releases\" as stated by the `ASF Release Policy`, but they can be used by the users\nwho do not want to build the software themselves.\n\nThose are - in the order of most common ways people install Airflow:\n\n- [PyPI releases](https://pypi.org/project/apache-airflow/) to install Airflow using standard `pip` tool\n- [Docker Images](https://hub.docker.com/r/apache/airflow) to install airflow via\n  `docker` tool, use them in Kubernetes, Helm Charts, `docker-compose`, `docker swarm`, etc. You can\n  read more about using, customizing, and extending the images in the\n  [Latest docs](https://airflow.apache.org/docs/docker-stack/index.html), and\n  learn details on the internals in the [images](https://airflow.apache.org/docs/docker-stack/index.html) document.\n- [Tags in GitHub](https://github.com/apache/airflow/tags) to retrieve the git project sources that\n  were used to generate official source packages via git\n\nAll those artifacts are not official releases, but they are prepared using officially released sources.\nSome of those artifacts are \"development\" or \"pre-release\" ones, and they are clearly marked as such\nfollowing the ASF Policy.\n\n## User Interface\n\n- **DAGs**: Overview of all DAGs in your environment.\n\n  ![DAGs](https://raw.githubusercontent.com/apache/airflow/main/airflow-core/docs/img/ui-dark/dags.png)\n\n- **Assets**: Overview of Assets with dependencies.\n\n  ![Asset Dependencies](https://raw.githubusercontent.com/apache/airflow/main/airflow-core/docs/img/ui-dark/assets_graph.png)\n\n- **Grid**: Grid representation of a DAG that spans across time.\n\n  ![Grid](https://raw.githubusercontent.com/apache/airflow/main/airflow-core/docs/img/ui-dark/grid.png)\n\n- **Graph**: Visualization of a DAG's dependencies and their current status for a specific run.\n\n  ![Graph](https://raw.githubusercontent.com/apache/airflow/main/airflow-core/docs/img/ui-dark/graph.png)\n\n- **Home**: Summary statistics of your Airflow environment.\n\n  ![Home](https://raw.githubusercontent.com/apache/airflow/main/airflow-core/docs/img/ui-dark/home.png)\n\n- **Backfill**: Backfilling a DAG for a specific date range.\n\n  ![Backfill](https://raw.githubusercontent.com/apache/airflow/main/airflow-core/docs/img/ui-dark/backfill.png)\n\n- **Code**: Quick way to view source code of a DAG.\n\n  ![Code](https://raw.githubusercontent.com/apache/airflow/main/airflow-core/docs/img/ui-dark/code.png)\n\n## Semantic versioning\n\nAs of Airflow 2.0.0, we support a strict [SemVer](https://semver.org/) approach for all packages released.\n\nThere are few specific rules that we agreed to that define details of versioning of the different\npackages:\n\n* **Airflow**: SemVer rules apply to core airflow only (excludes any changes to providers).\n  Changing limits for versions of Airflow dependencies is not a breaking change on its own.\n* **Airflow Providers**: SemVer rules apply to changes in the particular provider's code only.\n  SemVer MAJOR and MINOR versions for the packages are independent of the Airflow version.\n  For example, `google 4.1.0` and `amazon 3.1.0` providers can happily be installed\n  with `Airflow 2.1.2`. If there are limits of cross-dependencies between providers and Airflow packages,\n  they are present in providers as `install_requires` limitations. We aim to keep backwards\n  compatibility of providers with all previously released Airflow 2 versions but\n  there will sometimes be breaking changes that might make some, or all\n  providers, have minimum Airflow version specified.\n* **Airflow Helm Chart**: SemVer rules apply to changes in the chart only. SemVer MAJOR and MINOR\n  versions for the chart are independent of the Airflow version. We aim to keep backwards\n  compatibility of the Helm Chart with all released Airflow 2 versions, but some new features might\n  only work starting from specific Airflow releases. We might however limit the Helm\n  Chart to depend on minimal Airflow version.\n* **Airflow API clients**: Their versioning is independent from Airflow versions. They follow their own\n  SemVer rules for breaking changes and new features - which for example allows to change the way we generate\n  the clients.\n\n## Version Life Cycle\n\nApache Airflow version life cycle:\n\n<!-- This table is automatically updated by prek scripts/ci/prek/supported_versions.py -->\n<!-- Beginning of auto-generated table -->\n\n| Version   | Current Patch/Minor   | State     | First Release   | Limited Maintenance   | EOL/Terminated   |\n|-----------|-----------------------|-----------|-----------------|-----------------------|------------------|\n| 3         | 3.1.0                 | Supported | Apr 22, 2025    | TBD                   | TBD              |\n| 2         | 2.11.0                | Supported | Dec 17, 2020    | Oct 22, 2025          | Apr 22, 2026     |\n| 1.10      | 1.10.15               | EOL       | Aug 27, 2018    | Dec 17, 2020          | June 17, 2021    |\n| 1.9       | 1.9.0                 | EOL       | Jan 03, 2018    | Aug 27, 2018          | Aug 27, 2018     |\n| 1.8       | 1.8.2                 | EOL       | Mar 19, 2017    | Jan 03, 2018          | Jan 03, 2018     |\n| 1.7       | 1.7.1.2               | EOL       | Mar 28, 2016    | Mar 19, 2017          | Mar 19, 2017     |\n\n<!-- End of auto-generated table -->\n\nLimited support versions will be supported with security and critical bug fix only.\nEOL versions will not get any fixes nor support.\nWe always recommend that all users run the latest available minor release for whatever major version is in use.\nWe **highly** recommend upgrading to the latest Airflow major release at the earliest convenient time and before the EOL date.\n\n## Support for Python and Kubernetes versions\n\nAs of Airflow 2.0, we agreed to certain rules we follow for Python and Kubernetes support.\nThey are based on the official release schedule of Python and Kubernetes, nicely summarized in the\n[Python Developer's Guide](https://devguide.python.org/#status-of-python-branches) and\n[Kubernetes version skew policy](https://kubernetes.io/docs/setup/release/version-skew-policy/).\n\n1. We drop support for Python and Kubernetes versions when they reach EOL. Except for Kubernetes, a\n   version stays supported by Airflow if two major cloud providers still provide support for it. We drop\n   support for those EOL versions in main right after EOL date, and it is effectively removed when we release\n   the first new MINOR (Or MAJOR if there is no new MINOR version) of Airflow. For example, for Python 3.10 it\n   means that we will drop support in main right after 27.06.2023, and the first MAJOR or MINOR version of\n   Airflow released after will not have it.\n\n2. We support a new version of Python/Kubernetes in main after they are officially released, as soon as we\n   make them work in our CI pipeline (which might not be immediate due to dependencies catching up with\n   new versions of Python mostly) we release new images/support in Airflow based on the working CI setup.\n\n3. This policy is best-effort which means there may be situations where we might terminate support earlier\n   if circumstances require it.\n\n## Base OS support for reference Airflow images\n\nThe Airflow Community provides conveniently packaged container images that are published whenever\nwe publish an Apache Airflow release. Those images contain:\n\n* Base OS with necessary packages to install Airflow (stable Debian OS)\n* Base Python installation in versions supported at the time of release for the MINOR version of\n  Airflow released (so there could be different versions for 2.3 and 2.2 line for example)\n* Libraries required to connect to supported Databases (again the set of databases supported depends\n  on the MINOR version of Airflow)\n* Predefined set of popular providers (for details see the [Dockerfile](https://raw.githubusercontent.com/apache/airflow/main/Dockerfile)).\n* Possibility of building your own, custom image where the user can choose their own set of providers\n  and libraries (see [Building the image](https://airflow.apache.org/docs/docker-stack/build.html))\n* In the future Airflow might also support a \"slim\" version without providers nor database clients installed\n\nThe version of the base OS image is the stable version of Debian. Airflow supports using all currently active\nstable versions - as soon as all Airflow dependencies support building, and we set up the CI pipeline for\nbuilding and testing the OS version. Approximately 6 months before the end-of-regular support of a\nprevious stable version of the OS, Airflow switches the images released to use the latest supported\nversion of the OS.\n\nFor example switch from ``Debian Bullseye`` to ``Debian Bookworm`` has been implemented\nbefore 2.8.0 release in October 2023 and ``Debian Bookworm`` will be the only option supported as of\nAirflow 2.10.0.\n\nUsers will continue to be able to build their images using stable Debian releases until the end of regular\nsupport and building and verifying of the images happens in our CI but no unit tests were executed using\nthis image in the `main` branch.\n\n## Approach to dependencies of Airflow\n\nAirflow has a lot of dependencies - direct and transitive, also Airflow is both - library and application,\ntherefore our policies to dependencies has to include both - stability of installation of application,\nbut also ability to install newer version of dependencies for those users who develop DAGs. We developed\nthe approach where `constraints` are used to make sure airflow can be installed in a repeatable way, while\nwe do not limit our users to upgrade most of the dependencies. As a result we decided not to upper-bound\nversion of Airflow dependencies by default, unless we have good reasons to believe upper-bounding them is\nneeded because of importance of the dependency as well as risk it involves to upgrade specific dependency.\nWe also upper-bound the dependencies that we know cause problems.\n\nThe constraint mechanism of ours takes care about finding and upgrading all the non-upper bound dependencies\nautomatically (providing that all the tests pass). Our `main` build failures will indicate in case there\nare versions of dependencies that break our tests - indicating that we should either upper-bind them or\nthat we should fix our code/tests to account for the upstream changes from those dependencies.\n\nWhenever we upper-bound such a dependency, we should always comment why we are doing it - i.e. we should have\na good reason why dependency is upper-bound. And we should also mention what is the condition to remove the\nbinding.\n\n### Approach for dependencies for Airflow Core\n\nThose dependencies are maintained in ``pyproject.toml``.\n\nThere are few dependencies that we decided are important enough to upper-bound them by default, as they are\nknown to follow predictable versioning scheme, and we know that new versions of those are very likely to\nbring breaking changes. We commit to regularly review and attempt to upgrade to the newer versions of\nthe dependencies as they are released, but this is manual process.\n\nThe important dependencies are:\n\n* `SQLAlchemy`: upper-bound to specific MINOR version (SQLAlchemy is known to remove deprecations and\n   introduce breaking changes especially that support for different Databases varies and changes at\n   various speed)\n* `Alembic`: it is important to handle our migrations in predictable and performant way. It is developed\n   together with SQLAlchemy. Our experience with Alembic is that it very stable in MINOR version\n* `Flask`: We are using Flask as the back-bone of our web UI and API. We know major version of Flask\n   are very likely to introduce breaking changes across those so limiting it to MAJOR version makes sense\n* `werkzeug`: the library is known to cause problems in new versions. It is tightly coupled with Flask\n   libraries, and we should update them together\n* `celery`: Celery is a crucial component of Airflow as it used for CeleryExecutor (and similar). Celery\n   [follows SemVer](https://docs.celeryq.dev/en/stable/contributing.html?highlight=semver#versions), so\n   we should upper-bound it to the next MAJOR version. Also, when we bump the upper version of the library,\n   we should make sure Celery Provider minimum Airflow version is updated.\n* `kubernetes`: Kubernetes is a crucial component of Airflow as it is used for the KubernetesExecutor\n   (and similar). Kubernetes Python library [follows SemVer](https://github.com/kubernetes-client/python#compatibility),\n   so we should upper-bound it to the next MAJOR version. Also, when we bump the upper version of the library,\n   we should make sure Kubernetes Provider minimum Airflow version is updated.\n\n### Approach for dependencies in Airflow Providers and extras\n\nThe main part of the Airflow is the Airflow Core, but the power of Airflow also comes from a number of\nproviders that extend the core functionality and are released separately, even if we keep them (for now)\nin the same monorepo for convenience. You can read more about the providers in the\n[Providers documentation](https://airflow.apache.org/docs/apache-airflow-providers/index.html). We also\nhave set of policies implemented for maintaining and releasing community-managed providers as well\nas the approach for community vs. 3rd party providers in the [providers](https://github.com/apache/airflow/blob/main/PROVIDERS.rst) document.\n\nThose `extras` and `providers` dependencies are maintained in `provider.yaml` of each provider.\n\nBy default, we should not upper-bound dependencies for providers, however each provider's maintainer\nmight decide to add additional limits (and justify them with comment).\n\n<!-- START Contributing, please keep comment here to allow auto update of PyPI readme.md -->\n\n## Contributing\n\nWant to help build Apache Airflow? Check out our [contributors' guide](https://github.com/apache/airflow/blob/main/contributing-docs/README.rst) for a comprehensive overview of how to contribute, including setup instructions, coding standards, and pull request guidelines.\n\nIf you can't wait to contribute, and want to get started asap, check out the [contribution quickstart](https://github.com/apache/airflow/blob/main/contributing-docs/03a_contributors_quick_start_beginners.rst) here!\n\nOfficial Docker (container) images for Apache Airflow are described in [images](https://github.com/apache/airflow/blob/main/dev/breeze/doc/ci/02_images.md).\n\n<!-- END Contributing, please keep comment here to allow auto update of PyPI readme.md -->\n<!-- START Who uses Apache Airflow, please keep comment here to allow auto update of PyPI readme.md -->\n\n## Voting Policy\n\n* Commits need a +1 vote from a committer who is not the author\n* When we do AIP voting, both PMC member's and committer's `+1s` are considered a binding vote.\n\n## Who uses Apache Airflow?\n\nWe know about around 500 organizations that are using Apache Airflow (but there are likely many more)\n[in the wild](https://github.com/apache/airflow/blob/main/INTHEWILD.md).\n\nIf you use Airflow - feel free to make a PR to add your organisation to the list.\n\n<!-- END Who uses Apache Airflow, please keep comment here to allow auto update of PyPI readme.md -->\n<!-- START Who maintains Apache Airflow, please keep comment here to allow auto update of PyPI readme.md -->\n\n## Who maintains Apache Airflow?\n\nAirflow is the work of the [community](https://github.com/apache/airflow/graphs/contributors),\nbut the [core committers/maintainers](https://people.apache.org/committers-by-project.html#airflow)\nare responsible for reviewing and merging PRs as well as steering conversations around new feature requests.\nIf you would like to become a maintainer, please review the Apache Airflow\n[committer requirements](https://github.com/apache/airflow/blob/main/COMMITTERS.rst#guidelines-to-become-an-airflow-committer).\n\n<!-- END Who maintains Apache Airflow, please keep comment here to allow auto update of PyPI readme.md -->\n\n## What goes into the next release?\n\nOften you will see an issue that is assigned to specific milestone with Airflow version, or a PR that gets merged\nto the main branch and you might wonder which release the merged PR(s) will be released in or which release the fixed\nissues will be in. The answer to this is as usual - it depends on various scenarios. The answer is different for PRs and Issues.\n\nTo add a bit of context, we are following the [Semver](https://semver.org/) versioning scheme as described in\n[Airflow release process](https://airflow.apache.org/docs/apache-airflow/stable/release-process.html). More\ndetails are explained in detail in this README under the [Semantic versioning](#semantic-versioning) chapter, but\nin short, we have `MAJOR.MINOR.PATCH` versions of Airflow.\n\n* `MAJOR` version is incremented in case of breaking changes\n* `MINOR` version is incremented when there are new features added\n* `PATCH` version is incremented when there are only bug-fixes and doc-only changes\n\nGenerally we release `MINOR` versions of Airflow from a branch that is named after the MINOR version. For example\n`2.7.*` releases are released from `v2-7-stable` branch, `2.8.*` releases are released from `v2-8-stable`\nbranch, etc.\n\n1. Most of the time in our release cycle, when the branch for next `MINOR` branch is not yet created, all\nPRs merged to `main` (unless they get reverted), will find their way to the next `MINOR` release. For example\nif the last release is `2.7.3` and `v2-8-stable` branch is not created yet, the next `MINOR` release\nis `2.8.0` and all PRs merged to main will be released in `2.8.0`. However, some PRs (bug-fixes and\ndoc-only changes) when merged, can be cherry-picked to current `MINOR` branch and released in the\nnext `PATCHLEVEL` release. For example, if `2.8.1` is already released and we are working on `2.9.0dev`,  then\nmarking a PR with `2.8.2` milestone means that it will be cherry-picked to `v2-8-test` branch and\nreleased in `2.8.2rc1`, and eventually in `2.8.2`.\n\n2. When we prepare for the next `MINOR` release, we cut new `v2-*-test` and `v2-*-stable` branch\nand prepare `alpha`, `beta` releases for the next `MINOR` version, the PRs merged to main will still be\nreleased in the next `MINOR` release until `rc` version is cut. This is happening because the `v2-*-test`\nand `v2-*-stable` branches are rebased on top of main when next `beta` and `rc` releases are prepared.\nFor example, when we cut `2.10.0beta1` version, anything merged to main before `2.10.0rc1` is released,\nwill find its way to 2.10.0rc1.\n\n3. Then, once we prepare the first RC candidate for the MINOR release, we stop moving the `v2-*-test` and\n`v2-*-stable` branches and the PRs merged to main will be released in the next `MINOR` release.\nHowever, some PRs (bug-fixes and doc-only changes) when merged, can be cherry-picked to current `MINOR`\nbranch and released in the next `PATCHLEVEL` release - for example when the last released version from `v2-10-stable`\nbranch is `2.10.0rc1`, some of the PRs from main can be marked as `2.10.0` milestone by committers,\nthe release manager will try to cherry-pick them into the release branch.\nIf successful, they will be released in `2.10.0rc2` and subsequently in `2.10.0`. This also applies to\nsubsequent `PATCHLEVEL` versions. When for example `2.10.1` is already released, marking a PR with\n`2.10.2` milestone will mean that it will be cherry-picked to `v2-10-stable` branch and released in `2.10.2rc1`\nand eventually in `2.10.2`.\n\nThe final decision about cherry-picking is made by the release manager.\n\nMarking issues with a milestone is a bit different. Maintainers do not mark issues with a milestone usually,\nnormally they are only marked in PRs. If PR linked to the issue (and \"fixing it\") gets merged and released\nin a specific version following the process described above, the issue will be automatically closed, no\nmilestone will be set for the issue, you need to check the PR that fixed the issue to see which version\nit was released in.\n\nHowever, sometimes maintainers mark issues with specific milestone, which means that the\nissue is important to become a candidate to take a look when the release is being prepared. Since this is an\nOpen-Source project, where basically all contributors volunteer their time, there is no guarantee that specific\nissue will be fixed in specific version. We do not want to hold the release because some issue is not fixed,\nso in such case release manager will reassign such unfixed issues to the next milestone in case they are not\nfixed in time for the current release. Therefore, the milestone for issue is more of an intent that it should be\nlooked at, than promise it will be fixed in the version.\n\nMore context and **FAQ** about the patchlevel release can be found in the\n[What goes into the next release](dev/WHAT_GOES_INTO_THE_NEXT_RELEASE.md) document in the `dev` folder of the\nrepository.\n\n## Can I use the Apache Airflow logo in my presentation?\n\nYes! Be sure to abide by the Apache Foundation [trademark policies](https://www.apache.org/foundation/marks/#books) and the Apache Airflow [Brandbook](https://cwiki.apache.org/confluence/display/AIRFLOW/Brandbook). The most up-to-date logos are found in [this repo](https://github.com/apache/airflow/tree/main/airflow-core/docs/img/logos/) and on the Apache Software Foundation [website](https://www.apache.org/logos/about.html).\n\n## Links\n\n- [Documentation](https://airflow.apache.org/docs/apache-airflow/stable/)\n- [Chat](https://s.apache.org/airflow-slack)\n- [Community Information](https://airflow.apache.org/community/)\n\n## Sponsors\n\nThe CI infrastructure for Apache Airflow has been sponsored by:\n\n<!-- Ordered by most recently \"funded\" -->\n\n<a href=\"https://astronomer.io\"><img src=\"https://assets2.astronomer.io/logos/logoForLIGHTbackground.png\" alt=\"astronomer.io\" width=\"250px\"></a>\n<a href=\"https://aws.amazon.com/opensource/\"><img src=\"https://github.com/apache/airflow/blob/main/providers/amazon/docs/integration-logos/AWS-Cloud-alt_light-bg@4x.png?raw=true\" alt=\"AWS OpenSource\" width=\"130px\"></a>\n",
         "AI_DataScience"
        ],
        [
         "13",
         "MDEwOlJlcG9zaXRvcnkyMDQwODY4NjI=",
         "<br>\n\n<img src=\"https://user-images.githubusercontent.com/7164864/217935870-c0bc60a3-6fc0-4047-b011-7b4c59488c91.png\" alt=\"Streamlit logo\" style=\"margin-top:50px\"></img>\n\n# Welcome to Streamlit üëã\n\n**A faster way to build and share data apps.**\n\n## What is Streamlit?\n\nStreamlit lets you transform Python scripts into interactive web apps in minutes, instead of weeks. Build dashboards, generate reports, or create chat apps. Once you‚Äôve created an app, you can use our [Community Cloud platform](https://streamlit.io/cloud) to deploy, manage, and share your app.\n\n### Why choose Streamlit?\n\n- **Simple and Pythonic:** Write beautiful, easy-to-read code.\n- **Fast, interactive prototyping:** Let others interact with your data and provide feedback quickly.\n- **Live editing:** See your app update instantly as you edit your script.\n- **Open-source and free:** Join a vibrant community and contribute to Streamlit's future.\n\n## Installation\n\nOpen a terminal and run:\n\n```bash\n$ pip install streamlit\n$ streamlit hello\n```\n\nIf this opens our sweet _Streamlit Hello_ app in your browser, you're all set! If not, head over to [our docs](https://docs.streamlit.io/get-started) for specific installs.\n\nThe app features a bunch of examples of what you can do with Streamlit. Jump to the [quickstart](#quickstart) section to understand how that all works.\n\n<img src=\"https://user-images.githubusercontent.com/7164864/217936487-1017784e-68ec-4e0d-a7f6-6b97525ddf88.gif\" alt=\"Streamlit Hello\" width=500 href=\"none\"></img>\n\n## Quickstart\n\n### A little example\n\nCreate a new file named `streamlit_app.py` in your project directory with the following code:\n```python\nimport streamlit as st\nx = st.slider(\"Select a value\")\nst.write(x, \"squared is\", x * x)\n```\n\nNow run it to open the app!\n```\n$ streamlit run streamlit_app.py\n```\n\n<img src=\"https://user-images.githubusercontent.com/7164864/215172915-cf087c56-e7ae-449a-83a4-b5fa0328d954.gif\" width=300 alt=\"Little example\"></img>\n\n### Give me more!\n\nStreamlit comes in with [a ton of additional powerful elements](https://docs.streamlit.io/develop/api-reference) to spice up your data apps and delight your viewers. Some examples:\n\n<table border=\"0\">\n  <tr>\n    <td>\n      <a target=\"_blank\" href=\"https://docs.streamlit.io/develop/api-reference/widgets\">\n        <img src=\"https://user-images.githubusercontent.com/7164864/217936099-12c16f8c-7fe4-44b1-889a-1ac9ee6a1b44.png\" style=\"max-height:150px; width:auto; display:block;\">\n      </a>\n    </td>\n    <td>\n      <a target=\"_blank\" href=\"https://docs.streamlit.io/develop/api-reference/data/st.dataframe\">\n        <img src=\"https://user-images.githubusercontent.com/7164864/215110064-5eb4e294-8f30-4933-9563-0275230e52b5.gif\" style=\"max-height:150px; width:auto; display:block;\">\n      </a>\n    </td>\n    <td>\n      <a target=\"_blank\" href=\"https://docs.streamlit.io/develop/api-reference/charts\">\n        <img src=\"https://user-images.githubusercontent.com/7164864/215174472-bca8a0d7-cf4b-4268-9c3b-8c03dad50bcd.gif\" style=\"max-height:150px; width:auto; display:block;\">\n      </a>\n    </td>\n    <td>\n      <a target=\"_blank\" href=\"https://docs.streamlit.io/develop/api-reference/layout\">\n        <img src=\"https://user-images.githubusercontent.com/7164864/217936149-a35c35be-0d96-4c63-8c6a-1c4b52aa8f60.png\" style=\"max-height:150px; width:auto; display:block;\">\n      </a>\n    </td>\n    <td>\n      <a target=\"_blank\" href=\"https://docs.streamlit.io/develop/concepts/multipage-apps\">\n        <img src=\"https://user-images.githubusercontent.com/7164864/215173883-eae0de69-7c1d-4d78-97d0-3bc1ab865e5b.gif\" style=\"max-height:150px; width:auto; display:block;\">\n      </a>\n    </td>\n    <td>\n      <a target=\"_blank\" href=\"https://streamlit.io/gallery\">\n        <img src=\"https://user-images.githubusercontent.com/7164864/215109229-6ae9111f-e5c1-4f0b-b3a2-87a79268ccc9.gif\" style=\"max-height:150px; width:auto; display:block;\">\n      </a>\n    </td>\n  </tr>\n  <tr>\n    <td>Input widgets</td>\n    <td>Dataframes</td>\n    <td>Charts</td>\n    <td>Layout</td>\n    <td>Multi-page apps</td>\n    <td>Fun</td>\n  </tr>\n</table>\n\n\nOur vibrant creators community also extends Streamlit capabilities using ¬†üß© [Streamlit Components](https://streamlit.io/components).\n\n## Get inspired\n\nThere's so much you can build with Streamlit:\n- ü§ñ¬†¬†[LLMs & chatbot apps](https://streamlit.io/gallery?category=llms)\n- üß¨¬†¬†[Science & technology apps](https://streamlit.io/gallery?category=science-technology)\n- üí¨¬†¬†[NLP & language apps](https://streamlit.io/gallery?category=nlp-language)\n- üè¶¬†¬†[Finance & business apps](https://streamlit.io/gallery?category=finance-business)\n- üó∫¬†¬†[Geography & society apps](https://streamlit.io/gallery?category=geography-society)\n- and more!\n\n**Check out [our gallery!](https://streamlit.io/gallery)** üéà\n\n## Community Cloud\n\nDeploy, manage and share your apps for free using our [Community Cloud](https://streamlit.io/cloud)! Sign-up [here](https://share.streamlit.io/signup). <br><br>\n<img src=\"https://user-images.githubusercontent.com/7164864/214965336-64500db3-0d79-4a20-8052-2dda883902d2.gif\" width=\"400\"></img>\n\n## Resources\n\n- Explore our [docs](https://docs.streamlit.io) to learn how Streamlit works.\n- Ask questions and get help in our [community forum](https://discuss.streamlit.io).\n- Read our [blog](https://blog.streamlit.io) for tips from developers and creators.\n- Extend Streamlit's capabilities by installing or creating your own [Streamlit Components](https://streamlit.io/components).\n- Help others find and play with your app by using the Streamlit GitHub badge in your repository:\n```markdown\n[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](URL_TO_YOUR_APP)\n```\n[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/streamlit/roadmap)\n\n## Contribute\n\nüéâ Thanks for your interest in helping improve Streamlit! üéâ\n\nBefore contributing, please read our guidelines here: https://github.com/streamlit/streamlit/wiki/Contributing\n\n## License\n\nStreamlit is completely free and open-source and licensed under the [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0) license.\n",
         "AI_DataScience"
        ],
        [
         "14",
         "MDEwOlJlcG9zaXRvcnkxNjI0MDU5NjM=",
         "<!-- DO NOT EDIT THIS FILE DIRECTLY. INSTEAD EDIT THE `readme_template.md` OR `guides/01_getting-started/01_quickstart.md` TEMPLATES AND THEN RUN `render_readme.py` SCRIPT. -->\n\n<div align=\"center\">\n<a href=\"https://gradio.app\">\n<img src=\"readme_files/gradio.svg\" alt=\"gradio\" width=350>\n</a>\n</div>\n\n<div align=\"center\">\n<span>\n<a href=\"https://www.producthunt.com/posts/gradio-5-0?embed=true&utm_source=badge-featured&utm_medium=badge&utm_souce=badge-gradio&#0045;5&#0045;0\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=501906&theme=light\" alt=\"Gradio&#0032;5&#0046;0 - the&#0032;easiest&#0032;way&#0032;to&#0032;build&#0032;AI&#0032;web&#0032;apps | Product Hunt\" style=\"width: 150px; height: 54px;\" width=\"150\" height=\"54\" /></a>\n<a href=\"https://trendshift.io/repositories/2145\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2145\" alt=\"gradio-app%2Fgradio | Trendshift\" style=\"width: 150px; height: 55px;\" width=\"150\" height=\"55\"/></a>\n</span>\n\n[![gradio-backend](https://github.com/gradio-app/gradio/actions/workflows/test-python.yml/badge.svg)](https://github.com/gradio-app/gradio/actions/workflows/test-python.yml)\n[![gradio-ui](https://github.com/gradio-app/gradio/actions/workflows/tests-js.yml/badge.svg)](https://github.com/gradio-app/gradio/actions/workflows/tests-js.yml) \n[![PyPI](https://img.shields.io/pypi/v/gradio)](https://pypi.org/project/gradio/)\n[![PyPI downloads](https://img.shields.io/pypi/dm/gradio)](https://pypi.org/project/gradio/)\n![Python version](https://img.shields.io/badge/python-3.10+-important)\n[![Twitter follow](https://img.shields.io/twitter/follow/gradio?style=social&label=follow)](https://twitter.com/gradio)\n\n[Website](https://gradio.app)\n| [Documentation](https://gradio.app/docs/)\n| [Guides](https://gradio.app/guides/)\n| [Getting Started](https://gradio.app/getting_started/)\n| [Examples](demo/)\n\n</div>\n\n<div align=\"center\">\n\nEnglish | [‰∏≠Êñá](readme_files/zh-cn#readme)\n\n</div>\n\n# Gradio: Build Machine Learning Web Apps ‚Äî in Python\n\n\n\nGradio is an open-source Python package that allows you to quickly **build** a demo or web application for your machine learning model, API, or any arbitrary Python function. You can then **share** a link to your demo or web application in just a few seconds using Gradio's built-in sharing features. *No JavaScript, CSS, or web hosting experience needed!*\n\n<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/gif-version.gif\" style=\"padding-bottom: 10px\">\n\nIt just takes a few lines of Python to create your own demo, so let's get started üí´\n\n\n### Installation\n\n**Prerequisite**: Gradio requires [Python 3.10 or higher](https://www.python.org/downloads/).\n\n\nWe recommend installing Gradio using `pip`, which is included by default in Python. Run this in your terminal or command prompt:\n\n```bash\npip install --upgrade gradio\n```\n\n\n> [!TIP]\n > It is best to install Gradio in a virtual environment. Detailed installation instructions for all common operating systems <a href=\"https://www.gradio.app/main/guides/installing-gradio-in-a-virtual-environment\">are provided here</a>. \n\n### Building Your First Demo\n\nYou can run Gradio in your favorite code editor, Jupyter notebook, Google Colab, or anywhere else you write Python. Let's write your first Gradio app:\n\n\n```python\nimport gradio as gr\n\ndef greet(name, intensity):\n    return \"Hello, \" + name + \"!\" * int(intensity)\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"slider\"],\n    outputs=[\"text\"],\n)\n\ndemo.launch()\n```\n\n\n\n> [!TIP]\n > We shorten the imported name from <code>gradio</code> to <code>gr</code>. This is a widely adopted convention for better readability of code. \n\nNow, run your code. If you've written the Python code in a file named `app.py`, then you would run `python app.py` from the terminal.\n\nThe demo below will open in a browser on [http://localhost:7860](http://localhost:7860) if running from a file. If you are running within a notebook, the demo will appear embedded within the notebook.\n\n![`hello_world_4` demo](demo/hello_world_4/screenshot.gif)\n\nType your name in the textbox on the left, drag the slider, and then press the Submit button. You should see a friendly greeting on the right.\n\n> [!TIP]\n > When developing locally, you can run your Gradio app in <strong>hot reload mode</strong>, which automatically reloads the Gradio app whenever you make changes to the file. To do this, simply type in <code>gradio</code> before the name of the file instead of <code>python</code>. In the example above, you would type: `gradio app.py` in your terminal. You can also enable <strong>vibe mode</strong> by using the <code>--vibe</code> flag, e.g. <code>gradio --vibe app.py</code>, which provides an in-browser chat that can be used to write or edit your Gradio app using natural language. Learn more in the <a href=\"https://www.gradio.app/guides/developing-faster-with-reload-mode\">Hot Reloading Guide</a>.\n\n\n**Understanding the `Interface` Class**\n\nYou'll notice that in order to make your first demo, you created an instance of the `gr.Interface` class. The `Interface` class is designed to create demos for machine learning models which accept one or more inputs, and return one or more outputs. \n\nThe `Interface` class has three core arguments:\n\n- `fn`: the function to wrap a user interface (UI) around\n- `inputs`: the Gradio component(s) to use for the input. The number of components should match the number of arguments in your function.\n- `outputs`: the Gradio component(s) to use for the output. The number of components should match the number of return values from your function.\n\nThe `fn` argument is very flexible -- you can pass *any* Python function that you want to wrap with a UI. In the example above, we saw a relatively simple function, but the function could be anything from a music generator to a tax calculator to the prediction function of a pretrained machine learning model.\n\nThe `inputs` and `outputs` arguments take one or more Gradio components. As we'll see, Gradio includes more than [30 built-in components](https://www.gradio.app/docs/gradio/introduction) (such as the `gr.Textbox()`, `gr.Image()`, and `gr.HTML()` components) that are designed for machine learning applications. \n\n> [!TIP]\n > For the `inputs` and `outputs` arguments, you can pass in the name of these components as a string (`\"textbox\"`) or an instance of the class (`gr.Textbox()`).\n\nIf your function accepts more than one argument, as is the case above, pass a list of input components to `inputs`, with each input component corresponding to one of the arguments of the function, in order. The same holds true if your function returns more than one value: simply pass in a list of components to `outputs`. This flexibility makes the `Interface` class a very powerful way to create demos.\n\nWe'll dive deeper into the `gr.Interface` on our series on [building Interfaces](https://www.gradio.app/main/guides/the-interface-class).\n\n### Sharing Your Demo\n\nWhat good is a beautiful demo if you can't share it? Gradio lets you easily share a machine learning demo without having to worry about the hassle of hosting on a web server. Simply set `share=True` in `launch()`, and a publicly accessible URL will be created for your demo. Let's revisit our example demo,  but change the last line as follows:\n\n```python\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \ndemo.launch(share=True)  # Share your demo with just 1 extra parameter üöÄ\n```\n\nWhen you run this code, a public URL will be generated for your demo in a matter of seconds, something like:\n\nüëâ &nbsp; `https://a23dsf231adb.gradio.live`\n\nNow, anyone around the world can try your Gradio demo from their browser, while the machine learning model and all computation continues to run locally on your computer.\n\nTo learn more about sharing your demo, read our dedicated guide on [sharing your Gradio application](https://www.gradio.app/guides/sharing-your-app).\n\n\n### An Overview of Gradio\n\nSo far, we've been discussing the `Interface` class, which is a high-level class that lets to build demos quickly with Gradio. But what else does Gradio include?\n\n#### Custom Demos with `gr.Blocks`\n\nGradio offers a low-level approach for designing web apps with more customizable layouts and data flows with the `gr.Blocks` class. Blocks supports things like controlling where components appear on the page, handling multiple data flows and more complex interactions (e.g. outputs can serve as inputs to other functions), and updating properties/visibility of components based on user interaction ‚Äî still all in Python. \n\nYou can build very custom and complex applications using `gr.Blocks()`. For example, the popular image generation [Automatic1111 Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) is built using Gradio Blocks. We dive deeper into the `gr.Blocks` on our series on [building with Blocks](https://www.gradio.app/guides/blocks-and-event-listeners).\n\n#### Chatbots with `gr.ChatInterface`\n\nGradio includes another high-level class, `gr.ChatInterface`, which is specifically designed to create Chatbot UIs. Similar to `Interface`, you supply a function and Gradio creates a fully working Chatbot UI. If you're interested in creating a chatbot, you can jump straight to [our dedicated guide on `gr.ChatInterface`](https://www.gradio.app/guides/creating-a-chatbot-fast).\n\n#### The Gradio Python & JavaScript Ecosystem\n\nThat's the gist of the core `gradio` Python library, but Gradio is actually so much more! It's an entire ecosystem of Python and JavaScript libraries that let you build machine learning applications, or query them programmatically, in Python or JavaScript. Here are other related parts of the Gradio ecosystem:\n\n* [Gradio Python Client](https://www.gradio.app/guides/getting-started-with-the-python-client) (`gradio_client`): query any Gradio app programmatically in Python.\n* [Gradio JavaScript Client](https://www.gradio.app/guides/getting-started-with-the-js-client) (`@gradio/client`): query any Gradio app programmatically in JavaScript.\n* [Hugging Face Spaces](https://huggingface.co/spaces): the most popular place to host Gradio applications ‚Äî for free!\n\n### What's Next?\n\nKeep learning about Gradio sequentially using the Gradio Guides, which include explanations as well as example code and embedded interactive demos. Next up: [let's dive deeper into the Interface class](https://www.gradio.app/guides/the-interface-class).\n\nOr, if you already know the basics and are looking for something specific, you can search the more [technical API documentation](https://www.gradio.app/docs/).\n\n\n### Gradio Sketch\n\nYou can also build Gradio applications without writing any code. Simply type `gradio sketch` into your terminal to open up an editor that lets you define and modify Gradio components, adjust their layouts, add events, all through a web editor. Or [use this hosted version of Gradio Sketch, running on Hugging Face Spaces](https://huggingface.co/spaces/aliabid94/Sketch).\n\n## Questions?\n\nIf you'd like to report a bug or have a feature request, please create an [issue on GitHub](https://github.com/gradio-app/gradio/issues/new/choose). For general questions about usage, we are available on [our Discord server](https://discord.com/invite/feTf9x3ZSB) and happy to help.\n\nIf you like Gradio, please leave us a ‚≠ê on GitHub!\n\n## Open Source Stack\n\nGradio is built on top of many wonderful open-source libraries!\n\n[<img src=\"readme_files/huggingface_mini.svg\" alt=\"huggingface\" height=40>](https://huggingface.co)\n[<img src=\"readme_files/python.svg\" alt=\"python\" height=40>](https://www.python.org)\n[<img src=\"readme_files/fastapi.svg\" alt=\"fastapi\" height=40>](https://fastapi.tiangolo.com)\n[<img src=\"readme_files/encode.svg\" alt=\"encode\" height=40>](https://www.encode.io)\n[<img src=\"readme_files/svelte.svg\" alt=\"svelte\" height=40>](https://svelte.dev)\n[<img src=\"readme_files/vite.svg\" alt=\"vite\" height=40>](https://vitejs.dev)\n[<img src=\"readme_files/pnpm.svg\" alt=\"pnpm\" height=40>](https://pnpm.io)\n[<img src=\"readme_files/tailwind.svg\" alt=\"tailwind\" height=40>](https://tailwindcss.com)\n[<img src=\"readme_files/storybook.svg\" alt=\"storybook\" height=40>](https://storybook.js.org/)\n[<img src=\"readme_files/chromatic.svg\" alt=\"chromatic\" height=40>](https://www.chromatic.com/)\n\n## License\n\nGradio is licensed under the Apache License 2.0 found in the [LICENSE](LICENSE) file in the root directory of this repository.\n\n## Citation\n\nAlso check out the paper _[Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild](https://arxiv.org/abs/1906.02569), ICML HILL 2019_, and please cite it if you use Gradio in your work.\n\n```\n@article{abid2019gradio,\n  title = {Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild},\n  author = {Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},\n  journal = {arXiv preprint arXiv:1906.02569},\n  year = {2019},\n}\n```\n",
         "AI_DataScience"
        ],
        [
         "15",
         "R_kgDOIm2Jlg",
         "<h1 align=\"center\">\n    <span>Open-Assistant</span>\n  <img width=\"auto\" height=\"50px\" src=\"https://github.com/LAION-AI/Open-Assistant/blob/main/assets/logo_crop.png\"/>\n</h1>\n\n<blockquote>\n<p>:memo: <strong>NOTE</strong>: OpenAssistant is completed, and the project is now finished. Thank you to everyone who contributed! Check out our <a href=\"https://projects.laion.ai/Open-Assistant/blog/2023/10/25/open-assistant-is-completed\">blog post</a> for more information. The final published oasst2 dataset can be found on HuggingFace at <a href=\"https://huggingface.co/datasets/OpenAssistant/oasst2\">OpenAssistant/oasst2</a></p>\n</blockquote>\n\n<div align=\"center\">\n\n<a href=\"https://github.com/LAION-AI/Open-Assistant/stargazers\">![GitHub Repo stars](https://img.shields.io/github/stars/LAION-AI/Open-Assistant?style=social)</a>\n<a href=\"https://laion-ai.github.io/Open-Assistant/\">![Docs](https://img.shields.io/badge/docs-laion--ai.github.io%2FOpen--Assistant%2F-green)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/build-frontend.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/build-frontend.yaml?label=build-frontend)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/build-postgres.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/build-postgres.yaml?label=build-postgres)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/pre-commit.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/pre-commit.yaml?label=pre-commit)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/test-api-contract.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/test-api-contract.yaml?label=tests-api)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/test-e2e.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/test-e2e.yaml?label=tests-web)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/deploy-docs-site.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/deploy-docs-site.yaml?label=deploy-docs)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/production-deploy.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/production-deploy.yaml?label=deploy-production)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/actions/workflows/release.yaml\">![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/LAION-AI/Open-Assistant/release.yaml?label=deploy-release)</a>\n<a href=\"https://github.com/LAION-AI/Open-Assistant/releases\">![GitHub release (latest by date)](https://img.shields.io/github/v/release/LAION-AI/Open-Assistant)</a>\n<a href=\"https://github-com.translate.goog/LAION-AI/Open-Assistant/blob/main/README.md?_x_tr_sl=auto&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=wapp\">![Translate](https://img.shields.io/badge/Translate-blue)</a>\n\n</div>\n\n# Table of Contents\n\n- [What is Open Assistant?](#what-is-open-assistant)\n- [Useful Links](#useful-links)\n- [How To Try It Out](#how-to-try-it-out)\n- [The Vision](#the-vision)\n- [The Plan](#the-plan)\n- [How You Can Help](#how-you-can-help)\n\n---\n\n## What is Open Assistant?\n\n<p align=\"center\">\nOpen Assistant is a project meant to give everyone access to a great chat based\nlarge language model.\n</p>\n\nWe believe that by doing this we will create a revolution in innovation in\nlanguage. In the same way that stable-diffusion helped the world make art and\nimages in new ways we hope Open Assistant can help improve the world by\nimproving language itself.\n\n# Useful Links\n\n- [Data Collection](https://open-assistant.io)\n\n- [Chat](https://open-assistant.io/chat)\n\n- [Project Documentation](https://projects.laion.ai/Open-Assistant/)\n\n## How To Try It Out\n\n### Chatting with the AI\n\nThe chat frontend is now live [here](https://open-assistant.io/chat). Log in and\nstart chatting! Please try to react with a thumbs up or down for the assistant's\nresponses when chatting.\n\n### Contributing to Data Collection\n\nThe data collection frontend is now live [here](https://open-assistant.io/). Log\nin and start taking on tasks! We want to collect a high volume of quality data.\nBy submitting, ranking, and labelling model prompts and responses you will be\ndirectly helping to improve the capabilities of Open Assistant.\n\n### Running the Development Setup Locally (without chat)\n\n**You do not need to run the project locally unless you are contributing to the\ndevelopment process. The website link above will take you to the public website\nwhere you can use the data collection app and the chat.**\n\nIf you would like to run the data collection app locally for development, you\ncan set up an entire stack needed to run **Open-Assistant**, including the\nwebsite, backend, and associated dependent services, with Docker.\n\nTo start the demo, run this in the root directory of the repository (check\n[this FAQ](https://projects.laion.ai/Open-Assistant/docs/faq#docker-compose-instead-of-docker-compose)\nif you have problems):\n\n```sh\ndocker compose --profile ci up --build --attach-dependencies\n```\n\n> **Note:** when running on MacOS with an M1 chip you have to use:\n> `DB_PLATFORM=linux/x86_64 docker compose ...`\n\nThen, navigate to `http://localhost:3000` (It may take some time to boot up) and\ninteract with the website.\n\n> **Note:** If an issue occurs with the build, please head to the\n> [FAQ](https://projects.laion.ai/Open-Assistant/docs/faq) and check out the\n> entries about Docker.\n\n> **Note:** When logging in via email, navigate to `http://localhost:1080` to\n> get the magic email login link.\n\n> **Note:** If you would like to run this in a standardized development\n> environment (a\n> [\"devcontainer\"](https://code.visualstudio.com/docs/devcontainers/containers))\n> using\n> [vscode locally](https://code.visualstudio.com/docs/devcontainers/create-dev-container#_create-a-devcontainerjson-file)\n> or in a web browser using\n> [GitHub Codespaces](https://github.com/features/codespaces), you can use the\n> provided [`.devcontainer`](.devcontainer/) folder.\n\n### Running the Development Setup Locally for Chat\n\n**You do not need to run the project locally unless you are contributing to the\ndevelopment process. The website link above will take you to the public website\nwhere you can use the data collection app and the chat.**\n\n**Also note that the local setup is only for development and is not meant to be\nused as a local chatbot, unless you know what you are doing.**\n\nIf you _do_ know what you are doing, then see the `inference` folder for getting\nthe inference system up and running, or have a look at `--profile inference` in\naddition to `--profile ci` in the above command.\n\n## The Vision\n\nWe are not going to stop at replicating ChatGPT. We want to build the assistant\nof the future, able to not only write email and cover letters, but do meaningful\nwork, use APIs, dynamically research information, and much more, with the\nability to be personalized and extended by anyone. And we want to do this in a\nway that is open and accessible, which means we must not only build a great\nassistant, but also make it small and efficient enough to run on consumer\nhardware.\n\n## The Plan\n\n##### We want to get to an initial MVP as fast as possible, by following the 3-steps outlined in the [InstructGPT paper](https://arxiv.org/abs/2203.02155)\n\n1. Collect high-quality human generated Instruction-Fulfillment samples\n   (prompt + response), goal >50k. We design a crowdsourced process to collect\n   and reviewed prompts. We do not want to train on\n   flooding/toxic/spam/junk/personal information data. We will have a\n   leaderboard to motivate the community that shows progress and the most active\n   users. Swag will be given to the top-contributors.\n2. For each of the collected prompts we will sample multiple completions.\n   Completions of one prompt will then be shown randomly to users to rank them\n   from best to worst. Again this should happen crowd-sourced, e.g. we need to\n   deal with unreliable potentially malicious users. At least multiple votes by\n   independent users have to be collected to measure the overall agreement. The\n   gathered ranking-data will be used to train a reward model.\n3. Now follows the RLHF training phase based on the prompts and the reward\n   model.\n\nWe can then take the resulting model and continue with completion sampling step\n2 for a next iteration.\n\n### Slide Decks\n\n[Vision & Roadmap](https://docs.google.com/presentation/d/1n7IrAOVOqwdYgiYrXc8Sj0He8krn5MVZO_iLkCjTtu0/edit?usp=sharing)\n\n[Important Data Structures](https://docs.google.com/presentation/d/1iaX_nxasVWlvPiSNs0cllR9L_1neZq0RJxd6MFEalUY/edit?usp=sharing)\n\n## How You Can Help\n\nAll open source projects begin with people like you. Open source is the belief\nthat if we collaborate we can together gift our knowledge and technology to the\nworld for the benefit of humanity.\n\nCheck out our [contributing guide](CONTRIBUTING.md) to get started.\n",
         "AI_DataScience"
        ],
        [
         "16",
         "MDEwOlJlcG9zaXRvcnkxNTE2MTk3MTc=",
         "# Google Research\n\nThis repository contains code released by\n[Google Research](https://research.google).\n\nAll datasets in this repository are released under the CC BY 4.0 International\nlicense, which can be found here:\nhttps://creativecommons.org/licenses/by/4.0/legalcode.  All source files in this\nrepository are released under the Apache 2.0 license, the text of which can be\nfound in the LICENSE file.\n\n---\n\nBecause the repo is large, we recommend you download only the subdirectory of\ninterest:\n\n* Use GitHub editor to open the project. To open the editor change the url from\ngithub.com to github.dev in the address bar.\n* In the left navigation panel, right-click on the folder of interest and select\ndownload.\n\nIf you'd like to submit a pull request, you'll need to clone the repository;\nwe recommend making a shallow clone (without history).\n\n```\ngit clone git@github.com:google-research/google-research.git --depth=1\n```\n\n---\n\n*Disclaimer: This is not an official Google product.*\n\nUpdated in 2023.",
         "AI_DataScience"
        ],
        [
         "17",
         "MDEwOlJlcG9zaXRvcnkxMjc5MTY0Mg==",
         "# Caffe\n\n[![Build Status](https://travis-ci.org/BVLC/caffe.svg?branch=master)](https://travis-ci.org/BVLC/caffe)\n[![License](https://img.shields.io/badge/license-BSD-blue.svg)](LICENSE)\n\nCaffe is a deep learning framework made with expression, speed, and modularity in mind.\nIt is developed by Berkeley AI Research ([BAIR](http://bair.berkeley.edu))/The Berkeley Vision and Learning Center (BVLC) and community contributors.\n\nCheck out the [project site](http://caffe.berkeleyvision.org) for all the details like\n\n- [DIY Deep Learning for Vision with Caffe](https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.p)\n- [Tutorial Documentation](http://caffe.berkeleyvision.org/tutorial/)\n- [BAIR reference models](http://caffe.berkeleyvision.org/model_zoo.html) and the [community model zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo)\n- [Installation instructions](http://caffe.berkeleyvision.org/installation.html)\n\nand step-by-step examples.\n\n## Custom distributions\n\n - [Intel Caffe](https://github.com/BVLC/caffe/tree/intel) (Optimized for CPU and support for multi-node), in particular Intel¬Æ Xeon processors.\n- [OpenCL Caffe](https://github.com/BVLC/caffe/tree/opencl) e.g. for AMD or Intel devices.\n- [Windows Caffe](https://github.com/BVLC/caffe/tree/windows)\n\n## Community\n\n[![Join the chat at https://gitter.im/BVLC/caffe](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/BVLC/caffe?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nPlease join the [caffe-users group](https://groups.google.com/forum/#!forum/caffe-users) or [gitter chat](https://gitter.im/BVLC/caffe) to ask questions and talk about methods and models.\nFramework development discussions and thorough bug reports are collected on [Issues](https://github.com/BVLC/caffe/issues).\n\nHappy brewing!\n\n## License and Citation\n\nCaffe is released under the [BSD 2-Clause license](https://github.com/BVLC/caffe/blob/master/LICENSE).\nThe BAIR/BVLC reference models are released for unrestricted use.\n\nPlease cite Caffe in your publications if it helps your research:\n\n    @article{jia2014caffe,\n      Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},\n      Journal = {arXiv preprint arXiv:1408.5093},\n      Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},\n      Year = {2014}\n    }\n",
         "AI_DataScience"
        ],
        [
         "18",
         "MDEwOlJlcG9zaXRvcnk2MzQ3NzYxMg==",
         "# The Algorithms - C++ # {#mainpage}\n\n<!-- the suffix in the above line is required for doxygen to consider this as the index page of the generated documentation site -->\n\n[![Gitpod Ready-to-Code](https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/TheAlgorithms/C-Plus-Plus)\n[![CodeQL CI](https://github.com/TheAlgorithms/C-Plus-Plus/actions/workflows/codeql.yml/badge.svg)](https://github.com/TheAlgorithms/C-Plus-Plus/actions/workflows/codeql.yml)\n[![Gitter chat](https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&logo=gitter&style=flat-square)](https://gitter.im/TheAlgorithms)\n[![contributions welcome](https://img.shields.io/static/v1.svg?label=Contributions&message=Welcome&color=0059b3&style=flat-square)](https://github.com/TheAlgorithms/C-Plus-Plus/blob/master/CONTRIBUTING.md)\n![GitHub repo size](https://img.shields.io/github/repo-size/TheAlgorithms/C-Plus-Plus?color=red&style=flat-square)\n[![Doxygen CI](https://github.com/TheAlgorithms/C-Plus-Plus/workflows/Doxygen%20CI/badge.svg)](https://TheAlgorithms.github.io/C-Plus-Plus)\n[![Awesome CI](https://github.com/TheAlgorithms/C-Plus-Plus/workflows/Awesome%20CI%20Workflow/badge.svg)](https://github.com/TheAlgorithms/C-Plus-Plus/actions?query=workflow%3A%22Awesome+CI+Workflow%22)\n[![Income](https://img.shields.io/liberapay/receives/TheAlgorithms.svg?logo=liberapay)](https://liberapay.com/TheAlgorithms)\n[![Discord chat](https://img.shields.io/discord/808045925556682782.svg?logo=discord&colorB=5865F2)](https://the-algorithms.com/discord/)\n[![Donate](https://liberapay.com/assets/widgets/donate.svg)](https://liberapay.com/TheAlgorithms/donate)\n\n## Overview\n\nThis repository is a collection of open-source implementation of a variety of algorithms implemented in C++ and licensed under [MIT License](https://github.com/TheAlgorithms/C-Plus-Plus/blob/master/LICENSE). These algorithms span a variety of topics from computer science, mathematics and statistics, data science, machine learning, engineering, etc.. The implementations and the associated documentation are meant to provide a learning resource for educators and students. Hence, one may find more than one implementation for the same objective but using a different algorithm strategies and optimizations.\n\n## Features\n\n- The repository provides implementations of various algorithms in one of the most fundamental general purpose languages - [C++](https://en.wikipedia.org/wiki/C%2B%2B).\n- Well documented source code with detailed explanations provide a valuable resource for educators and students alike.\n- Each source code is atomic using [STL classes](https://en.wikipedia.org/wiki/Standard_Template_Library) and _no external libraries_ are required for their compilation and execution. Thus, the fundamentals of the algorithms can be studied in much depth.\n- Source codes are [compiled and tested](https://github.com/TheAlgorithms/C-Plus-Plus/actions?query=workflow%3A%22Awesome+CI+Workflow%22) for every commit on the latest versions of three major operating systems viz., Windows, MacOS, and Ubuntu (Linux) using MSVC 19 2022, AppleClang 15.0.15, and GNU 13.3.0 respectively.\n- Strict adherence to [C++17](https://en.wikipedia.org/wiki/C%2B%2B17) standard ensures portability of code to embedded systems as well like [ESP32](https://docs.espressif.com/projects/esp-idf/en/stable/esp32/api-guides/cplusplus.html#c-language-standard), [ARM Cortex](https://developer.arm.com/documentation/101458/2404/Standards-support/Supported-C-C---standards-in-Arm-C-C---Compiler), etc. with little to no changes.\n- Self-checks within programs ensure correct implementations with confidence.\n- Modular implementations and OpenSource licensing enable the functions to be utilized conveniently in other applications.\n\n## Documentation\n\n[Online Documentation](https://TheAlgorithms.github.io/C-Plus-Plus) is generated from the repository source codes directly. The documentation contains all resources including source code snippets, details on execution of the programs, diagrammatic representation of program flow, and links to external resources where necessary. The documentation also introduces interactive source code with links to documentation for C++ STL library functions used.\nClick on [Files menu](https://TheAlgorithms.github.io/C-Plus-Plus/files.html) to see the list of all the files documented with the code.\n\n[Documentation of Algorithms in C++](https://thealgorithms.github.io/C-Plus-Plus) by [The Algorithms Contributors](https://github.com/TheAlgorithms/C-Plus-Plus/graphs/contributors) is licensed under [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/?ref=chooser-v1)<br/>\n<a href=\"https://creativecommons.org/licenses/by-sa/4.0\"><img alt=\"Creative Commons License\" style=\"height:22px!important;margin-left: 3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg\" /><img  alt=\"Credit must be given to the creator\" style=\"height:22px!important;margin-left: 3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg\" /><img alt=\"Adaptations must be shared under the same terms\" style=\"height:22px!important;margin-left: 3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg\" /></a>\n\n## Contributions\n\nAs a community developed and maintained repository, we welcome new un-plagiarized quality contributions. Please read our [Contribution Guidelines](https://github.com/TheAlgorithms/C-Plus-Plus/blob/master/CONTRIBUTING.md).\n",
         "AI_DataScience"
        ],
        [
         "19",
         "MDEwOlJlcG9zaXRvcnkyMTQ2NzExMA==",
         "<a href=\"https://explosion.ai\"><img src=\"https://explosion.ai/assets/img/logo.svg\" width=\"125\" height=\"125\" align=\"right\" /></a>\n\n# spaCy: Industrial-strength NLP\n\nspaCy is a library for **advanced Natural Language Processing** in Python and\nCython. It's built on the very latest research, and was designed from day one to\nbe used in real products.\n\nspaCy comes with [pretrained pipelines](https://spacy.io/models) and currently\nsupports tokenization and training for **70+ languages**. It features\nstate-of-the-art speed and **neural network models** for tagging, parsing,\n**named entity recognition**, **text classification** and more, multi-task\nlearning with pretrained **transformers** like BERT, as well as a\nproduction-ready [**training system**](https://spacy.io/usage/training) and easy\nmodel packaging, deployment and workflow management. spaCy is commercial\nopen-source software, released under the\n[MIT license](https://github.com/explosion/spaCy/blob/master/LICENSE).\n\nüí´ **Version 3.8 out now!**\n[Check out the release notes here.](https://github.com/explosion/spaCy/releases)\n\n[![tests](https://github.com/explosion/spaCy/actions/workflows/tests.yml/badge.svg)](https://github.com/explosion/spaCy/actions/workflows/tests.yml)\n[![Current Release Version](https://img.shields.io/github/release/explosion/spacy.svg?style=flat-square&logo=github)](https://github.com/explosion/spaCy/releases)\n[![pypi Version](https://img.shields.io/pypi/v/spacy.svg?style=flat-square&logo=pypi&logoColor=white)](https://pypi.org/project/spacy/)\n[![conda Version](https://img.shields.io/conda/vn/conda-forge/spacy.svg?style=flat-square&logo=conda-forge&logoColor=white)](https://anaconda.org/conda-forge/spacy)\n[![Python wheels](https://img.shields.io/badge/wheels-%E2%9C%93-4c1.svg?longCache=true&style=flat-square&logo=python&logoColor=white)](https://github.com/explosion/wheelwright/releases)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/ambv/black)\n<br />\n[![PyPi downloads](https://static.pepy.tech/personalized-badge/spacy?period=total&units=international_system&left_color=grey&right_color=orange&left_text=pip%20downloads)](https://pypi.org/project/spacy/)\n[![Conda downloads](https://img.shields.io/conda/dn/conda-forge/spacy?label=conda%20downloads)](https://anaconda.org/conda-forge/spacy)\n\n## üìñ Documentation\n\n| Documentation                                                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                              |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| ‚≠êÔ∏è **[spaCy 101]**                                                                                                                                                                                                       | New to spaCy? Here's everything you need to know!                                                                                                                                                                                                                                                                                            |\n| üìö **[Usage Guides]**                                                                                                                                                                                                     | How to use spaCy and its features.                                                                                                                                                                                                                                                                                                           |\n| üöÄ **[New in v3.0]**                                                                                                                                                                                                      | New features, backwards incompatibilities and migration guide.                                                                                                                                                                                                                                                                               |\n| ü™ê **[Project Templates]**                                                                                                                                                                                                | End-to-end workflows you can clone, modify and run.                                                                                                                                                                                                                                                                                          |\n| üéõ **[API Reference]**                                                                                                                                                                                                     | The detailed reference for spaCy's API.                                                                                                                                                                                                                                                                                                      |\n| ‚è© **[GPU Processing]**                                                                                                                                                                                                    | Use spaCy with CUDA-compatible GPU processing.                                                                                                                                                                                                                                                                                               |\n| üì¶ **[Models]**                                                                                                                                                                                                           | Download trained pipelines for spaCy.                                                                                                                                                                                                                                                                                                        |\n| ü¶ô **[Large Language Models]**                                                                                                                                                                                            | Integrate LLMs into spaCy pipelines.                                                                                                                                                                                                                                                                                                        |\n| üåå **[Universe]**                                                                                                                                                                                                         | Plugins, extensions, demos and books from the spaCy ecosystem.                                                                                                                                                                                                                                                                               |\n| ‚öôÔ∏è **[spaCy VS Code Extension]**                                                                                                                                                                                          | Additional tooling and features for working with spaCy's config files.                                                                                                                                                                                                                                                                       |\n| üë©‚Äçüè´ **[Online Course]**                                                                                                                                                                                                    | Learn spaCy in this free and interactive online course.                                                                                                                                                                                                                                                                                      |\n| üì∞ **[Blog]**                                                                                                                                                                                                             | Read about current spaCy and Prodigy development, releases, talks and more from Explosion.                                                                                                                                                                                                                 |\n| üì∫ **[Videos]**                                                                                                                                                                                                           | Our YouTube channel with video tutorials, talks and more.                                                                                                                                                                                                                                                                                    |\n| üî¥ **[Live Stream]**                                                                                                                                                                                                       | Join Matt as he works on spaCy and chat about NLP, live every week.                                                                                                                                                                                                                                                                         |\n| üõ† **[Changelog]**                                                                                                                                                                                                         | Changes and version history.                                                                                                                                                                                                                                                                                                                 |\n| üíù **[Contribute]**                                                                                                                                                                                                       | How to contribute to the spaCy project and code base.                                                                                                                                                                                                                                                                                        |\n| üëï **[Swag]**                                                                                                                                                                                                             | Support us and our work with unique, custom-designed swag!                                                                                                                                                                                                                                                                                   |\n| <a href=\"https://explosion.ai/tailored-solutions\"><img src=\"https://github.com/explosion/spaCy/assets/13643239/36d2a42e-98c0-4599-90e1-788ef75181be\" width=\"150\" alt=\"Tailored Solutions\"/></a> | Custom NLP consulting, implementation and strategic advice by spaCy‚Äôs core development team. Streamlined, production-ready, predictable and maintainable. Send us an email or take our 5-minute questionnaire, and well'be in touch! **[Learn more &rarr;](https://explosion.ai/tailored-solutions)**                 |\n\n[spacy 101]: https://spacy.io/usage/spacy-101\n[new in v3.0]: https://spacy.io/usage/v3\n[usage guides]: https://spacy.io/usage/\n[api reference]: https://spacy.io/api/\n[gpu processing]: https://spacy.io/usage#gpu\n[models]: https://spacy.io/models\n[large language models]: https://spacy.io/usage/large-language-models\n[universe]: https://spacy.io/universe\n[spacy vs code extension]: https://github.com/explosion/spacy-vscode\n[videos]: https://www.youtube.com/c/ExplosionAI\n[live stream]: https://www.youtube.com/playlist?list=PLBmcuObd5An5_iAxNYLJa_xWmNzsYce8c\n[online course]: https://course.spacy.io\n[blog]: https://explosion.ai\n[project templates]: https://github.com/explosion/projects\n[changelog]: https://spacy.io/usage#changelog\n[contribute]: https://github.com/explosion/spaCy/blob/master/CONTRIBUTING.md\n[swag]: https://explosion.ai/merch\n\n## üí¨ Where to ask questions\n\nThe spaCy project is maintained by the [spaCy team](https://explosion.ai/about).\nPlease understand that we won't be able to provide individual support via email.\nWe also believe that help is much more valuable if it's shared publicly, so that\nmore people can benefit from it.\n\n| Type                            | Platforms                               |\n| ------------------------------- | --------------------------------------- |\n| üö® **Bug Reports**              | [GitHub Issue Tracker]                  |\n| üéÅ **Feature Requests & Ideas** | [GitHub Discussions] ¬∑ [Live Stream]    |\n| üë©‚Äçüíª **Usage Questions**          | [GitHub Discussions] ¬∑ [Stack Overflow] |\n| üóØ **General Discussion**        | [GitHub Discussions] ¬∑ [Live Stream]   |\n\n[github issue tracker]: https://github.com/explosion/spaCy/issues\n[github discussions]: https://github.com/explosion/spaCy/discussions\n[stack overflow]: https://stackoverflow.com/questions/tagged/spacy\n[live stream]: https://www.youtube.com/playlist?list=PLBmcuObd5An5_iAxNYLJa_xWmNzsYce8c\n\n## Features\n\n- Support for **70+ languages**\n- **Trained pipelines** for different languages and tasks\n- Multi-task learning with pretrained **transformers** like BERT\n- Support for pretrained **word vectors** and embeddings\n- State-of-the-art speed\n- Production-ready **training system**\n- Linguistically-motivated **tokenization**\n- Components for named **entity recognition**, part-of-speech-tagging,\n  dependency parsing, sentence segmentation, **text classification**,\n  lemmatization, morphological analysis, entity linking and more\n- Easily extensible with **custom components** and attributes\n- Support for custom models in **PyTorch**, **TensorFlow** and other frameworks\n- Built in **visualizers** for syntax and NER\n- Easy **model packaging**, deployment and workflow management\n- Robust, rigorously evaluated accuracy\n\nüìñ **For more details, see the\n[facts, figures and benchmarks](https://spacy.io/usage/facts-figures).**\n\n## ‚è≥ Install spaCy\n\nFor detailed installation instructions, see the\n[documentation](https://spacy.io/usage).\n\n- **Operating system**: macOS / OS X ¬∑ Linux ¬∑ Windows (Cygwin, MinGW, Visual\n  Studio)\n- **Python version**: Python >=3.7, <3.13 (only 64 bit)\n- **Package managers**: [pip] ¬∑ [conda] (via `conda-forge`)\n\n[pip]: https://pypi.org/project/spacy/\n[conda]: https://anaconda.org/conda-forge/spacy\n\n### pip\n\nUsing pip, spaCy releases are available as source packages and binary wheels.\nBefore you install spaCy and its dependencies, make sure that your `pip`,\n`setuptools` and `wheel` are up to date.\n\n```bash\npip install -U pip setuptools wheel\npip install spacy\n```\n\nTo install additional data tables for lemmatization and normalization you can\nrun `pip install spacy[lookups]` or install\n[`spacy-lookups-data`](https://github.com/explosion/spacy-lookups-data)\nseparately. The lookups package is needed to create blank models with\nlemmatization data, and to lemmatize in languages that don't yet come with\npretrained models and aren't powered by third-party libraries.\n\nWhen using pip it is generally recommended to install packages in a virtual\nenvironment to avoid modifying system state:\n\n```bash\npython -m venv .env\nsource .env/bin/activate\npip install -U pip setuptools wheel\npip install spacy\n```\n\n### conda\n\nYou can also install spaCy from `conda` via the `conda-forge` channel. For the\nfeedstock including the build recipe and configuration, check out\n[this repository](https://github.com/conda-forge/spacy-feedstock).\n\n```bash\nconda install -c conda-forge spacy\n```\n\n### Updating spaCy\n\nSome updates to spaCy may require downloading new statistical models. If you're\nrunning spaCy v2.0 or higher, you can use the `validate` command to check if\nyour installed models are compatible and if not, print details on how to update\nthem:\n\n```bash\npip install -U spacy\npython -m spacy validate\n```\n\nIf you've trained your own models, keep in mind that your training and runtime\ninputs must match. After updating spaCy, we recommend **retraining your models**\nwith the new version.\n\nüìñ **For details on upgrading from spaCy 2.x to spaCy 3.x, see the\n[migration guide](https://spacy.io/usage/v3#migrating).**\n\n## üì¶ Download model packages\n\nTrained pipelines for spaCy can be installed as **Python packages**. This means\nthat they're a component of your application, just like any other module. Models\ncan be installed using spaCy's [`download`](https://spacy.io/api/cli#download)\ncommand, or manually by pointing pip to a path or URL.\n\n| Documentation              |                                                                  |\n| -------------------------- | ---------------------------------------------------------------- |\n| **[Available Pipelines]**  | Detailed pipeline descriptions, accuracy figures and benchmarks. |\n| **[Models Documentation]** | Detailed usage and installation instructions.                    |\n| **[Training]**             | How to train your own pipelines on your data.                    |\n\n[available pipelines]: https://spacy.io/models\n[models documentation]: https://spacy.io/usage/models\n[training]: https://spacy.io/usage/training\n\n```bash\n# Download best-matching version of specific model for your spaCy installation\npython -m spacy download en_core_web_sm\n\n# pip install .tar.gz archive or .whl from path or URL\npip install /Users/you/en_core_web_sm-3.0.0.tar.gz\npip install /Users/you/en_core_web_sm-3.0.0-py3-none-any.whl\npip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n```\n\n### Loading and using models\n\nTo load a model, use [`spacy.load()`](https://spacy.io/api/top-level#spacy.load)\nwith the model name or a path to the model data directory.\n\n```python\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"This is a sentence.\")\n```\n\nYou can also `import` a model directly via its full name and then call its\n`load()` method with no arguments.\n\n```python\nimport spacy\nimport en_core_web_sm\n\nnlp = en_core_web_sm.load()\ndoc = nlp(\"This is a sentence.\")\n```\n\nüìñ **For more info and examples, check out the\n[models documentation](https://spacy.io/docs/usage/models).**\n\n## ‚öí Compile from source\n\nThe other way to install spaCy is to clone its\n[GitHub repository](https://github.com/explosion/spaCy) and build it from\nsource. That is the common way if you want to make changes to the code base.\nYou'll need to make sure that you have a development environment consisting of a\nPython distribution including header files, a compiler,\n[pip](https://pip.pypa.io/en/latest/installing/),\n[virtualenv](https://virtualenv.pypa.io/en/latest/) and\n[git](https://git-scm.com) installed. The compiler part is the trickiest. How to\ndo that depends on your system.\n\n| Platform    |                                                                                                                                                                                                                                                                     |\n| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Ubuntu**  | Install system-level dependencies via `apt-get`: `sudo apt-get install build-essential python-dev git` .                                                                                                                                                            |\n| **Mac**     | Install a recent version of [XCode](https://developer.apple.com/xcode/), including the so-called \"Command Line Tools\". macOS and OS X ship with Python and git preinstalled.                                                                                        |\n| **Windows** | Install a version of the [Visual C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/) or [Visual Studio Express](https://visualstudio.microsoft.com/vs/express/) that matches the version that was used to compile your Python interpreter. |\n\nFor more details and instructions, see the documentation on\n[compiling spaCy from source](https://spacy.io/usage#source) and the\n[quickstart widget](https://spacy.io/usage#section-quickstart) to get the right\ncommands for your platform and Python version.\n\n```bash\ngit clone https://github.com/explosion/spaCy\ncd spaCy\n\npython -m venv .env\nsource .env/bin/activate\n\n# make sure you are using the latest pip\npython -m pip install -U pip setuptools wheel\n\npip install -r requirements.txt\npip install --no-build-isolation --editable .\n```\n\nTo install with extras:\n\n```bash\npip install --no-build-isolation --editable .[lookups,cuda102]\n```\n\n## üö¶ Run tests\n\nspaCy comes with an [extensive test suite](spacy/tests). In order to run the\ntests, you'll usually want to clone the repository and build spaCy from source.\nThis will also install the required development dependencies and test utilities\ndefined in the [`requirements.txt`](requirements.txt).\n\nAlternatively, you can run `pytest` on the tests from within the installed\n`spacy` package. Don't forget to also install the test utilities via spaCy's\n[`requirements.txt`](requirements.txt):\n\n```bash\npip install -r requirements.txt\npython -m pytest --pyargs spacy\n```\n",
         "AI_DataScience"
        ],
        [
         "20",
         "MDEwOlJlcG9zaXRvcnkxOTE4MjAxMDA=",
         "---\nlayout: forward\ntarget: https://developers.google.com/mediapipe\ntitle: Home\nnav_order: 1\n---\n\n----\n\n**Attention:** *We have moved to\n[https://developers.google.com/mediapipe](https://developers.google.com/mediapipe)\nas the primary developer documentation site for MediaPipe as of April 3, 2023.*\n\n![MediaPipe](https://developers.google.com/static/mediapipe/images/home/hero_01_1920.png)\n\n**Attention**: MediaPipe Solutions Preview is an early release. [Learn\nmore](https://developers.google.com/mediapipe/solutions/about#notice).\n\n**On-device machine learning for everyone**\n\nDelight your customers with innovative machine learning features. MediaPipe\ncontains everything that you need to customize and deploy to mobile (Android,\niOS), web, desktop, edge devices, and IoT, effortlessly.\n\n*   [See demos](https://goo.gle/mediapipe-studio)\n*   [Learn more](https://developers.google.com/mediapipe/solutions)\n\n## Get started\n\nYou can get started with MediaPipe Solutions by by checking out any of the\ndeveloper guides for\n[vision](https://developers.google.com/mediapipe/solutions/vision/object_detector),\n[text](https://developers.google.com/mediapipe/solutions/text/text_classifier),\nand\n[audio](https://developers.google.com/mediapipe/solutions/audio/audio_classifier)\ntasks. If you need help setting up a development environment for use with\nMediaPipe Tasks, check out the setup guides for\n[Android](https://developers.google.com/mediapipe/solutions/setup_android), [web\napps](https://developers.google.com/mediapipe/solutions/setup_web), and\n[Python](https://developers.google.com/mediapipe/solutions/setup_python).\n\n## Solutions\n\nMediaPipe Solutions provides a suite of libraries and tools for you to quickly\napply artificial intelligence (AI) and machine learning (ML) techniques in your\napplications. You can plug these solutions into your applications immediately,\ncustomize them to your needs, and use them across multiple development\nplatforms. MediaPipe Solutions is part of the MediaPipe [open source\nproject](https://github.com/google/mediapipe), so you can further customize the\nsolutions code to meet your application needs.\n\nThese libraries and resources provide the core functionality for each MediaPipe\nSolution:\n\n*   **MediaPipe Tasks**: Cross-platform APIs and libraries for deploying\n    solutions. [Learn\n    more](https://developers.google.com/mediapipe/solutions/tasks).\n*   **MediaPipe models**: Pre-trained, ready-to-run models for use with each\n    solution.\n\nThese tools let you customize and evaluate solutions:\n\n*   **MediaPipe Model Maker**: Customize models for solutions with your data.\n    [Learn more](https://developers.google.com/mediapipe/solutions/model_maker).\n*   **MediaPipe Studio**: Visualize, evaluate, and benchmark solutions in your\n    browser. [Learn\n    more](https://developers.google.com/mediapipe/solutions/studio).\n\n### Legacy solutions\n\nWe have ended support for [these MediaPipe Legacy Solutions](https://developers.google.com/mediapipe/solutions/guide#legacy)\nas of March 1, 2023. All other MediaPipe Legacy Solutions will be upgraded to\na new MediaPipe Solution. See the [Solutions guide](https://developers.google.com/mediapipe/solutions/guide#legacy)\nfor details. The [code repository](https://github.com/google/mediapipe/tree/master/mediapipe)\nand prebuilt binaries for all MediaPipe Legacy Solutions will continue to be\nprovided on an as-is basis.\n\nFor more on the legacy solutions, see the [documentation](https://github.com/google/mediapipe/tree/master/docs/solutions).\n\n## Framework\n\nTo start using MediaPipe Framework, [install MediaPipe\nFramework](https://developers.google.com/mediapipe/framework/getting_started/install)\nand start building example applications in C++, Android, and iOS.\n\n[MediaPipe Framework](https://developers.google.com/mediapipe/framework) is the\nlow-level component used to build efficient on-device machine learning\npipelines, similar to the premade MediaPipe Solutions.\n\nBefore using MediaPipe Framework, familiarize yourself with the following key\n[Framework\nconcepts](https://developers.google.com/mediapipe/framework/framework_concepts/overview.md):\n\n*   [Packets](https://developers.google.com/mediapipe/framework/framework_concepts/packets.md)\n*   [Graphs](https://developers.google.com/mediapipe/framework/framework_concepts/graphs.md)\n*   [Calculators](https://developers.google.com/mediapipe/framework/framework_concepts/calculators.md)\n\n## Community\n\n*   [Slack community](https://mediapipe.page.link/joinslack) for MediaPipe\n    users.\n*   [Discuss](https://groups.google.com/forum/#!forum/mediapipe) - General\n    community discussion around MediaPipe.\n*   [Awesome MediaPipe](https://mediapipe.page.link/awesome-mediapipe) - A\n    curated list of awesome MediaPipe related frameworks, libraries and\n    software.\n\n## Contributing\n\nWe welcome contributions. Please follow these\n[guidelines](https://github.com/google/mediapipe/blob/master/CONTRIBUTING.md).\n\nWe use GitHub issues for tracking requests and bugs. Please post questions to\nthe MediaPipe Stack Overflow with a `mediapipe` tag.\n\n## Resources\n\n### Publications\n\n*   [Bringing artworks to life with AR](https://developers.googleblog.com/2021/07/bringing-artworks-to-life-with-ar.html)\n    in Google Developers Blog\n*   [Prosthesis control via Mirru App using MediaPipe hand tracking](https://developers.googleblog.com/2021/05/control-your-mirru-prosthesis-with-mediapipe-hand-tracking.html)\n    in Google Developers Blog\n*   [SignAll SDK: Sign language interface using MediaPipe is now available for\n    developers](https://developers.googleblog.com/2021/04/signall-sdk-sign-language-interface-using-mediapipe-now-available.html)\n    in Google Developers Blog\n*   [MediaPipe Holistic - Simultaneous Face, Hand and Pose Prediction, on\n    Device](https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html)\n    in Google AI Blog\n*   [Background Features in Google Meet, Powered by Web ML](https://ai.googleblog.com/2020/10/background-features-in-google-meet.html)\n    in Google AI Blog\n*   [MediaPipe 3D Face Transform](https://developers.googleblog.com/2020/09/mediapipe-3d-face-transform.html)\n    in Google Developers Blog\n*   [Instant Motion Tracking With MediaPipe](https://developers.googleblog.com/2020/08/instant-motion-tracking-with-mediapipe.html)\n    in Google Developers Blog\n*   [BlazePose - On-device Real-time Body Pose Tracking](https://ai.googleblog.com/2020/08/on-device-real-time-body-pose-tracking.html)\n    in Google AI Blog\n*   [MediaPipe Iris: Real-time Eye Tracking and Depth Estimation](https://ai.googleblog.com/2020/08/mediapipe-iris-real-time-iris-tracking.html)\n    in Google AI Blog\n*   [MediaPipe KNIFT: Template-based feature matching](https://developers.googleblog.com/2020/04/mediapipe-knift-template-based-feature-matching.html)\n    in Google Developers Blog\n*   [Alfred Camera: Smart camera features using MediaPipe](https://developers.googleblog.com/2020/03/alfred-camera-smart-camera-features-using-mediapipe.html)\n    in Google Developers Blog\n*   [Real-Time 3D Object Detection on Mobile Devices with MediaPipe](https://ai.googleblog.com/2020/03/real-time-3d-object-detection-on-mobile.html)\n    in Google AI Blog\n*   [AutoFlip: An Open Source Framework for Intelligent Video Reframing](https://ai.googleblog.com/2020/02/autoflip-open-source-framework-for.html)\n    in Google AI Blog\n*   [MediaPipe on the Web](https://developers.googleblog.com/2020/01/mediapipe-on-web.html)\n    in Google Developers Blog\n*   [Object Detection and Tracking using MediaPipe](https://developers.googleblog.com/2019/12/object-detection-and-tracking-using-mediapipe.html)\n    in Google Developers Blog\n*   [On-Device, Real-Time Hand Tracking with MediaPipe](https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html)\n    in Google AI Blog\n*   [MediaPipe: A Framework for Building Perception Pipelines](https://arxiv.org/abs/1906.08172)\n\n### Videos\n\n*   [YouTube Channel](https://www.youtube.com/c/MediaPipe)\n",
         "AI_DataScience"
        ],
        [
         "21",
         "MDEwOlJlcG9zaXRvcnkxMTk4NTM5",
         "<div align=\"center\">\n<img width=\"400px\" height=\"100px\" src=\"https://github.com/lutzroeder/netron/raw/main/.github/logo-light.svg#gh-light-mode-only\">\n<img width=\"400px\" height=\"100px\" src=\"https://github.com/lutzroeder/netron/raw/main/.github/logo-dark.svg#gh-dark-mode-only\">\n</div>\n\nNetron is a viewer for neural network, deep learning and machine learning models.\n\nNetron supports ONNX, TensorFlow Lite, Core ML, Keras, Caffe, Darknet, PyTorch, TensorFlow.js, Safetensors and NumPy.\n\nNetron has experimental support for TorchScript, torch.export, ExecuTorch, TensorFlow, OpenVINO, RKNN, ncnn, MNN, PaddlePaddle, GGUF and scikit-learn.\n\n<p align='center'><a href='https://www.lutzroeder.com/ai'><img src='.github/screenshot.png' width='800'></a></p>\n\n## Install\n\n**Browser**: [**Start**](https://netron.app) the browser version.\n\n**macOS**: [**Download**](https://github.com/lutzroeder/netron/releases/latest) the `.dmg` file or run `brew install --cask netron`.\n\n**Linux**: [**Download**](https://github.com/lutzroeder/netron/releases/latest) the `.deb` or `.rpm` file.\n\n**Windows**: [**Download**](https://github.com/lutzroeder/netron/releases/latest) the `.exe` installer or run `winget install -s winget netron`.\n\n**Python**: `pip install netron`, then run `netron [FILE]` or `netron.start('[FILE]')`.\n\n## Models\n\nSample model files to download or open using the browser version:\n\n * **ONNX**: [squeezenet](https://github.com/onnx/models/raw/main/validated/vision/classification/squeezenet/model/squeezenet1.0-3.onnx) [[open](https://netron.app?url=https://github.com/onnx/models/raw/main/validated/vision/classification/squeezenet/model/squeezenet1.0-3.onnx)]\n * **TorchScript**: [traced_online_pred_layer](https://github.com/ApolloAuto/apollo/raw/master/modules/prediction/data/traced_online_pred_layer.pt) [[open](https://netron.app?url=https://github.com/ApolloAuto/apollo/raw/master/modules/prediction/data/traced_online_pred_layer.pt)]\n * **TensorFlow Lite**: [yamnet](https://huggingface.co/thelou1s/yamnet/resolve/main/lite-model_yamnet_tflite_1.tflite) [[open](https://netron.app?url=https://huggingface.co/thelou1s/yamnet/blob/main/lite-model_yamnet_tflite_1.tflite)]\n * **TensorFlow**: [chessbot](https://github.com/srom/chessbot/raw/master/model/chessbot.pb) [[open](https://netron.app?url=https://github.com/srom/chessbot/raw/master/model/chessbot.pb)]\n * **Keras**: [mobilenet](https://github.com/aio-libs/aiohttp-demos/raw/master/demos/imagetagger/tests/data/mobilenet.h5) [[open](https://netron.app?url=https://github.com/aio-libs/aiohttp-demos/raw/master/demos/imagetagger/tests/data/mobilenet.h5)]\n * **Core ML**: [exermote](https://github.com/Lausbert/Exermote/raw/master/ExermoteInference/ExermoteCoreML/ExermoteCoreML/Model/Exermote.mlmodel) [[open](https://netron.app?url=https://github.com/Lausbert/Exermote/raw/master/ExermoteInference/ExermoteCoreML/ExermoteCoreML/Model/Exermote.mlmodel)]\n * **Darknet**: [yolo](https://github.com/AlexeyAB/darknet/raw/master/cfg/yolo.cfg) [[open](https://netron.app?url=https://github.com/AlexeyAB/darknet/raw/master/cfg/yolo.cfg)]\n",
         "AI_DataScience"
        ],
        [
         "22",
         "MDEwOlJlcG9zaXRvcnkzMjE5NjA0NDc=",
         "# CLIP\n\n[[Blog]](https://openai.com/blog/clip/) [[Paper]](https://arxiv.org/abs/2103.00020) [[Model Card]](model-card.md) [[Colab]](https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb)\n\nCLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs. It can be instructed in natural language to predict the most relevant text snippet, given an image, without directly optimizing for the task, similarly to the zero-shot capabilities of GPT-2 and 3. We found CLIP matches the performance of the original ResNet50 on ImageNet ‚Äúzero-shot‚Äù without using any of the original 1.28M labeled examples, overcoming several major challenges in computer vision.\n\n\n\n## Approach\n\n![CLIP](CLIP.png)\n\n\n\n## Usage\n\nFirst, [install PyTorch 1.7.1](https://pytorch.org/get-started/locally/) (or later) and torchvision, as well as small additional dependencies, and then install this repo as a Python package. On a CUDA GPU machine, the following will do the trick:\n\n```bash\n$ conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n$ pip install ftfy regex tqdm\n$ pip install git+https://github.com/openai/CLIP.git\n```\n\nReplace `cudatoolkit=11.0` above with the appropriate CUDA version on your machine or `cpuonly` when installing on a machine without a GPU.\n\n```python\nimport torch\nimport clip\nfrom PIL import Image\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load(\"ViT-B/32\", device=device)\n\nimage = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).to(device)\ntext = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n\nwith torch.no_grad():\n    image_features = model.encode_image(image)\n    text_features = model.encode_text(text)\n    \n    logits_per_image, logits_per_text = model(image, text)\n    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n\nprint(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]\n```\n\n\n## API\n\nThe CLIP module `clip` provides the following methods:\n\n#### `clip.available_models()`\n\nReturns the names of the available CLIP models.\n\n#### `clip.load(name, device=..., jit=False)`\n\nReturns the model and the TorchVision transform needed by the model, specified by the model name returned by `clip.available_models()`. It will download the model as necessary. The `name` argument can also be a path to a local checkpoint.\n\nThe device to run the model can be optionally specified, and the default is to use the first CUDA device if there is any, otherwise the CPU. When `jit` is `False`, a non-JIT version of the model will be loaded.\n\n#### `clip.tokenize(text: Union[str, List[str]], context_length=77)`\n\nReturns a LongTensor containing tokenized sequences of given text input(s). This can be used as the input to the model\n\n---\n\nThe model returned by `clip.load()` supports the following methods:\n\n#### `model.encode_image(image: Tensor)`\n\nGiven a batch of images, returns the image features encoded by the vision portion of the CLIP model.\n\n#### `model.encode_text(text: Tensor)`\n\nGiven a batch of text tokens, returns the text features encoded by the language portion of the CLIP model.\n\n#### `model(image: Tensor, text: Tensor)`\n\nGiven a batch of images and a batch of text tokens, returns two Tensors, containing the logit scores corresponding to each image and text input. The values are cosine similarities between the corresponding image and text features, times 100.\n\n\n\n## More Examples\n\n### Zero-Shot Prediction\n\nThe code below performs zero-shot prediction using CLIP, as shown in Appendix B in the paper. This example takes an image from the [CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), and predicts the most likely labels among the 100 textual labels from the dataset.\n\n```python\nimport os\nimport clip\nimport torch\nfrom torchvision.datasets import CIFAR100\n\n# Load the model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load('ViT-B/32', device)\n\n# Download the dataset\ncifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n\n# Prepare the inputs\nimage, class_id = cifar100[3637]\nimage_input = preprocess(image).unsqueeze(0).to(device)\ntext_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n\n# Calculate features\nwith torch.no_grad():\n    image_features = model.encode_image(image_input)\n    text_features = model.encode_text(text_inputs)\n\n# Pick the top 5 most similar labels for the image\nimage_features /= image_features.norm(dim=-1, keepdim=True)\ntext_features /= text_features.norm(dim=-1, keepdim=True)\nsimilarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\nvalues, indices = similarity[0].topk(5)\n\n# Print the result\nprint(\"\\nTop predictions:\\n\")\nfor value, index in zip(values, indices):\n    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")\n```\n\nThe output will look like the following (the exact numbers may be slightly different depending on the compute device):\n\n```\nTop predictions:\n\n           snake: 65.31%\n          turtle: 12.29%\n    sweet_pepper: 3.83%\n          lizard: 1.88%\n       crocodile: 1.75%\n```\n\nNote that this example uses the `encode_image()` and `encode_text()` methods that return the encoded features of given inputs.\n\n\n### Linear-probe evaluation\n\nThe example below uses [scikit-learn](https://scikit-learn.org/) to perform logistic regression on image features.\n\n```python\nimport os\nimport clip\nimport torch\n\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import CIFAR100\nfrom tqdm import tqdm\n\n# Load the model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load('ViT-B/32', device)\n\n# Load the dataset\nroot = os.path.expanduser(\"~/.cache\")\ntrain = CIFAR100(root, download=True, train=True, transform=preprocess)\ntest = CIFAR100(root, download=True, train=False, transform=preprocess)\n\n\ndef get_features(dataset):\n    all_features = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(DataLoader(dataset, batch_size=100)):\n            features = model.encode_image(images.to(device))\n\n            all_features.append(features)\n            all_labels.append(labels)\n\n    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n\n# Calculate the image features\ntrain_features, train_labels = get_features(train)\ntest_features, test_labels = get_features(test)\n\n# Perform logistic regression\nclassifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\nclassifier.fit(train_features, train_labels)\n\n# Evaluate using the logistic regression classifier\npredictions = classifier.predict(test_features)\naccuracy = np.mean((test_labels == predictions).astype(float)) * 100.\nprint(f\"Accuracy = {accuracy:.3f}\")\n```\n\nNote that the `C` value should be determined via a hyperparameter sweep using a validation split.\n\n\n## See Also\n\n* [OpenCLIP](https://github.com/mlfoundations/open_clip): includes larger and independently trained CLIP models up to ViT-G/14\n* [Hugging Face implementation of CLIP](https://huggingface.co/docs/transformers/model_doc/clip): for easier integration with the HF ecosystem\n",
         "AI_DataScience"
        ],
        [
         "23",
         "MDEwOlJlcG9zaXRvcnkxNzg2MjY3MjA=",
         "<div align=\"center\">\n\n<img alt=\"Lightning\" src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/ptl_banner.png\" width=\"800px\" style=\"max-width: 100%;\">\n\n<br/>\n<br/>\n\n**The deep learning framework to pretrain, finetune and deploy AI models.**\n\n**NEW- Deploying models? Check out [LitServe](https://github.com/Lightning-AI/litserve), the PyTorch Lightning for model serving**\n\n______________________________________________________________________\n\n<p align=\"center\">\n    <a href=\"#quick-start\" style=\"margin: 0 10px;\">Quick start</a> ‚Ä¢\n  <a href=\"#examples\">Examples</a> ‚Ä¢\n  <a href=\"#why-pytorch-lightning\">PyTorch Lightning</a> ‚Ä¢\n  <a href=\"#lightning-fabric-expert-control\">Fabric</a> ‚Ä¢\n  <a href=\"https://lightning.ai/\">Lightning AI</a> ‚Ä¢   \n  <a href=\"#community\">Community</a> ‚Ä¢\n  <a href=\"https://pytorch-lightning.readthedocs.io/en/stable/\">Docs</a>\n</p>\n\n<!-- DO NOT ADD CONDA DOWNLOADS... README CHANGES MUST BE APPROVED BY EDEN OR WILL -->\n\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pytorch-lightning)](https://pypi.org/project/pytorch-lightning/)\n[![PyPI Status](https://badge.fury.io/py/pytorch-lightning.svg)](https://badge.fury.io/py/pytorch-lightning)\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/pytorch-lightning)](https://pepy.tech/project/pytorch-lightning)\n[![Conda](https://img.shields.io/conda/v/conda-forge/lightning?label=conda&color=success)](https://anaconda.org/conda-forge/lightning)\n[![codecov](https://codecov.io/gh/Lightning-AI/pytorch-lightning/graph/badge.svg?token=SmzX8mnKlA)](https://codecov.io/gh/Lightning-AI/pytorch-lightning)\n\n[![Discord](https://img.shields.io/discord/1077906959069626439?style=plastic)](https://discord.gg/VptPCZkGNa)\n![GitHub commit activity](https://img.shields.io/github/commit-activity/w/lightning-ai/lightning)\n[![license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/Lightning-AI/pytorch-lightning/blob/master/LICENSE)\n\n<!--\n[![CodeFactor](https://www.codefactor.io/repository/github/Lightning-AI/lightning/badge)](https://www.codefactor.io/repository/github/Lightning-AI/lightning)\n-->\n\n</div>\n\n<div align=\"center\">\n  \n<p align=\"center\">\n\n&nbsp;\n  \n<a target=\"_blank\" href=\"https://lightning.ai/docs/pytorch/latest/starter/introduction.html#define-a-lightningmodule\">\n  <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/get-started-badge.svg\" height=\"36px\" alt=\"Get started\"/>\n</a>\n\n</p>\n\n</div>\n\n&nbsp;\n\n# Why PyTorch Lightning?   \n\nTraining models in plain PyTorch is tedious and error-prone - you have to manually handle things like backprop, mixed precision, multi-GPU, and distributed training, often rewriting code for every new project. PyTorch Lightning organizes PyTorch code to automate those complexities so you can focus on your model and data, while keeping full control and scaling from CPU to multi-node without changing your core code. But if you want control of those things, you can still opt into more DIY.   \n\nFun analogy: If PyTorch is Javascript, PyTorch Lightning is ReactJS or NextJS.\n\n# Lightning has 2 core packages\n\n[PyTorch Lightning: Train and deploy PyTorch at scale](#why-pytorch-lightning).\n<br/>\n[Lightning Fabric: Expert control](#lightning-fabric-expert-control).\n\nLightning gives you granular control over how much abstraction you want to add over PyTorch.\n\n<div align=\"center\">\n    <img src=\"https://pl-public-data.s3.amazonaws.com/assets_lightning/continuum.png\" width=\"80%\">\n</div>\n\n&nbsp;\n\n# Quick start\nInstall Lightning:\n\n```bash\npip install lightning\n```\n\n<!-- following section will be skipped from PyPI description -->\n\n<details>\n  <summary>Advanced install options</summary>\n    <!-- following section will be skipped from PyPI description -->\n\n#### Install with optional dependencies\n\n```bash\npip install lightning['extra']\n```\n\n#### Conda\n\n```bash\nconda install lightning -c conda-forge\n```\n\n#### Install stable version\n\nInstall future release from the source\n\n```bash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/release/stable.zip -U\n```\n\n#### Install bleeding-edge\n\nInstall nightly from the source (no guarantees)\n\n```bash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/master.zip -U\n```\n\nor from testing PyPI\n\n```bash\npip install -iU https://test.pypi.org/simple/ pytorch-lightning\n```\n\n</details>\n<!-- end skipping PyPI description -->\n\n### PyTorch Lightning example\nDefine the training workflow. Here's a toy example ([explore real examples](https://lightning.ai/lightning-ai/studios?view=public&section=featured&query=pytorch+lightning)):\n\n```python\n# main.py\n# ! pip install torchvision\nimport torch, torch.nn as nn, torch.utils.data as data, torchvision as tv, torch.nn.functional as F\nimport lightning as L\n\n# --------------------------------\n# Step 1: Define a LightningModule\n# --------------------------------\n# A LightningModule (nn.Module subclass) defines a full *system*\n# (ie: an LLM, diffusion model, autoencoder, or simple image classifier).\n\n\nclass LitAutoEncoder(L.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))\n        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))\n\n    def forward(self, x):\n        # in lightning, forward defines the prediction/inference actions\n        embedding = self.encoder(x)\n        return embedding\n\n    def training_step(self, batch, batch_idx):\n        # training_step defines the train loop. It is independent of forward\n        x, _ = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer\n\n\n# -------------------\n# Step 2: Define data\n# -------------------\ndataset = tv.datasets.MNIST(\".\", download=True, transform=tv.transforms.ToTensor())\ntrain, val = data.random_split(dataset, [55000, 5000])\n\n# -------------------\n# Step 3: Train\n# -------------------\nautoencoder = LitAutoEncoder()\ntrainer = L.Trainer()\ntrainer.fit(autoencoder, data.DataLoader(train), data.DataLoader(val))\n```\n\nRun the model on your terminal\n\n```bash\npip install torchvision\npython main.py\n```\n\n&nbsp;\n\n\n# Why PyTorch Lightning?\n\nPyTorch Lightning is just organized PyTorch - Lightning disentangles PyTorch code to decouple the science from the engineering.\n\n![PT to PL](docs/source-pytorch/_static/images/general/pl_quick_start_full_compressed.gif)\n\n&nbsp;\n\n----\n\n### Examples\nExplore various types of training possible with PyTorch Lightning. Pretrain and finetune ANY kind of model to perform ANY task like classification, segmentation, summarization and more:    \n\n| Task                                                                                                        | Description                                                    | Run |\n|-------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------|---|\n| [Hello world](#hello-simple-model)                                                                          | Pretrain - Hello world example                                 | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/pytorch-lightning-hello-world\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |\n| [Image classification](https://lightning.ai/lightning-ai/studios/image-classification-with-pytorch-lightning) | Finetune - ResNet-34 model to classify images of cars          | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/image-classification-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Image segmentation](https://lightning.ai/lightning-ai/studios/image-segmentation-with-pytorch-lightning)   | Finetune - ResNet-50 model to segment images                   | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/image-segmentation-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Object detection](https://lightning.ai/lightning-ai/studios/object-detection-with-pytorch-lightning)       | Finetune - Faster R-CNN model to detect objects                   | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/object-detection-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |\n| [Text classification](https://lightning.ai/lightning-ai/studios/text-classification-with-pytorch-lightning) | Finetune - text classifier (BERT model)                        | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/text-classification-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Text summarization](https://lightning.ai/lightning-ai/studios/text-summarization-with-pytorch-lightning)   | Finetune - text summarization (Hugging Face transformer model) | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/text-summarization-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Audio generation](https://lightning.ai/lightning-ai/studios/finetune-a-personal-ai-music-generator)        | Finetune - audio generator (transformer model)                 | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/finetune-a-personal-ai-music-generator\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [LLM finetuning](https://lightning.ai/lightning-ai/studios/finetune-an-llm-with-pytorch-lightning)          | Finetune - LLM (Meta Llama 3.1 8B)                | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/finetune-an-llm-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n| [Image generation](https://lightning.ai/lightning-ai/studios/train-a-diffusion-model-with-pytorch-lightning)          | Pretrain - Image generator (diffusion model)                | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/train-a-diffusion-model-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n| [Recommendation system](https://lightning.ai/lightning-ai/studios/recommendation-system-with-pytorch-lightning)  | Train - recommendation system (factorization and embedding)    | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/recommendation-system-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n| [Time-series forecasting](https://lightning.ai/lightning-ai/studios/time-series-forecasting-with-pytorch-lightning) | Train - Time-series forecasting with LSTM               | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/time-series-forecasting-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n\n______________________________________________________________________\n\n## Advanced features\n\nLightning has over [40+ advanced features](https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-flags) designed for professional AI research at scale.\n\nHere are some examples:\n\n<div align=\"center\">\n    <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/features_2.jpg\" max-height=\"600px\">\n  </div>\n\n<details>\n  <summary>Train on 1000s of GPUs without code changes</summary>\n\n```python\n# 8 GPUs\n# no code changes needed\ntrainer = Trainer(accelerator=\"gpu\", devices=8)\n\n# 256 GPUs\ntrainer = Trainer(accelerator=\"gpu\", devices=8, num_nodes=32)\n```\n\n</details>\n\n<details>\n  <summary>Train on other accelerators like TPUs without code changes</summary>\n\n```python\n# no code changes needed\ntrainer = Trainer(accelerator=\"tpu\", devices=8)\n```\n\n</details>\n\n<details>\n  <summary>16-bit precision</summary>\n\n```python\n# no code changes needed\ntrainer = Trainer(precision=16)\n```\n\n</details>\n\n<details>\n  <summary>Experiment managers</summary>\n\n```python\nfrom lightning import loggers\n\n# tensorboard\ntrainer = Trainer(logger=TensorBoardLogger(\"logs/\"))\n\n# weights and biases\ntrainer = Trainer(logger=loggers.WandbLogger())\n\n# comet\ntrainer = Trainer(logger=loggers.CometLogger())\n\n# mlflow\ntrainer = Trainer(logger=loggers.MLFlowLogger())\n\n# neptune\ntrainer = Trainer(logger=loggers.NeptuneLogger())\n\n# ... and dozens more\n```\n\n</details>\n\n<details>\n\n<summary>Early Stopping</summary>\n\n```python\nes = EarlyStopping(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[es])\n```\n\n</details>\n\n<details>\n  <summary>Checkpointing</summary>\n\n```python\ncheckpointing = ModelCheckpoint(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[checkpointing])\n```\n\n</details>\n\n<details>\n  <summary>Export to torchscript (JIT) (production use)</summary>\n\n```python\n# torchscript\nautoencoder = LitAutoEncoder()\ntorch.jit.save(autoencoder.to_torchscript(), \"model.pt\")\n```\n\n</details>\n\n<details>\n  <summary>Export to ONNX (production use)</summary>\n\n```python\n# onnx\nwith tempfile.NamedTemporaryFile(suffix=\".onnx\", delete=False) as tmpfile:\n    autoencoder = LitAutoEncoder()\n    input_sample = torch.randn((1, 64))\n    autoencoder.to_onnx(tmpfile.name, input_sample, export_params=True)\n    os.path.isfile(tmpfile.name)\n```\n\n</details>\n\n______________________________________________________________________\n\n## Advantages over unstructured PyTorch\n\n- Models become hardware agnostic\n- Code is clear to read because engineering code is abstracted away\n- Easier to reproduce\n- Make fewer mistakes because lightning handles the tricky engineering\n- Keeps all the flexibility (LightningModules are still PyTorch modules), but removes a ton of boilerplate\n- Lightning has dozens of integrations with popular machine learning tools.\n- [Tested rigorously with every new PR](https://github.com/Lightning-AI/lightning/tree/master/tests). We test every combination of PyTorch and Python supported versions, every OS, multi GPUs and even TPUs.\n- Minimal running speed overhead (about 300 ms per epoch compared with pure PyTorch).\n\n______________________________________________________________________\n\n<div align=\"center\">\n    <a href=\"https://lightning.ai/docs/pytorch/stable/\">Read the PyTorch Lightning docs</a>\n</div>\n\n______________________________________________________________________\n\n&nbsp;\n&nbsp;\n\n# Lightning Fabric: Expert control\n\nRun on any device at any scale with expert-level control over PyTorch training loop and scaling strategy. You can even write your own Trainer.\n\nFabric is designed for the most complex models like foundation model scaling, LLMs, diffusion, transformers, reinforcement learning, active learning. Of any size.\n\n<table>\n<tr>\n<th>What to change</th>\n<th>Resulting Fabric Code (copy me!)</th>\n</tr>\n<tr>\n<td>\n<sub>\n\n```diff\n+ import lightning as L\n  import torch; import torchvision as tv\n\n dataset = tv.datasets.CIFAR10(\"data\", download=True,\n                               train=True,\n                               transform=tv.transforms.ToTensor())\n\n+ fabric = L.Fabric()\n+ fabric.launch()\n\n  model = tv.models.resnet18()\n  optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n- device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n- model.to(device)\n+ model, optimizer = fabric.setup(model, optimizer)\n\n  dataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\n+ dataloader = fabric.setup_dataloaders(dataloader)\n\n  model.train()\n  num_epochs = 10\n  for epoch in range(num_epochs):\n      for batch in dataloader:\n          inputs, labels = batch\n-         inputs, labels = inputs.to(device), labels.to(device)\n          optimizer.zero_grad()\n          outputs = model(inputs)\n          loss = torch.nn.functional.cross_entropy(outputs, labels)\n-         loss.backward()\n+         fabric.backward(loss)\n          optimizer.step()\n          print(loss.data)\n```\n\n</sub>\n<td>\n<sub>\n\n```Python\nimport lightning as L\nimport torch; import torchvision as tv\n\ndataset = tv.datasets.CIFAR10(\"data\", download=True,\n                              train=True,\n                              transform=tv.transforms.ToTensor())\n\nfabric = L.Fabric()\nfabric.launch()\n\nmodel = tv.models.resnet18()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001)\nmodel, optimizer = fabric.setup(model, optimizer)\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\ndataloader = fabric.setup_dataloaders(dataloader)\n\nmodel.train()\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for batch in dataloader:\n        inputs, labels = batch\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        fabric.backward(loss)\n        optimizer.step()\n        print(loss.data)\n```\n\n</sub>\n</td>\n</tr>\n</table>\n\n## Key features\n\n<details>\n  <summary>Easily switch from running on CPU to GPU (Apple Silicon, CUDA, ‚Ä¶), TPU, multi-GPU or even multi-node training</summary>\n\n```python\n# Use your available hardware\n# no code changes needed\nfabric = Fabric()\n\n# Run on GPUs (CUDA or MPS)\nfabric = Fabric(accelerator=\"gpu\")\n\n# 8 GPUs\nfabric = Fabric(accelerator=\"gpu\", devices=8)\n\n# 256 GPUs, multi-node\nfabric = Fabric(accelerator=\"gpu\", devices=8, num_nodes=32)\n\n# Run on TPUs\nfabric = Fabric(accelerator=\"tpu\")\n```\n\n</details>\n\n<details>\n  <summary>Use state-of-the-art distributed training strategies (DDP, FSDP, DeepSpeed) and mixed precision out of the box</summary>\n\n```python\n# Use state-of-the-art distributed training techniques\nfabric = Fabric(strategy=\"ddp\")\nfabric = Fabric(strategy=\"deepspeed\")\nfabric = Fabric(strategy=\"fsdp\")\n\n# Switch the precision\nfabric = Fabric(precision=\"16-mixed\")\nfabric = Fabric(precision=\"64\")\n```\n\n</details>\n\n<details>\n  <summary>All the device logic boilerplate is handled for you</summary>\n\n```diff\n  # no more of this!\n- model.to(device)\n- batch.to(device)\n```\n\n</details>\n\n<details>\n  <summary>Build your own custom Trainer using Fabric primitives for training checkpointing, logging, and more</summary>\n\n```python\nimport lightning as L\n\n\nclass MyCustomTrainer:\n    def __init__(self, accelerator=\"auto\", strategy=\"auto\", devices=\"auto\", precision=\"32-true\"):\n        self.fabric = L.Fabric(accelerator=accelerator, strategy=strategy, devices=devices, precision=precision)\n\n    def fit(self, model, optimizer, dataloader, max_epochs):\n        self.fabric.launch()\n\n        model, optimizer = self.fabric.setup(model, optimizer)\n        dataloader = self.fabric.setup_dataloaders(dataloader)\n        model.train()\n\n        for epoch in range(max_epochs):\n            for batch in dataloader:\n                input, target = batch\n                optimizer.zero_grad()\n                output = model(input)\n                loss = loss_fn(output, target)\n                self.fabric.backward(loss)\n                optimizer.step()\n```\n\nYou can find a more extensive example in our [examples](examples/fabric/build_your_own_trainer)\n\n</details>\n\n______________________________________________________________________\n\n<div align=\"center\">\n    <a href=\"https://lightning.ai/docs/fabric/stable/\">Read the Lightning Fabric docs</a>\n</div>\n\n______________________________________________________________________\n\n&nbsp;\n&nbsp;\n\n## Examples\n\n###### Self-supervised Learning\n\n- [CPC transforms](https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#cpc-transforms)\n- [Moco v2 transforms](https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#moco-v2-transforms)\n- [SimCLR transforms](https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#simclr-transforms)\n\n###### Convolutional Architectures\n\n- [GPT-2](https://lightning-bolts.readthedocs.io/en/stable/models/convolutional.html#gpt-2)\n- [UNet](https://lightning-bolts.readthedocs.io/en/stable/models/convolutional.html#unet)\n\n###### Reinforcement Learning\n\n- [DQN Loss](https://lightning-bolts.readthedocs.io/en/stable/losses.html#dqn-loss)\n- [Double DQN Loss](https://lightning-bolts.readthedocs.io/en/stable/losses.html#double-dqn-loss)\n- [Per DQN Loss](https://lightning-bolts.readthedocs.io/en/stable/losses.html#per-dqn-loss)\n\n###### GANs\n\n- [Basic GAN](https://lightning-bolts.readthedocs.io/en/stable/models/gans.html#basic-gan)\n- [DCGAN](https://lightning-bolts.readthedocs.io/en/stable/models/gans.html#dcgan)\n\n###### Classic ML\n\n- [Logistic Regression](https://lightning-bolts.readthedocs.io/en/stable/models/classic_ml.html#logistic-regression)\n- [Linear Regression](https://lightning-bolts.readthedocs.io/en/stable/models/classic_ml.html#linear-regression)\n\n&nbsp;\n&nbsp;\n\n## Continuous Integration\n\nLightning is rigorously tested across multiple CPUs, GPUs and TPUs and against major Python and PyTorch versions.\n\n###### \\*Codecov is > 90%+ but build delays may show less\n\n<details>\n  <summary>Current build statuses</summary>\n\n<center>\n\n|       System / PyTorch ver.        | 1.13                                                                                                                                                                                                                            | 2.0                                                                                                                                                                                                                             |                                                                                                               2.1                                                                                                               |\n| :--------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n|        Linux py3.9 \\[GPUs\\]        |  |  | [![Build Status](https://dev.azure.com/Lightning-AI/lightning/_apis/build/status%2Fpytorch-lightning%20%28GPUs%29?branchName=master)](https://dev.azure.com/Lightning-AI/lightning/_build/latest?definitionId=24&branchName=master) |\n|  Linux (multiple Python versions)  | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 |                 [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                 |\n|   OSX (multiple Python versions)   | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 |                 [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                 |\n| Windows (multiple Python versions) | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 |                 [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                 |\n\n</center>\n</details>\n\n&nbsp;\n&nbsp;\n\n## Community\n\nThe lightning community is maintained by\n\n- [10+ core contributors](https://lightning.ai/docs/pytorch/latest/community/governance.html) who are all a mix of professional engineers, Research Scientists, and Ph.D. students from top AI labs.\n- 800+ community contributors.\n\nWant to help us build Lightning and reduce boilerplate for thousands of researchers? [Learn how to make your first contribution here](https://lightning.ai/docs/pytorch/stable/generated/CONTRIBUTING.html)\n\nLightning is also part of the [PyTorch ecosystem](https://pytorch.org/ecosystem/) which requires projects to have solid testing, documentation and support.\n\n### Asking for help\n\nIf you have any questions please:\n\n1. [Read the docs](https://lightning.ai/docs).\n1. [Search through existing Discussions](https://github.com/Lightning-AI/lightning/discussions), or [add a new question](https://github.com/Lightning-AI/lightning/discussions/new)\n1. [Join our discord](https://discord.com/invite/tfXFetEZxv).\n",
         "AI_DataScience"
        ],
        [
         "24",
         "MDEwOlJlcG9zaXRvcnkzMjE2NTkwNjI=",
         "<table align=\"center\" border=\"0\">\n\n<tr><td colspan=2 align=\"center\">\n\n![](doc/deepfacelive_intro.png)\n\n![](doc/logo_onnx.png)![](doc/logo_directx.png)![](doc/logo_python.png)\n\n</td></tr>\n</table>\n<table align=\"center\" border=\"0\">\n\n<tr><td colspan=2 align=\"center\">\n\n## Face Swap (DFM)\n\nYou can swap your face from a webcam or the face in the video using trained face models.\n\nHere is a list of available ready-to-use public face models.\n\nThese persons do not exists. Similarities with real people are accidental. Except Keanu Reeves. He exists, and he's breathtaking!\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\n\n<table align=\"center\" border=\"0\">\n<tr><td align=\"center\">\nKeanu Reeves\n\n<img src=\"doc/celebs/Keanu_Reeves/Keanu_Reeves.png\" width=128></img>\n\n<a href=\"doc/celebs/Keanu_Reeves/examples.md\">examples</a>\n</td><td align=\"center\">\nIrina Arty\n\n<img src=\"doc/celebs/Irina_Arty/Irina_Arty.png\" width=128></img>\n\nexamples\n</td><td align=\"center\">\nMillie Park\n\n<img src=\"doc/celebs/Millie_Park/Millie_Park.png\" width=128></img>\n\nexamples\n</td><td align=\"center\">\nRob Doe\n\n<img src=\"doc/celebs/Rob_Doe/Rob_Doe.png\" width=128></img>\n\n<a href=\"doc/celebs/Rob_Doe/examples.md\">examples</a>\n</td><td align=\"center\">\nJesse Stat\n\n<img src=\"doc/celebs/Jesse_Stat/Jesse_Stat.png\" width=128></img>\n\nexamples\n</td></tr>\n\n</table>\n\n<table align=\"center\" border=\"0\">\n<tr><td align=\"center\">\nBryan Greynolds\n\n<img src=\"doc/celebs/Bryan_Greynolds/Bryan_Greynolds.png\" width=128></img>\n\n<a href=\"doc/celebs/Bryan_Greynolds/examples.md\">examples</a>\n</td><td align=\"center\">\nMr. Bean\n\n<img src=\"doc/celebs/Mr_Bean/Mr_Bean.png\" width=128></img>\n\nexamples\n</td><td align=\"center\">\nEwon Spice\n\n<img src=\"doc/celebs/Ewon_Spice/Ewon_Spice.png\" width=128></img>\n\n<a href=\"doc/celebs/Ewon_Spice/examples.md\">examples</a>\n\n</td><td align=\"center\">\nNatasha Former\n\n<img src=\"doc/celebs/Natasha_Former/Natasha_Former.png\" width=128></img>\n\n<a href=\"doc/celebs/Natasha_Former/examples.md\">examples</a>\n\n</td><td align=\"center\">\nEmily Winston\n\n<img src=\"doc/celebs/Emily_Winston/Emily_Winston.png\" width=128></img>\n\n<a href=\"doc/celebs/Emily_Winston/examples.md\">examples</a>\n\n</td></tr></table>\n<table align=\"center\" border=\"0\">\n<tr><td align=\"center\">\nAva de Addario\n\n<img src=\"doc/celebs/Ava_de_Addario/Ava_de_Addario.png\" width=128></img>\n\n<a href=\"doc/celebs/Ava_de_Addario/examples.md\">examples</a>\n</td><td align=\"center\">\nDilraba Dilmurat\n\n<img src=\"doc/celebs/Dilraba_Dilmurat/Dilraba_Dilmurat.png\" width=128></img>\n\nexamples\n</td><td align=\"center\">\nMatilda Bobbie\n\n<img src=\"doc/celebs/Matilda_Bobbie/Matilda_Bobbie.png\" width=128></img>\n\n<a href=\"doc/celebs/Matilda_Bobbie/examples.md\">examples</a>\n</td><td align=\"center\">\nYohanna Coralson\n\n<img src=\"doc/celebs/Yohanna_Coralson/Yohanna_Coralson.png\" width=128></img>\n\n<a href=\"doc/celebs/Yohanna_Coralson/examples.md\">examples</a>\n\n</td><td align=\"center\">\nAmber Song\n\n<img src=\"doc/celebs/Amber_Song/Amber_Song.png\" width=128></img>\n\nexamples\n\n</td></tr></table>\n<table align=\"center\" border=\"0\">\n<tr align=\"center\"><td align=\"center\">\nKim Jarrey\n\n<img src=\"doc/celebs/Kim_Jarrey/Kim_Jarrey.png\" width=128></img>\n\n<a href=\"doc/celebs/Kim_Jarrey/examples.md\">examples</a>\n</td><td align=\"center\">\nDavid Kovalniy\n\n<img src=\"doc/celebs/David_Kovalniy/David_Kovalniy.png\" width=128></img>\n\n<a href=\"doc/celebs/David_Kovalniy/examples.md\">examples</a>\n</td><td align=\"center\">\nJackie Chan\n\n<img src=\"doc/celebs/Jackie_Chan/Jackie_Chan.png\" width=128></img>\n\nexamples\n</td><td align=\"center\">\nNicola Badge\n\n<img src=\"doc/celebs/Nicola_Badge/Nicola_Badge.png\" width=128></img>\n\n<a href=\"doc/celebs/Nicola_Badge/examples.md\">examples</a>\n</td><td align=\"center\">\nJoker\n\n<img src=\"doc/celebs/Joker/Joker.png\" width=128></img>\n\nexamples\n</td></tr></table>\n<table align=\"center\" border=\"0\">\n<tr align=\"center\"><td>\nDean Wiesel\n\n<img src=\"doc/celebs/Dean_Wiesel/Dean_Wiesel.png\" width=128></img>\n\n<a href=\"doc/celebs/Dean_Wiesel/examples.md\">examples</a>\n</td><td align=\"center\">\nSilwan Stillwone\n\n<img src=\"doc/celebs/Silwan_Stillwone/Silwan_Stillwone.png\" width=128></img>\n\n<a href=\"doc/celebs/Silwan_Stillwone/examples.md\">examples</a>\n</td><td align=\"center\">\nTim Chrys\n\n<img src=\"doc/celebs/Tim_Chrys/Tim_Chrys.png\" width=128></img>\n\n<a href=\"doc/celebs/Tim_Chrys/examples.md\">examples</a>\n\n</td><td align=\"center\">\nZahar Lupin\n\n<img src=\"doc/celebs/Zahar_Lupin/Zahar_Lupin.png\" width=128></img>\n\n<a href=\"doc/celebs/Zahar_Lupin/examples.md\">examples</a>\n</td><td align=\"center\">\nTim Norland\n\n<img src=\"doc/celebs/Tim_Norland/Tim_Norland.png\" width=128></img>\n\n<a href=\"doc/celebs/Tim_Norland/examples.md\">examples</a>\n</td></tr></table>\n\n\n<table align=\"center\" border=\"0\">\n<tr align=\"center\"><td>\nNatalie Fatman\n\n<img src=\"doc/celebs/Natalie_Fatman/Natalie_Fatman.png\" width=128></img>\n\n<a href=\"doc/celebs/Natalie_Fatman/examples.md\">examples</a>\n</td><td align=\"center\">\nLiu Lice\n\n<img src=\"doc/celebs/Liu_Lice/Liu_Lice.png\" width=128></img>\n\n<a href=\"doc/celebs/Liu_Lice/examples.md\">examples</a>\n</td><td align=\"center\">\nAlbica Johns\n\n<img src=\"doc/celebs/Albica_Johns/Albica_Johns.png\" width=128></img>\n\n<a href=\"doc/celebs/Albica_Johns/examples.md\">examples</a>\n\n</td><td align=\"center\">\nMeggie Merkel\n\n<img src=\"doc/celebs/Meggie_Merkel/Meggie_Merkel.png\" width=128></img>\n\n<a href=\"doc/celebs/Meggie_Merkel/examples.md\">examples</a>\n</td><td align=\"center\">\nTina Shift\n\n<img src=\"doc/celebs/Tina_Shift/Tina_Shift.png\" width=128></img>\n\n<a href=\"doc/celebs/Tina_Shift/examples.md\">examples</a>\n</td></tr></table>\n\n</td></tr>\n\n<tr><td colspan=2 align=\"center\">\nIf you want a higher quality or better face match, you can train your own face model using <a href=\"https://github.com/iperov/DeepFaceLab\">DeepFaceLab</a>\n\nHere is an <a href=\"https://www.tiktok.com/@arnoldschwarzneggar/video/6995538782204300545\">example</a> of Arnold Schwarzneggar trained on a particular face and used in a video call. Read the FAQ for more information.\n\n</td></tr>\n\n</table>\n<table align=\"center\" border=\"0\">\n\n<tr><td colspan=2 align=\"center\">\n\n## Face Swap (Insight)\n\nYou can swap your face from a webcam or the face in the video using your own single photo.\n\n<img src=\"doc/lukashenko.png\" width=128></img>\n\n<img src=\"doc/insight_faceswap_example.gif\"></img>\n\n</td></tr>\n\n</table>\n<table align=\"center\" border=\"0\">\n\n<tr><td colspan=2 align=\"center\">\n\n## Face Animator\n\nThere is also a Face Animator module in DeepFaceLive app. You can control a static face picture using video or your own face from the camera. The quality is not the best, and requires fine face matching and tuning parameters for every face pair, but enough for funny videos and memes or real-time streaming at 25 fps using 35 TFLOPS GPU.\n\n<img src=\"doc/face_animator_example.gif\"></img>\n\n[![Stranger Things theme intro acapella](doc/Ng1C78Ceyxg_screenshot.png)](https://www.youtube.com/watch?v=Ng1C78Ceyxg)\n\nHere is a [mini video](doc/FaceAnimator_tutor.webm?raw=true) showing the process of setting up the Face Animator for Obama controlling Kim Chen's face.\n\n</td></tr>\n\n</table>\n\n<table align=\"center\" border=\"0\">\n\n<tr><td colspan=2 align=\"center\">\n\n## System requirements\n\nany DirectX12 compatible graphics card\n\n(Recommended RTX 2070+ / Radeon RX 5700 XT+ )\n\nModern CPU with AVX instructions\n\n4GB RAM, 32GB+ paging file\n\nWindows 10\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n## Documentation\n\n</td></tr>\n<tr><td align=\"right\">\nWindows\n</td><td align=\"left\">\n\n<a href=\"doc/windows/main_setup.md\">Main setup</a>\n\n- <a href=\"doc/windows/for_streaming.md\">additional setup for streaming</a>\n\n- <a href=\"doc/windows/for_video_calls.md\">additional setup for video calls</a>       \n\n<a href=\"doc/windows/using_android_phone_camera.md\">Using Android phone camera</a>  \n\n</td></tr>\n<tr><td align=\"right\">\nLinux\n</td><td align=\"left\">\n<a href=\"build/linux\">Build info</a>\n</td></tr>\n<tr><td align=\"right\">\nFrequently asked questions\n</td><td align=\"left\">\n<a href=\"doc/user_faq/user_faq.md\">for User</a>\n\n<a href=\"doc/developer_faq/developer_faq.md\">for Developer</a>\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n## Releases\n\n</td></tr>\n<tr><td align=\"right\">\n\n<a href=\"https://disk.yandex.ru/d/7i5XTKIKVg5UUg\">Windows 10 x64 (yandex.ru)</a>\n\n<a href=\"https://mega.nz/folder/m10iELBK#Y0H6BflF9C4k_clYofC7yA\">Windows 10 x64 (mega.nz)</a>\n\n\n</td><td align=\"left\">\nContains stand-alone zero-dependency all-in-one ready-to-use portable self-extracting folder! You don't need to install anything other than video drivers.\n<br><br>\nDirectX12 build : NVIDIA, AMD, Intel videocards.\n<br><br>\nNVIDIA build : NVIDIA cards only, GT730 and higher. Works faster than DX12. FaceMerger can work also on AMD/Intel.\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n## Communication groups\n\n<tr><td align=\"right\">\n<a href=\"https://discord.gg/rxa7h9M6rH\">Discord</a>\n</td><td align=\"left\">Official discord channel. English / Russian.</td></tr>\n\n<tr><td align=\"right\">\nQQÁæ§124500433\n</td><td align=\"left\">‰∏≠Êñá‰∫§ÊµÅQQÁæ§ÔºåÂïÜÂä°Âêà‰ΩúÊâæÁæ§‰∏ª</td></tr>\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n## How can I help the project?\n\n</td></tr>\n<tr><td colspan=2 align=\"center\">\nTrain your own face model by following the recommendations in the FAQ section and share it on Discord. If the model fits the quality, it will be added to the public library.\n</td></tr>\n<tr><td colspan=2 align=\"center\">\nRegister github account and push \"Star\" button.\n</td></tr>\n<!--<tr><td colspan=2 align=\"center\">\n<a href=\"https://www.paypal.com/paypalme/DeepFaceLab\">Donate via Paypal</a>\n</td></tr>-->\n<tr><td colspan=2 align=\"center\">\n<a href=\"https://yoomoney.ru/to/41001142318065\">Donate via Yoomoney</a>\n</td></tr>\n<tr><td colspan=2 align=\"center\">\nbitcoin:bc1qewl062v70rszulml3f0mjdjrys8uxdydw3v6rq\n</td></tr>\n<tr><td colspan=2 align=\"center\">\n\n\n<!--\n    <a href=\"https://br-stone.online\"><img src=\"doc/logo_barclay_stone.png\"></img></a><a href=\"https://exmo.com\"><img src=\"doc/logo_exmo.png\"></img></a>\n\n    presents\n\n    <tr><td align=\"right\">\n\n\n    <a href=\"\">Windows (magnet link)</a>\n    </td><td align=\"center\">Latest release. Use torrent client to download.</td></tr>\n    </tr>\n-->\n\n</table>\n\n\n\n",
         "AI_DataScience"
        ],
        [
         "25",
         "MDEwOlJlcG9zaXRvcnk4MDk5MDQ2MQ==",
         "# Machine Learning From Scratch\n\n## About\nPython implementations of some of the fundamental Machine Learning models and algorithms from scratch.\n\nThe purpose of this project is not to produce as optimized and computationally efficient algorithms as possible\nbut rather to present the inner workings of them in a transparent and accessible way.\n\n## Table of Contents\n- [Machine Learning From Scratch](#machine-learning-from-scratch)\n  * [About](#about)\n  * [Table of Contents](#table-of-contents)\n  * [Installation](#installation)\n  * [Examples](#examples)\n    + [Polynomial Regression](#polynomial-regression)\n    + [Classification With CNN](#classification-with-cnn)\n    + [Density-Based Clustering](#density-based-clustering)\n    + [Generating Handwritten Digits](#generating-handwritten-digits)\n    + [Deep Reinforcement Learning](#deep-reinforcement-learning)\n    + [Image Reconstruction With RBM](#image-reconstruction-with-rbm)\n    + [Evolutionary Evolved Neural Network](#evolutionary-evolved-neural-network)\n    + [Genetic Algorithm](#genetic-algorithm)\n    + [Association Analysis](#association-analysis)\n  * [Implementations](#implementations)\n    + [Supervised Learning](#supervised-learning)\n    + [Unsupervised Learning](#unsupervised-learning)\n    + [Reinforcement Learning](#reinforcement-learning)\n    + [Deep Learning](#deep-learning)\n  * [Contact](#contact)\n\n## Installation\n    $ git clone https://github.com/eriklindernoren/ML-From-Scratch\n    $ cd ML-From-Scratch\n    $ python setup.py install\n\n## Examples\n### Polynomial Regression\n    $ python mlfromscratch/examples/polynomial_regression.py\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/p_reg.gif\" width=\"640\"\\>\n</p>\n<p align=\"center\">\n    Figure: Training progress of a regularized polynomial regression model fitting <br>\n    temperature data measured in Link√∂ping, Sweden 2016.\n</p>\n\n### Classification With CNN\n    $ python mlfromscratch/examples/convolutional_neural_network.py\n\n    +---------+\n    | ConvNet |\n    +---------+\n    Input Shape: (1, 8, 8)\n    +----------------------+------------+--------------+\n    | Layer Type           | Parameters | Output Shape |\n    +----------------------+------------+--------------+\n    | Conv2D               | 160        | (16, 8, 8)   |\n    | Activation (ReLU)    | 0          | (16, 8, 8)   |\n    | Dropout              | 0          | (16, 8, 8)   |\n    | BatchNormalization   | 2048       | (16, 8, 8)   |\n    | Conv2D               | 4640       | (32, 8, 8)   |\n    | Activation (ReLU)    | 0          | (32, 8, 8)   |\n    | Dropout              | 0          | (32, 8, 8)   |\n    | BatchNormalization   | 4096       | (32, 8, 8)   |\n    | Flatten              | 0          | (2048,)      |\n    | Dense                | 524544     | (256,)       |\n    | Activation (ReLU)    | 0          | (256,)       |\n    | Dropout              | 0          | (256,)       |\n    | BatchNormalization   | 512        | (256,)       |\n    | Dense                | 2570       | (10,)        |\n    | Activation (Softmax) | 0          | (10,)        |\n    +----------------------+------------+--------------+\n    Total Parameters: 538570\n\n    Training: 100% [------------------------------------------------------------------------] Time: 0:01:55\n    Accuracy: 0.987465181058\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/mlfs_cnn1.png\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Classification of the digit dataset using CNN.\n</p>\n\n### Density-Based Clustering\n    $ python mlfromscratch/examples/dbscan.py\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/mlfs_dbscan.png\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Clustering of the moons dataset using DBSCAN.\n</p>\n\n### Generating Handwritten Digits\n    $ python mlfromscratch/unsupervised_learning/generative_adversarial_network.py\n\n    +-----------+\n    | Generator |\n    +-----------+\n    Input Shape: (100,)\n    +------------------------+------------+--------------+\n    | Layer Type             | Parameters | Output Shape |\n    +------------------------+------------+--------------+\n    | Dense                  | 25856      | (256,)       |\n    | Activation (LeakyReLU) | 0          | (256,)       |\n    | BatchNormalization     | 512        | (256,)       |\n    | Dense                  | 131584     | (512,)       |\n    | Activation (LeakyReLU) | 0          | (512,)       |\n    | BatchNormalization     | 1024       | (512,)       |\n    | Dense                  | 525312     | (1024,)      |\n    | Activation (LeakyReLU) | 0          | (1024,)      |\n    | BatchNormalization     | 2048       | (1024,)      |\n    | Dense                  | 803600     | (784,)       |\n    | Activation (TanH)      | 0          | (784,)       |\n    +------------------------+------------+--------------+\n    Total Parameters: 1489936\n\n    +---------------+\n    | Discriminator |\n    +---------------+\n    Input Shape: (784,)\n    +------------------------+------------+--------------+\n    | Layer Type             | Parameters | Output Shape |\n    +------------------------+------------+--------------+\n    | Dense                  | 401920     | (512,)       |\n    | Activation (LeakyReLU) | 0          | (512,)       |\n    | Dropout                | 0          | (512,)       |\n    | Dense                  | 131328     | (256,)       |\n    | Activation (LeakyReLU) | 0          | (256,)       |\n    | Dropout                | 0          | (256,)       |\n    | Dense                  | 514        | (2,)         |\n    | Activation (Softmax)   | 0          | (2,)         |\n    +------------------------+------------+--------------+\n    Total Parameters: 533762\n\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/gan_mnist5.gif\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Training progress of a Generative Adversarial Network generating <br>\n    handwritten digits.\n</p>\n\n### Deep Reinforcement Learning\n    $ python mlfromscratch/examples/deep_q_network.py\n\n    +----------------+\n    | Deep Q-Network |\n    +----------------+\n    Input Shape: (4,)\n    +-------------------+------------+--------------+\n    | Layer Type        | Parameters | Output Shape |\n    +-------------------+------------+--------------+\n    | Dense             | 320        | (64,)        |\n    | Activation (ReLU) | 0          | (64,)        |\n    | Dense             | 130        | (2,)         |\n    +-------------------+------------+--------------+\n    Total Parameters: 450\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/mlfs_dql1.gif\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Deep Q-Network solution to the CartPole-v1 environment in OpenAI gym.\n</p>\n\n### Image Reconstruction With RBM\n    $ python mlfromscratch/examples/restricted_boltzmann_machine.py\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/rbm_digits1.gif\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Shows how the network gets better during training at reconstructing <br>\n    the digit 2 in the MNIST dataset.\n</p>\n\n### Evolutionary Evolved Neural Network\n    $ python mlfromscratch/examples/neuroevolution.py\n\n    +---------------+\n    | Model Summary |\n    +---------------+\n    Input Shape: (64,)\n    +----------------------+------------+--------------+\n    | Layer Type           | Parameters | Output Shape |\n    +----------------------+------------+--------------+\n    | Dense                | 1040       | (16,)        |\n    | Activation (ReLU)    | 0          | (16,)        |\n    | Dense                | 170        | (10,)        |\n    | Activation (Softmax) | 0          | (10,)        |\n    +----------------------+------------+--------------+\n    Total Parameters: 1210\n\n    Population Size: 100\n    Generations: 3000\n    Mutation Rate: 0.01\n\n    [0 Best Individual - Fitness: 3.08301, Accuracy: 10.5%]\n    [1 Best Individual - Fitness: 3.08746, Accuracy: 12.0%]\n    ...\n    [2999 Best Individual - Fitness: 94.08513, Accuracy: 98.5%]\n    Test set accuracy: 96.7%\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/evo_nn4.png\" width=\"640\">\n</p>\n<p align=\"center\">\n    Figure: Classification of the digit dataset by a neural network which has<br>\n    been evolutionary evolved.\n</p>\n\n### Genetic Algorithm\n    $ python mlfromscratch/examples/genetic_algorithm.py\n\n    +--------+\n    |   GA   |\n    +--------+\n    Description: Implementation of a Genetic Algorithm which aims to produce\n    the user specified target string. This implementation calculates each\n    candidate's fitness based on the alphabetical distance between the candidate\n    and the target. A candidate is selected as a parent with probabilities proportional\n    to the candidate's fitness. Reproduction is implemented as a single-point\n    crossover between pairs of parents. Mutation is done by randomly assigning\n    new characters with uniform probability.\n\n    Parameters\n    ----------\n    Target String: 'Genetic Algorithm'\n    Population Size: 100\n    Mutation Rate: 0.05\n\n    [0 Closest Candidate: 'CJqlJguPlqzvpoJmb', Fitness: 0.00]\n    [1 Closest Candidate: 'MCxZxdr nlfiwwGEk', Fitness: 0.01]\n    [2 Closest Candidate: 'MCxZxdm nlfiwwGcx', Fitness: 0.01]\n    [3 Closest Candidate: 'SmdsAklMHn kBIwKn', Fitness: 0.01]\n    [4 Closest Candidate: '  lotneaJOasWfu Z', Fitness: 0.01]\n    ...\n    [292 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]\n    [293 Closest Candidate: 'GeneticaAlgorithm', Fitness: 1.00]\n    [294 Answer: 'Genetic Algorithm']\n\n### Association Analysis\n    $ python mlfromscratch/examples/apriori.py\n    +-------------+\n    |   Apriori   |\n    +-------------+\n    Minimum Support: 0.25\n    Minimum Confidence: 0.8\n    Transactions:\n        [1, 2, 3, 4]\n        [1, 2, 4]\n        [1, 2]\n        [2, 3, 4]\n        [2, 3]\n        [3, 4]\n        [2, 4]\n    Frequent Itemsets:\n        [1, 2, 3, 4, [1, 2], [1, 4], [2, 3], [2, 4], [3, 4], [1, 2, 4], [2, 3, 4]]\n    Rules:\n        1 -> 2 (support: 0.43, confidence: 1.0)\n        4 -> 2 (support: 0.57, confidence: 0.8)\n        [1, 4] -> 2 (support: 0.29, confidence: 1.0)\n\n\n## Implementations\n### Supervised Learning\n- [Adaboost](mlfromscratch/supervised_learning/adaboost.py)\n- [Bayesian Regression](mlfromscratch/supervised_learning/bayesian_regression.py)\n- [Decision Tree](mlfromscratch/supervised_learning/decision_tree.py)\n- [Elastic Net](mlfromscratch/supervised_learning/regression.py)\n- [Gradient Boosting](mlfromscratch/supervised_learning/gradient_boosting.py)\n- [K Nearest Neighbors](mlfromscratch/supervised_learning/k_nearest_neighbors.py)\n- [Lasso Regression](mlfromscratch/supervised_learning/regression.py)\n- [Linear Discriminant Analysis](mlfromscratch/supervised_learning/linear_discriminant_analysis.py)\n- [Linear Regression](mlfromscratch/supervised_learning/regression.py)\n- [Logistic Regression](mlfromscratch/supervised_learning/logistic_regression.py)\n- [Multi-class Linear Discriminant Analysis](mlfromscratch/supervised_learning/multi_class_lda.py)\n- [Multilayer Perceptron](mlfromscratch/supervised_learning/multilayer_perceptron.py)\n- [Naive Bayes](mlfromscratch/supervised_learning/naive_bayes.py)\n- [Neuroevolution](mlfromscratch/supervised_learning/neuroevolution.py)\n- [Particle Swarm Optimization of Neural Network](mlfromscratch/supervised_learning/particle_swarm_optimization.py)\n- [Perceptron](mlfromscratch/supervised_learning/perceptron.py)\n- [Polynomial Regression](mlfromscratch/supervised_learning/regression.py)\n- [Random Forest](mlfromscratch/supervised_learning/random_forest.py)\n- [Ridge Regression](mlfromscratch/supervised_learning/regression.py)\n- [Support Vector Machine](mlfromscratch/supervised_learning/support_vector_machine.py)\n- [XGBoost](mlfromscratch/supervised_learning/xgboost.py)\n\n### Unsupervised Learning\n- [Apriori](mlfromscratch/unsupervised_learning/apriori.py)\n- [Autoencoder](mlfromscratch/unsupervised_learning/autoencoder.py)\n- [DBSCAN](mlfromscratch/unsupervised_learning/dbscan.py)\n- [FP-Growth](mlfromscratch/unsupervised_learning/fp_growth.py)\n- [Gaussian Mixture Model](mlfromscratch/unsupervised_learning/gaussian_mixture_model.py)\n- [Generative Adversarial Network](mlfromscratch/unsupervised_learning/generative_adversarial_network.py)\n- [Genetic Algorithm](mlfromscratch/unsupervised_learning/genetic_algorithm.py)\n- [K-Means](mlfromscratch/unsupervised_learning/k_means.py)\n- [Partitioning Around Medoids](mlfromscratch/unsupervised_learning/partitioning_around_medoids.py)\n- [Principal Component Analysis](mlfromscratch/unsupervised_learning/principal_component_analysis.py)\n- [Restricted Boltzmann Machine](mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py)\n\n### Reinforcement Learning\n- [Deep Q-Network](mlfromscratch/reinforcement_learning/deep_q_network.py)\n\n### Deep Learning\n  + [Neural Network](mlfromscratch/deep_learning/neural_network.py)\n  + [Layers](mlfromscratch/deep_learning/layers.py)\n    * Activation Layer\n    * Average Pooling Layer\n    * Batch Normalization Layer\n    * Constant Padding Layer\n    * Convolutional Layer\n    * Dropout Layer\n    * Flatten Layer\n    * Fully-Connected (Dense) Layer\n    * Fully-Connected RNN Layer\n    * Max Pooling Layer\n    * Reshape Layer\n    * Up Sampling Layer\n    * Zero Padding Layer\n  + Model Types\n    * [Convolutional Neural Network](mlfromscratch/examples/convolutional_neural_network.py)\n    * [Multilayer Perceptron](mlfromscratch/examples/multilayer_perceptron.py)\n    * [Recurrent Neural Network](mlfromscratch/examples/recurrent_neural_network.py)\n\n## Contact\nIf there's some implementation you would like to see here or if you're just feeling social,\nfeel free to [email](mailto:eriklindernoren@gmail.com) me or connect with me on [LinkedIn](https://www.linkedin.com/in/eriklindernoren/).\n",
         "AI_DataScience"
        ],
        [
         "26",
         "MDEwOlJlcG9zaXRvcnkyNzcxNjg5NTc=",
         "# applied-ml\nCurated papers, articles, and blogs on **data science & machine learning in production**. ‚öôÔ∏è\n\n[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](./CONTRIBUTING.md) [![Summaries](https://img.shields.io/badge/summaries-in%20tweets-%2300acee.svg?style=flat)](https://twitter.com/eugeneyan/status/1350509546133811200) ![HitCount](http://hits.dwyl.com/eugeneyan/applied-ml.svg)\n\nFiguring out how to implement your ML project? Learn how other organizations did it:\n\n- **How** the problem is framed üîé(e.g., personalization as recsys vs. search vs. sequences)\n- **What** machine learning techniques worked ‚úÖ (and sometimes, what didn't ‚ùå)\n- **Why** it works, the science behind it with research, literature, and references üìÇ\n- **What** real-world results were achieved (so you can better assess ROI ‚è∞üí∞üìà)\n\nP.S., Want a summary of ML advancements? üëâ[`ml-surveys`](https://github.com/eugeneyan/ml-surveys)\n\nP.P.S, Looking for guides and interviews on applying ML? üëâ[`applyingML`](https://applyingml.com)\n\n**Table of Contents**\n\n1. [Data Quality](#data-quality)\n2. [Data Engineering](#data-engineering)\n3. [Data Discovery](#data-discovery)\n4. [Feature Stores](#feature-stores)\n5. [Classification](#classification)\n6. [Regression](#regression)\n7. [Forecasting](#forecasting)\n8. [Recommendation](#recommendation)\n9. [Search & Ranking](#search--ranking)\n10. [Embeddings](#embeddings)\n11. [Natural Language Processing](#natural-language-processing)\n12. [Sequence Modelling](#sequence-modelling)\n13. [Computer Vision](#computer-vision)\n14. [Reinforcement Learning](#reinforcement-learning)\n15. [Anomaly Detection](#anomaly-detection)\n16. [Graph](#graph)\n17. [Optimization](#optimization)\n18. [Information Extraction](#information-extraction)\n19. [Weak Supervision](#weak-supervision)\n20. [Generation](#generation)\n21. [Audio](#audio)\n22. [Privacy-Preserving Machine Learning](#privacy-preserving-machine-learning)\n23. [Validation and A/B Testing](#validation-and-ab-testing)\n24. [Model Management](#model-management)\n25. [Efficiency](#efficiency)\n26. [Ethics](#ethics)\n27. [Infra](#infra)\n28. [MLOps Platforms](#mlops-platforms)\n29. [Practices](#practices)\n30. [Team Structure](#team-structure)\n31. [Fails](#fails)\n\n## Data Quality\n1. [Reliable and Scalable Data Ingestion at Airbnb](https://www.slideshare.net/HadoopSummit/reliable-and-scalable-data-ingestion-at-airbnb-63920989) `Airbnb` `2016`\n2. [Monitoring Data Quality at Scale with Statistical Modeling](https://eng.uber.com/monitoring-data-quality-at-scale/) `Uber` `2017`\n3. [Data Management Challenges in Production Machine Learning](https://research.google/pubs/pub46178/) ([Paper](https://thodrek.github.io/CS839_spring18/papers/p1723-polyzotis.pdf)) `Google` `2017`\n4. [Automating Large-Scale Data Quality Verification](https://www.amazon.science/publications/automating-large-scale-data-quality-verification) ([Paper](https://assets.amazon.science/a6/88/ad858ee240c38c6e9dce128250c0/automating-large-scale-data-quality-verification.pdf))`Amazon` `2018`\n5. [Meet Hodor ‚Äî Gojek‚Äôs Upstream Data Quality Tool](https://www.gojek.io/blog/meet-hodor-gojeks-upstream-data-quality-tool) `Gojek` `2019`\n6. [Data Validation for Machine Learning](https://research.google/pubs/pub47967/) ([Paper](https://mlsys.org/Conferences/2019/doc/2019/167.pdf)) `Google` `2019`\n6. [An Approach to Data Quality for Netflix Personalization Systems](https://www.youtube.com/watch?v=t7vHpA39TXM) `Netflix` `2020`\n7. [Improving Accuracy By Certainty Estimation of Human Decisions, Labels, and Raters](https://research.fb.com/blog/2020/08/improving-the-accuracy-of-community-standards-enforcement-by-certainty-estimation-of-human-decisions/) ([Paper](https://research.fb.com/wp-content/uploads/2020/08/CLARA-Confidence-of-Labels-and-Raters.pdf)) `Facebook` `2020`\n\n## Data Engineering\n1. [Zipline: Airbnb‚Äôs Machine Learning Data Management Platform](https://www.youtube.com/watch?v=Tg5VEMEsC-0) `Airbnb` `2018`\n2. [Sputnik: Airbnb‚Äôs Apache Spark Framework for Data Engineering](https://www.youtube.com/watch?v=BQumogSBsUw) `Airbnb` `2020`\n3. [Unbundling Data Science Workflows with Metaflow and AWS Step Functions](https://netflixtechblog.com/unbundling-data-science-workflows-with-metaflow-and-aws-step-functions-d454780c6280) `Netflix` `2020`\n4. [How DoorDash is Scaling its Data Platform to Delight Customers and Meet Growing Demand](https://doordash.engineering/2020/09/25/how-doordash-is-scaling-its-data-platform/) `DoorDash` `2020`\n5. [Revolutionizing Money Movements at Scale with Strong Data Consistency](https://eng.uber.com/money-scale-strong-data/) `Uber` `2020`\n6. [Zipline - A Declarative Feature Engineering Framework](https://www.youtube.com/watch?v=LjcKCm0G_OY) `Airbnb` `2020`\n7. [Automating Data Protection at Scale, Part 1](https://medium.com/airbnb-engineering/automating-data-protection-at-scale-part-1-c74909328e08) ([Part 2](https://medium.com/airbnb-engineering/automating-data-protection-at-scale-part-2-c2b8d2068216)) `Airbnb` `2021`\n8. [Real-time Data Infrastructure at Uber](https://arxiv.org/pdf/2104.00087.pdf) `Uber` `2021`\n9. [Introducing Fabricator: A Declarative Feature Engineering Framework](https://doordash.engineering/2022/01/11/introducing-fabricator-a-declarative-feature-engineering-framework/) `DoorDash` `2022`\n10. [Functions & DAGs: introducing Hamilton, a microframework for dataframe generation](https://multithreaded.stitchfix.com/blog/2021/10/14/functions-dags-hamilton/) `Stitch Fix` `2021`\n11. [Optimizing Pinterest‚Äôs Data Ingestion Stack: Findings and Learnings](https://medium.com/@Pinterest_Engineering/optimizing-pinterests-data-ingestion-stack-findings-and-learnings-994fddb063bf) `Pinterest` `2022`\n12. [Lessons Learned From Running Apache Airflow at Scale](https://shopifyengineering.myshopify.com/blogs/engineering/lessons-learned-apache-airflow-scale) `Shopify` `2022`\n13. [Understanding Data Storage and Ingestion for Large-Scale Deep Recommendation Model Training](https://arxiv.org/abs/2108.09373v4) `Meta` `2022`\n14. [Data Mesh ‚Äî A Data Movement and Processing Platform @ Netflix](https://netflixtechblog.com/data-mesh-a-data-movement-and-processing-platform-netflix-1288bcab2873) `Netflix` `2022`\n15. [Building Scalable Real Time Event Processing with Kafka and Flink](https://doordash.engineering/2022/08/02/building-scalable-real-time-event-processing-with-kafka-and-flink/) `DoorDash` `2022`\n\n## Data Discovery\n1. [Apache Atlas: Data Goverance and Metadata Framework for Hadoop](https://atlas.apache.org/#/) ([Code](https://github.com/apache/atlas)) `Apache`\n2. [Collect, Aggregate, and Visualize a Data Ecosystem's Metadata](https://marquezproject.github.io/marquez/) ([Code](https://github.com/MarquezProject/marquez)) `WeWork`\n3. [Discovery and Consumption of Analytics Data at Twitter](https://blog.twitter.com/engineering/en_us/topics/insights/2016/discovery-and-consumption-of-analytics-data-at-twitter.html) `Twitter` `2016`\n4. [Democratizing Data at Airbnb](https://medium.com/airbnb-engineering/democratizing-data-at-airbnb-852d76c51770) `Airbnb` `2017`\n5. [Databook: Turning Big Data into Knowledge with Metadata at Uber](https://eng.uber.com/databook/) `Uber` `2018`\n6. [Metacat: Making Big Data Discoverable and Meaningful at Netflix](https://netflixtechblog.com/metacat-making-big-data-discoverable-and-meaningful-at-netflix-56fb36a53520) ([Code](https://github.com/Netflix/metacat)) `Netflix` `2018`\n7. [Amundsen ‚Äî Lyft‚Äôs Data Discovery & Metadata Engine](https://eng.lyft.com/amundsen-lyfts-data-discovery-metadata-engine-62d27254fbb9) `Lyft` `2019`\n8. [Open Sourcing Amundsen: A Data Discovery And Metadata Platform](https://eng.lyft.com/open-sourcing-amundsen-a-data-discovery-and-metadata-platform-2282bb436234) ([Code](https://github.com/lyft/amundsen)) `Lyft` `2019`\n9. [DataHub: A Generalized Metadata Search & Discovery Tool](https://engineering.linkedin.com/blog/2019/data-hub) ([Code](https://github.com/linkedin/datahub)) `LinkedIn` `2019`\n10. [Amundsen: One Year Later](https://eng.lyft.com/amundsen-1-year-later-7b60bf28602) `Lyft` `2020`\n11. [Using Amundsen to Support User Privacy via Metadata Collection at Square](https://developer.squareup.com/blog/using-amundsen-to-support-user-privacy-via-metadata-collection-at-square/) `Square` `2020`\n12. [Turning Metadata Into Insights with Databook](https://eng.uber.com/metadata-insights-databook/) `Uber` `2020`\n13. [DataHub: Popular Metadata Architectures Explained](https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained) `LinkedIn` `2020`\n14. [How We Improved Data Discovery for Data Scientists at Spotify](https://engineering.atspotify.com/2020/02/27/how-we-improved-data-discovery-for-data-scientists-at-spotify/) `Spotify` `2020` \n15. [How We‚Äôre Solving Data Discovery Challenges at Shopify](https://engineering.shopify.com/blogs/engineering/solving-data-discovery-challenges-shopify) `Shopify` `2020`\n16. [Nemo: Data discovery at Facebook](https://engineering.fb.com/data-infrastructure/nemo/) `Facebook` `2020`\n17. [Exploring Data @ Netflix](https://netflixtechblog.com/exploring-data-netflix-9d87e20072e3) ([Code](https://github.com/Netflix/nf-data-explorer)) `Netflix` `2021`\n\n## Feature Stores\n1. [Distributed Time Travel for Feature Generation](https://netflixtechblog.com/distributed-time-travel-for-feature-generation-389cccdd3907) `Netflix` `2016`\n2. [Building the Activity Graph, Part 2 (Feature Storage Section)](https://engineering.linkedin.com/blog/2017/07/building-the-activity-graph--part-2) `LinkedIn` `2017`\n3. [Fact Store at Scale for Netflix Recommendations](https://www.youtube.com/watch?v=DiwKg8KynVU) `Netflix` `2018`\n4. [Zipline: Airbnb‚Äôs Machine Learning Data Management Platform](https://www.youtube.com/watch?v=Tg5VEMEsC-0) `Airbnb` `2018`\n5. [Feature Store: The missing data layer for Machine Learning pipelines?](https://www.hopsworks.ai/post/feature-store-the-missing-data-layer-in-ml-pipelines) `Hopsworks` `2018`\n6. [Introducing Feast: An Open Source Feature Store for Machine Learning](https://cloud.google.com/blog/products/ai-machine-learning/introducing-feast-an-open-source-feature-store-for-machine-learning) ([Code](https://github.com/feast-dev/feast)) `Gojek` `2019`\n7. [Michelangelo Palette: A Feature Engineering Platform at Uber](https://www.infoq.com/presentations/michelangelo-palette-uber/) `Uber` `2019`\n8. [The Architecture That Powers Twitter's Feature Store](https://www.youtube.com/watch?v=UNailXoiIrY) `Twitter` `2019`\n9. [Accelerating Machine Learning with the Feature Store Service](https://technology.condenast.com/story/accelerating-machine-learning-with-the-feature-store-service) `Cond√© Nast` `2019` \n10. [Feast: Bridging ML Models and Data](https://www.gojek.io/blog/feast-bridging-ml-models-and-data) `Gojek` `2020`\n11. [Building a Scalable ML Feature Store with Redis, Binary Serialization, and Compression](https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/) `DoorDash` `2020`\n12. [Rapid Experimentation Through Standardization: Typed AI features for LinkedIn‚Äôs Feed](https://engineering.linkedin.com/blog/2020/feed-typed-ai-features) `LinkedIn` `2020`\n13. [Building a Feature Store](https://nlathia.github.io/2020/12/Building-a-feature-store.html) `Monzo Bank` `2020`\n14. [Butterfree: A Spark-based Framework for Feature Store Building](https://medium.com/quintoandar-tech-blog/butterfree-a-spark-based-framework-for-feature-store-building-48c3640522c7) ([Code](https://github.com/quintoandar/butterfree)) `QuintoAndar` `2020`\n15. [Building Riviera: A Declarative Real-Time Feature Engineering Framework](https://doordash.engineering/2021/03/04/building-a-declarative-real-time-feature-engineering-framework/) `DoorDash` `2021`\n16. [Optimal Feature Discovery: Better, Leaner Machine Learning Models Through Information Theory](https://eng.uber.com/optimal-feature-discovery-ml/) `Uber` `2021`\n17. [ML Feature Serving Infrastructure at Lyft](https://eng.lyft.com/ml-feature-serving-infrastructure-at-lyft-d30bf2d3c32a) `Lyft` `2021`\n18. [Near real-time features for near real-time personalization](https://engineering.linkedin.com/blog/2022/near-real-time-features-for-near-real-time-personalization) `LinkedIn` `2022`\n19. [Building the Model Behind DoorDash‚Äôs Expansive Merchant Selection](https://doordash.engineering/2022/04/19/building-merchant-selection/) `DoorDash` `2022`\n20. [Open sourcing Feathr ‚Äì LinkedIn‚Äôs feature store for productive machine learning](https://engineering.linkedin.com/blog/2022/open-sourcing-feathr---linkedin-s-feature-store-for-productive-m) `LinkedIn` `2022`\n21. [Evolution of ML Fact Store](https://netflixtechblog.com/evolution-of-ml-fact-store-5941d3231762) `Netflix` `2022`\n22. [Developing scalable feature engineering DAGs](https://outerbounds.com/blog/developing-scalable-feature-engineering-dags) `Metaflow + Hamilton` via `Outerbounds` `2022`\n23. [Feature Store Design at Constructor](https://medium.com/constructor-engineering/feature-store-design-at-constructor-330b65f64b18) `Constructor.io` `2023`\n\n\n## Classification\n1. [Prediction of Advertiser Churn for Google AdWords](https://research.google/pubs/pub36678/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36678.pdf)) `Google` `2010`\n2. [High-Precision Phrase-Based Document Classification on a Modern Scale](https://engineering.linkedin.com/research/2011/high-precision-phrase-based-document-classification-on-a-modern-scale) ([Paper](http://web.stanford.edu/~gavish/documents/phrase_based.pdf)) `LinkedIn` `2011`\n3. [Chimera: Large-scale Classification using Machine Learning, Rules, and Crowdsourcing](https://dl.acm.org/doi/10.14778/2733004.2733024) ([Paper](http://pages.cs.wisc.edu/%7Eanhai/papers/chimera-vldb14.pdf)) `Walmart` `2014`\n4. [Large-scale Item Categorization in e-Commerce Using Multiple Recurrent Neural Networks](https://www.kdd.org/kdd2016/subtopic/view/large-scale-item-categorization-in-e-commerce-using-multiple-recurrent-neur/) ([Paper](https://www.kdd.org/kdd2016/papers/files/adf0392-haAemb.pdf)) `NAVER` `2016`\n5. [Learning to Diagnose with LSTM Recurrent Neural Networks](https://arxiv.org/abs/1511.03677) ([Paper](https://arxiv.org/pdf/1511.03677.pdf)) `Google` `2017`\n6. [Discovering and Classifying In-app Message Intent at Airbnb](https://medium.com/airbnb-engineering/discovering-and-classifying-in-app-message-intent-at-airbnb-6a55f5400a0c) `Airbnb` `2019`\n7. [Teaching Machines to Triage Firefox Bugs](https://hacks.mozilla.org/2019/04/teaching-machines-to-triage-firefox-bugs/) `Mozilla` `2019`\n8. [Categorizing Products at Scale](https://engineering.shopify.com/blogs/engineering/categorizing-products-at-scale) `Shopify` `2020`\n9. [How We Built the Good First Issues Feature](https://github.blog/2020-01-22-how-we-built-good-first-issues/) `GitHub` `2020`\n10. [Testing Firefox More Efficiently with Machine Learning](https://hacks.mozilla.org/2020/07/testing-firefox-more-efficiently-with-machine-learning/) `Mozilla` `2020`\n11. [Using ML to Subtype Patients Receiving Digital Mental Health Interventions](https://www.microsoft.com/en-us/research/blog/a-path-to-personalization-using-ml-to-subtype-patients-receiving-digital-mental-health-interventions/) ([Paper](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2768347)) `Microsoft` `2020`\n12. [Scalable Data Classification for Security and Privacy](https://engineering.fb.com/security/data-classification-system/) ([Paper](https://arxiv.org/pdf/2006.14109.pdf)) `Facebook` `2020`\n13. [Uncovering Online Delivery Menu Best Practices with Machine Learning](https://doordash.engineering/2020/11/10/uncovering-online-delivery-menu-best-practices-with-machine-learning/) `DoorDash` `2020`\n14. [Using a Human-in-the-Loop to Overcome the Cold Start Problem in Menu Item Tagging](https://doordash.engineering/2020/08/28/overcome-the-cold-start-problem-in-menu-item-tagging/) `DoorDash` `2020`\n15. [Deep Learning: Product Categorization and Shelving](https://medium.com/walmartglobaltech/deep-learning-product-categorization-and-shelving-630571e81e96) `Walmart` `2021`\n16. [Large-scale Item Categorization for e-Commerce](https://dl.acm.org/doi/10.1145/2396761.2396838) ([Paper](https://www.researchgate.net/profile/Jean_David_Ruvini/publication/262270957_Large-scale_item_categorization_for_e-commerce/links/5512dc3d0cf270fd7e33a0d5/Large-scale-item-categorization-for-e-commerce.pdf)) `DianPing`, `eBay` `2012`\n17. [Semantic Label Representation with an Application on Multimodal Product Categorization](https://medium.com/walmartglobaltech/semantic-label-representation-with-an-application-on-multimodal-product-categorization-63d668b943b7) `Walmart` `2022`\n18. [Building Airbnb Categories with ML and Human-in-the-Loop](https://medium.com/airbnb-engineering/building-airbnb-categories-with-ml-and-human-in-the-loop-e97988e70ebb) `Airbnb` `2022`\n\n\n## Regression\n1. [Using Machine Learning to Predict Value of Homes On Airbnb](https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d) `Airbnb` `2017`\n2. [Using Machine Learning to Predict the Value of Ad Requests](https://blog.twitter.com/engineering/en_us/topics/insights/2020/using-machine-learning-to-predict-the-value-of-ad-requests.html) `Twitter` `2020`\n3. [Open-Sourcing Riskquant, a Library for Quantifying Risk](https://netflixtechblog.com/open-sourcing-riskquant-a-library-for-quantifying-risk-6720cc1e4968) ([Code](https://github.com/Netflix-Skunkworks/riskquant)) `Netflix` `2020`\n4. [Solving for Unobserved Data in a Regression Model Using a Simple Data Adjustment](https://doordash.engineering/2020/10/14/solving-for-unobserved-data-in-a-regression-model/) `DoorDash` `2020`\n\n## Forecasting\n1. [Engineering Extreme Event Forecasting at Uber with RNN](https://eng.uber.com/neural-networks/) `Uber` `2017`\n2. [Forecasting at Uber: An Introduction](https://eng.uber.com/forecasting-introduction/) `Uber` `2018`\n3. [Transforming Financial Forecasting with Data Science and Machine Learning at Uber](https://eng.uber.com/transforming-financial-forecasting-machine-learning/) `Uber` `2018`\n4. [Under the Hood of Gojek‚Äôs Automated Forecasting Tool](https://www.gojek.io/blog/under-the-hood-of-gojeks-automated-forecasting-tool) `Gojek` `2019`\n5. [BusTr: Predicting Bus Travel Times from Real-Time Traffic](https://dl.acm.org/doi/abs/10.1145/3394486.3403376) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403376), [Video](https://crossminds.ai/video/5f3369790576dd25aef288db/)) `Google` `2020`\n6. [Retraining Machine Learning Models in the Wake of COVID-19](https://doordash.engineering/2020/09/15/retraining-ml-models-covid-19/) `DoorDash` `2020`\n7. [Automatic Forecasting using Prophet, Databricks, Delta Lake and MLflow](https://www.youtube.com/watch?v=TkcpjnLh690) ([Paper](https://peerj.com/preprints/3190.pdf), [Code](https://github.com/facebook/prophet)) `Atlassian` `2020`\n8. [Introducing Orbit, An Open Source Package for Time Series Inference and Forecasting](https://eng.uber.com/orbit/) ([Paper](https://arxiv.org/abs/2004.08492), [Video](https://youtu.be/LXDpq_iwcWY), [Code](https://github.com/uber/orbit)) `Uber` `2021`\n9. [Managing Supply and Demand Balance Through Machine Learning](https://doordash.engineering/2021/06/29/managing-supply-and-demand-balance-through-machine-learning/) `DoorDash` `2021`\n10. [Greykite: A flexible, intuitive, and fast forecasting library](https://engineering.linkedin.com/blog/2021/greykite--a-flexible--intuitive--and-fast-forecasting-library) `LinkedIn` `2021`\n11. [The history of Amazon‚Äôs forecasting algorithm](https://www.amazon.science/latest-news/the-history-of-amazons-forecasting-algorithm) `Amazon` `2021`\n11. [DeepETA: How Uber Predicts Arrival Times Using Deep Learning](https://eng.uber.com/deepeta-how-uber-predicts-arrival-times/) `Uber` `2022`\n12. [Forecasting Grubhub Order Volume At Scale](https://bytes.grubhub.com/forecasting-grubhub-order-volume-at-scale-a966c2f901d2) `Grubhub` `2022`\n13. [Causal Forecasting at Lyft (Part 1)](https://eng.lyft.com/causal-forecasting-at-lyft-part-1-14cca6ff3d6d) `Lyft` `2022`\n\n## Recommendation\n1. [Amazon.com Recommendations: Item-to-Item Collaborative Filtering](https://ieeexplore.ieee.org/document/1167344) ([Paper](https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf)) `Amazon` `2003`\n2. [Netflix Recommendations: Beyond the 5 stars (Part 1](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429) ([Part 2](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5)) `Netflix` `2012`\n3. [How Music Recommendation Works ‚Äî And Doesn‚Äôt Work](https://notes.variogram.com/2012/12/11/how-music-recommendation-works-and-doesnt-work/) `Spotify` `2012`\n4. [Learning to Rank Recommendations with the k -Order Statistic Loss](https://dl.acm.org/doi/10.1145/2507157.2507210) ([Paper](https://dl.acm.org/doi/pdf/10.1145/2507157.2507210)) `Google` `2013`\n5. [Recommending Music on Spotify with Deep Learning](https://benanne.github.io/2014/08/05/spotify-cnns.html) `Spotify` `2014`\n6. [Learning a Personalized Homepage](https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a) `Netflix` `2015`\n7. [The Netflix Recommender System: Algorithms, Business Value, and Innovation](https://dl.acm.org/doi/10.1145/2843948) ([Paper](https://dl.acm.org/doi/pdf/10.1145/2843948)) `Netflix` `2015`\n7. [Session-based Recommendations with Recurrent Neural Networks](https://arxiv.org/abs/1511.06939) ([Paper](https://arxiv.org/pdf/1511.06939.pdf)) `Telefonica` `2016`\n8. [Deep Neural Networks for YouTube Recommendations](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf) `YouTube` `2016`\n9. [E-commerce in Your Inbox: Product Recommendations at Scale](https://arxiv.org/abs/1606.07154) ([Paper](https://arxiv.org/pdf/1606.07154.pdf)) `Yahoo` `2016`\n10. [To Be Continued: Helping you find shows to continue watching on Netflix](https://netflixtechblog.com/to-be-continued-helping-you-find-shows-to-continue-watching-on-7c0d8ee4dab6) `Netflix` `2016`\n11. [Personalized Recommendations in LinkedIn Learning](https://engineering.linkedin.com/blog/2016/12/personalized-recommendations-in-linkedin-learning) `LinkedIn` `2016`\n12. [Personalized Channel Recommendations in Slack](https://slack.engineering/personalized-channel-recommendations-in-slack/) `Slack` `2016`\n13. [Recommending Complementary Products in E-Commerce Push Notifications](https://arxiv.org/abs/1707.08113) ([Paper](https://arxiv.org/pdf/1707.08113.pdf)) `Alibaba` `2017`\n14. [Artwork Personalization at Netflix](https://netflixtechblog.com/artwork-personalization-c589f074ad76) `Netflix` `2017`\n15. [A Meta-Learning Perspective on Cold-Start Recommendations for Items](https://papers.nips.cc/paper/7266-a-meta-learning-perspective-on-cold-start-recommendations-for-items) ([Paper](https://papers.nips.cc/paper/7266-a-meta-learning-perspective-on-cold-start-recommendations-for-items.pdf)) `Twitter` `2017`\n16. [Pixie: A System for Recommending 3+ Billion Items to 200+ Million Users in Real-Time](https://arxiv.org/abs/1711.07601) ([Paper](https://arxiv.org/pdf/1711.07601.pdf)) `Pinterest` `2017`\n17. [Powering Search & Recommendations at DoorDash](https://doordash.news/company/powering-search-recommendations-at-doordash/) `DoorDash` `2017`\n17. [How 20th Century Fox uses ML to predict a movie audience](https://cloud.google.com/blog/products/ai-machine-learning/how-20th-century-fox-uses-ml-to-predict-a-movie-audience) ([Paper](https://arxiv.org/abs/1810.08189)) `20th Century Fox` `2018`\n18. [Calibrated Recommendations](https://dl.acm.org/doi/10.1145/3240323.3240372) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3240323.3240372)) `Netflix` `2018`\n19. [Food Discovery with Uber Eats: Recommending for the Marketplace](https://eng.uber.com/uber-eats-recommending-marketplace/) `Uber` `2018`\n20. [Explore, Exploit, and Explain: Personalizing Explainable Recommendations with Bandits](https://dl.acm.org/doi/10.1145/3240323.3240354) ([Paper](https://static1.squarespace.com/static/5ae0d0b48ab7227d232c2bea/t/5ba849e3c83025fa56814f45/1537755637453/BartRecSys.pdf)) `Spotify` `2018`\n21. [Talent Search and Recommendation Systems at LinkedIn: Practical Challenges and Lessons Learned](https://arxiv.org/abs/1809.06481) ([Paper](https://arxiv.org/pdf/1809.06481.pdf)) `LinkedIn` `2018`\n21. [Behavior Sequence Transformer for E-commerce Recommendation in Alibaba](https://arxiv.org/abs/1905.06874) ([Paper](https://arxiv.org/pdf/1905.06874.pdf)) `Alibaba` `2019`\n22. [SDM: Sequential Deep Matching Model for Online Large-scale Recommender System](https://arxiv.org/abs/1909.00385) ([Paper](https://arxiv.org/pdf/1909.00385.pdf)) `Alibaba` `2019`\n23. [Multi-Interest Network with Dynamic Routing for Recommendation at Tmall](https://arxiv.org/abs/1904.08030) ([Paper](https://arxiv.org/pdf/1904.08030.pdf)) `Alibaba` `2019`\n24. [Personalized Recommendations for Experiences Using Deep Learning](https://www.tripadvisor.com/engineering/personalized-recommendations-for-experiences-using-deep-learning/) `TripAdvisor` `2019`\n25. [Powered by AI: Instagram‚Äôs Explore recommender system](https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/) `Facebook` `2019`\n26. [Marginal Posterior Sampling for Slate Bandits](https://www.ijcai.org/proceedings/2019/308) ([Paper](https://www.ijcai.org/proceedings/2019/0308.pdf)) `Netflix` `2019`\n27. [Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations](https://eng.uber.com/uber-eats-graph-learning/) `Uber` `2019`\n28. [Music recommendation at Spotify](http://sigir.org/afirm2019/slides/16.%20Friday%20-%20Music%20Recommendation%20at%20Spotify%20-%20Ben%20Carterette.pdf) `Spotify` `2019`\n29. [Using Machine Learning to Predict what File you Need Next (Part 1)](https://dropbox.tech/machine-learning/content-suggestions-machine-learning) `Dropbox` `2019`\n30. [Using Machine Learning to Predict what File you Need Next (Part 2)](https://dropbox.tech/machine-learning/using-machine-learning-to-predict-what-file-you-need-next-part-2) `Dropbox` `2019`\n31. [Learning to be Relevant: Evolution of a Course Recommendation System](https://dl.acm.org/doi/pdf/10.1145/3357384.3357817) (**PAPER NEEDED**)`LinkedIn` `2019`\n32. [Temporal-Contextual Recommendation in Real-Time](https://www.amazon.science/publications/temporal-contextual-recommendation-in-real-time) ([Paper](https://assets.amazon.science/96/71/d1f25754497681133c7aa2b7eb05/temporal-contextual-recommendation-in-real-time.pdf)) `Amazon` `2020`\n33. [P-Companion: A Framework for Diversified Complementary Product Recommendation](https://www.amazon.science/publications/p-companion-a-principled-framework-for-diversified-complementary-product-recommendation) ([Paper](https://assets.amazon.science/d5/16/3f7809974a899a11bacdadefdf24/p-companion-a-principled-framework-for-diversified-complementary-product-recommendation.pdf)) `Amazon` `2020`\n34. [Deep Interest with Hierarchical Attention Network for Click-Through Rate Prediction](https://arxiv.org/abs/2005.12981) ([Paper](https://arxiv.org/pdf/2005.12981.pdf)) `Alibaba` `2020`\n35. [TPG-DNN: A Method for User Intent Prediction with Multi-task Learning](https://arxiv.org/abs/2008.02122) ([Paper](https://arxiv.org/pdf/2008.02122.pdf)) `Alibaba` `2020`\n36. [PURS: Personalized Unexpected Recommender System for Improving User Satisfaction](https://dl.acm.org/doi/10.1145/3383313.3412238) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3383313.3412238)) `Alibaba` `2020`\n37. [Controllable Multi-Interest Framework for Recommendation](https://arxiv.org/abs/2005.09347) ([Paper](https://arxiv.org/pdf/2005.09347)) `Alibaba` `2020`\n38. [MiNet: Mixed Interest Network for Cross-Domain Click-Through Rate Prediction](https://arxiv.org/abs/2008.02974) ([Paper](https://arxiv.org/pdf/2008.02974.pdf)) `Alibaba` `2020`\n39. [ATBRG: Adaptive Target-Behavior Relational Graph Network for Effective Recommendation](https://arxiv.org/abs/2005.12002) ([Paper](https://arxiv.org/pdf/2005.12002.pdf)) `Alibaba` `2020`\n40. [For Your Ears Only: Personalizing Spotify Home with Machine Learning](https://engineering.atspotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/) `Spotify` `2020`\n41. [Reach for the Top: How Spotify Built Shortcuts in Just Six Months](https://engineering.atspotify.com/2020/04/15/reach-for-the-top-how-spotify-built-shortcuts-in-just-six-months/) `Spotify` `2020`\n42. [Contextual and Sequential User Embeddings for Large-Scale Music Recommendation](https://dl.acm.org/doi/10.1145/3383313.3412248) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3383313.3412248)) `Spotify` `2020`\n43. [The Evolution of Kit: Automating Marketing Using Machine Learning](https://engineering.shopify.com/blogs/engineering/evolution-kit-automating-marketing-machine-learning) `Shopify` `2020`\n44. [A Closer Look at the AI Behind Course Recommendations on LinkedIn Learning (Part 1)](https://engineering.linkedin.com/blog/2020/course-recommendations-ai-part-one) `LinkedIn` `2020`\n45. [A Closer Look at the AI Behind Course Recommendations on LinkedIn Learning (Part 2)](https://engineering.linkedin.com/blog/2020/course-recommendations-ai-part-two) `LinkedIn` `2020`\n46. [Building a Heterogeneous Social Network Recommendation System](https://engineering.linkedin.com/blog/2020/building-a-heterogeneous-social-network-recommendation-system) `LinkedIn` `2020`\n47. [How TikTok recommends videos #ForYou](https://newsroom.tiktok.com/en-us/how-tiktok-recommends-videos-for-you) `ByteDance` `2020`\n48. [Zero-Shot Heterogeneous Transfer Learning from RecSys to Cold-Start Search Retrieval](https://arxiv.org/abs/2008.02930) ([Paper](https://arxiv.org/pdf/2008.02930.pdf)) `Google` `2020`\n49. [Improved Deep & Cross Network for Feature Cross Learning in Web-scale LTR Systems](https://arxiv.org/abs/2008.13535) ([Paper](https://arxiv.org/pdf/2008.13535.pdf)) `Google` `2020`\n50. [Mixed Negative Sampling for Learning Two-tower Neural Networks in Recommendations](https://research.google/pubs/pub50257/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/b9f4e78a8830fe5afcf2f0452862fb3c0d6584ea.pdf)) `Google` `2020`\n51. [Future Data Helps Training: Modeling Future Contexts for Session-based Recommendation](https://arxiv.org/pdf/1906.04473.pdf) ([Paper](https://arxiv.org/pdf/1906.04473.pdf)) `Tencent` `2020`\n52. [A Case Study of Session-based Recommendations in the Home-improvement Domain](https://dl.acm.org/doi/10.1145/3383313.3412235) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3383313.3412235)) `Home Depot` `2020`\n53. [Balancing Relevance and Discovery to Inspire Customers in the IKEA App](https://dl.acm.org/doi/10.1145/3383313.3411550) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3383313.3411550)) `Ikea` `2020`\n54. [How we use AutoML, Multi-task learning and Multi-tower models for Pinterest Ads](https://medium.com/pinterest-engineering/how-we-use-automl-multi-task-learning-and-multi-tower-models-for-pinterest-ads-db966c3dc99e) `Pinterest` `2020`\n55. [Multi-task Learning for Related Products Recommendations at Pinterest](https://medium.com/pinterest-engineering/multi-task-learning-for-related-products-recommendations-at-pinterest-62684f631c12) `Pinterest` `2020`\n56. [Improving the Quality of Recommended Pins with Lightweight Ranking](https://medium.com/pinterest-engineering/improving-the-quality-of-recommended-pins-with-lightweight-ranking-8ff5477b20e3) `Pinterest` `2020`\n57. [Multi-task Learning and Calibration for Utility-based Home Feed Ranking](https://medium.com/pinterest-engineering/multi-task-learning-and-calibration-for-utility-based-home-feed-ranking-64087a7bcbad) `Pinterest` `2020`\n57. [Personalized Cuisine Filter Based on Customer Preference and Local Popularity](https://doordash.engineering/2020/01/27/personalized-cuisine-filter/) `DoorDash` `2020`\n58. [How We Built a Matchmaking Algorithm to Cross-Sell Products](https://www.gojek.io/blog/how-we-built-a-matchmaking-algorithm-to-cross-sell-products) `Gojek` `2020`\n59. [Lessons Learned Addressing Dataset Bias in Model-Based Candidate Generation](https://arxiv.org/abs/2105.09293) ([Paper](https://arxiv.org/pdf/2105.09293.pdf)) `Twitter` `2021`\n60. [Self-supervised Learning for Large-scale Item Recommendations](https://arxiv.org/abs/2007.12865) ([Paper](https://arxiv.org/pdf/2007.12865.pdf)) `Google` `2021`\n61. [Deep Retrieval: End-to-End Learnable Structure Model for Large-Scale Recommendations](https://arxiv.org/abs/2007.07203) ([Paper](https://arxiv.org/pdf/2007.07203.pdf)) `ByteDance` `2021`\n62. [Using AI to Help Health Experts Address the COVID-19 Pandemic](https://ai.facebook.com/blog/using-ai-to-help-health-experts-address-the-covid-19-pandemic/) `Facebook` `2021`\n63. [Advertiser Recommendation Systems at Pinterest](https://medium.com/pinterest-engineering/advertiser-recommendation-systems-at-pinterest-ccb255fbde20) `Pinterest` `2021`\n64. [On YouTube's Recommendation System](https://blog.youtube/inside-youtube/on-youtubes-recommendation-system/) `YouTube` `2021`\n65. [\"Are you sure?\": Preliminary Insights from Scaling Product Comparisons to Multiple Shops](https://arxiv.org/abs/2107.03256) `Coveo` `2021`\n66. [Mozrt, a Deep Learning Recommendation System Empowering Walmart Store Associates](https://medium.com/walmartglobaltech/mozrt-a-deep-learning-recommendation-system-empowering-walmart-store-associates-with-a-5d42c08d88da) `Walmart` `2021`\n67. [Understanding Data Storage and Ingestion for Large-Scale Deep Recommendation Model Training](https://arxiv.org/abs/2108.09373) ([Paper](https://arxiv.org/pdf/2108.09373.pdf)) `Meta` `2021`\n67. [The Amazon Music conversational recommender is hitting the right notes](https://www.amazon.science/latest-news/how-amazon-music-uses-recommendation-system-machine-learning) `Amazon` `2022`\n68. [Personalized complementary product recommendation](https://www.amazon.science/publications/personalized-complementary-product-recommendation) ([Paper](https://assets.amazon.science/6c/d9/a0ec3eda4f0fb4312ce0ada41771/personalized-complementary-product-recommendation.pdf)) `Amazon` `2022`\n69. [Building a Deep Learning Based Retrieval System for Personalized Recommendations](https://tech.ebayinc.com/engineering/building-a-deep-learning-based-retrieval-system-for-personalized-recommendations/) `eBay` `2022`\n70. [How We Built: An Early-Stage Machine Learning Model for Recommendations](https://www.onepeloton.com/press/articles/how-we-built-machine-learning) `Peloton` `2022`\n71. [Lessons Learned from Building out Context-Aware Recommender Systems](https://www.onepeloton.com/press/articles/lessons-learned-from-building-context-aware-recommender-systems) `Peloton` `2022`\n72. [Beyond Matrix Factorization: Using hybrid features for user-business recommendations](https://engineeringblog.yelp.com/2022/04/beyond-matrix-factorization-using-hybrid-features-for-user-business-recommendations.html) `Yelp` `2022`\n73. [Improving job matching with machine-learned activity features](https://engineering.linkedin.com/blog/2022/improving-job-matching-with-machine-learned-activity-features-) `LinkedIn` `2022`\n74. [Understanding Data Storage and Ingestion for Large-Scale Deep Recommendation Model Training](https://arxiv.org/abs/2108.09373v4) `Meta` `2022`\n75. [Blueprints for recommender system architectures: 10th anniversary edition](https://amatriain.net/blog/RecsysArchitectures) `Xavier Amatriain` `2022`\n76. [How Pinterest Leverages Realtime User Actions in Recommendation to Boost Homefeed Engagement Volume](https://medium.com/pinterest-engineering/how-pinterest-leverages-realtime-user-actions-in-recommendation-to-boost-homefeed-engagement-volume-165ae2e8cde8) `Pinterest` `2022`\n77. [RecSysOps: Best Practices for Operating a Large-Scale Recommender System](https://netflixtechblog.medium.com/recsysops-best-practices-for-operating-a-large-scale-recommender-system-95bbe195a841) `Netflix` `2022`\n78. [Recommend API: Unified end-to-end machine learning infrastructure to generate recommendations](https://slack.engineering/recommend-api/) `Slack` `2022`\n79. [Evolving DoorDash‚Äôs Substitution Recommendations Algorithm](https://doordash.engineering/2022/09/08/evolving-doordashs-substitution-recommendations-algorithm/) `DoorDash` `2022`\n80. [Homepage Recommendation with Exploitation and Exploration](https://doordash.engineering/2022/10/05/homepage-recommendation-with-exploitation-and-exploration/) `DoorDash` `2022`\n81. [GPU-accelerated ML Inference at Pinterest](https://medium.com/@Pinterest_Engineering/gpu-accelerated-ml-inference-at-pinterest-ad1b6a03a16d) `Pinterest` `2022`\n82. [Addressing Confounding Feature Issue for Causal Recommendation](https://arxiv.org/abs/2205.06532) ([Paper](https://arxiv.org/pdf/2205.06532.pdf)) `Tencent` `2022`\n\n\n## Search & Ranking\n1. [Amazon Search: The Joy of Ranking Products](https://www.amazon.science/publications/amazon-search-the-joy-of-ranking-products) ([Paper](https://assets.amazon.science/89/cd/34289f1f4d25b5857d776bdf04d5/amazon-search-the-joy-of-ranking-products.pdf), [Video](https://www.youtube.com/watch?v=NLrhmn-EZ88), [Code](https://github.com/dariasor/TreeExtra)) `Amazon` `2016`\n2. [How Lazada Ranks Products to Improve Customer Experience and Conversion](https://www.slideshare.net/eugeneyan/how-lazada-ranks-products-to-improve-customer-experience-and-conversion) `Lazada` `2016`\n3. [Ranking Relevance in Yahoo Search](https://www.kdd.org/kdd2016/subtopic/view/ranking-relevance-in-yahoo-search) ([Paper](https://www.kdd.org/kdd2016/papers/files/adf0361-yinA.pdf)) `Yahoo` `2016`\n4. [Learning to Rank Personalized Search Results in Professional Networks](https://arxiv.org/abs/1605.04624) ([Paper](https://arxiv.org/pdf/1605.04624.pdf)) `LinkedIn` `2016`\n5. [Using Deep Learning at Scale in Twitter‚Äôs Timelines](https://blog.twitter.com/engineering/en_us/topics/insights/2017/using-deep-learning-at-scale-in-twitters-timelines.html) `Twitter` `2017`\n6. [An Ensemble-based Approach to Click-Through Rate Prediction for Promoted Listings at Etsy](https://arxiv.org/abs/1711.01377) ([Paper](https://arxiv.org/pdf/1711.01377.pdf)) `Etsy` `2017`\n7. [Powering Search & Recommendations at DoorDash](https://doordash.engineering/2017/07/06/powering-search-recommendations-at-doordash/) `DoorDash` `2017`\n8. [Applying Deep Learning To Airbnb Search](https://arxiv.org/abs/1810.09591) ([Paper](https://arxiv.org/pdf/1810.09591.pdf)) `Airbnb` `2018`\n9. [In-session Personalization for Talent Search](https://arxiv.org/abs/1809.06488) ([Paper](https://arxiv.org/pdf/1809.06488.pdf)) `LinkedIn` `2018`\n10. [Talent Search and Recommendation Systems at LinkedIn](https://arxiv.org/abs/1809.06481) ([Paper](https://arxiv.org/pdf/1809.06481.pdf)) `LinkedIn` `2018`\n11. [Food Discovery with Uber Eats: Building a Query Understanding Engine](https://eng.uber.com/uber-eats-query-understanding/) `Uber` `2018`\n12. [Globally Optimized Mutual Influence Aware Ranking in E-Commerce Search](https://arxiv.org/abs/1805.08524) ([Paper](https://arxiv.org/pdf/1805.08524.pdf)) `Alibaba` `2018`\n13. [Reinforcement Learning to Rank in E-Commerce Search Engine](https://arxiv.org/abs/1803.00710) ([Paper](https://arxiv.org/pdf/1803.00710.pdf)) `Alibaba` `2018`\n14. [Semantic Product Search](https://arxiv.org/abs/1907.00937) ([Paper](https://arxiv.org/pdf/1907.00937.pdf)) `Amazon` `2019`\n15. [Machine Learning-Powered Search Ranking of Airbnb Experiences](https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789) `Airbnb` `2019`\n16. [Entity Personalized Talent Search Models with Tree Interaction Features](https://arxiv.org/abs/1902.09041) ([Paper](https://arxiv.org/pdf/1902.09041.pdf)) `LinkedIn` `2019`\n17. [The AI Behind LinkedIn Recruiter Search and recommendation systems](https://engineering.linkedin.com/blog/2019/04/ai-behind-linkedin-recruiter-search-and-recommendation-systems) `LinkedIn` `2019`\n18. [Learning Hiring Preferences: The AI Behind LinkedIn Jobs](https://engineering.linkedin.com/blog/2019/02/learning-hiring-preferences--the-ai-behind-linkedin-jobs) `LinkedIn` `2019`\n19. [The Secret Sauce Behind Search Personalisation](https://www.gojek.io/blog/the-secret-sauce-behind-search-personalisation) `Gojek` `2019`\n20. [Neural Code Search: ML-based Code Search Using Natural Language Queries](https://ai.facebook.com/blog/neural-code-search-ml-based-code-search-using-natural-language-queries/) `Facebook` `2019`\n21. [Aggregating Search Results from Heterogeneous Sources via Reinforcement Learning](https://arxiv.org/abs/1902.08882) ([Paper](https://arxiv.org/pdf/1902.08882.pdf)) `Alibaba` `2019`\n22. [Cross-domain Attention Network with Wasserstein Regularizers for E-commerce Search](https://dl.acm.org/doi/10.1145/3357384.3357809) `Alibaba` `2019`\n23. [Understanding Searches Better Than Ever Before](https://www.blog.google/products/search/search-language-understanding-bert/) ([Paper](https://arxiv.org/pdf/1810.04805.pdf)) `Google` `2019`\n24. [How We Used Semantic Search to Make Our Search 10x Smarter](https://medium.com/tokopedia-engineering/how-we-used-semantic-search-to-make-our-search-10x-smarter-bd9c7f601821) `Tokopedia` `2019`\n25. [Query2vec: Search query expansion with query embeddings](https://bytes.grubhub.com/search-query-embeddings-using-query2vec-f5931df27d79) `GrubHub` `2019`\n26. [MOBIUS: Towards the Next Generation of Query-Ad Matching in Baidu‚Äôs Sponsored Search](http://research.baidu.com/Public/uploads/5d12eca098d40.pdf) `Baidu` `2019`\n27. [Why Do People Buy Seemingly Irrelevant Items in Voice Product Search?](https://www.amazon.science/publications/why-do-people-buy-irrelevant-items-in-voice-product-search) ([Paper](https://assets.amazon.science/f7/48/0562b2c14338a0b76ccf4f523fa5/why-do-people-buy-irrelevant-items-in-voice-product-search.pdf)) `Amazon` `2020`\n28. [Managing Diversity in Airbnb Search](https://arxiv.org/abs/2004.02621) ([Paper](https://arxiv.org/pdf/2004.02621.pdf)) `Airbnb` `2020`\n29. [Improving Deep Learning for Airbnb Search](https://arxiv.org/abs/2002.05515) ([Paper](https://arxiv.org/pdf/2002.05515.pdf)) `Airbnb` `2020`\n30. [Quality Matches Via Personalized AI for Hirer and Seeker Preferences](https://engineering.linkedin.com/blog/2020/quality-matches-via-personalized-ai) `LinkedIn` `2020`\n31. [Understanding Dwell Time to Improve LinkedIn Feed Ranking](https://engineering.linkedin.com/blog/2020/understanding-feed-dwell-time) `LinkedIn` `2020`\n32. [Ads Allocation in Feed via Constrained Optimization](https://dl.acm.org/doi/abs/10.1145/3394486.3403391) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403391), [Video](https://crossminds.ai/video/5f33697a0576dd25aef288ea/)) `LinkedIn` `2020`\n33. [Understanding Dwell Time to Improve LinkedIn Feed Ranking](https://engineering.linkedin.com/blog/2020/understanding-feed-dwell-time) `LinkedIn` `2020`\n34. [AI at Scale in Bing](https://blogs.bing.com/search/2020_05/AI-at-Scale-in-Bing) `Microsoft` `2020`\n35. [Query Understanding Engine in Traveloka Universal Search](https://medium.com/traveloka-engineering/query-understanding-engine-in-traveloka-universal-search-410ad3895db7) `Traveloka` `2020`\n36. [Bayesian Product Ranking at Wayfair](https://tech.wayfair.com/data-science/2020/01/bayesian-product-ranking-at-wayfair) `Wayfair` `2020`\n37. [COLD: Towards the Next Generation of Pre-Ranking System](https://arxiv.org/abs/2007.16122) ([Paper](https://arxiv.org/pdf/2007.16122.pdf)) `Alibaba` `2020`\n38. [Shop The Look: Building a Large Scale Visual Shopping System at Pinterest](https://dl.acm.org/doi/abs/10.1145/3394486.3403372) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403372), [Video](https://crossminds.ai/video/5f3369790576dd25aef288d7/)) `Pinterest` `2020`\n39. [Driving Shopping Upsells from Pinterest Search](https://medium.com/pinterest-engineering/driving-shopping-upsells-from-pinterest-search-d06329255402) `Pinterest` `2020`\n40. [GDMix: A Deep Ranking Personalization Framework](https://engineering.linkedin.com/blog/2020/gdmix--a-deep-ranking-personalization-framework) ([Code](https://github.com/linkedin/gdmix)) `LinkedIn` `2020`\n41. [Bringing Personalized Search to Etsy](https://codeascraft.com/2020/10/29/bringing-personalized-search-to-etsy/) `Etsy` `2020`\n42. [Building a Better Search Engine for Semantic Scholar](https://medium.com/ai2-blog/building-a-better-search-engine-for-semantic-scholar-ea23a0b661e7) `Allen Institute for AI` `2020`\n43. [Query Understanding for Natural Language Enterprise Search](https://arxiv.org/abs/2012.06238) ([Paper](https://arxiv.org/pdf/2012.06238.pdf)) `Salesforce` `2020`\n44. [Things Not Strings: Understanding Search Intent with Better Recall](https://doordash.engineering/2020/12/15/understanding-search-intent-with-better-recall/) `DoorDash` `2020`\n45. [Query Understanding for Surfacing Under-served Music Content](https://research.atspotify.com/publications/query-understanding-for-surfacing-under-served-music-content/) ([Paper](https://labtomarket.files.wordpress.com/2020/08/cikm2020.pdf)) `Spotify` `2020`\n46. [Embedding-based Retrieval in Facebook Search](https://arxiv.org/abs/2006.11632) ([Paper](https://arxiv.org/pdf/2006.11632.pdf)) `Facebook` `2020`\n47. [Towards Personalized and Semantic Retrieval for E-commerce Search via Embedding Learning](https://arxiv.org/abs/2006.02282) ([Paper](https://arxiv.org/pdf/2006.02282.pdf)) `JD` `2020`\n48. [QUEEN: Neural query rewriting in e-commerce](https://www.amazon.science/publications/queen-neural-query-rewriting-in-e-commerce) ([Paper](https://assets.amazon.science/f9/78/dda8f1e143dba8ca96e43ec487c6/queen-neural-query-rewriting-in-ecommerce.pdf)) `Amazon` `2021`\n49. [Using Learning-to-rank to Precisely Locate Where to Deliver Packages](https://www.amazon.science/blog/using-learning-to-rank-to-precisely-locate-where-to-deliver-packages) ([Paper](https://www.amazon.science/publications/getting-your-package-to-the-right-place-supervised-machine-learning-for-geolocation)) `Amazon` `2021`\n50. [Seasonal relevance in e-commerce search](https://www.amazon.science/publications/seasonal-relevance-in-e-commerce-search) ([Paper](https://assets.amazon.science/ac/5e/d47612a846d6bec15738d7c8ab40/seasonal-relevance-in-ecommerce-search.pdf)) `Amazon` `2021`\n51. [Graph Intention Network for Click-through Rate Prediction in Sponsored Search](https://arxiv.org/abs/2103.16164) ([Paper](https://arxiv.org/pdf/2103.16164.pdf)) `Alibaba` `2021`\n52. [How We Built A Context-Specific Bidding System for Etsy Ads](https://codeascraft.com/2021/03/23/how-we-built-a-context-specific-bidding-system-for-etsy-ads/) `Etsy` `2021`\n53. [Pre-trained Language Model based Ranking in Baidu Search](https://arxiv.org/abs/2105.11108) ([Paper](https://arxiv.org/pdf/2105.11108.pdf)) `Baidu` `2021`\n54. [Stitching together spaces for query-based recommendations](https://multithreaded.stitchfix.com/blog/2021/08/13/stitching-together-spaces-for-query-based-recommendations/) `Stitch Fix` `2021`\n55. [Deep Natural Language Processing for LinkedIn Search Systems](https://arxiv.org/abs/2108.08252) ([Paper](https://arxiv.org/pdf/2108.08252.pdf)) `LinkedIn` `2021`\n56. [Siamese BERT-based Model for Web Search Relevance Ranking](https://arxiv.org/abs/2112.01810) ([Paper](https://arxiv.org/pdf/2112.01810.pdf), [Code](https://github.com/seznam/DaReCzech)) `Seznam` `2021`\n57. [SearchSage: Learning Search Query Representations at Pinterest](https://medium.com/pinterest-engineering/searchsage-learning-search-query-representations-at-pinterest-654f2bb887fc) `Pinterest` `2021`\n58. [Query2Prod2Vec: Grounded Word Embeddings for eCommerce](https://aclanthology.org/2021.naacl-industry.20/) `Coveo` `2021`\n59. [3 Changes to Expand DoorDash‚Äôs Product Search Beyond Delivery](https://doordash.engineering/2022/05/10/3-changes-to-expand-doordashs-product-search/) `DoorDash` `2022`\n60. [Learning To Rank Diversely](https://medium.com/airbnb-engineering/learning-to-rank-diversely-add6b1929621) `Airbnb` `2022`\n61. [How to Optimise Rankings with Cascade Bandits](https://medium.com/expedia-group-tech/how-to-optimise-rankings-with-cascade-bandits-5d92dfa0f16b) `Expedia` `2022`\n62. [A Guide to Google Search Ranking Systems](https://developers.google.com/search/docs/appearance/ranking-systems-guide) `Google` `2022` \n63. [Deep Learning for Search Ranking at Etsy](https://www.etsy.com/codeascraft/deep-learning-for-search-ranking-at-etsy) `Etsy` `2022`\n64. [Search at Calm](https://eng.calm.com/posts/search-at-calm) `Calm` `2022`\n\n## Embeddings\n1. [Vector Representation Of Items, Customer And Cart To Build A Recommendation System](https://arxiv.org/abs/1705.06338) ([Paper](https://arxiv.org/pdf/1705.06338.pdf)) `Sears` `2017`\n2. [Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba](https://arxiv.org/abs/1803.02349) ([Paper](https://arxiv.org/pdf/1803.02349.pdf)) `Alibaba` `2018`\n3. [Embeddings@Twitter](https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html) `Twitter` `2018`\n4. [Listing Embeddings in Search Ranking](https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e) ([Paper](https://www.kdd.org/kdd2018/accepted-papers/view/real-time-personalization-using-embeddings-for-search-ranking-at-airbnb)) `Airbnb` `2018`\n5. [Understanding Latent Style](https://multithreaded.stitchfix.com/blog/2018/06/28/latent-style/) `Stitch Fix` `2018`\n6. [Towards Deep and Representation Learning for Talent Search at LinkedIn](https://arxiv.org/abs/1809.06473) ([Paper](https://arxiv.org/pdf/1809.06473.pdf)) `LinkedIn` `2018`\n7. [Personalized Store Feed with Vector Embeddings](https://doordash.engineering/2018/04/02/personalized-store-feed-with-vector-embeddings/) `DoorDash` `2018`\n8. [Should we Embed? A Study on Performance of Embeddings for Real-Time Recommendations](https://arxiv.org/abs/1907.06556)([Paper](https://arxiv.org/pdf/1907.06556.pdf)) `Moshbit` `2019`\n9. [Machine Learning for a Better Developer Experience](https://netflixtechblog.com/machine-learning-for-a-better-developer-experience-1e600c69f36c) `Netflix` `2020`\n10. [Announcing ScaNN: Efficient Vector Similarity Search](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) ([Paper](https://arxiv.org/pdf/1908.10396.pdf), [Code](https://github.com/google-research/google-research/tree/master/scann)) `Google` `2020`\n11. [BERT Goes Shopping: Comparing Distributional Models for Product Representations](https://aclanthology.org/2021.ecnlp-1.1/) `Coveo` `2021`\n12. [The Embeddings That Came in From the Cold: Improving Vectors for New and Rare Products with Content-Based Inference](https://dl.acm.org/doi/10.1145/3383313.3411477) `Coveo` `2022`\n13. [Embedding-based Retrieval at Scribd](https://tech.scribd.com/blog/2021/embedding-based-retrieval-scribd.html) `Scribd` `2021`\n14. [Multi-objective Hyper-parameter Optimization of Behavioral Song Embeddings](https://arxiv.org/abs/2208.12724) ([Paper](https://arxiv.org/pdf/2208.12724.pdf)) `Apple` `2022`\n15. [Embeddings at Spotify's Scale - How Hard Could It Be?](https://arize.com/resource/embeddings-at-scale-spotify-recsys/) `Spotify` `2023`\n\n## Natural Language Processing\n1. [Abusive Language Detection in Online User Content](https://dl.acm.org/doi/10.1145/2872427.2883062) ([Paper](http://www.yichang-cs.com/yahoo/WWW16_Abusivedetection.pdf)) `Yahoo` `2016`\n2. [Smart Reply: Automated Response Suggestion for Email](https://research.google/pubs/pub45189/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45189.pdf)) `Google` `2016` \n3. [Building Smart Replies for Member Messages](https://engineering.linkedin.com/blog/2017/10/building-smart-replies-for-member-messages) `LinkedIn` `2017`\n4. [How Natural Language Processing Helps LinkedIn Members Get Support Easily](https://engineering.linkedin.com/blog/2019/04/how-natural-language-processing-help-support) `LinkedIn` `2019`\n5. [Gmail Smart Compose: Real-Time Assisted Writing](https://arxiv.org/abs/1906.00080) ([Paper](https://arxiv.org/pdf/1906.00080.pdf)) `Google` `2019`\n6. [Goal-Oriented End-to-End Conversational Models with Profile Features in a Real-World Setting](https://www.amazon.science/publications/goal-oriented-end-to-end-chatbots-with-profile-features-in-a-real-world-setting) ([Paper](https://assets.amazon.science/47/03/e0d14dc34d3eb6e0d4ec282067bd/goal-oriented-end-to-end-chatbots-with-profile-features-in-a-real-world-setting.pdf)) `Amazon` `2019`\n7. [Give Me Jeans not Shoes: How BERT Helps Us Deliver What Clients Want](https://multithreaded.stitchfix.com/blog/2019/07/15/give-me-jeans/) `Stitch Fix` `2019`\n8. [DeText: A deep NLP Framework for Intelligent Text Understanding](https://engineering.linkedin.com/blog/2020/open-sourcing-detext) ([Code](https://github.com/linkedin/detext)) `LinkedIn` `2020`\n9. [SmartReply for YouTube Creators](https://ai.googleblog.com/2020/07/smartreply-for-youtube-creators.html) `Google` `2020`\n10. [Using Neural Networks to Find Answers in Tables](https://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html) ([Paper](https://arxiv.org/pdf/2004.02349.pdf)) `Google` `2020`\n11. [A Scalable Approach to Reducing Gender Bias in Google Translate](https://ai.googleblog.com/2020/04/a-scalable-approach-to-reducing-gender.html) `Google` `2020`\n12. [Assistive AI Makes Replying Easier](https://www.microsoft.com/en-us/research/group/msai/articles/assistive-ai-makes-replying-easier-2/) `Microsoft` `2020`\n13. [AI Advances to Better Detect Hate Speech](https://ai.facebook.com/blog/ai-advances-to-better-detect-hate-speech/) `Facebook` `2020`\n14. [A State-of-the-Art Open Source Chatbot](https://ai.facebook.com/blog/state-of-the-art-open-source-chatbot) ([Paper](https://arxiv.org/pdf/2004.13637.pdf)) `Facebook` `2020`\n15. [A Highly Efficient, Real-Time Text-to-Speech System Deployed on CPUs](https://ai.facebook.com/blog/a-highly-efficient-real-time-text-to-speech-system-deployed-on-cpus/) `Facebook` `2020`\n16. [Deep Learning to Translate Between Programming Languages](https://ai.facebook.com/blog/deep-learning-to-translate-between-programming-languages/) ([Paper](https://arxiv.org/abs/2006.03511), [Code](https://github.com/facebookresearch/TransCoder)) `Facebook` `2020`\n17. [Deploying Lifelong Open-Domain Dialogue Learning](https://arxiv.org/abs/2008.08076) ([Paper](https://arxiv.org/pdf/2008.08076.pdf)) `Facebook` `2020`\n18. [Introducing Dynabench: Rethinking the way we benchmark AI](https://ai.facebook.com/blog/dynabench-rethinking-ai-benchmarking/) `Facebook` `2020`\n19. [How Gojek Uses NLP to Name Pickup Locations at Scale](https://www.gojek.io/blog/nlp-cartobert) `Gojek` `2020`\n20. [The State-of-the-art Open-Domain Chatbot in Chinese and English](http://research.baidu.com/Blog/index-view?id=142) ([Paper](https://arxiv.org/pdf/2006.16779.pdf)) `Baidu` `2020`\n21. [PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization](https://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html) ([Paper](https://arxiv.org/pdf/1912.08777.pdf), [Code](https://github.com/google-research/pegasus)) `Google` `2020`\n22. [Photon: A Robust Cross-Domain Text-to-SQL System](https://www.aclweb.org/anthology/2020.acl-demos.24/) ([Paper](https://www.aclweb.org/anthology/2020.acl-demos.24.pdf)) ([Demo](http://naturalsql.com)) `Salesforce`\t`2020`\n23. [GeDi: A Powerful New Method for Controlling Language Models](https://blog.einstein.ai/gedi/) ([Paper](https://arxiv.org/abs/2009.06367), [Code](https://github.com/salesforce/GeDi)) `Salesforce` `2020`\n24. [Applying Topic Modeling to Improve Call Center Operations](https://www.youtube.com/watch?v=kzRR8OjF_eI&t=2s) `RICOH` `2020`\n25. [WIDeText: A Multimodal Deep Learning Framework](https://medium.com/airbnb-engineering/widetext-a-multimodal-deep-learning-framework-31ce2565880c) `Airbnb` `2020`\n26. [Dynaboard: Moving Beyond Accuracy to Holistic Model Evaluation in NLP](https://ai.facebook.com/blog/dynaboard-moving-beyond-accuracy-to-holistic-model-evaluation-in-nlp) ([Code](https://github.com/facebookresearch/dynalab?fbclid=IwAR3qcV7QK2uXm4s4M0XUoQQo4i2DEsDy0LZFKxSQCHhP-3hF6fr2-NDFWX8)) `Facebook`  `2021`\n27. [How we reduced our text similarity runtime by 99.96%](https://medium.com/data-science-at-microsoft/how-we-reduced-our-text-similarity-runtime-by-99-96-e8e4b4426b35) `Microsoft` `2021`\n28. [Textless NLP: Generating expressive speech from raw audio](https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio/) [(Part 1)](https://arxiv.org/abs/2102.01192) [(Part 2)](https://arxiv.org/abs/2104.00355) [(Part 3)](https://arxiv.org/abs/2109.03264) [(Code and Pretrained Models)](https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp) `Facebook` `2021`\n29. [Grammar Correction as You Type, on Pixel 6](https://ai.googleblog.com/2021/10/grammar-correction-as-you-type-on-pixel.html) `Google` `2021`\n30. [Auto-generated Summaries in Google Docs](https://ai.googleblog.com/2022/03/auto-generated-summaries-in-google-docs.html) `Google` `2022`\n31. [ML-Enhanced Code Completion Improves Developer Productivity](https://ai.googleblog.com/2022/07/ml-enhanced-code-completion-improves.html) `Google` `2022`\n32. [Words All the Way Down ‚Äî Conversational Sentiment Analysis](https://medium.com/paypal-tech/words-all-the-way-down-conversational-sentiment-analysis-afe0165b84db) `PayPal` `2022`\n\n## Sequence Modelling\n1. [Doctor AI: Predicting Clinical Events via Recurrent Neural Networks](https://arxiv.org/abs/1511.05942) ([Paper](https://arxiv.org/pdf/1511.05942.pdf)) `Sutter Health` `2015`\n2. [Deep Learning for Understanding Consumer Histories](https://engineering.zalando.com/posts/2016/10/deep-learning-for-understanding-consumer-histories.html) ([Paper](https://doogkong.github.io/2017/papers/paper2.pdf)) `Zalando` `2016`\n3. [Using Recurrent Neural Network Models for Early Detection of Heart Failure Onset](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5391725/) ([Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5391725/pdf/ocw112.pdf)) `Sutter Health` `2016`\n4. [Continual Prediction of Notification Attendance with Classical and Deep Networks](https://arxiv.org/abs/1712.07120) ([Paper](https://arxiv.org/pdf/1712.07120.pdf)) `Telefonica` `2017` \n5. [Deep Learning for Electronic Health Records](https://ai.googleblog.com/2018/05/deep-learning-for-electronic-health.html) ([Paper](https://www.nature.com/articles/s41746-018-0029-1.pdf)) `Google` `2018`\n6. [Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction](https://arxiv.org/abs/1905.09248) ([Paper](https://arxiv.org/pdf/1905.09248.pdf))`Alibaba` `2019`\n7. [Search-based User Interest Modeling with Sequential Behavior Data for CTR Prediction](https://arxiv.org/abs/2006.05639) ([Paper](https://arxiv.org/pdf/2006.05639.pdf)) `Alibaba` `2020`\n8. [How Duolingo uses AI in every part of its app](https://venturebeat.com/2020/08/18/how-duolingo-uses-ai-in-every-part-of-its-app/) `Duolingo` `2020`\n9. [Leveraging Online Social Interactions For Enhancing Integrity at Facebook](https://research.fb.com/blog/2020/08/leveraging-online-social-interactions-for-enhancing-integrity-at-facebook/) ([Paper](https://research.fb.com/wp-content/uploads/2020/08/TIES-Temporal-Interaction-Embeddings-For-Enhancing-Social-Media-Integrity-At-Facebook.pdf), [Video](https://crossminds.ai/video/5f3369780576dd25aef288cf/)) `Facebook` `2020`\n10. [Using deep learning to detect abusive sequences of member activity](https://engineering.linkedin.com/blog/2021/using-deep-learning-to-detect-abusive-sequences-of-member-activi) ([Video](https://exchange.scale.com/public/videos/using-deep-learning-to-detect-abusive-sequences-of-member-activity-on-linkedin)) `LinkedIn` `2021`\n\n## Computer Vision\n1. [Creating a Modern OCR Pipeline Using Computer Vision and Deep Learning](https://dropbox.tech/machine-learning/creating-a-modern-ocr-pipeline-using-computer-vision-and-deep-learning) `Dropbox` `2017`\n2. [Categorizing Listing Photos at Airbnb](https://medium.com/airbnb-engineering/categorizing-listing-photos-at-airbnb-f9483f3ab7e3) `Airbnb` `2018`\n3. [Amenity Detection and Beyond ‚Äî New Frontiers of Computer Vision at Airbnb](https://medium.com/airbnb-engineering/amenity-detection-and-beyond-new-frontiers-of-computer-vision-at-airbnb-144a4441b72e) `Airbnb` `2019`\n4. [How we Improved Computer Vision Metrics by More Than 5% Only by Cleaning Labelling Errors](https://deepomatic.com/en/how-we-improved-computer-vision-metrics-by-more-than-5-percent-only-by-cleaning-labelling-errors/) `Deepomatic`\n5. [Making machines recognize and transcribe conversations in meetings using audio and video](https://www.microsoft.com/en-us/research/blog/making-machines-recognize-and-transcribe-conversations-in-meetings-using-audio-and-video/) `Microsoft` `2019`\n6. [Powered by AI: Advancing product understanding and building new shopping experiences](https://ai.facebook.com/blog/powered-by-ai-advancing-product-understanding-and-building-new-shopping-experiences/) `Facebook` `2020`\n7. [A Neural Weather Model for Eight-Hour Precipitation Forecasting](https://ai.googleblog.com/2020/03/a-neural-weather-model-for-eight-hour.html) ([Paper](https://arxiv.org/pdf/2003.12140.pdf)) `Google` `2020`\n8. [Machine Learning-based Damage Assessment for Disaster Relief](https://ai.googleblog.com/2020/06/machine-learning-based-damage.html) ([Paper](https://arxiv.org/pdf/1910.06444.pdf)) `Google` `2020`\n9. [RepNet: Counting Repetitions in Videos](https://ai.googleblog.com/2020/06/repnet-counting-repetitions-in-videos.html) ([Paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Dwibedi_Counting_Out_Time_Class_Agnostic_Video_Repetition_Counting_in_the_CVPR_2020_paper.pdf)) `Google` `2020`\n10. [Converting Text to Images for Product Discovery](https://www.amazon.science/blog/converting-text-to-images-for-product-discovery) ([Paper](https://assets.amazon.science/4c/76/5830542547b7a11089ce3af943b4/scipub-972.pdf)) `Amazon` `2020`\n11. [How Disney Uses PyTorch for Animated Character Recognition](https://medium.com/pytorch/how-disney-uses-pytorch-for-animated-character-recognition-a1722a182627) `Disney` `2020`\n12. [Image Captioning as an Assistive Technology](https://www.ibm.com/blogs/research/2020/07/image-captioning-assistive-technology/) ([Video](https://ivc.ischool.utexas.edu/~yz9244/VizWiz_workshop/videos/MMTeam-oral.mp4)) `IBM` `2020`\n13. [AI for AG: Production machine learning for agriculture](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1) `Blue River` `2020`\n14. [AI for Full-Self Driving at Tesla](https://youtu.be/hx7BXih7zx8?t=513) `Tesla` `2020`\n15. [On-device Supermarket Product Recognition](https://ai.googleblog.com/2020/07/on-device-supermarket-product.html) `Google` `2020`\n16. [Using Machine Learning to Detect Deficient Coverage in Colonoscopy Screenings](https://ai.googleblog.com/2020/08/using-machine-learning-to-detect.html) ([Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9097918)) `Google` `2020`\n17. [Shop The Look: Building a Large Scale Visual Shopping System at Pinterest](https://dl.acm.org/doi/abs/10.1145/3394486.3403372) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403372), [Video](https://crossminds.ai/video/5f3369790576dd25aef288d7/)) `Pinterest` `2020`\n18. [Developing Real-Time, Automatic Sign Language Detection for Video Conferencing](https://ai.googleblog.com/2020/10/developing-real-time-automatic-sign.html) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/2eaf0d18ec6bef00d7dd88f39dd4f9ff13eeeeb2.pdf)) `Google` `2020`\n19. [Vision-based Price Suggestion for Online Second-hand Items](https://arxiv.org/abs/2012.06009) ([Paper](https://arxiv.org/pdf/2012.06009.pdf)) `Alibaba` `2020`\n20. [New AI Research to Help Predict COVID-19 Resource Needs From X-rays](https://ai.facebook.com/blog/new-ai-research-to-help-predict-covid-19-resource-needs-from-a-series-of-x-rays/) ([Paper](https://arxiv.org/pdf/2101.04909.pdf), [Model](https://github.com/facebookresearch/CovidPrognosis)) `Facebook` `2021`\n21. [An Efficient Training Approach for Very Large Scale Face Recognition](https://arxiv.org/abs/2105.10375) ([Paper](https://arxiv.org/pdf/2105.10375)) `Alibaba` `2021`\n22. [Identifying Document Types at Scribd](https://tech.scribd.com/blog/2021/identifying-document-types.html) `Scribd` `2021`\n23. [Semi-Supervised Visual Representation Learning for Fashion Compatibility](https://arxiv.org/pdf/2109.08052.pdf) ([Paper](https://arxiv.org/pdf/2109.08052.pdf)) `Walmart` `2021`\n24. [Recognizing People in Photos Through Private On-Device Machine Learning](https://machinelearning.apple.com/research/recognizing-people-photos) `Apple` `2021`\n25. [DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection](https://arxiv.org/pdf/2203.08195.pdf) `Google` `2022`\n26. [Contrastive language and vision learning of general fashion concepts](https://www.nature.com/articles/s41598-022-23052-9) ([Paper](https://www.nature.com/articles/s41598-022-23052-9.pdf))`Coveo` `2022`\n27. [Leveraging Computer Vision for Search Ranking](https://arize.com/resource/bazaarvoice-leveraging-computer-vision-models-for-search-ranking/) `BazaarVoice` `2023`\n\n## Reinforcement Learning\n1. [Deep Reinforcement Learning for Sponsored Search Real-time Bidding](https://arxiv.org/abs/1803.00259) ([Paper](https://arxiv.org/pdf/1803.00259.pdf)) `Alibaba` `2018`\n2. [Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising](https://arxiv.org/abs/1802.08365) ([Paper](https://arxiv.org/pdf/1802.08365.pdf)) `Alibaba` `2018`\n3. [Reinforcement Learning for On-Demand Logistics](https://doordash.engineering/2018/09/10/reinforcement-learning-for-on-demand-logistics/) `DoorDash` `2018`\n4. [Reinforcement Learning to Rank in E-Commerce Search Engine](https://arxiv.org/abs/1803.00710) ([Paper](https://arxiv.org/pdf/1803.00710.pdf)) `Alibaba` `2018`\n5. [Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning](https://arxiv.org/abs/1912.02572) ([Paper](https://arxiv.org/pdf/1912.02572.pdf)) `Alibaba` `2019`\n6. [Productionizing Deep Reinforcement Learning with Spark and MLflow](https://www.youtube.com/watch?v=hy-w69zf4oo) `Zynga` `2020`\n7. [Deep Reinforcement Learning in Production Part1](https://towardsdatascience.com/deep-reinforcement-learning-in-production-7e1e63471e2) [Part 2](https://towardsdatascience.com/deep-reinforcement-learning-in-production-part-2-personalizing-user-notifications-812a68ce2355) `Zynga` `2020`\n8. [Building AI Trading Systems](https://dennybritz.com/blog/ai-trading/) `Denny Britz` `2020`\n9. [Shifting Consumption towards Diverse content via Reinforcement Learning](https://research.atspotify.com/shifting-consumption-towards-diverse-content-via-reinforcement-learning/) ([Paper](https://dl.acm.org/doi/10.1145/3437963.3441775)) `Spotify` `2022`\n10. [Bandits for Online Calibration: An Application to Content Moderation on Social Media Platforms](https://arxiv.org/abs/2211.06516) `Meta` `2022`\n11. [How to Optimise Rankings with Cascade Bandits](https://medium.com/expedia-group-tech/how-to-optimise-rankings-with-cascade-bandits-5d92dfa0f16b) `Expedia` `2022`\n12. [Selecting the Best Image for Each Merchant Using Exploration and Machine Learning](https://doordash.engineering/2023/01/04/selecting-the-best-image-for-each-merchant-using-exploration-and-machine-learning/) `DoorDash` `2023`\n\n## Anomaly Detection\n1. [Detecting Performance Anomalies in External Firmware Deployments](https://netflixtechblog.com/detecting-performance-anomalies-in-external-firmware-deployments-ed41b1bfcf46) `Netflix` `2019`\n2. [Detecting and Preventing Abuse on LinkedIn using Isolation Forests](https://engineering.linkedin.com/blog/2019/isolation-forest) ([Code](https://github.com/linkedin/isolation-forest)) `LinkedIn` `2019`\n3. [Deep Anomaly Detection with Spark and Tensorflow](https://databricks.com/session_eu19/deep-anomaly-detection-from-research-to-production-leveraging-spark-and-tensorflow) [(Hopsworks Video](https://www.youtube.com/watch?v=TgXVU8DSyCQ)) `Swedbank`, `Hopsworks` `2019`\n4. [Preventing Abuse Using Unsupervised Learning](https://www.youtube.com/watch?v=sFRrFWYNAUI) `LinkedIn` `2020`\n5. [The Technology Behind Fighting Harassment on LinkedIn](https://engineering.linkedin.com/blog/2020/fighting-harassment) `LinkedIn` `2020`\n6. [Uncovering Insurance Fraud Conspiracy with Network Learning](https://arxiv.org/abs/2002.12789) ([Paper](https://arxiv.org/pdf/2002.12789.pdf)) `Ant Financial` `2020`\n7. [How Does Spam Protection Work on Stack Exchange?](https://stackoverflow.blog/2020/06/25/how-does-spam-protection-work-on-stack-exchange/) `Stack Exchange` `2020`\n8. [Auto Content Moderation in C2C e-Commerce](https://www.usenix.org/conference/opml20/presentation/ueta) `Mercari` `2020`\n9. [Blocking Slack Invite Spam With Machine Learning](https://slack.engineering/blocking-slack-invite-spam-with-machine-learning/) `Slack` `2020`\n10. [Cloudflare Bot Management: Machine Learning and More](https://blog.cloudflare.com/cloudflare-bot-management-machine-learning-and-more/) `Cloudflare` `2020`\n11. [Anomalies in Oil Temperature Variations in a Tunnel Boring Machine](https://www.youtube.com/watch?v=YV_uLLhPRAk) `SENER` `2020`\n12. [Using Anomaly Detection to Monitor Low-Risk Bank Customers](https://www.youtube.com/watch?v=MExokMM_Bp4&t=3s) `Rabobank` `2020`\n13. [Fighting fraud with Triplet Loss](https://tech.olx.com/fighting-fraud-with-triplet-loss-86e5f79c7a3e) `OLX Group` `2020`\n14. [Facebook is Now Using AI to Sort Content for Quicker Moderation](https://www.theverge.com/2020/11/13/21562596/facebook-ai-moderation) ([Alternative](https://venturebeat.com/2020/11/13/facebooks-redoubled-ai-efforts-wont-stop-the-spread-of-harmful-content/)) `Facebook` `2020`\n15. How AI is getting better at detecting hate speech [Part 1](https://ai.facebook.com/blog/how-ai-is-getting-better-at-detecting-hate-speech/), [Part 2](https://ai.facebook.com/blog/heres-how-were-using-ai-to-help-detect-misinformation/), [Part 3](https://ai.facebook.com/blog/training-ai-to-detect-hate-speech-in-the-real-world/), [Part 4](https://ai.facebook.com/blog/how-facebook-uses-super-efficient-ai-models-to-detect-hate-speech/) `Facebook` `2020`\n16. [Using deep learning to detect abusive sequences of member activity](https://engineering.linkedin.com/blog/2021/using-deep-learning-to-detect-abusive-sequences-of-member-activi) ([Video](https://exchange.scale.com/public/videos/using-deep-learning-to-detect-abusive-sequences-of-member-activity-on-linkedin)) `LinkedIn` `2021`\n17. [Project RADAR: Intelligent Early Fraud Detection System with Humans in the Loop](https://eng.uber.com/project-radar-intelligent-early-fraud-detection/) `Uber` `2022`\n18. [Graph for Fraud Detection](https://engineering.grab.com/graph-for-fraud-detection) `Grab` `2022`\n19. [Bandits for Online Calibration: An Application to Content Moderation on Social Media Platforms](https://arxiv.org/abs/2211.06516) `Meta` `2022`\n20. [Evolving our machine learning to stop mobile bots](https://blog.cloudflare.com/machine-learning-mobile-traffic-bots/) `Cloudflare` `2022`\n21. [Improving the accuracy of our machine learning WAF using data augmentation and sampling](https://blog.cloudflare.com/data-generation-and-sampling-strategies/) `Cloudflare` `2022`\n22. [Machine Learning for Fraud Detection in Streaming Services](https://netflixtechblog.com/machine-learning-for-fraud-detection-in-streaming-services-b0b4ef3be3f6) `Netflix` `2022`\n23. [Pricing at Lyft](https://eng.lyft.com/pricing-at-lyft-8a4022065f8b) `Lyft` `2022`\n\n## Graph\n1. [Building The LinkedIn Knowledge Graph](https://engineering.linkedin.com/blog/2016/10/building-the-linkedin-knowledge-graph) `LinkedIn` `2016`\n2. [Scaling Knowledge Access and Retrieval at Airbnb](https://medium.com/airbnb-engineering/scaling-knowledge-access-and-retrieval-at-airbnb-665b6ba21e95) `Airbnb` `2018`\n3. [Graph Convolutional Neural Networks for Web-Scale Recommender Systems](https://arxiv.org/abs/1806.01973) ([Paper](https://arxiv.org/pdf/1806.01973.pdf))`Pinterest` `2018`\n4. [Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations](https://eng.uber.com/uber-eats-graph-learning/) `Uber` `2019`\n5. [AliGraph: A Comprehensive Graph Neural Network Platform](https://arxiv.org/abs/1902.08730) ([Paper](https://arxiv.org/pdf/1902.08730.pdf)) `Alibaba` `2019`\n6. [Contextualizing Airbnb by Building Knowledge Graph](https://medium.com/airbnb-engineering/contextualizing-airbnb-by-building-knowledge-graph-b7077e268d5a) `Airbnb` `2019`\n7. [Retail Graph ‚Äî Walmart‚Äôs Product Knowledge Graph](https://medium.com/walmartlabs/retail-graph-walmarts-product-knowledge-graph-6ef7357963bc) `Walmart` `2020`\n8. [Traffic Prediction with Advanced Graph Neural Networks](https://deepmind.com/blog/article/traffic-prediction-with-advanced-graph-neural-networks) `DeepMind` `2020`\n9. [SimClusters: Community-Based Representations for Recommendations](https://dl.acm.org/doi/10.1145/3394486.3403370) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3394486.3403370), [Video](https://crossminds.ai/video/5f3369790576dd25aef288d5/)) `Twitter` `2020`\n10. [Metapaths guided Neighbors aggregated Network for Heterogeneous Graph Reasoning](https://arxiv.org/abs/2103.06474) ([Paper](https://arxiv.org/pdf/2103.06474.pdf)) `Alibaba` `2021`\n11. [Graph Intention Network for Click-through Rate Prediction in Sponsored Search](https://arxiv.org/abs/2103.16164) ([Paper](https://arxiv.org/pdf/2103.16164.pdf)) `Alibaba` `2021`\n12. [JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase](https://ojs.aaai.org/index.php/AAAI/article/view/17796) ([Paper](https://www.aaai.org/AAAI21Papers/IAAI-21.DingW.pdf)) `JPMorgan Chase` `2021`\n13. [How AWS uses graph neural networks to meet customer needs](https://www.amazon.science/blog/how-aws-uses-graph-neural-networks-to-meet-customer-needs) `Amazon` `2022`\n14. [Graph for Fraud Detection](https://engineering.grab.com/graph-for-fraud-detection) `Grab` `2022`\n\n## Optimization\n1. [Matchmaking in Lyft Line (Part 1)](https://eng.lyft.com/matchmaking-in-lyft-line-9c2635fe62c4) [(Part 2)](https://eng.lyft.com/matchmaking-in-lyft-line-691a1a32a008) [(Part 3)](https://eng.lyft.com/matchmaking-in-lyft-line-part-3-d8f9497c0e51) `Lyft` `2016`\n2. [The Data and Science behind GrabShare Carpooling](https://ieeexplore.ieee.org/document/8259801) [(Part 1)](https://engineering.grab.com/the-data-and-science-behind-grabshare-part-i) (**PAPER NEEDED**) `Grab` `2017`\n3. [How Trip Inferences and Machine Learning Optimize Delivery Times on Uber Eats](https://eng.uber.com/uber-eats-trip-optimization/) `Uber` `2018`\n4. [Next-Generation Optimization for Dasher Dispatch at DoorDash](https://doordash.engineering/2020/02/28/next-generation-optimization-for-dasher-dispatch-at-doordash/) `DoorDash` `2020` \n5. [Optimization of Passengers Waiting Time in Elevators Using Machine Learning](https://www.youtube.com/watch?v=vXndCC89BCw&t=4s) `Thyssen Krupp AG` `2020`\n6. [Think Out of The Package: Recommending Package Types for E-commerce Shipments](https://www.amazon.science/publications/think-out-of-the-package-recommending-package-types-for-e-commerce-shipments) ([Paper](https://assets.amazon.science/0c/6c/9d0986b94bef92d148f0ac0da1ea/think-out-of-the-package-recommending-package-types-for-e-commerce-shipments.pdf)) `Amazon` `2020`\n7. [Optimizing DoorDash‚Äôs Marketing Spend with Machine Learning](https://doordash.engineering/2020/07/31/optimizing-marketing-spend-with-ml/) `DoorDash` `2020`\n8. [Using learning-to-rank to precisely locate where to deliver packages](https://www.amazon.science/blog/using-learning-to-rank-to-precisely-locate-where-to-deliver-packages) ([Paper](https://assets.amazon.science/69/8d/2249945a4e10ba8fc758f7523b0c/getting-your-package-to-the-right-place-supervised-machine-learning-for-geolocation.pdf))`Amazon` `2021`\n\n## Information Extraction\n1. [Unsupervised Extraction of Attributes and Their Values from Product Description](https://www.aclweb.org/anthology/I13-1190/) ([Paper](https://www.aclweb.org/anthology/I13-1190.pdf)) `Rakuten` `2013`\n2. [Using Machine Learning to Index Text from Billions of Images](https://dropbox.tech/machine-learning/using-machine-learning-to-index-text-from-billions-of-images) `Dropbox` `2018`\n3. [Extracting Structured Data from Templatic Documents](https://ai.googleblog.com/2020/06/extracting-structured-data-from.html) ([Paper](https://www.aclweb.org/anthology/I13-1190.pdf)) `Google` `2020`\n4. [AutoKnow: self-driving knowledge collection for products of thousands of types](https://www.amazon.science/publications/autoknow-self-driving-knowledge-collection-for-products-of-thousands-of-types) ([Paper](https://arxiv.org/pdf/2006.13473.pdf), [Video](https://crossminds.ai/video/5f3369730576dd25aef288a6/)) `Amazon` `2020`\n5. [One-shot Text Labeling using Attention and Belief Propagation for Information Extraction](https://arxiv.org/abs/2009.04153) ([Paper](https://arxiv.org/pdf/2009.04153.pdf)) `Alibaba` `2020`\n6. [Information Extraction from Receipts with Graph Convolutional Networks](https://nanonets.com/blog/information-extraction-graph-convolutional-networks/) `Nanonets` `2021`\n\n## Weak Supervision\n1. [Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale](https://dl.acm.org/doi/abs/10.1145/3299869.3314036) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3299869.3314036)) `Google` `2019`\n2. [Osprey: Weak Supervision of Imbalanced Extraction Problems without Code](https://dl.acm.org/doi/abs/10.1145/3329486.3329492) ([Paper](https://ajratner.github.io/assets/papers/Osprey_DEEM.pdf)) `Intel` `2019` \n3. [Overton: A Data System for Monitoring and Improving Machine-Learned Products](https://arxiv.org/abs/1909.05372) ([Paper](https://arxiv.org/pdf/1909.05372.pdf)) `Apple` `2019`\n4. [Bootstrapping Conversational Agents with Weak Supervision](https://www.aaai.org/ojs/index.php/AAAI/article/view/5011) ([Paper](https://arxiv.org/pdf/1812.06176.pdf)) `IBM` `2019`\n\n## Generation\n1. [Better Language Models and Their Implications](https://openai.com/blog/better-language-models/) ([Paper](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf))`OpenAI` `2019`\n2. [Image GPT](https://openai.com/blog/image-gpt/) ([Paper](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf), [Code](https://github.com/openai/image-gpt)) `OpenAI` `2019`\n3. [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) ([Paper](https://arxiv.org/pdf/2005.14165.pdf)) ([GPT-3 Blog post](https://openai.com/blog/openai-api/)) `OpenAI` `2020`\n4. [Deep Learned Super Resolution for Feature Film Production](https://graphics.pixar.com/library/SuperResolution/) ([Paper](https://graphics.pixar.com/library/SuperResolution/paper.pdf)) `Pixar` `2020`\n5. [Unit Test Case Generation with Transformers](https://arxiv.org/pdf/2009.05617.pdf) `Microsoft` `2021`\n\n## Audio\n1. [Improving On-Device Speech Recognition with VoiceFilter-Lite](https://ai.googleblog.com/2020/11/improving-on-device-speech-recognition.html) ([Paper](https://arxiv.org/pdf/2009.04323.pdf))`Google` `2020`\n2. [The Machine Learning Behind Hum to Search](https://ai.googleblog.com/2020/11/the-machine-learning-behind-hum-to.html) `Google` `2020`\n\n## Privacy-preserving Machine Learning\n1. [Federated Learning: Collaborative Machine Learning without Centralized Training Data](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html) ([Paper](https://arxiv.org/pdf/1602.05629)) `Google` `2017`\n2. [Federated Learning with Formal Differential Privacy Guarantees](https://ai.googleblog.com/2022/02/federated-learning-with-formal.html) ([Paper](https://arxiv.org/pdf/2103.00039)) `Google` `2022`\n3. [MPC-based machine learning: Achieving end-to-end privacy-preserving machine learning](https://research.facebook.com/blog/2022/10/mpc-based-machine-learning-achieving-end-to-end-privacy-preserving-machine-learning/) ([Paper](https://research.facebook.com/file/455681589729383/Private-Computation-Framework-2.0-White-Paper.pdf)) `Facebook` `2022`\n\n\n## Validation and A/B Testing\n1. [Overlapping Experiment Infrastructure: More, Better, Faster Experimentation](https://research.google/pubs/pub36500/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36500.pdf)) `Google` `2010`\n2. [The Reusable Holdout: Preserving Validity in Adaptive Data Analysis](https://ai.googleblog.com/2015/08/the-reusable-holdout-preserving.html) ([Paper](https://science.sciencemag.org/content/sci/349/6248/636.full.pdf)) `Google` `2015`\n3. [Twitter Experimentation: Technical Overview](https://blog.twitter.com/engineering/en_us/a/2015/twitter-experimentation-technical-overview.html) `Twitter` `2015`\n4. [It‚Äôs All A/Bout Testing: The Netflix Experimentation Platform](https://netflixtechblog.com/its-all-a-bout-testing-the-netflix-experimentation-platform-4e1ca458c15) `Netflix` `2016`\n5. [Building Pinterest‚Äôs A/B Testing Platform](https://medium.com/pinterest-engineering/building-pinterests-a-b-testing-platform-ab4934ace9f4) `Pinterest` `2016` \n6. [Experimenting to Solve Cramming](https://blog.twitter.com/engineering/en_us/topics/insights/2017/Experimenting-To-Solve-Cramming.html) `Twitter` `2017`\n7. [Building an Intelligent Experimentation Platform with Uber Engineering](https://eng.uber.com/experimentation-platform/) `Uber` `2017`\n8. [Scaling Airbnb‚Äôs Experimentation Platform](https://medium.com/airbnb-engineering/https-medium-com-jonathan-parks-scaling-erf-23fd17c91166) `Airbnb` `2017`\n9. [Meet Wasabi, an Open Source A/B Testing Platform](https://www.intuit.com/blog/technology/engineering/meet-wasabi-an-open-source-ab-testing-platform/) ([Code](https://github.com/intuit/wasabi)) `Intuit` `2017` \n10. [Analyzing Experiment Outcomes: Beyond Average Treatment Effects](https://eng.uber.com/analyzing-experiment-outcomes/) `Uber` `2018`\n11. [Under the Hood of Uber‚Äôs Experimentation Platform](https://eng.uber.com/xp/) `Uber` `2018`\n12. [Constrained Bayesian Optimization with Noisy Experiments](https://research.fb.com/publications/constrained-bayesian-optimization-with-noisy-experiments/) ([Paper](https://arxiv.org/pdf/1706.07094.pdf)) `Facebook` `2018`\n13. [Reliable and Scalable Feature Toggles and A/B Testing SDK at Grab](https://engineering.grab.com/feature-toggles-ab-testing) `Grab` `2018`\n14. [Modeling Conversion Rates and Saving Millions Using Kaplan-Meier and Gamma Distributions](https://better.engineering/modeling-conversion-rates-and-saving-millions-of-dollars-using-kaplan-meier-and-gamma-distributions/) ([Code](https://github.com/better/convoys)) `Better` `2019`\n15. [Detecting Interference: An A/B Test of A/B Tests](https://engineering.linkedin.com/blog/2019/06/detecting-interference--an-a-b-test-of-a-b-tests) `LinkedIn` `2019`\n16. [Announcing a New Framework for Designing Optimal Experiments with Pyro](https://eng.uber.com/oed-pyro-release/) ([Paper](https://papers.nips.cc/paper/9553-variational-bayesian-optimal-experimental-design.pdf)) ([Paper](https://arxiv.org/pdf/1911.00294.pdf)) `Uber` `2020`\n17. [Enabling 10x More Experiments with Traveloka Experiment Platform](https://medium.com/traveloka-engineering/enabling-10x-more-experiments-with-traveloka-experiment-platform-8cea13e952c) `Traveloka` `2020`\n18. [Large Scale Experimentation at Stitch Fix](https://multithreaded.stitchfix.com/blog/2020/07/07/large-scale-experimentation/) ([Paper](http://proceedings.mlr.press/v89/schmit19a/schmit19a.pdf)) `Stitch Fix` `2020`\n19. [Multi-Armed Bandits and the Stitch Fix Experimentation Platform](https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/) `Stitch Fix` `2020`\n20. [Experimentation with Resource Constraints](https://multithreaded.stitchfix.com/blog/2020/11/18/virtual-warehouse/) `Stitch Fix` `2020`\n21. [Computational Causal Inference at Netflix](https://netflixtechblog.com/computational-causal-inference-at-netflix-293591691c62) ([Paper](https://arxiv.org/pdf/2007.10979.pdf)) `Netflix` `2020`\n22. [Key Challenges with Quasi Experiments at Netflix](https://netflixtechblog.com/key-challenges-with-quasi-experiments-at-netflix-89b4f234b852) `Netflix` `2020`\n23. [Making the LinkedIn experimentation engine 20x faster](https://engineering.linkedin.com/blog/2020/making-the-linkedin-experimentation-engine-20x-faster) `LinkedIn` `2020`\n24. [Our Evolution Towards T-REX: The Prehistory of Experimentation Infrastructure at LinkedIn](https://engineering.linkedin.com/blog/2020/our-evolution-towards-t-rex--the-prehistory-of-experimentation-i) `LinkedIn` `2020`\n25. [How to Use Quasi-experiments and Counterfactuals to Build Great Products](https://engineering.shopify.com/blogs/engineering/using-quasi-experiments-counterfactuals) `Shopify` `2020`\n26. [Improving Experimental Power through Control Using Predictions as Covariate](https://doordash.engineering/2020/06/08/improving-experimental-power-through-control-using-predictions-as-covariate-cupac/) `DoorDash` `2020`\n27. [Supporting Rapid Product Iteration with an Experimentation Analysis Platform](https://doordash.engineering/2020/09/09/experimentation-analysis-platform-mvp/) `DoorDash` `2020`\n28. [Improving Online Experiment Capacity by 4X with Parallelization and Increased Sensitivity](https://doordash.engineering/2020/10/07/improving-experiment-capacity-by-4x/) `DoorDash` `2020`\n29. [Leveraging Causal Modeling to Get More Value from Flat Experiment Results](https://doordash.engineering/2020/09/18/causal-modeling-to-get-more-value-from-flat-experiment-results/) `DoorDash` `2020`\n30. [Iterating Real-time Assignment Algorithms Through Experimentation](https://doordash.engineering/2020/12/08/optimizing-real-time-algorithms-experimentation/) `DoorDash` `2020`\n31. [Spotify‚Äôs New Experimentation Platform (Part 1)](https://engineering.atspotify.com/2020/10/29/spotifys-new-experimentation-platform-part-1/) [(Part 2)](https://engineering.atspotify.com/2020/11/02/spotifys-new-experimentation-platform-part-2/) `Spotify` `2020`\n32. [Interpreting A/B Test Results: False Positives and Statistical Significance](https://netflixtechblog.com/interpreting-a-b-test-results-false-positives-and-statistical-significance-c1522d0db27a) `Netflix` `2021`\n33. [Interpreting A/B Test Results: False Negatives and Power](https://netflixtechblog.com/interpreting-a-b-test-results-false-negatives-and-power-6943995cf3a8) `Netflix` `2021`\n34. [Running Experiments with Google Adwords for Campaign Optimization](https://doordash.engineering/2021/02/05/google-adwords-campaign-optimization/) `DoorDash` `2021`\n35. [The 4 Principles DoorDash Used to Increase Its Logistics Experiment Capacity by 1000%](https://doordash.engineering/2021/09/21/the-4-principles-doordash-used-to-increase-its-logistics-experiment-capacity-by-1000/) `DoorDash` `2021`\n36. [Experimentation Platform at Zalando: Part 1 - Evolution](https://engineering.zalando.com/posts/2021/01/experimentation-platform-part1.html) `Zalando` `2021`\n37. [Designing Experimentation Guardrails](https://medium.com/airbnb-engineering/designing-experimentation-guardrails-ed6a976ec669) `Airbnb` `2021`\n38. [How Airbnb Measures Future Value to Standardize Tradeoffs](https://medium.com/airbnb-engineering/how-airbnb-measures-future-value-to-standardize-tradeoffs-3aa99a941ba5) `Airbnb` `2021`\n38. [Network Experimentation at Scale](https://research.fb.com/publications/network-experimentation-at-scale/)([Paper](https://arxiv.org/abs/2012.08591)] `Facebook` `2021`\n39. [Universal Holdout Groups at Disney Streaming](https://medium.com/disney-streaming/universal-holdout-groups-at-disney-streaming-2043360def4f) `Disney` `2021`\n40. [Experimentation is a major focus of Data Science across Netflix](https://netflixtechblog.com/experimentation-is-a-major-focus-of-data-science-across-netflix-f67923f8e985) `Netflix` `2022`\n41. [Search Journey Towards Better Experimentation Practices](https://engineering.atspotify.com/2022/02/search-journey-towards-better-experimentation-practices/) `Spotify` `2022`\n42. [Artificial Counterfactual Estimation: Machine Learning-Based Causal Inference at Airbnb](https://medium.com/airbnb-engineering/artificial-counterfactual-estimation-ace-machine-learning-based-causal-inference-at-airbnb-ee32ee4d0512) `Airbnb` `2022`\n43. [Beyond A/B Test : Speeding up Airbnb Search Ranking Experimentation through Interleaving](https://medium.com/airbnb-engineering/beyond-a-b-test-speeding-up-airbnb-search-ranking-experimentation-through-interleaving-7087afa09c8e) `Airbnb` `2022`\n44. [Challenges in Experimentation](https://eng.lyft.com/challenges-in-experimentation-be9ab98a7ef4) `Lyft` `2022`\n45. [Overtracking and Trigger Analysis: Reducing sample sizes while INCREASING sensitivity](https://booking.ai/overtracking-and-trigger-analysis-how-to-reduce-sample-sizes-and-increase-the-sensitivity-of-71755bad0e5f) `Booking` `2022`\n46. [Meet Dash-AB ‚Äî The Statistics Engine of Experimentation at DoorDash](https://doordash.engineering/2022/05/24/meet-dash-ab-the-statistics-engine-of-experimentation-at-doordash/) `DoorDash` `2022`\n47. [Comparing quantiles at scale in online A/B-testing](https://engineering.atspotify.com/2022/03/comparing-quantiles-at-scale-in-online-a-b-testing) `Spotify` `2022`\n48. [Accelerating our A/B experiments with machine learning](https://dropbox.tech/machine-learning/accelerating-our-a-b-experiments-with-machine-learning-xr) `Dropbox` `2023`\n49. [Supercharging A/B Testing at Uber](https://www.uber.com/blog/supercharging-a-b-testing-at-uber/) `Uber` \n\n## Model Management\n1. [Operationalizing Machine Learning‚ÄîManaging Provenance from Raw Data to Predictions](https://vimeo.com/274396495) `Comcast` `2018`\n2. [Overton: A Data System for Monitoring and Improving Machine-Learned Products](https://arxiv.org/abs/1909.05372) ([Paper](https://arxiv.org/pdf/1909.05372.pdf)) `Apple` `2019`\n3. [Runway - Model Lifecycle Management at Netflix](https://www.usenix.org/conference/opml20/presentation/cepoi) `Netflix` `2020`\n4. [Managing ML Models @ Scale - Intuit‚Äôs ML Platform](https://www.usenix.org/conference/opml20/presentation/wenzel) `Intuit` `2020`\n5. [ML Model Monitoring - 9 Tips From the Trenches](https://building.nubank.com.br/ml-model-monitoring-9-tips-from-the-trenches/) `Nubank` `2021`\n6. [Dealing with Train-serve Skew in Real-time ML Models: A Short Guide](https://building.nubank.com.br/dealing-with-train-serve-skew-in-real-time-ml-models-a-short-guide/) `Nubank` `2023`\n\n## Efficiency\n1. [GrokNet: Unified Computer Vision Model Trunk and Embeddings For Commerce](https://ai.facebook.com/research/publications/groknet-unified-computer-vision-model-trunk-and-embeddings-for-commerce/) ([Paper](https://scontent-sea1-1.xx.fbcdn.net/v/t39.8562-6/99353320_565175057533429_3886205100842024960_n.pdf?_nc_cat=110&_nc_sid=ae5e01&_nc_ohc=WQBaZy1gnmUAX8Ecqtt&_nc_ht=scontent-sea1-1.xx&oh=cab2f11dd9154d817149cb73e8b692a8&oe=5F5A3778)) `Facebook` `2020`\n2. [How We Scaled Bert To Serve 1+ Billion Daily Requests on CPUs](https://blog.roblox.com/2020/05/scaled-bert-serve-1-billion-daily-requests-cpus/) `Roblox` `2020`\n3. [Permute, Quantize, and Fine-tune: Efficient Compression of Neural Networks](https://arxiv.org/abs/2010.15703) ([Paper](https://arxiv.org/pdf/2010.15703.pdf)) `Uber` `2021`\n4. [GPU-accelerated ML Inference at Pinterest](https://medium.com/@Pinterest_Engineering/gpu-accelerated-ml-inference-at-pinterest-ad1b6a03a16d) `Pinterest` `2022`\n\n## Ethics\n1. [Building Inclusive Products Through A/B Testing](https://engineering.linkedin.com/blog/2020/building-inclusive-products-through-a-b-testing) ([Paper](https://arxiv.org/pdf/2002.05819.pdf)) `LinkedIn` `2020`\n2. [LiFT: A Scalable Framework for Measuring Fairness in ML Applications](https://engineering.linkedin.com/blog/2020/lift-addressing-bias-in-large-scale-ai-applications) ([Paper](https://arxiv.org/pdf/2008.07433.pdf)) `LinkedIn` `2020`\n3. [Introducing Twitter‚Äôs first algorithmic bias bounty challenge](https://blog.twitter.com/engineering/en_us/topics/insights/2021/algorithmic-bias-bounty-challenge) `Twitter` `2021`\n4. [Examining algorithmic amplification of political content on Twitter](https://blog.twitter.com/en_us/topics/company/2021/rml-politicalcontent) `Twitter` `2021`\n5. [A closer look at how LinkedIn integrates fairness into its AI products](https://engineering.linkedin.com/blog/2022/a-closer-look-at-how-linkedin-integrates-fairness-into-its-ai-pr) `LinkedIn` `2022`\n\n## Infra\n1. [Reengineering Facebook AI‚Äôs Deep Learning Platforms for Interoperability](https://ai.facebook.com/blog/reengineering-facebook-ais-deep-learning-platforms-for-interoperability) `Facebook` `2020`\n2. [Elastic Distributed Training with XGBoost on Ray](https://eng.uber.com/elastic-xgboost-ray/) `Uber` `2021`\n\n## MLOps Platforms\n1. [Meet Michelangelo: Uber‚Äôs Machine Learning Platform](https://eng.uber.com/michelangelo-machine-learning-platform/) `Uber` `2017`\n2. [Operationalizing Machine Learning‚ÄîManaging Provenance from Raw Data to Predictions](https://vimeo.com/274396495) `Comcast` `2018`\n3. [Big Data Machine Learning Platform at Pinterest](https://www.slideshare.net/Alluxio/pinterest-big-data-machine-learning-platform-at-pinterest) `Pinterest` `2019`\n4. [Core Modeling at Instagram](https://instagram-engineering.com/core-modeling-at-instagram-a51e0158aa48) `Instagram` `2019`\n5. [Open-Sourcing Metaflow - a Human-Centric Framework for Data Science](https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9) `Netflix` `2019`\n6. [Managing ML Models @ Scale - Intuit‚Äôs ML Platform](https://www.usenix.org/conference/opml20/presentation/wenzel) `Intuit` `2020`\n7. [Real-time Machine Learning Inference Platform at Zomato](https://www.youtube.com/watch?v=0-3ES1vzW14) `Zomato` `2020`\n8. [Introducing Flyte: Cloud Native Machine Learning and Data Processing Platform](https://eng.lyft.com/introducing-flyte-cloud-native-machine-learning-and-data-processing-platform-fb2bb3046a59) `Lyft` `2020`\n9. [Building Flexible Ensemble ML Models with a Computational Graph](https://doordash.engineering/2021/01/26/computational-graph-machine-learning-ensemble-model-support/) `DoorDash` `2021`\n10. [LyftLearn: ML Model Training Infrastructure built on Kubernetes](https://eng.lyft.com/lyftlearn-ml-model-training-infrastructure-built-on-kubernetes-aef8218842bb) `Lyft` `2021`\n11. [\"You Don't Need a Bigger Boat\": A Full Data Pipeline Built with Open-Source Tools](https://github.com/jacopotagliabue/you-dont-need-a-bigger-boat) ([Paper](https://arxiv.org/abs/2107.07346)) `Coveo` `2021`\n12. [MLOps at GreenSteam: Shipping Machine Learning](https://neptune.ai/blog/mlops-at-greensteam-shipping-machine-learning-case-study) `GreenSteam` `2021`\n13. [Evolving Reddit‚Äôs ML Model Deployment and Serving Architecture](https://www.reddit.com/r/RedditEng/comments/q14tsw/evolving_reddits_ml_model_deployment_and_serving/) `Reddit` `2021`\n14. [Redesigning Etsy‚Äôs Machine Learning Platform](https://www.etsy.com/codeascraft/redesigning-etsys-machine-learning-platform/) `Etsy` `2021`\n15. [Understanding Data Storage and Ingestion for Large-Scale Deep Recommendation Model Training](https://arxiv.org/abs/2108.09373) ([Paper](https://arxiv.org/pdf/2108.09373.pdf)) `Meta` `2021`\n15. [Building a Platform for Serving Recommendations at Etsy](https://www.etsy.com/codeascraft/building-a-platform-for-serving-recommendations-at-etsy) `Etsy` `2022` \n16. [Intelligent Automation Platform: Empowering Conversational AI and Beyond at Airbnb](https://medium.com/airbnb-engineering/intelligent-automation-platform-empowering-conversational-ai-and-beyond-at-airbnb-869c44833ff2) `Airbnb` `2022`\n17. [DARWIN: Data Science and Artificial Intelligence Workbench at LinkedIn](https://engineering.linkedin.com/blog/2022/darwin--data-science-and-artificial-intelligence-workbench-at-li) `LinkedIn` `2022`\n18. [The Magic of Merlin: Shopify's New Machine Learning Platform](https://shopify.engineering/merlin-shopify-machine-learning-platform) `Shopify` `2022`\n19. [Zalando's Machine Learning Platform](https://engineering.zalando.com/posts/2022/04/zalando-machine-learning-platform.html) `Zalando` `2022`\n20. [Inside Meta's AI optimization platform for engineers across the company](https://ai.facebook.com/blog/looper-meta-ai-optimization-platform-for-engineers/) ([Paper](https://arxiv.org/pdf/2110.07554.pdf)) `Meta` `2022`\n21. [Monzo‚Äôs machine learning stack](https://monzo.com/blog/2022/04/26/monzos-machine-learning-stack) `Monzo` `2022`\n22. [Evolution of ML Fact Store](https://netflixtechblog.com/evolution-of-ml-fact-store-5941d3231762) `Netflix` `2022`\n23. [Using MLOps to Build a Real-time End-to-End Machine Learning Pipeline](https://www.binance.com/en/blog/all/using-mlops-to-build-a-realtime-endtoend-machine-learning-pipeline-3820048062346322706) `Binance` `2022`\n24. [Serving Machine Learning Models Efficiently at Scale at Zillow](https://www.zillow.com/tech/serving-machine-learning-models-efficiently-at-scale-at-zillow/) `Zillow` `2022`\n25. [Didact AI: The anatomy of an ML-powered stock picking engine](https://principiamundi.com/posts/didact-anatomy/?utm_campaign=Data_Elixir&utm_source=Data_Elixir_407/) `Didact AI` `2022`\n26. [Deployment for Free - A Machine Learning Platform for Stitch Fix's Data Scientists](https://multithreaded.stitchfix.com/blog/2022/07/14/deployment-for-free/) `Stitch Fix` `2022`\n27. [Machine Learning Operations (MLOps): Overview, Definition, and Architecture](https://arxiv.org/abs/2205.02302) ([Paper](https://arxiv.org/ftp/arxiv/papers/2205/2205.02302.pdf)) `IBM` `2022`\n\n## Practices\n1. [Practical Recommendations for Gradient-Based Training of Deep Architectures](https://arxiv.org/abs/1206.5533) ([Paper](https://arxiv.org/pdf/1206.5533.pdf)) `Yoshua Bengio` `2012`\n2. [Machine Learning: The High Interest Credit Card of Technical Debt](https://research.google/pubs/pub43146/) ([Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43146.pdf)) ([Paper](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)) `Google` `2014`\n3. [Rules of Machine Learning: Best Practices for ML Engineering](https://developers.google.com/machine-learning/guides/rules-of-ml) `Google` `2018`\n4. [On Challenges in Machine Learning Model Management](http://sites.computer.org/debull/A18dec/p5.pdf) `Amazon` `2018`\n5. [Machine Learning in Production: The Booking.com Approach](https://booking.ai/https-booking-ai-machine-learning-production-3ee8fe943c70) `Booking` `2019`\n6. [150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com](https://booking.ai/150-successful-machine-learning-models-6-lessons-learned-at-booking-com-681e09107bec) ([Paper](https://dl.acm.org/doi/pdf/10.1145/3292500.3330744)) `Booking` `2019`\n7. [Successes and Challenges in Adopting Machine Learning at Scale at a Global Bank](https://www.youtube.com/watch?v=QYQKG5OcwEI) `Rabobank` `2019`\n8. [Challenges in Deploying Machine Learning: a Survey of Case Studies](https://arxiv.org/abs/2011.09926) ([Paper](https://arxiv.org/pdf/2011.09926.pdf)) `Cambridge` `2020`\n9. [Reengineering Facebook AI‚Äôs Deep Learning Platforms for Interoperability](https://ai.facebook.com/blog/reengineering-facebook-ais-deep-learning-platforms-for-interoperability) `Facebook` `2020`\n10. [The problem with AI developer tools for enterprises](https://towardsdatascience.com/the-problem-with-ai-developer-tools-for-enterprises-and-what-ikea-has-to-do-with-it-b26277841661) `Databricks` `2020`\n11. [Continuous Integration and Deployment for Machine Learning Online Serving and Models](https://eng.uber.com/continuous-integration-deployment-ml/) `Uber` `2021`\n12. [Tuning Model Performance](https://eng.uber.com/tuning-model-performance/) `Uber` `2021`\n13. [Maintaining Machine Learning Model Accuracy Through Monitoring](https://doordash.engineering/2021/05/20/monitor-machine-learning-model-drift/) `DoorDash` `2021`\n14. [Building Scalable and Performant Marketing ML Systems at Wayfair](https://www.aboutwayfair.com/careers/tech-blog/building-scalable-and-performant-marketing-ml-systems-at-wayfair) `Wayfair` `2021`\n15. [Our approach to building transparent and explainable AI systems](https://engineering.linkedin.com/blog/2021/transparent-and-explainable-AI-systems) `LinkedIn` `2021`\n16. [5 Steps for Building Machine Learning Models for Business](https://shopify.engineering/building-business-machine-learning-models) `Shopify` `2021`\n17. [Data Is An Art, Not Just A Science‚ÄîAnd Storytelling Is The Key](https://shopifyengineering.myshopify.com/blogs/engineering/data-storytelling-shopify) `Shopify` `2022`\n18. [Best Practices for Real-time Machine Learning: Alerting](https://building.nubank.com.br/best-practices-for-real-time-machine-learning-alerting/) `Nubank` `2022`\n19. [Automatic Retraining for Machine Learning Models: Tips and Lessons Learned](https://building.nubank.com.br/automatic-retraining-for-machine-learning-models/) `Nubank` `2022`\n20. [RecSysOps: Best Practices for Operating a Large-Scale Recommender System](https://netflixtechblog.medium.com/recsysops-best-practices-for-operating-a-large-scale-recommender-system-95bbe195a841) `Netflix` `2022`\n21. [ML Education at Uber: Frameworks Inspired by Engineering Principles](https://www.uber.com/en-PL/blog/ml-education-at-uber/) `Uber` `2022`\n22. [Building and Maintaining Internal Tools for DS/ML teams: Lessons Learned](https://building.nubank.com.br/building-and-maintaining-internal-tools-for-ds-ml-teams-lessons-learned) `Nubank` `2024`\n\n## Team structure\n1. [What is the most effective way to structure a data science team?](https://towardsdatascience.com/what-is-the-most-effective-way-to-structure-a-data-science-team-498041b88dae) `Udemy` `2017`\n1. [Engineers Shouldn‚Äôt Write ETL: A Guide to Building a High Functioning Data Science Department](https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/) `Stitch Fix` `2016`\n2. [Building The Analytics Team At Wish](https://medium.com/wish-engineering/scaling-analytics-at-wish-619eacb97d16) `Wish` `2018`\n3. [Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist](https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/) `Stitch Fix` `2019`\n4. [Cultivating Algorithms: How We Grow Data Science at Stitch Fix](https://cultivating-algos.stitchfix.com) `Stitch Fix`\n5. [Analytics at Netflix: Who We Are and What We Do](https://netflixtechblog.com/analytics-at-netflix-who-we-are-and-what-we-do-7d9c08fe6965) `Netflix` `2020`\n6. [Building a Data Team at a Mid-stage Startup: A Short Story](https://erikbern.com/2021/07/07/the-data-team-a-short-story.html) `Erikbern` `2021`\n7. [A Behind-the-Scenes Look at How Postman‚Äôs Data Team Works](https://entrepreneurshandbook.co/a-behind-the-scenes-look-at-how-postmans-data-team-works-fded0b8bfc64) `Postman` `2021`\n8. [Data Scientist x Machine Learning Engineer Roles: How are they different? How are they alike?](https://building.nubank.com.br/data-scientist-x-machine-learning-engineer-roles-how-are-they-different-how-are-they-alike/) `Nubank` `2022`\n\n## Fails\n1. [When It Comes to Gorillas, Google Photos Remains Blind](https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/) `Google` `2018`\n2. [160k+ High School Students Will Graduate Only If a Model Allows Them to](http://positivelysemidefinite.com/2020/06/160k-students.html) `International Baccalaureate` `2020`\n3. [An Algorithm That ‚ÄòPredicts‚Äô Criminality Based on a Face Sparks a Furor](https://www.wired.com/story/algorithm-predicts-criminality-based-face-sparks-furor/) `Harrisburg University` `2020`\n4. [It's Hard to Generate Neural Text From GPT-3 About Muslims](https://twitter.com/abidlabs/status/1291165311329341440) `OpenAI` `2020`\n5. [A British AI Tool to Predict Violent Crime Is Too Flawed to Use](https://www.wired.co.uk/article/police-violence-prediction-ndas) `United Kingdom` `2020`\n6. More in [awful-ai](https://github.com/daviddao/awful-ai)\n7. [AI Incident Database](https://incidentdatabase.ai/) `Partnership on AI` `2022`\n\n<br>\n\n**P.S., Want a summary of ML advancements?** Get up to speed with survey papers üëâ[`ml-surveys`](https://github.com/eugeneyan/ml-surveys)\n",
         "AI_DataScience"
        ],
        [
         "27",
         "MDEwOlJlcG9zaXRvcnkyNjgxNjM2MDk=",
         "<p align=\"center\">\n  <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/qdrant/qdrant/raw/master/docs/logo-dark.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/qdrant/qdrant/raw/master/docs/logo-light.svg\">\n      <img height=\"100\" alt=\"Qdrant\" src=\"https://github.com/qdrant/qdrant/raw/master/docs/logo.svg\">\n  </picture>\n</p>\n\n<p align=\"center\">\n    <b>Vector Search Engine for the next generation of AI applications</b>\n</p>\n\n<p align=center>\n    <a href=\"https://github.com/qdrant/qdrant/actions/workflows/rust.yml\"><img src=\"https://img.shields.io/github/actions/workflow/status/qdrant/qdrant/rust.yml?style=flat-square\" alt=\"Tests status\"></a>\n    <a href=\"https://api.qdrant.tech/\"><img src=\"https://img.shields.io/badge/Docs-OpenAPI%203.0-success?style=flat-square\" alt=\"OpenAPI Docs\"></a>\n    <a href=\"https://github.com/qdrant/qdrant/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/qdrant/qdrant?style=flat-square\" alt=\"Apache 2.0 License\"></a>\n    <a href=\"https://qdrant.to/discord\"><img src=\"https://img.shields.io/discord/907569970500743200?logo=Discord&style=flat-square&color=7289da\" alt=\"Discord\"></a>\n    <a href=\"https://qdrant.to/roadmap\"><img src=\"https://img.shields.io/badge/Roadmap-2025-bc1439.svg?style=flat-square\" alt=\"Roadmap 2025\"></a>\n    <a href=\"https://cloud.qdrant.io/\"><img src=\"https://img.shields.io/badge/Qdrant-Cloud-24386C.svg?logo=cloud&style=flat-square\" alt=\"Qdrant Cloud\"></a>\n</p>\n\n**Qdrant** (read: _quadrant_) is a vector similarity search engine and vector database.\nIt provides a production-ready service with a convenient API to store, search, and manage points‚Äîvectors with an additional payload\nQdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.\n\nQdrant is written in Rust ü¶Ä, which makes it fast and reliable even under high load. See [benchmarks](https://qdrant.tech/benchmarks/).\n\nWith Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\n\nQdrant is also available as a fully managed **[Qdrant Cloud](https://cloud.qdrant.io/)** ‚õÖ including a **free tier**.\n\n<p align=\"center\">\n<strong><a href=\"docs/QUICK_START.md\">Quick Start</a> ‚Ä¢ <a href=\"#clients\">Client Libraries</a> ‚Ä¢ <a href=\"#demo-projects\">Demo Projects</a> ‚Ä¢ <a href=\"#integrations\">Integrations</a> ‚Ä¢ <a href=\"#contacts\">Contact</a>\n\n</strong>\n</p>\n\n## Getting Started\n\n### Python\n\n```\npip install qdrant-client\n```\n\nThe python client offers a convenient way to start with Qdrant locally:\n\n```python\nfrom qdrant_client import QdrantClient\nqdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance, for testing, CI/CD\n# OR\nclient = QdrantClient(path=\"path/to/db\")  # Persists changes to disk, fast prototyping\n```\n\n### Client-Server\n\nTo experience the full power of Qdrant locally, run the container with this command:\n\n```bash\ndocker run -p 6333:6333 qdrant/qdrant\n```\n\nNow you can connect to this with any client, including Python:\n\n```python\nqdrant = QdrantClient(\"http://localhost:6333\") # Connect to existing Qdrant instance\n```\n\nBefore deploying Qdrant to production, be sure to read our [installation](https://qdrant.tech/documentation/guides/installation/) and [security](https://qdrant.tech/documentation/guides/security/) guides.\n\n### Clients\n\nQdrant offers the following client libraries to help you integrate it into your application stack with ease:\n\n- Official:\n  - [Go client](https://github.com/qdrant/go-client)\n  - [Rust client](https://github.com/qdrant/rust-client)\n  - [JavaScript/TypeScript client](https://github.com/qdrant/qdrant-js)\n  - [Python client](https://github.com/qdrant/qdrant-client)\n  - [.NET/C# client](https://github.com/qdrant/qdrant-dotnet)\n  - [Java client](https://github.com/qdrant/java-client)\n- Community:\n  - [Elixir](https://hexdocs.pm/qdrant/readme.html)\n  - [PHP](https://github.com/hkulekci/qdrant-php)\n  - [Ruby](https://github.com/andreibondarev/qdrant-ruby)\n  - [Java](https://github.com/metaloom/qdrant-java-client)\n\n### Where do I go from here?\n\n- [Quick Start Guide](docs/QUICK_START.md)\n- End to End [Colab Notebook](https://colab.research.google.com/drive/1Bz8RSVHwnNDaNtDwotfPj0w7AYzsdXZ-?usp=sharing) demo with SentenceBERT and Qdrant\n- Detailed [Documentation](https://qdrant.tech/documentation/) are great starting points\n- [Step-by-Step Tutorial](https://qdrant.to/qdrant-tutorial) to create your first neural network project with Qdrant\n\n## Demo Projects<a href=\"https://replit.com/@qdrant\"><img align=\"right\" src=\"https://replit.com/badge/github/qdrant/qdrant\" alt=\"Run on Repl.it\"></a>\n\n### Discover Semantic Text Search üîç\n\nUnlock the power of semantic embeddings with Qdrant, transcending keyword-based search to find meaningful connections in short texts. Deploy a neural search in minutes using a pre-trained neural network, and experience the future of text search. [Try it online!](https://qdrant.to/semantic-search-demo)\n\n### Explore Similar Image Search - Food Discovery üçï\n\nThere's more to discovery than text search, especially when it comes to food. People often choose meals based on appearance rather than descriptions and ingredients. Let Qdrant help your users find their next delicious meal using visual search, even if they don't know the dish's name. [Check it out!](https://qdrant.to/food-discovery)\n\n### Master Extreme Classification - E-commerce Product Categorization üì∫\n\nEnter the cutting-edge realm of extreme classification, an emerging machine learning field tackling multi-class and multi-label problems with millions of labels. Harness the potential of similarity learning models, and see how a pre-trained transformer model and Qdrant can revolutionize e-commerce product categorization. [Play with it online!](https://qdrant.to/extreme-classification-demo)\n\n<details>\n<summary> More solutions </summary>\n\n<table>\n    <tr>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/text_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/image_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/recommendations.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Semantic Text Search\n        </td>\n        <td>\n            Similar Image Search\n        </td>\n        <td>\n            Recommendations\n        </td>\n    </tr>\n</table>\n\n<table>\n    <tr>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/chat_bots.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/matching_engines.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/anomalies_detection.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Chat Bots\n        </td>\n        <td>\n            Matching Engines\n        </td>\n        <td>\n            Anomaly Detection\n        </td>\n    </tr>\n</table>\n\n</details>\n\n## API\n\n### REST\n\nOnline OpenAPI 3.0 documentation is available [here](https://api.qdrant.tech/).\nOpenAPI makes it easy to generate a client for virtually any framework or programming language.\n\nYou can also download raw OpenAPI [definitions](https://github.com/qdrant/qdrant/blob/master/docs/redoc/master/openapi.json).\n\n### gRPC\n\nFor faster production-tier searches, Qdrant also provides a gRPC interface. You can find gRPC documentation [here](https://qdrant.tech/documentation/interfaces/#grpc-interface).\n\n## Features\n\n### Filtering and Payload\n\nQdrant can attach any JSON payloads to vectors, allowing for both the storage and filtering of data based on the values in these payloads.\nPayload supports a wide range of data types and query conditions, including keyword matching, full-text filtering, numerical ranges, geo-locations, and more.\n\nFiltering conditions can be combined in various ways, including `should`, `must`, and `must_not` clauses,\nensuring that you can implement any desired business logic on top of similarity matching.\n\n\n### Hybrid Search with Sparse Vectors\n\nTo address the limitations of vector embeddings when searching for specific keywords, Qdrant introduces support for sparse vectors in addition to the regular dense ones.\n\nSparse vectors can be viewed as an generalization of BM25 or TF-IDF ranking. They enable you to harness the capabilities of transformer-based neural networks to weigh individual tokens effectively.\n\n\n### Vector Quantization and On-Disk Storage\n\nQdrant provides multiple options to make vector search cheaper and more resource-efficient.\nBuilt-in vector quantization reduces RAM usage by up to 97% and dynamically manages the trade-off between search speed and precision.\n\n\n### Distributed Deployment\n\nQdrant offers comprehensive horizontal scaling support through two key mechanisms:\n1. Size expansion via sharding and throughput enhancement via replication\n2. Zero-downtime rolling updates and seamless dynamic scaling of the collections\n\n\n### Highlighted Features\n\n* **Query Planning and Payload Indexes** - leverages stored payload information to optimize query execution strategy.\n* **SIMD Hardware Acceleration** - utilizes modern CPU x86-x64 and Neon architectures to deliver better performance.\n* **Async I/O** - uses `io_uring` to maximize disk throughput utilization even on a network-attached storage.\n* **Write-Ahead Logging** - ensures data persistence with update confirmation, even during power outages.\n\n\n# Integrations\n\nExamples and/or documentation of Qdrant integrations:\n\n- [Cohere](https://docs.cohere.com/docs/qdrant-and-cohere) ([blogpost on building a QA app with Cohere and Qdrant](https://qdrant.tech/articles/qa-with-cohere-and-qdrant/)) - Use Cohere embeddings with Qdrant\n- [DocArray](https://docs.docarray.org/user_guide/storing/index_qdrant/) - Use Qdrant as a document store in DocArray\n- [Haystack](https://haystack.deepset.ai/integrations/qdrant-document-store) - Use Qdrant as a document store with Haystack ([blogpost](https://haystack.deepset.ai/blog/qdrant-integration)).\n- [LangChain](https://python.langchain.com/docs/integrations/providers/qdrant/) ([blogpost](https://qdrant.tech/articles/langchain-integration/)) - Use Qdrant as a memory backend for LangChain.\n- [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/QdrantIndexDemo.html) - Use Qdrant as a Vector Store with LlamaIndex.\n- [OpenAI - ChatGPT retrieval plugin](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/docs/providers/qdrant/setup.md) - Use Qdrant as a memory backend for ChatGPT\n- [Microsoft Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel/the-power-of-persistent-memory-with-semantic-kernel-and-qdrant-vector-database/) - Use Qdrant as persistent memory with Semantic Kernel\n\n## Contacts\n\n- Have questions? Join our [Discord channel](https://qdrant.to/discord) or mention [@qdrant_engine on Twitter](https://qdrant.to/twitter)\n- Want to stay in touch with latest releases? Subscribe to our [Newsletters](https://qdrant.tech/subscribe/)\n- Looking for a managed cloud? Check [pricing](https://qdrant.tech/pricing/), need something personalised? We're at [info@qdrant.tech](mailto:info@qdrant.tech)\n\n## License\n\nQdrant is licensed under the Apache License, Version 2.0. View a copy of the [License file](https://github.com/qdrant/qdrant/blob/master/LICENSE).\n",
         "AI_DataScience"
        ],
        [
         "28",
         "R_kgDOLr2o1g",
         "# üöÄ Perplexica - An AI-powered search engine üîé <!-- omit in toc -->\n\n<div align=\"center\" markdown=\"1\">\n   <sup>Special thanks to:</sup>\n   <br>\n   <br>\n   <a href=\"https://www.warp.dev/perplexica\">\n      <img alt=\"Warp sponsorship\" width=\"400\" src=\"https://github.com/user-attachments/assets/775dd593-9b5f-40f1-bf48-479faff4c27b\">\n   </a>\n\n### [Warp, the AI Devtool that lives in your terminal](https://www.warp.dev/perplexica)\n\n[Available for MacOS, Linux, & Windows](https://www.warp.dev/perplexica)\n\n</div>\n\n<hr/>\n\n[![Discord](https://dcbadge.limes.pink/api/server/26aArMy8tT?style=flat)](https://discord.gg/26aArMy8tT)\n\n![preview](.assets/perplexica-screenshot.png?)\n\n## Table of Contents <!-- omit in toc -->\n\n- [Overview](#overview)\n- [Preview](#preview)\n- [Features](#features)\n- [Installation](#installation)\n  - [Getting Started with Docker (Recommended)](#getting-started-with-docker-recommended)\n  - [Non-Docker Installation](#non-docker-installation)\n  - [Ollama Connection Errors](#ollama-connection-errors)\n  - [Lemonade Connection Errors](#lemonade-connection-errors)\n- [Using as a Search Engine](#using-as-a-search-engine)\n- [Using Perplexica's API](#using-perplexicas-api)\n- [Expose Perplexica to a network](#expose-perplexica-to-network)\n- [One-Click Deployment](#one-click-deployment)\n- [Upcoming Features](#upcoming-features)\n- [Support Us](#support-us)\n  - [Donations](#donations)\n- [Contribution](#contribution)\n- [Help and Support](#help-and-support)\n\n## Overview\n\nPerplexica is an open-source AI-powered searching tool or an AI-powered search engine that goes deep into the internet to find answers. Inspired by Perplexity AI, it's an open-source option that not just searches the web but understands your questions. It uses advanced machine learning algorithms like similarity searching and embeddings to refine results and provides clear answers with sources cited.\n\nUsing SearxNG to stay current and fully open source, Perplexica ensures you always get the most up-to-date information without compromising your privacy.\n\nWant to know more about its architecture and how it works? You can read it [here](https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/architecture/README.md).\n\n## Preview\n\n![video-preview](.assets/perplexica-preview.gif)\n\n## Features\n\n- **Local LLMs**: You can utilize local LLMs such as Qwen, DeepSeek, Llama, and Mistral.\n- **Two Main Modes:**\n  - **Copilot Mode:** (In development) Boosts search by generating different queries to find more relevant internet sources. Like normal search instead of just using the context by SearxNG, it visits the top matches and tries to find relevant sources to the user's query directly from the page.\n  - **Normal Mode:** Processes your query and performs a web search.\n- **Focus Modes:** Special modes to better answer specific types of questions. Perplexica currently has 6 focus modes:\n  - **All Mode:** Searches the entire web to find the best results.\n  - **Writing Assistant Mode:** Helpful for writing tasks that do not require searching the web.\n  - **Academic Search Mode:** Finds articles and papers, ideal for academic research.\n  - **YouTube Search Mode:** Finds YouTube videos based on the search query.\n  - **Wolfram Alpha Search Mode:** Answers queries that need calculations or data analysis using Wolfram Alpha.\n  - **Reddit Search Mode:** Searches Reddit for discussions and opinions related to the query.\n- **Current Information:** Some search tools might give you outdated info because they use data from crawling bots and convert them into embeddings and store them in a index. Unlike them, Perplexica uses SearxNG, a metasearch engine to get the results and rerank and get the most relevant source out of it, ensuring you always get the latest information without the overhead of daily data updates.\n- **API**: Integrate Perplexica into your existing applications and make use of its capibilities.\n\nIt has many more features like image and video search. Some of the planned features are mentioned in [upcoming features](#upcoming-features).\n\n## Installation\n\nThere are mainly 2 ways of installing Perplexica - With Docker, Without Docker. Using Docker is highly recommended.\n\n### Getting Started with Docker (Recommended)\n\n1. Ensure Docker is installed and running on your system.\n2. Clone the Perplexica repository:\n\n   ```bash\n   git clone https://github.com/ItzCrazyKns/Perplexica.git\n   ```\n\n3. After cloning, navigate to the directory containing the project files.\n\n4. Rename the `sample.config.toml` file to `config.toml`. For Docker setups, you need only fill in the following fields:\n\n   - `OPENAI`: Your OpenAI API key. **You only need to fill this if you wish to use OpenAI's models**.\n   - `CUSTOM_OPENAI`: Your OpenAI-API-compliant local server URL, model name, and API key. You should run your local server with host set to `0.0.0.0`, take note of which port number it is running on, and then use that port number to set `API_URL = http://host.docker.internal:PORT_NUMBER`. You must specify the model name, such as `MODEL_NAME = \"unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF:Q4_K_XL\"`. Finally, set `API_KEY` to the appropriate value. If you have not defined an API key, just put anything you want in-between the quotation marks: `API_KEY = \"whatever-you-want-but-not-blank\"` **You only need to configure these settings if you want to use a local OpenAI-compliant server, such as Llama.cpp's [`llama-server`](https://github.com/ggml-org/llama.cpp/blob/master/tools/server/README.md)**.\n   - `OLLAMA`: Your Ollama API URL. You should enter it as `http://host.docker.internal:PORT_NUMBER`. If you installed Ollama on port 11434, use `http://host.docker.internal:11434`. For other ports, adjust accordingly. **You need to fill this if you wish to use Ollama's models instead of OpenAI's**.\n   - `LEMONADE`: Your Lemonade API URL. Since Lemonade runs directly on your local machine (not in Docker), you should enter it as `http://host.docker.internal:PORT_NUMBER`. If you installed Lemonade on port 8000, use `http://host.docker.internal:8000`. For other ports, adjust accordingly. **You need to fill this if you wish to use Lemonade's models**.\n   - `GROQ`: Your Groq API key. **You only need to fill this if you wish to use Groq's hosted models**.`\n   - `ANTHROPIC`: Your Anthropic API key. **You only need to fill this if you wish to use Anthropic models**.\n   - `Gemini`: Your Gemini API key. **You only need to fill this if you wish to use Google's models**.\n   - `DEEPSEEK`: Your Deepseek API key. **Only needed if you want Deepseek models.**\n   - `AIMLAPI`: Your AI/ML API key. **Only needed if you want to use AI/ML API models and embeddings.**\n\n     **Note**: You can change these after starting Perplexica from the settings dialog.\n\n   - `SIMILARITY_MEASURE`: The similarity measure to use (This is filled by default; you can leave it as is if you are unsure about it.)\n\n5. Ensure you are in the directory containing the `docker-compose.yaml` file and execute:\n\n   ```bash\n   docker compose up -d\n   ```\n\n6. Wait a few minutes for the setup to complete. You can access Perplexica at http://localhost:3000 in your web browser.\n\n**Note**: After the containers are built, you can start Perplexica directly from Docker without having to open a terminal.\n\n### Non-Docker Installation\n\n1. Install SearXNG and allow `JSON` format in the SearXNG settings.\n2. Clone the repository and rename the `sample.config.toml` file to `config.toml` in the root directory. Ensure you complete all required fields in this file.\n3. After populating the configuration run `npm i`.\n4. Install the dependencies and then execute `npm run build`.\n5. Finally, start the app by running `npm run start`\n\n**Note**: Using Docker is recommended as it simplifies the setup process, especially for managing environment variables and dependencies.\n\nSee the [installation documentation](https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/installation) for more information like updating, etc.\n\n### Troubleshooting\n\n#### Local OpenAI-API-Compliant Servers\n\nIf Perplexica tells you that you haven't configured any chat model providers, ensure that:\n\n1. Your server is running on `0.0.0.0` (not `127.0.0.1`) and on the same port you put in the API URL.\n2. You have specified the correct model name loaded by your local LLM server.\n3. You have specified the correct API key, or if one is not defined, you have put _something_ in the API key field and not left it empty.\n\n#### Ollama Connection Errors\n\nIf you're encountering an Ollama connection error, it is likely due to the backend being unable to connect to Ollama's API. To fix this issue you can:\n\n1. **Check your Ollama API URL:** Ensure that the API URL is correctly set in the settings menu.\n2. **Update API URL Based on OS:**\n\n   - **Windows:** Use `http://host.docker.internal:11434`\n   - **Mac:** Use `http://host.docker.internal:11434`\n   - **Linux:** Use `http://<private_ip_of_host>:11434`\n\n   Adjust the port number if you're using a different one.\n\n3. **Linux Users - Expose Ollama to Network:**\n\n   - Inside `/etc/systemd/system/ollama.service`, you need to add `Environment=\"OLLAMA_HOST=0.0.0.0:11434\"`. (Change the port number if you are using a different one.) Then reload the systemd manager configuration with `systemctl daemon-reload`, and restart Ollama by `systemctl restart ollama`. For more information see [Ollama docs](https://github.com/ollama/ollama/blob/main/docs/faq.md#setting-environment-variables-on-linux)\n\n   - Ensure that the port (default is 11434) is not blocked by your firewall.\n\n#### Lemonade Connection Errors\n\nIf you're encountering a Lemonade connection error, it is likely due to the backend being unable to connect to Lemonade's API. To fix this issue you can:\n\n1. **Check your Lemonade API URL:** Ensure that the API URL is correctly set in the settings menu.\n2. **Update API URL Based on OS:**\n\n   - **Windows:** Use `http://host.docker.internal:8000`\n   - **Mac:** Use `http://host.docker.internal:8000`\n   - **Linux:** Use `http://<private_ip_of_host>:8000`\n\n   Adjust the port number if you're using a different one.\n\n3. **Ensure Lemonade Server is Running:**\n\n   - Make sure your Lemonade server is running and accessible on the configured port (default is 8000).\n   - Verify that Lemonade is configured to accept connections from all interfaces (`0.0.0.0`), not just localhost (`127.0.0.1`).\n   - Ensure that the port (default is 8000) is not blocked by your firewall.\n\n## Using as a Search Engine\n\nIf you wish to use Perplexica as an alternative to traditional search engines like Google or Bing, or if you want to add a shortcut for quick access from your browser's search bar, follow these steps:\n\n1. Open your browser's settings.\n2. Navigate to the 'Search Engines' section.\n3. Add a new site search with the following URL: `http://localhost:3000/?q=%s`. Replace `localhost` with your IP address or domain name, and `3000` with the port number if Perplexica is not hosted locally.\n4. Click the add button. Now, you can use Perplexica directly from your browser's search bar.\n\n## Using Perplexica's API\n\nPerplexica also provides an API for developers looking to integrate its powerful search engine into their own applications. You can run searches, use multiple models and get answers to your queries.\n\nFor more details, check out the full documentation [here](https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/API/SEARCH.md).\n\n## Expose Perplexica to network\n\nPerplexica runs on Next.js and handles all API requests. It works right away on the same network and stays accessible even with port forwarding.\n\n## One-Click Deployment\n\n[![Deploy to Sealos](https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg)](https://usw.sealos.io/?openapp=system-template%3FtemplateName%3Dperplexica)\n[![Deploy to RepoCloud](https://d16t0pc4846x52.cloudfront.net/deploylobe.svg)](https://repocloud.io/details/?app_id=267)\n[![Run on ClawCloud](https://raw.githubusercontent.com/ClawCloud/Run-Template/refs/heads/main/Run-on-ClawCloud.svg)](https://template.run.claw.cloud/?referralCode=U11MRQ8U9RM4&openapp=system-fastdeploy%3FtemplateName%3Dperplexica)\n[![Deploy on Hostinger](https://assets.hostinger.com/vps/deploy.svg)](https://www.hostinger.com/vps/docker-hosting?compose_url=https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/refs/heads/master/docker-compose.yaml)\n\n## Upcoming Features\n\n- [x] Add settings page\n- [x] Adding support for local LLMs\n- [x] History Saving features\n- [x] Introducing various Focus Modes\n- [x] Adding API support\n- [x] Adding Discover\n- [ ] Finalizing Copilot Mode\n\n## Support Us\n\nIf you find Perplexica useful, consider giving us a star on GitHub. This helps more people discover Perplexica and supports the development of new features. Your support is greatly appreciated.\n\n### Donations\n\nWe also accept donations to help sustain our project. If you would like to contribute, you can use the following options to donate. Thank you for your support!\n\n| Ethereum                                              |\n| ----------------------------------------------------- |\n| Address: `0xB025a84b2F269570Eb8D4b05DEdaA41D8525B6DD` |\n\n## Contribution\n\nPerplexica is built on the idea that AI and large language models should be easy for everyone to use. If you find bugs or have ideas, please share them in via GitHub Issues. For more information on contributing to Perplexica you can read the [CONTRIBUTING.md](CONTRIBUTING.md) file to learn more about Perplexica and how you can contribute to it.\n\n## Help and Support\n\nIf you have any questions or feedback, please feel free to reach out to us. You can create an issue on GitHub or join our Discord server. There, you can connect with other users, share your experiences and reviews, and receive more personalized help. [Click here](https://discord.gg/EFwsmQDgAu) to join the Discord server. To discuss matters outside of regular support, feel free to contact me on Discord at `itzcrazykns`.\n\nThank you for exploring Perplexica, the AI-powered search engine designed to enhance your search experience. We are constantly working to improve Perplexica and expand its capabilities. We value your feedback and contributions which help us make Perplexica even better. Don't forget to check back for updates and new features!\n",
         "AI_DataScience"
        ],
        [
         "29",
         "MDEwOlJlcG9zaXRvcnk2MDMyNTA2Mg==",
         "# Awesome - Most Cited Deep Learning Papers\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\n[Notice] This list is not being maintained anymore because of the overwhelming amount of deep learning papers published every day since 2017.\n\nA curated list of the most cited deep learning papers (2012-2016)\n\nWe believe that there exist *classic* deep learning papers which are worth reading regardless of their application domain. Rather than providing overwhelming amount of papers, We would like to provide a *curated list* of the awesome deep learning papers which are considered as *must-reads* in certain research domains.\n\n## Background\n\nBefore this list, there exist other *awesome deep learning lists*, for example, [Deep Vision](https://github.com/kjw0612/awesome-deep-vision) and [Awesome Recurrent Neural Networks](https://github.com/kjw0612/awesome-rnn). Also, after this list comes out, another awesome list for deep learning beginners, called [Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap), has been created and loved by many deep learning researchers.\n\nAlthough the *Roadmap List* includes lots of important deep learning papers, it feels overwhelming for me to read them all. As I mentioned in the introduction, I believe that seminal works can give us lessons regardless of their application domain. Thus, I would like to introduce **top 100 deep learning papers** here as a good starting point of overviewing deep learning researches.\n\nTo get the news for newly released papers everyday, follow my [twitter](https://twitter.com/TerryUm_ML) or [facebook page](https://www.facebook.com/terryum.io/)! \n\n## Awesome list criteria\n\n1. A list of **top 100 deep learning papers** published from 2012 to 2016 is suggested.\n2. If a paper is added to the list, another paper (usually from *More Papers from 2016\" section) should be removed to keep top 100 papers. (Thus, removing papers is also important contributions as well as adding papers)\n3. Papers that are important, but failed to be included in the list, will be listed in *More than Top 100* section.\n4. Please refer to *New Papers* and *Old Papers* sections for the papers published in recent 6 months or before 2012.\n\n*(Citation criteria)*\n- **< 6 months** : *New Papers* (by discussion)\n- **2016** :  +60 citations or \"More Papers from 2016\"\n- **2015** :  +200 citations\n- **2014** :  +400 citations\n- **2013** :  +600 citations\n- **2012** :  +800 citations\n- **~2012** : *Old Papers* (by discussion)\n\nPlease note that we prefer seminal deep learning papers that can be applied to various researches rather than application papers. For that reason, some papers that meet the criteria may not be accepted while others can be. It depends on the impact of the paper, applicability to other researches scarcity of the research domain, and so on.\n\n**We need your contributions!**\n\nIf you have any suggestions (missing papers, new papers, key researchers or typos), please feel free to edit and pull a request.\n(Please read the [contributing guide](https://github.com/terryum/awesome-deep-learning-papers/blob/master/Contributing.md) for further instructions, though just letting me know the title of papers can also be a big contribution to us.)\n\n(Update) You can download all top-100 papers with [this](https://github.com/terryum/awesome-deep-learning-papers/blob/master/fetch_papers.py) and collect all authors' names with [this](https://github.com/terryum/awesome-deep-learning-papers/blob/master/get_authors.py). Also, [bib file](https://github.com/terryum/awesome-deep-learning-papers/blob/master/top100papers.bib) for all top-100 papers are available. Thanks, doodhwala, [Sven](https://github.com/sunshinemyson) and [grepinsight](https://github.com/grepinsight)!\n\n+ Can anyone contribute the code for obtaining the statistics of the authors of Top-100 papers?\n\n\n## Contents\n\n* [Understanding / Generalization / Transfer](#understanding--generalization--transfer)\n* [Optimization / Training Techniques](#optimization--training-techniques)\n* [Unsupervised / Generative Models](#unsupervised--generative-models)\n* [Convolutional Network Models](#convolutional-neural-network-models)\n* [Image Segmentation / Object Detection](#image-segmentation--object-detection)\n* [Image / Video / Etc](#image--video--etc)\n* [Natural Language Processing / RNNs](#natural-language-processing--rnns)\n* [Speech / Other Domain](#speech--other-domain)\n* [Reinforcement Learning / Robotics](#reinforcement-learning--robotics)\n* [More Papers from 2016](#more-papers-from-2016)\n\n*(More than Top 100)*\n\n* [New Papers](#new-papers) : Less than 6 months\n* [Old Papers](#old-papers) : Before 2012\n* [HW / SW / Dataset](#hw--sw--dataset) : Technical reports\n* [Book / Survey / Review](#book--survey--review)\n* [Video Lectures / Tutorials / Blogs](#video-lectures--tutorials--blogs)\n* [Appendix: More than Top 100](#appendix-more-than-top-100) : More papers not in the list\n\n* * *\n\n### Understanding / Generalization / Transfer\n- **Distilling the knowledge in a neural network** (2015), G. Hinton et al. [[pdf]](http://arxiv.org/pdf/1503.02531)\n- **Deep neural networks are easily fooled: High confidence predictions for unrecognizable images** (2015), A. Nguyen et al. [[pdf]](http://arxiv.org/pdf/1412.1897)\n- **How transferable are features in deep neural networks?** (2014), J. Yosinski et al. [[pdf]](http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf)\n- **CNN features off-the-Shelf: An astounding baseline for recognition** (2014), A. Razavian et al. [[pdf]](http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/W15/papers/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.pdf)\n- **Learning and transferring mid-Level image representations using convolutional neural networks** (2014), M. Oquab et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf)\n- **Visualizing and understanding convolutional networks** (2014), M. Zeiler and R. Fergus [[pdf]](http://arxiv.org/pdf/1311.2901)\n- **Decaf: A deep convolutional activation feature for generic visual recognition** (2014), J. Donahue et al. [[pdf]](http://arxiv.org/pdf/1310.1531)\n\n<!---[Key researchers]  [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Jason Yosinski](https://scholar.google.ca/citations?hl=en&user=gxL1qj8AAAAJ) -->\n\n### Optimization / Training Techniques\n- **Training very deep networks** (2015), R. Srivastava et al. [[pdf]](http://papers.nips.cc/paper/5850-training-very-deep-networks.pdf)\n- **Batch normalization: Accelerating deep network training by reducing internal covariate shift** (2015), S. Loffe and C. Szegedy [[pdf]](http://arxiv.org/pdf/1502.03167)\n- **Delving deep into rectifiers: Surpassing human-level performance on imagenet classification** (2015), K. He et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf)\n- **Dropout: A simple way to prevent neural networks from overfitting** (2014), N. Srivastava et al. [[pdf]](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n- **Adam: A method for stochastic optimization** (2014), D. Kingma and J. Ba [[pdf]](http://arxiv.org/pdf/1412.6980)\n- **Improving neural networks by preventing co-adaptation of feature detectors** (2012), G. Hinton et al. [[pdf]](http://arxiv.org/pdf/1207.0580.pdf)\n- **Random search for hyper-parameter optimization** (2012) J. Bergstra and Y. Bengio [[pdf]](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a)\n\n<!---[Key researchers] [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Christian Szegedy](https://scholar.google.ca/citations?hl=en&user=3QeF7mAAAAAJ), [Sergey Ioffe](https://scholar.google.ca/citations?user=S5zOyIkAAAAJ), [Kaming He](https://scholar.google.ca/citations?hl=en&user=DhtAFkwAAAAJ), [Diederik P. Kingma](https://scholar.google.ca/citations?hl=en&user=yyIoQu4AAAAJ)-->\n\n### Unsupervised / Generative Models\n- **Pixel recurrent neural networks** (2016), A. Oord et al. [[pdf]](http://arxiv.org/pdf/1601.06759v2.pdf)\n- **Improved techniques for training GANs** (2016), T. Salimans et al. [[pdf]](http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf)\n- **Unsupervised representation learning with deep convolutional generative adversarial networks** (2015), A. Radford et al. [[pdf]](https://arxiv.org/pdf/1511.06434v2)\n- **DRAW: A recurrent neural network for image generation** (2015), K. Gregor et al. [[pdf]](http://arxiv.org/pdf/1502.04623)\n- **Generative adversarial nets** (2014), I. Goodfellow et al. [[pdf]](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)\n- **Auto-encoding variational Bayes** (2013), D. Kingma and M. Welling [[pdf]](http://arxiv.org/pdf/1312.6114)\n- **Building high-level features using large scale unsupervised learning** (2013), Q. Le et al. [[pdf]](http://arxiv.org/pdf/1112.6209)\n\n<!---[Key researchers] [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Ian Goodfellow](https://scholar.google.ca/citations?user=iYN86KEAAAAJ), [Alex Graves](https://scholar.google.ca/citations?user=DaFHynwAAAAJ)-->\n### Convolutional Neural Network Models\n- **Rethinking the inception architecture for computer vision** (2016), C. Szegedy et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf)\n- **Inception-v4, inception-resnet and the impact of residual connections on learning** (2016), C. Szegedy et al. [[pdf]](http://arxiv.org/pdf/1602.07261)\n- **Identity Mappings in Deep Residual Networks** (2016), K. He et al. [[pdf]](https://arxiv.org/pdf/1603.05027v2.pdf)\n- **Deep residual learning for image recognition** (2016), K. He et al. [[pdf]](http://arxiv.org/pdf/1512.03385)\n- **Spatial transformer network** (2015), M. Jaderberg et al., [[pdf]](http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf)\n- **Going deeper with convolutions** (2015), C. Szegedy et al.  [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)\n- **Very deep convolutional networks for large-scale image recognition** (2014), K. Simonyan and A. Zisserman [[pdf]](http://arxiv.org/pdf/1409.1556)\n- **Return of the devil in the details: delving deep into convolutional nets** (2014), K. Chatfield et al. [[pdf]](http://arxiv.org/pdf/1405.3531)\n- **OverFeat: Integrated recognition, localization and detection using convolutional networks** (2013), P. Sermanet et al. [[pdf]](http://arxiv.org/pdf/1312.6229)\n- **Maxout networks** (2013), I. Goodfellow et al. [[pdf]](http://arxiv.org/pdf/1302.4389v4)\n- **Network in network** (2013), M. Lin et al. [[pdf]](http://arxiv.org/pdf/1312.4400)\n- **ImageNet classification with deep convolutional neural networks** (2012), A. Krizhevsky et al. [[pdf]](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n\n<!---[Key researchers]  [Christian Szegedy](https://scholar.google.ca/citations?hl=en&user=3QeF7mAAAAAJ), [Kaming He](https://scholar.google.ca/citations?hl=en&user=DhtAFkwAAAAJ), [Shaoqing Ren](https://scholar.google.ca/citations?hl=en&user=AUhj438AAAAJ), [Jian Sun](https://scholar.google.ca/citations?hl=en&user=ALVSZAYAAAAJ), [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Yann LeCun](https://scholar.google.ca/citations?hl=en&user=WLN3QrAAAAAJ)-->\n\n### Image: Segmentation / Object Detection\n- **You only look once: Unified, real-time object detection** (2016), J. Redmon et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf)\n- **Fully convolutional networks for semantic segmentation** (2015), J. Long et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)\n- **Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks** (2015), S. Ren et al. [[pdf]](http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf)\n- **Fast R-CNN** (2015), R. Girshick [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf)\n- **Rich feature hierarchies for accurate object detection and semantic segmentation** (2014), R. Girshick et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf)\n- **Spatial pyramid pooling in deep convolutional networks for visual recognition** (2014), K. He et al. [[pdf]](http://arxiv.org/pdf/1406.4729)\n- **Semantic image segmentation with deep convolutional nets and fully connected CRFs**, L. Chen et al. [[pdf]](https://arxiv.org/pdf/1412.7062)\n- **Learning hierarchical features for scene labeling** (2013), C. Farabet et al. [[pdf]](https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/PDF/farabet-pami-13.pdf)\n\n<!---[Key researchers]  [Ross Girshick](https://scholar.google.ca/citations?hl=en&user=W8VIEZgAAAAJ), [Jeff Donahue](https://scholar.google.ca/citations?hl=en&user=UfbuDH8AAAAJ), [Trevor Darrell](https://scholar.google.ca/citations?hl=en&user=bh-uRFMAAAAJ)-->\n\n### Image / Video / Etc\n- **Image Super-Resolution Using Deep Convolutional Networks** (2016), C. Dong et al. [[pdf]](https://arxiv.org/pdf/1501.00092v3.pdf)\n- **A neural algorithm of artistic style** (2015), L. Gatys et al. [[pdf]](https://arxiv.org/pdf/1508.06576)\n- **Deep visual-semantic alignments for generating image descriptions** (2015), A. Karpathy and L. Fei-Fei [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.pdf)\n- **Show, attend and tell: Neural image caption generation with visual attention** (2015), K. Xu et al. [[pdf]](http://arxiv.org/pdf/1502.03044)\n- **Show and tell: A neural image caption generator** (2015), O. Vinyals et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf)\n- **Long-term recurrent convolutional networks for visual recognition and description** (2015), J. Donahue et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper.pdf)\n- **VQA: Visual question answering** (2015), S. Antol et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Antol_VQA_Visual_Question_ICCV_2015_paper.pdf)\n- **DeepFace: Closing the gap to human-level performance in face verification** (2014), Y. Taigman et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Taigman_DeepFace_Closing_the_2014_CVPR_paper.pdf):\n- **Large-scale video classification with convolutional neural networks** (2014), A. Karpathy et al. [[pdf]](http://vision.stanford.edu/pdf/karpathy14.pdf)\n- **Two-stream convolutional networks for action recognition in videos** (2014), K. Simonyan et al. [[pdf]](http://papers.nips.cc/paper/5353-two-stream-convolutional-networks-for-action-recognition-in-videos.pdf)\n- **3D convolutional neural networks for human action recognition** (2013), S. Ji et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_JiXYY10.pdf)\n\n<!---[Key researchers]  [Oriol Vinyals](https://scholar.google.ca/citations?user=NkzyCvUAAAAJ), [Andrej Karpathy](https://scholar.google.ca/citations?user=l8WuQJgAAAAJ)-->\n\n<!---[Key researchers]  [Alex Graves](https://scholar.google.ca/citations?user=DaFHynwAAAAJ)-->\n\n### Natural Language Processing / RNNs\n- **Neural Architectures for Named Entity Recognition** (2016), G. Lample et al. [[pdf]](http://aclweb.org/anthology/N/N16/N16-1030.pdf)\n- **Exploring the limits of language modeling** (2016), R. Jozefowicz et al. [[pdf]](http://arxiv.org/pdf/1602.02410)\n- **Teaching machines to read and comprehend** (2015), K. Hermann et al. [[pdf]](http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf)\n- **Effective approaches to attention-based neural machine translation** (2015), M. Luong et al. [[pdf]](https://arxiv.org/pdf/1508.04025)\n- **Conditional random fields as recurrent neural networks** (2015), S. Zheng and S. Jayasumana. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zheng_Conditional_Random_Fields_ICCV_2015_paper.pdf)\n- **Memory networks** (2014), J. Weston et al. [[pdf]](https://arxiv.org/pdf/1410.3916)\n- **Neural turing machines** (2014), A. Graves et al. [[pdf]](https://arxiv.org/pdf/1410.5401)\n- **Neural machine translation by jointly learning to align and translate** (2014), D. Bahdanau et al. [[pdf]](http://arxiv.org/pdf/1409.0473)\n- **Sequence to sequence learning with neural networks** (2014), I. Sutskever et al. [[pdf]](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n- **Learning phrase representations using RNN encoder-decoder for statistical machine translation** (2014), K. Cho et al. [[pdf]](http://arxiv.org/pdf/1406.1078)\n- **A convolutional neural network for modeling sentences** (2014), N. Kalchbrenner et al. [[pdf]](http://arxiv.org/pdf/1404.2188v1)\n- **Convolutional neural networks for sentence classification** (2014), Y. Kim [[pdf]](http://arxiv.org/pdf/1408.5882)\n- **Glove: Global vectors for word representation** (2014), J. Pennington et al. [[pdf]](http://anthology.aclweb.org/D/D14/D14-1162.pdf)\n- **Distributed representations of sentences and documents** (2014), Q. Le and T. Mikolov [[pdf]](http://arxiv.org/pdf/1405.4053)\n- **Distributed representations of words and phrases and their compositionality** (2013), T. Mikolov et al. [[pdf]](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n- **Efficient estimation of word representations in vector space** (2013), T. Mikolov et al.  [[pdf]](http://arxiv.org/pdf/1301.3781)\n- **Recursive deep models for semantic compositionality over a sentiment treebank** (2013), R. Socher et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.383.1327&rep=rep1&type=pdf)\n- **Generating sequences with recurrent neural networks** (2013), A. Graves. [[pdf]](https://arxiv.org/pdf/1308.0850)\n\n<!---[Key researchers]  [Kyunghyun Cho](https://scholar.google.ca/citations?user=0RAmmIAAAAAJ), [Oriol Vinyals](https://scholar.google.ca/citations?user=NkzyCvUAAAAJ), [Richard Socher](https://scholar.google.ca/citations?hl=en&user=FaOcyfMAAAAJ), [Tomas Mikolov](https://scholar.google.ca/citations?user=oBu8kMMAAAAJ), [Christopher D. Manning](https://scholar.google.ca/citations?user=1zmDOdwAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ)-->\n\n### Speech / Other Domain\n- **End-to-end attention-based large vocabulary speech recognition** (2016), D. Bahdanau et al. [[pdf]](https://arxiv.org/pdf/1508.04395)\n- **Deep speech 2: End-to-end speech recognition in English and Mandarin** (2015), D. Amodei et al. [[pdf]](https://arxiv.org/pdf/1512.02595)\n- **Speech recognition with deep recurrent neural networks** (2013), A. Graves [[pdf]](http://arxiv.org/pdf/1303.5778.pdf)\n- **Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups** (2012), G. Hinton et al. [[pdf]](http://www.cs.toronto.edu/~asamir/papers/SPM_DNN_12.pdf)\n- **Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition** (2012) G. Dahl et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.337.7548&rep=rep1&type=pdf)\n- **Acoustic modeling using deep belief networks** (2012), A. Mohamed et al. [[pdf]](http://www.cs.toronto.edu/~asamir/papers/speechDBN_jrnl.pdf)\n\n<!---[Key researchers]  [Alex Graves](https://scholar.google.ca/citations?user=DaFHynwAAAAJ), [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Dong Yu](https://scholar.google.ca/citations?hl=en&user=tMY31_gAAAAJ)-->\n\n### Reinforcement Learning / Robotics\n- **End-to-end training of deep visuomotor policies** (2016), S. Levine et al. [[pdf]](http://www.jmlr.org/papers/volume17/15-522/source/15-522.pdf)\n- **Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection** (2016), S. Levine et al. [[pdf]](https://arxiv.org/pdf/1603.02199)\n- **Asynchronous methods for deep reinforcement learning** (2016), V. Mnih et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/mniha16.pdf)\n- **Deep Reinforcement Learning with Double Q-Learning** (2016), H. Hasselt et al. [[pdf]](https://arxiv.org/pdf/1509.06461.pdf )\n- **Mastering the game of Go with deep neural networks and tree search** (2016), D. Silver et al. [[pdf]](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)\n- **Continuous control with deep reinforcement learning** (2015), T. Lillicrap et al. [[pdf]](https://arxiv.org/pdf/1509.02971)\n- **Human-level control through deep reinforcement learning** (2015), V. Mnih et al. [[pdf]](http://www.davidqiu.com:8888/research/nature14236.pdf)\n- **Deep learning for detecting robotic grasps** (2015), I. Lenz et al. [[pdf]](http://www.cs.cornell.edu/~asaxena/papers/lenz_lee_saxena_deep_learning_grasping_ijrr2014.pdf)\n- **Playing atari with deep reinforcement learning** (2013), V. Mnih et al. [[pdf]](http://arxiv.org/pdf/1312.5602.pdf))\n\n<!---[Key researchers]  [Sergey Levine](https://scholar.google.ca/citations?user=8R35rCwAAAAJ), [Volodymyr Mnih](https://scholar.google.ca/citations?hl=en&user=rLdfJ1gAAAAJ), [David Silver](https://scholar.google.ca/citations?user=-8DNE4UAAAAJ)-->\n\n### More Papers from 2016\n- **Layer Normalization** (2016), J. Ba et al. [[pdf]](https://arxiv.org/pdf/1607.06450v1.pdf)\n- **Learning to learn by gradient descent by gradient descent** (2016), M. Andrychowicz et al. [[pdf]](http://arxiv.org/pdf/1606.04474v1)\n- **Domain-adversarial training of neural networks** (2016), Y. Ganin et al. [[pdf]](http://www.jmlr.org/papers/volume17/15-239/source/15-239.pdf)\n- **WaveNet: A Generative Model for Raw Audio** (2016), A. Oord et al. [[pdf]](https://arxiv.org/pdf/1609.03499v2) [[web]](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)\n- **Colorful image colorization** (2016), R. Zhang et al. [[pdf]](https://arxiv.org/pdf/1603.08511)\n- **Generative visual manipulation on the natural image manifold** (2016), J. Zhu et al. [[pdf]](https://arxiv.org/pdf/1609.03552)\n- **Texture networks: Feed-forward synthesis of textures and stylized images** (2016), D Ulyanov et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/ulyanov16.pdf)\n- **SSD: Single shot multibox detector** (2016), W. Liu et al. [[pdf]](https://arxiv.org/pdf/1512.02325)\n- **SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size** (2016), F. Iandola et al. [[pdf]](http://arxiv.org/pdf/1602.07360)\n- **Eie: Efficient inference engine on compressed deep neural network** (2016), S. Han et al. [[pdf]](http://arxiv.org/pdf/1602.01528)\n- **Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1** (2016), M. Courbariaux et al. [[pdf]](https://arxiv.org/pdf/1602.02830)\n- **Dynamic memory networks for visual and textual question answering** (2016), C. Xiong et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/xiong16.pdf)\n- **Stacked attention networks for image question answering** (2016), Z. Yang et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_Stacked_Attention_Networks_CVPR_2016_paper.pdf)\n- **Hybrid computing using a neural network with dynamic external memory** (2016), A. Graves et al. [[pdf]](https://www.gwern.net/docs/2016-graves.pdf)\n- **Google's neural machine translation system: Bridging the gap between human and machine translation** (2016), Y. Wu et al. [[pdf]](https://arxiv.org/pdf/1609.08144)\n\n* * *\n\n\n### New papers\n*Newly published papers (< 6 months) which are worth reading*\n- MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (2017), Andrew G. Howard et al. [[pdf]](https://arxiv.org/pdf/1704.04861.pdf)\n- Convolutional Sequence to Sequence Learning (2017), Jonas Gehring et al. [[pdf]](https://arxiv.org/pdf/1705.03122)\n- A Knowledge-Grounded Neural Conversation Model (2017), Marjan Ghazvininejad et al. [[pdf]](https://arxiv.org/pdf/1702.01932)\n- Accurate, Large Minibatch SGD:Training ImageNet in 1 Hour (2017), Priya Goyal et al. [[pdf]](https://research.fb.com/wp-content/uploads/2017/06/imagenet1kin1h3.pdf)\n- TACOTRON: Towards end-to-end speech synthesis (2017), Y. Wang et al. [[pdf]](https://arxiv.org/pdf/1703.10135.pdf)\n- Deep Photo Style Transfer (2017), F. Luan et al. [[pdf]](http://arxiv.org/pdf/1703.07511v1.pdf)\n- Evolution Strategies as a Scalable Alternative to Reinforcement Learning (2017), T. Salimans et al. [[pdf]](http://arxiv.org/pdf/1703.03864v1.pdf)\n- Deformable Convolutional Networks (2017), J. Dai et al. [[pdf]](http://arxiv.org/pdf/1703.06211v2.pdf)\n- Mask R-CNN (2017), K. He et al. [[pdf]](https://128.84.21.199/pdf/1703.06870)\n- Learning to discover cross-domain relations with generative adversarial networks (2017), T. Kim et al. [[pdf]](http://arxiv.org/pdf/1703.05192v1.pdf) \n- Deep voice: Real-time neural text-to-speech (2017), S. Arik et al., [[pdf]](http://arxiv.org/pdf/1702.07825v2.pdf)\n- PixelNet: Representation of the pixels, by the pixels, and for the pixels (2017), A. Bansal et al. [[pdf]](http://arxiv.org/pdf/1702.06506v1.pdf)\n- Batch renormalization: Towards reducing minibatch dependence in batch-normalized models (2017), S. Ioffe. [[pdf]](https://arxiv.org/abs/1702.03275)\n- Wasserstein GAN (2017), M. Arjovsky et al. [[pdf]](https://arxiv.org/pdf/1701.07875v1)\n- Understanding deep learning requires rethinking generalization (2017), C. Zhang et al. [[pdf]](https://arxiv.org/pdf/1611.03530)\n- Least squares generative adversarial networks (2016), X. Mao et al. [[pdf]](https://arxiv.org/abs/1611.04076v2)\n\n\n### Old Papers\n*Classic papers published before 2012*\n- An analysis of single-layer networks in unsupervised feature learning (2011), A. Coates et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf)\n- Deep sparse rectifier neural networks (2011), X. Glorot et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_GlorotBB11.pdf)\n- Natural language processing (almost) from scratch (2011), R. Collobert et al. [[pdf]](http://arxiv.org/pdf/1103.0398)\n- Recurrent neural network based language model (2010), T. Mikolov et al. [[pdf]](http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf)\n- Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010), P. Vincent et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.3484&rep=rep1&type=pdf)\n- Learning mid-level features for recognition (2010), Y. Boureau [[pdf]](http://ece.duke.edu/~lcarin/boureau-cvpr-10.pdf)\n- A practical guide to training restricted boltzmann machines (2010), G. Hinton [[pdf]](http://www.csri.utoronto.ca/~hinton/absps/guideTR.pdf)\n- Understanding the difficulty of training deep feedforward neural networks (2010), X. Glorot and Y. Bengio [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf)\n- Why does unsupervised pre-training help deep learning (2010), D. Erhan et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_ErhanCBV10.pdf)\n- Learning deep architectures for AI (2009), Y. Bengio. [[pdf]](http://sanghv.com/download/soft/machine%20learning,%20artificial%20intelligence,%20mathematics%20ebooks/ML/learning%20deep%20architectures%20for%20AI%20(2009).pdf)\n- Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009), H. Lee et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.802&rep=rep1&type=pdf)\n- Greedy layer-wise training of deep networks (2007), Y. Bengio et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_739.pdf)\n- Reducing the dimensionality of data with neural networks, G. Hinton and R. Salakhutdinov. [[pdf]](http://homes.mpimf-heidelberg.mpg.de/~mhelmsta/pdf/2006%20Hinton%20Salakhudtkinov%20Science.pdf)\n- A fast learning algorithm for deep belief nets (2006), G. Hinton et al. [[pdf]](http://nuyoo.utm.mx/~jjf/rna/A8%20A%20fast%20learning%20algorithm%20for%20deep%20belief%20nets.pdf)\n- Gradient-based learning applied to document recognition (1998), Y. LeCun et al. [[pdf]](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n- Long short-term memory (1997), S. Hochreiter and J. Schmidhuber. [[pdf]](http://www.mitpressjournals.org/doi/pdfplus/10.1162/neco.1997.9.8.1735)\n\n\n### HW / SW / Dataset\n-  SQuAD: 100,000+ Questions for Machine Comprehension of Text (2016), Rajpurkar et al. [[pdf]](https://arxiv.org/pdf/1606.05250.pdf)\n- OpenAI gym (2016), G. Brockman et al. [[pdf]](https://arxiv.org/pdf/1606.01540)\n- TensorFlow: Large-scale machine learning on heterogeneous distributed systems (2016), M. Abadi et al. [[pdf]](http://arxiv.org/pdf/1603.04467)\n- Theano: A Python framework for fast computation of mathematical expressions, R. Al-Rfou et al.\n- Torch7: A matlab-like environment for machine learning, R. Collobert et al. [[pdf]](https://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf)\n- MatConvNet: Convolutional neural networks for matlab (2015), A. Vedaldi and K. Lenc [[pdf]](http://arxiv.org/pdf/1412.4564)\n- Imagenet large scale visual recognition challenge (2015), O. Russakovsky et al. [[pdf]](http://arxiv.org/pdf/1409.0575)\n- Caffe: Convolutional architecture for fast feature embedding (2014), Y. Jia et al. [[pdf]](http://arxiv.org/pdf/1408.5093)\n\n\n### Book / Survey / Review\n- On the Origin of Deep Learning (2017), H. Wang and Bhiksha Raj. [[pdf]](https://arxiv.org/pdf/1702.07800)\n- Deep Reinforcement Learning: An Overview (2017), Y. Li, [[pdf]](http://arxiv.org/pdf/1701.07274v2.pdf)\n- Neural Machine Translation and Sequence-to-sequence Models(2017): A Tutorial, G. Neubig. [[pdf]](http://arxiv.org/pdf/1703.01619v1.pdf)\n- Neural Network and Deep Learning (Book, Jan 2017), Michael Nielsen. [[html]](http://neuralnetworksanddeeplearning.com/index.html)\n- Deep learning (Book, 2016), Goodfellow et al. [[html]](http://www.deeplearningbook.org/)\n- LSTM: A search space odyssey (2016), K. Greff et al. [[pdf]](https://arxiv.org/pdf/1503.04069.pdf?utm_content=buffereddc5&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer)\n- Tutorial on Variational Autoencoders (2016), C. Doersch. [[pdf]](https://arxiv.org/pdf/1606.05908)\n- Deep learning (2015), Y. LeCun, Y. Bengio and G. Hinton [[pdf]](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)\n- Deep learning in neural networks: An overview (2015), J. Schmidhuber [[pdf]](http://arxiv.org/pdf/1404.7828)\n- Representation learning: A review and new perspectives (2013), Y. Bengio et al. [[pdf]](http://arxiv.org/pdf/1206.5538)\n\n### Video Lectures / Tutorials / Blogs\n\n*(Lectures)*\n- CS231n, Convolutional Neural Networks for Visual Recognition, Stanford University [[web]](http://cs231n.stanford.edu/)\n- CS224d, Deep Learning for Natural Language Processing, Stanford University [[web]](http://cs224d.stanford.edu/)\n- Oxford Deep NLP 2017, Deep Learning for Natural Language Processing, University of Oxford [[web]](https://github.com/oxford-cs-deepnlp-2017/lectures)\n\n*(Tutorials)*\n- NIPS 2016 Tutorials, Long Beach [[web]](https://nips.cc/Conferences/2016/Schedule?type=Tutorial)\n- ICML 2016 Tutorials, New York City [[web]](http://techtalks.tv/icml/2016/tutorials/)\n- ICLR 2016 Videos, San Juan [[web]](http://videolectures.net/iclr2016_san_juan/)\n- Deep Learning Summer School 2016, Montreal [[web]](http://videolectures.net/deeplearning2016_montreal/)\n- Bay Area Deep Learning School 2016, Stanford [[web]](https://www.bayareadlschool.org/)\n\n*(Blogs)*\n- OpenAI [[web]](https://www.openai.com/)\n- Distill [[web]](http://distill.pub/)\n- Andrej Karpathy Blog [[web]](http://karpathy.github.io/)\n- Colah's Blog [[Web]](http://colah.github.io/)\n- WildML [[Web]](http://www.wildml.com/)\n- FastML [[web]](http://www.fastml.com/)\n- TheMorningPaper [[web]](https://blog.acolyer.org)\n\n### Appendix: More than Top 100\n*(2016)*\n- A character-level decoder without explicit segmentation for neural machine translation (2016), J. Chung et al. [[pdf]](https://arxiv.org/pdf/1603.06147)\n- Dermatologist-level classification of skin cancer with deep neural networks (2017), A. Esteva et al. [[html]](http://www.nature.com/nature/journal/v542/n7639/full/nature21056.html)\n- Weakly supervised object localization with multi-fold multiple instance learning (2017), R. Gokberk et al. [[pdf]](https://arxiv.org/pdf/1503.00949)\n- Brain tumor segmentation with deep neural networks (2017), M. Havaei et al. [[pdf]](https://arxiv.org/pdf/1505.03540)\n- Professor Forcing: A New Algorithm for Training Recurrent Networks (2016), A. Lamb et al. [[pdf]](https://arxiv.org/pdf/1610.09038)\n- Adversarially learned inference (2016), V. Dumoulin et al. [[web]](https://ishmaelbelghazi.github.io/ALI/)[[pdf]](https://arxiv.org/pdf/1606.00704v1)\n- Understanding convolutional neural networks (2016), J. Koushik [[pdf]](https://arxiv.org/pdf/1605.09081v1)\n- Taking the human out of the loop: A review of bayesian optimization (2016), B. Shahriari et al. [[pdf]](https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf)\n- Adaptive computation time for recurrent neural networks (2016), A. Graves [[pdf]](http://arxiv.org/pdf/1603.08983)\n- Densely connected convolutional networks (2016), G. Huang et al. [[pdf]](https://arxiv.org/pdf/1608.06993v1)\n- Region-based convolutional networks for accurate object detection and segmentation (2016), R. Girshick et al. \n- Continuous deep q-learning with model-based acceleration (2016), S. Gu et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/gu16.pdf)\n- A thorough examination of the cnn/daily mail reading comprehension task (2016), D. Chen et al. [[pdf]](https://arxiv.org/pdf/1606.02858)\n- Achieving open vocabulary neural machine translation with hybrid word-character models, M. Luong and C. Manning. [[pdf]](https://arxiv.org/pdf/1604.00788)\n- Very Deep Convolutional Networks for Natural Language Processing (2016), A. Conneau et al. [[pdf]](https://arxiv.org/pdf/1606.01781)\n- Bag of tricks for efficient text classification (2016), A. Joulin et al. [[pdf]](https://arxiv.org/pdf/1607.01759)\n- Efficient piecewise training of deep structured models for semantic segmentation (2016), G. Lin et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lin_Efficient_Piecewise_Training_CVPR_2016_paper.pdf)\n- Learning to compose neural networks for question answering (2016), J. Andreas et al. [[pdf]](https://arxiv.org/pdf/1601.01705)\n- Perceptual losses for real-time style transfer and super-resolution (2016), J. Johnson et al. [[pdf]](https://arxiv.org/pdf/1603.08155)\n- Reading text in the wild with convolutional neural networks (2016), M. Jaderberg et al. [[pdf]](http://arxiv.org/pdf/1412.1842)\n- What makes for effective detection proposals? (2016), J. Hosang et al. [[pdf]](https://arxiv.org/pdf/1502.05082)\n- Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks (2016), S. Bell et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Bell_Inside-Outside_Net_Detecting_CVPR_2016_paper.pdf).\n- Instance-aware semantic segmentation via multi-task network cascades (2016), J. Dai et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Dai_Instance-Aware_Semantic_Segmentation_CVPR_2016_paper.pdf)\n- Conditional image generation with pixelcnn decoders (2016), A. van den Oord et al. [[pdf]](http://papers.nips.cc/paper/6527-tree-structured-reinforcement-learning-for-sequential-object-localization.pdf)\n- Deep networks with stochastic depth (2016), G. Huang et al., [[pdf]](https://arxiv.org/pdf/1603.09382)\n- Consistency and Fluctuations For Stochastic Gradient Langevin Dynamics (2016), Yee Whye Teh et al. [[pdf]](http://www.jmlr.org/papers/volume17/teh16a/teh16a.pdf)\n\n*(2015)*\n- Ask your neurons: A neural-based approach to answering questions about images (2015), M. Malinowski et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Malinowski_Ask_Your_Neurons_ICCV_2015_paper.pdf)\n- Exploring models and data for image question answering (2015), M. Ren et al. [[pdf]](http://papers.nips.cc/paper/5640-stochastic-variational-inference-for-hidden-markov-models.pdf)\n- Are you talking to a machine? dataset and methods for multilingual image question (2015), H. Gao et al. [[pdf]](http://papers.nips.cc/paper/5641-are-you-talking-to-a-machine-dataset-and-methods-for-multilingual-image-question.pdf)\n- Mind's eye: A recurrent visual representation for image caption generation (2015), X. Chen and C. Zitnick. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Chen_Minds_Eye_A_2015_CVPR_paper.pdf)\n- From captions to visual concepts and back (2015), H. Fang et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Fang_From_Captions_to_2015_CVPR_paper.pdf).\n- Towards AI-complete question answering: A set of prerequisite toy tasks (2015), J. Weston et al. [[pdf]](http://arxiv.org/pdf/1502.05698)\n- Ask me anything: Dynamic memory networks for natural language processing (2015), A. Kumar et al. [[pdf]](http://arxiv.org/pdf/1506.07285)\n- Unsupervised learning of video representations using LSTMs (2015), N. Srivastava et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v37/srivastava15.pdf)\n- Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2015), S. Han et al. [[pdf]](https://arxiv.org/pdf/1510.00149)\n- Improved semantic representations from tree-structured long short-term memory networks (2015), K. Tai et al. [[pdf]](https://arxiv.org/pdf/1503.00075)\n- Character-aware neural language models (2015), Y. Kim et al. [[pdf]](https://arxiv.org/pdf/1508.06615)\n- Grammar as a foreign language (2015), O. Vinyals et al. [[pdf]](http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf)\n- Trust Region Policy Optimization (2015), J. Schulman et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf)\n- Beyond short snippents: Deep networks for video classification (2015) [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Ng_Beyond_Short_Snippets_2015_CVPR_paper.pdf)\n- Learning Deconvolution Network for Semantic Segmentation (2015), H. Noh et al. [[pdf]](https://arxiv.org/pdf/1505.04366v1)\n- Learning spatiotemporal features with 3d convolutional networks (2015), D. Tran et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Tran_Learning_Spatiotemporal_Features_ICCV_2015_paper.pdf)\n- Understanding neural networks through deep visualization (2015), J. Yosinski et al. [[pdf]](https://arxiv.org/pdf/1506.06579)\n- An Empirical Exploration of Recurrent Network Architectures (2015), R. Jozefowicz et al.  [[pdf]](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n- Deep generative image models using aÔøº laplacian pyramid of adversarial networks (2015), E.Denton et al. [[pdf]](http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-laplacian-pyramid-of-adversarial-networks.pdf)\n- Gated Feedback Recurrent Neural Networks (2015), J. Chung et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v37/chung15.pdf)\n- Fast and accurate deep network learning by exponential linear units (ELUS) (2015), D. Clevert et al. [[pdf]](https://arxiv.org/pdf/1511.07289.pdf%5Cnhttp://arxiv.org/abs/1511.07289%5Cnhttp://arxiv.org/abs/1511.07289)\n- Pointer networks (2015), O. Vinyals et al. [[pdf]](http://papers.nips.cc/paper/5866-pointer-networks.pdf)\n- Visualizing and Understanding Recurrent Networks (2015), A. Karpathy et al. [[pdf]](https://arxiv.org/pdf/1506.02078)\n- Attention-based models for speech recognition (2015), J. Chorowski et al. [[pdf]](http://papers.nips.cc/paper/5847-attention-based-models-for-speech-recognition.pdf)\n- End-to-end memory networks (2015), S. Sukbaatar et al. [[pdf]](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf)\n- Describing videos by exploiting temporal structure (2015), L. Yao et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yao_Describing_Videos_by_ICCV_2015_paper.pdf)\n- A neural conversational model (2015), O. Vinyals and Q. Le. [[pdf]](https://arxiv.org/pdf/1506.05869.pdf)\n- Improving distributional similarity with lessons learned from word embeddings, O. Levy et al. [[pdf]] (https://www.transacl.org/ojs/index.php/tacl/article/download/570/124)\n- Transition-Based Dependency Parsing with Stack Long Short-Term Memory (2015), C. Dyer et al. [[pdf]](http://aclweb.org/anthology/P/P15/P15-1033.pdf)\n- Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs (2015), M. Ballesteros et al. [[pdf]](http://aclweb.org/anthology/D/D15/D15-1041.pdf)\n- Finding function in form: Compositional character models for open vocabulary word representation (2015), W. Ling et al. [[pdf]](http://aclweb.org/anthology/D/D15/D15-1176.pdf)\n\n\n*(~2014)*\n- DeepPose: Human pose estimation via deep neural networks (2014), A. Toshev and C. Szegedy [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Toshev_DeepPose_Human_Pose_2014_CVPR_paper.pdf)\n- Learning a Deep Convolutional Network for Image Super-Resolution (2014, C. Dong et al. [[pdf]](https://www.researchgate.net/profile/Chen_Change_Loy/publication/264552416_Lecture_Notes_in_Computer_Science/links/53e583e50cf25d674e9c280e.pdf)\n- Recurrent models of visual attention (2014), V. Mnih et al. [[pdf]](http://arxiv.org/pdf/1406.6247.pdf)\n- Empirical evaluation of gated recurrent neural networks on sequence modeling (2014), J. Chung et al. [[pdf]](https://arxiv.org/pdf/1412.3555)\n- Addressing the rare word problem in neural machine translation (2014), M. Luong et al. [[pdf]](https://arxiv.org/pdf/1410.8206)\n- On the properties of neural machine translation: Encoder-decoder approaches (2014), K. Cho et. al.\n- Recurrent neural network regularization (2014), W. Zaremba et al. [[pdf]](http://arxiv.org/pdf/1409.2329)\n- Intriguing properties of neural networks (2014), C. Szegedy et al. [[pdf]](https://arxiv.org/pdf/1312.6199.pdf)\n- Towards end-to-end speech recognition with recurrent neural networks (2014), A. Graves and N. Jaitly. [[pdf]](http://www.jmlr.org/proceedings/papers/v32/graves14.pdf)\n- Scalable object detection using deep neural networks (2014), D. Erhan et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Erhan_Scalable_Object_Detection_2014_CVPR_paper.pdf)\n- On the importance of initialization and momentum in deep learning (2013), I. Sutskever et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_sutskever13.pdf)\n- Regularization of neural networks using dropconnect (2013), L. Wan et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_wan13.pdf)\n- Learning Hierarchical Features for Scene Labeling (2013), C. Farabet et al. [[pdf]](https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/PDF/farabet-pami-13.pdf)\n- Linguistic Regularities in Continuous Space Word Representations (2013), T. Mikolov et al. [[pdf]](http://www.aclweb.org/anthology/N13-1#page=784)\n- Large scale distributed deep networks (2012), J. Dean et al. [[pdf]](http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf)\n- A Fast and Accurate Dependency Parser using Neural Networks. Chen and Manning. [[pdf]](http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf)\n\n\n\n## Acknowledgement\n\nThank you for all your contributions. Please make sure to read the [contributing guide](https://github.com/terryum/awesome-deep-learning-papers/blob/master/Contributing.md) before you make a pull request.\n\n## License\n[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)\n\nTo the extent possible under law, [Terry T. Um](https://www.facebook.com/terryum.io/) has waived all copyright and related or neighboring rights to this work.\n",
         "AI_DataScience"
        ],
        [
         "30",
         "MDEwOlJlcG9zaXRvcnk1MTg2MzU0Nw==",
         "Machine Learning Notebooks\n==========================\n\n# ‚ö† THE <a href=\"https://github.com/ageron/handson-ml3\">THIRD EDITION OF MY BOOK</a> IS NOW AVAILABLE.\n\nThis project is for the first edition, which is now outdated.\n\n<details>\n\nThis project aims at teaching you the fundamentals of Machine Learning in\npython. It contains the example code and solutions to the exercises in my O'Reilly book [Hands-on Machine Learning with Scikit-Learn and TensorFlow](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/):\n\n[![book](http://akamaicovers.oreilly.com/images/9781491962282/cat.gif)](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781491962282/)\n\n\n## Quick Start\n\n### Want to play with these notebooks online without having to install anything?\nUse any of the following services.\n\n**WARNING**: Please be aware that these services provide temporary environments: anything you do will be deleted after a while, so make sure you download any data you care about.\n\n* **Recommended**: open this repository in [Colaboratory](https://colab.research.google.com/github/ageron/handson-ml/blob/master/):\n<a href=\"https://colab.research.google.com/github/ageron/handson-ml/blob/master/\"><img src=\"https://colab.research.google.com/img/colab_favicon.ico\" width=\"90\" /></a>\n\n* Or open it in [Binder](https://mybinder.org/v2/gh/ageron/handson-ml/master):\n<a href=\"https://mybinder.org/v2/gh/ageron/handson-ml/master\"><img src=\"https://matthiasbussonnier.com/posts/img/binder_logo_128x128.png\" width=\"90\" /></a>\n\n  * _Note_: Most of the time, Binder starts up quickly and works great, but when handson-ml is updated, Binder creates a new environment from scratch, and this can take quite some time.\n\n* Or open it in [Deepnote](https://beta.deepnote.com/launch?template=data-science&url=https%3A//github.com/ageron/handson-ml/blob/master/index.ipynb):\n<a href=\"https://beta.deepnote.com/launch?template=data-science&url=https%3A//github.com/ageron/handson-ml/blob/master/index.ipynb\"><img src=\"https://www.deepnote.com/static/illustration.png\" width=\"150\" /></a>\n\n### Just want to quickly look at some notebooks, without executing any code?\n\nBrowse this repository using [jupyter.org's notebook viewer](https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/index.ipynb):\n<a href=\"https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/index.ipynb\"><img src=\"https://jupyter.org/assets/logos/rectanglelogo-greytext-orangebody-greymoons.svg\" width=\"150\" /></a>\n\n_Note_: [github.com's notebook viewer](index.ipynb) also works but it is slower and the math equations are not always displayed correctly.\n\n### Want to run this project using a Docker image?\nRead the [Docker instructions](https://github.com/ageron/handson-ml/tree/master/docker).\n\n### Want to install this project on your own machine?\n\nStart by installing [Anaconda](https://www.anaconda.com/distribution/) (or [Miniconda](https://docs.conda.io/en/latest/miniconda.html)), [git](https://git-scm.com/downloads), and if you have a TensorFlow-compatible GPU, install the [GPU driver](https://www.nvidia.com/Download/index.aspx), as well as the appropriate version of CUDA and cuDNN (see TensorFlow's documentation for more details).\n\nNext, clone this project by opening a terminal and typing the following commands (do not type the first `$` signs on each line, they just indicate that these are terminal commands):\n\n    $ git clone https://github.com/ageron/handson-ml.git\n    $ cd handson-ml\n\nNext, run the following commands:\n\n    $ conda env create -f environment.yml\n    $ conda activate tf1\n    $ python -m ipykernel install --user --name=python3\n\nFinally, start Jupyter:\n\n    $ jupyter notebook\n\nIf you need further instructions, read the [detailed installation instructions](INSTALL.md).\n\n# FAQ\n\n**Which Python version should I use?**\n\nI recommend Python 3.7. If you follow the installation instructions above, that's the version you will get. Most code will work with other versions of Python 3, but some libraries do not support Python 3.8 or 3.9 yet, which is why I recommend Python 3.7.\n\n**I'm getting an error when I call `load_housing_data()`**\n\nMake sure you call `fetch_housing_data()` *before* you call `load_housing_data()`. If you're getting an HTTP error, make sure you're running the exact same code as in the notebook (copy/paste it if needed). If the problem persists, please check your network configuration.\n\n**I'm getting an SSL error on MacOSX**\n\nYou probably need to install the SSL certificates (see this [StackOverflow question](https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error)). If you downloaded Python from the official website, then run `/Applications/Python\\ 3.7/Install\\ Certificates.command` in a terminal (change `3.7` to whatever version you installed). If you installed Python using MacPorts, run `sudo port install curl-ca-bundle` in a terminal.\n\n**I've installed this project locally. How do I update it to the latest version?**\n\nSee [INSTALL.md](INSTALL.md)\n\n**How do I update my Python libraries to the latest versions, when using Anaconda?**\n\nSee [INSTALL.md](INSTALL.md)\n\n## Contributors\nI would like to thank everyone [who contributed to this project](https://github.com/ageron/handson-ml/graphs/contributors), either by providing useful feedback, filing issues or submitting Pull Requests. Special thanks go to Haesun Park and Ian Beauregard who reviewed every notebook and submitted many PRs, including help on some of the exercise solutions. Thanks as well to Steven Bunkley and Ziembla who created the `docker` directory, and to github user SuperYorio who helped on some exercise solutions.\n\n</details>\n",
         "AI_DataScience"
        ],
        [
         "31",
         "MDEwOlJlcG9zaXRvcnk2OTY2MjcyMA==",
         "# WaveFunctionCollapse\nThis program generates bitmaps that are locally similar to the input bitmap.\n<p align=\"center\"><img alt=\"main collage\" src=\"images/wfc.png\"></p>\n<p align=\"center\"><img alt=\"main gif\" src=\"images/wfc.gif\"></p>\n\nLocal similarity means that\n\n* (C1) The output should contain only those NxN patterns of pixels that are present in the input.\n* (Weak C2) Distribution of NxN patterns in the input should be similar to the distribution of NxN patterns over a sufficiently large number of outputs. In other words, probability to meet a particular pattern in the output should be close to the density of such patterns in the input.\n\nIn the examples a typical value of N is 3.\n<p align=\"center\"><img alt=\"local similarity\" src=\"images/patterns.png\"></p>\n\nWFC initializes output bitmap in a completely unobserved state, where each pixel value is in superposition of colors of the input bitmap (so if the input was black & white then the unobserved states are shown in different shades of grey). The coefficients in these superpositions are real numbers, not complex numbers, so it doesn't do the actual quantum mechanics, but it was inspired by QM. Then the program goes into the observation-propagation cycle:\n\n* On each observation step an NxN region is chosen among the unobserved which has the lowest Shannon entropy. This region's state then collapses into a definite state according to its coefficients and the distribution of NxN patterns in the input.\n* On each propagation step new information gained from the collapse on the previous step propagates through the output.\n\nOn each step the number of non-zero coefficients decreases and in the end we have a completely observed state, the wave function has collapsed.\n\nIt may happen that during propagation all the coefficients for a certain pixel become zero. That means that the algorithm has run into a contradiction and can not continue. The problem of determining whether a certain bitmap allows other nontrivial bitmaps satisfying condition (C1) is NP-hard, so it's impossible to create a fast solution that always finishes. In practice, however, the algorithm runs into contradictions surprisingly rarely.\n\nWave Function Collapse algorithm has been implemented in\n[C++](https://github.com/math-fehr/fast-wfc),\n[Python](https://github.com/ikarth/wfc_2019f),\n[Kotlin](https://github.com/j-roskopf/WFC),\n[Rust](https://github.com/sdleffler/collapse),\n[Julia](https://github.com/roberthoenig/WaveFunctionCollapse.jl),\n[Go](https://github.com/shawnridgeway/wfc),\n[Haxe](https://github.com/Mitim-84/WFC-Gen),\n[Java](https://github.com/sjcasey21/wavefunctioncollapse),\n[Clojure](https://github.com/sjcasey21/wavefunctioncollapse-clj),\n[Free Pascal](https://github.com/PascalCorpsman/mini_projects/tree/main/miniprojects/Wave_function_collapse/Overlap_model),\n[Dart](https://github.com/rick-dalley/wfc),\n[p5js](https://github.com/D-T-666/wave-function-collapse-p5),\n[JavaScript](https://github.com/kchapelier/wavefunctioncollapse)\nand adapted to [Unity](https://selfsame.itch.io/unitywfc),\n[Unreal Engine 5](https://docs.unrealengine.com/5.0/en-US/BlueprintAPI/WaveFunctionCollapse/)\nand [Houdini](https://www.sidefx.com/tutorials/wfc-dungeon-generator/).\nYou can [build WFC from source](https://github.com/mxgmn/WaveFunctionCollapse#how-to-build),\ndownload an official [release](https://github.com/mxgmn/WaveFunctionCollapse/releases) for Windows,\ndownload an interactive graphical version from [itch.io](https://exutumno.itch.io/wavefunctioncollapse)\nor [run it in the browser](http://www.kchapelier.com/wfc-example/overlapping-model.html).\nWFC generates levels in [Bad North](https://www.badnorth.com/),\n[Caves of Qud](https://store.steampowered.com/app/333640/Caves_of_Qud/),\n[Dead Static Drive](https://twitter.com/deadstaticdrive),\n[Townscaper](https://store.steampowered.com/app/1291340/Townscaper/),\n[Matrix Awakens](https://www.youtube.com/watch?v=usJrcwN6T4I),\n[several](https://arcadia-clojure.itch.io/proc-skater-2016)\n[smaller](https://arcadia-clojure.itch.io/swapland)\n[games](https://marian42.itch.io/wfc) and many prototypes.\nIt led to [new](https://escholarship.org/uc/item/3rm1w0mn)\n[research](https://hal.inria.fr/hal-01706539v3/document).\nFor [more](https://twitter.com/OskSta/status/784847588893814785)\n[related](https://twitter.com/dwtw/status/810166761270243328)\n[work](https://github.com/mewo2/oisin),\n[explanations](https://trasevol.dog/2017/09/01/di19/),\n[interactive demos](http://oskarstalberg.com/game/wave/wave.html),\n[guides](https://www.dropbox.com/s/zeiat1w8zre9ro8/Knots%20breakdown.png?dl=0),\n[tutorials](http://www.procjam.com/tutorials/wfc/)\nand [examples](https://twitter.com/ExUtumno/status/895684431477747715)\nsee the [ports, forks and spinoffs section](https://github.com/mxgmn/WaveFunctionCollapse#notable-ports-forks-and-spinoffs).\n\nWatch a video demonstration of WFC algorithm on YouTube: [https://youtu.be/DOQTr2Xmlz0](https://youtu.be/DOQTr2Xmlz0)\n\n## Algorithm\n1. Read the input bitmap and count NxN patterns.\n    1. (optional) Augment pattern data with rotations and reflections.\n2. Create an array with the dimensions of the output (called \"wave\" in the source). Each element of this array represents a state of an NxN region in the output. A state of an NxN region is a superposition of NxN patterns of the input with boolean coefficients (so a state of a pixel in the output is a superposition of input colors with real coefficients). False coefficient means that the corresponding pattern is forbidden, true coefficient means that the corresponding pattern is not yet forbidden.\n3. Initialize the wave in the completely unobserved state, i.e. with all the boolean coefficients being true.\n4. Repeat the following steps:\n    1. Observation:\n        1. Find a wave element with the minimal nonzero entropy. If there is no such elements (if all elements have zero or undefined entropy) then break the cycle (4) and go to step (5).\n        2. Collapse this element into a definite state according to its coefficients and the distribution of NxN patterns in the input.\n    2. Propagation: propagate information gained on the previous observation step.\n5. By now all the wave elements are either in a completely observed state (all the coefficients except one being zero) or in the contradictory state (all the coefficients being zero). In the first case return the output. In the second case finish the work without returning anything.\n\n## Tilemap generation\nThe simplest nontrivial case of the algorithm is when NxN=1x2 (well, NxM). If we simplify it even further by storing not the probabilities of pairs of colors but the probabilities of colors themselves, we get what we call a \"simple tiled model\". The propagation phase in this model is just adjacency constraint propagation. It's convenient to initialize the simple tiled model with a list of tiles and their adjacency data (adjacency data can be viewed as a large set of very small samples) rather than a sample bitmap.\n<p align=\"center\"><a href=\"http://i.imgur.com/jIctSoT.gifv\"><img src=\"images/tile.gif\"/></a></p>\n<!--<p align=\"center\">\n  <a href=\"images/tile.gif\">GIF</a> |\n  <a href=\"http://i.imgur.com/jIctSoT.gifv\">GIFV</a>\n</p>-->\n\nLists of all the possible pairs of adjacent tiles in practical tilesets can be quite long, so I implemented a symmetry system for tiles to shorten the enumeration. In this system each tile should be assigned with its symmetry type.\n<p align=\"center\"><img alt=\"symmetries\" src=\"images/symmetry-system.png\"></p>\n\nNote that the tiles have the same symmetry type as their assigned letters (or, in other words, actions of the \ndihedral group D4 are isomorphic for tiles and their corresponding letters). With this system it's enough to enumerate pairs of adjacent tiles only up to symmetry, which makes lists of adjacencies for tilesets with many symmetrical tiles (even the summer tileset, despite drawings not being symmetrical the system considers such tiles to be symmetrical) several times shorter.\n<p align=\"center\">\n<img alt=\"knots\" src=\"images/knots.png\">\n<img alt=\"tiled rooms\" src=\"images/rooms.png\">\n<img alt=\"circuit 1\" src=\"images/circuit-1.png\">\n<img alt=\"circuit 2\" src=\"images/circuit-2.png\">\n<img alt=\"circles\" src=\"images/circles.png\">\n<img alt=\"castle\" src=\"images/castle.png\">\n<img alt=\"summer 1\" src=\"images/summer-1.png\">\n<img alt=\"summer 2\" src=\"images/summer-2.png\">\n</p>\n\nNote that the unrestrained knot tileset (with all 5 tiles being allowed) is not interesting for WFC, because you can't run into a situation where you can't place a tile. We call tilesets with this property \"easy\". Without special heuristics easy tilesets don't produce interesting global arrangements, because correlations of tiles in easy tilesets quickly fall off with a distance. Many easy tilesets can be found on [Guy Walker's website](http://cr31.co.uk/stagecast/wang/tiles_e.html). Consider the \"Dual\" 2-edge tileset there. How can it generate knots (without t-junctions, not easy) while being easy? The answer is, it can only generate a narrow class of knots, it can't produce an arbitrary knot.\n\nNote also that Circuit, Summer and Rooms tilesets are non-Wang. That is, their adjacency data cannot be induced from edge labels. For example, in Circuit two Corners cannot be adjacent, yet they can be connected with a Connection tile, and diagonal tracks cannot change direction.\n\n## Higher dimensions\nWFC algorithm in higher dimensions works completely the same way as in dimension 2, though performance becomes an issue. These voxel models were generated with N=2 overlapping tiled model using 5x5x5 and 5x5x2 blocks and additional heuristics (height, density, curvature, ...).\n<p align=\"center\"><img alt=\"voxels\" src=\"images/castles-3d.png\"></p>\n\nHigher resolution screenshots: [1](http://i.imgur.com/0bsjlBY.png), [2](http://i.imgur.com/GduN0Vr.png), [3](http://i.imgur.com/IEOsbIy.png).\n\n[MarkovJunior](https://github.com/mxgmn/MarkovJunior) repository contains an implementation of the 3d simple tiled model with many [tilesets](https://github.com/mxgmn/MarkovJunior/tree/main/resources/tilesets) and [examples](https://github.com/mxgmn/MarkovJunior/blob/main/images/top-1764.png).\n\n## Constrained synthesis\nWFC algorithm supports constraints. Therefore, it can be easily combined with other generative algorithms or with manual creation.\n\nHere is WFC autocompleting a level started by a human:\n<p align=\"center\"><a href=\"http://i.imgur.com/X3aNDUv.gifv\"><img src=\"images/constrained.gif\"/></a></p>\n<!--<p align=\"center\">\n  <a href=\"images/constrained.gif\">GIF</a> |\n  <a href=\"http://i.imgur.com/X3aNDUv.gifv\">GIFV</a>\n</p>-->\n\n[ConvChain](https://github.com/mxgmn/ConvChain) algorithm satisfies the strong version of the condition (C2): the limit distribution of NxN patterns in the outputs it is producing is exactly the same as the distributions of patterns in the input. However, ConvChain doesn't satisfy (C1): it often produces noticeable defects. It makes sense to run ConvChain first to get a well-sampled configuration and then run WFC to correct local defects. This is similar to a common strategy in optimization: first run a Monte-Carlo method to find a point close to a global optimum and then run a gradient descent from that point for greater accuracy.\n\nP. F. Harrison's [texture synthesis](https://github.com/mxgmn/TextureSynthesis) algorithm is significantly faster than WFC, but it has trouble with long correlations (for example, it's difficult for this algorithm to synthesize brick wall textures with correctly aligned bricks). But this is exactly where WFC shines, and Harrison's algorithm supports constraints. It makes sense first to generate a perfect brick wall blueprint with WFC and then run a constrained texture synthesis algorithm on that blueprint.\n\n## Comments\nWhy the minimal entropy heuristic? I noticed that when humans draw something they often follow the [minimal entropy heuristic](images/lowest-entropy-heuristic.gif) themselves. That's why the algorithm is so enjoyable to watch.\n\nThe overlapping model relates to the simple tiled model the same way higher order Markov chains relate to order one Markov chains.\n\nWFC's propagation phase is very similar to the loopy belief propagation algorithm. In fact, I first programmed belief propagation, but then switched to constraint propagation with a saved stationary distribution, because BP is significantly slower without a massive parallelization (on a CPU) and didn't produce significantly better results in my problems.\n\nNote that the \"Simple Knot\" and \"Trick Knot\" samples have 3 colors, not 2.\n\nOne of the dimensions can be time. In particular, d-dimensional WFC captures the behaviour of any (d-1)-dimensional cellular automata.\n\n## Used work\n1. Alexei A. Efros and Thomas K. Leung, [Texture Synthesis by Non-parametric Sampling](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/papers/efros-iccv99.pdf), 1999. WaveFunctionCollapse is a [texture synthesis](https://en.wikipedia.org/wiki/Texture_synthesis) algorithm. Compared to the earlier texture synthesis algorithms, WFC guarantees that the output contains only those NxN patterns that are present in the input. This makes WFC perfect for level generation in games and pixel art, and less suited for large full-color textures.\n2. Paul C. Merrell, [Model Synthesis](http://graphics.stanford.edu/~pmerrell/thesis.pdf), 2009. Merrell derives adjacency constraints between tiles from an example model and generates a new larger model with the AC-3 algorithm. We generalize his approach to work with NxN overlapping patterns of tiles instead of individual tiles. This allows to use a single image as the input to the algorithm. By varying N, we can make the output look more like the input or less. We introduce the [lowest entropy heuristic](images/lowest-entropy-heuristic.gif) that removes the [directional bias](images/directional-bias.png) in generated results, is defined for irregular grids and is better suited for [pre-constrained problems](images/constrained.gif). We implement a tile symmetry system to reduce the sizes of inputs. We visualize partially observed states, either with [color averaging](images/wfc.gif) or [per-voxel voting](https://twitter.com/ExUtumno/status/900395635412787202). Merrell also introduced a method of incrementally modifying the model in parts to reduce the failure rate (which we don't use here). Recently the author created a [page](https://paulmerrell.org/model-synthesis/) for model synthesis and published [code](https://github.com/merrell42/model-synthesis).\n3. Alan K. Mackworth, [Consistency in Networks of Relations](https://www.cs.ubc.ca/~mack/Publications/AI77.pdf), 1977. WFC translates a texture synthesis problem into a constraint satisfaction problem. Currently it uses the [AC-4 algorithm](http://www.cs.utah.edu/~tch/CS4300/resources/AC4.pdf) by Roger Mohr and Thomas C. Henderson, 1986.\n4. Paul F. Harrison, [Image Texture Tools](http://logarithmic.net/pfh-files/thesis/dissertation.pdf), 2005. WFC was also influenced by the declarative texture synthesis chapter of Paul Harrison's dissertation. The author defines adjacency data of tiles by labeling their borders and uses backtracking search to fill the tilemap. A [demonstration of the algorithm](https://logarithmic.net/ghost.xhtml) is available on the web.\n\n## How to build\nWFC is a console application that depends only on the standard library. Get [.NET Core](https://www.microsoft.com/net/download) for Windows, Linux or macOS and run\n```\ndotnet run --configuration Release WaveFunctionCollapse.csproj\n```\nGenerated results are saved into the `output` folder. Edit `samples.xml` to change model parameters.\n\nAlternatively, use build instructions from the community for various platforms from the [relevant issue](https://github.com/mxgmn/WaveFunctionCollapse/issues/3). Casey Marshall made a [pull request](https://github.com/mxgmn/WaveFunctionCollapse/pull/18) that makes using the program with the command line more convenient and includes snap packaging.\n\n## Notable ports, forks and spinoffs\n* Emil Ernerfeldt made a [C++ port](https://github.com/emilk/wfc).\n* [Max Aller](https://github.com/nanodeath) made a Kotlin (JVM) library, [Kollapse](https://gitlab.com/nanodeath/kollapse). Joseph Roskopf made a line by line Kotlin [port](https://github.com/j-roskopf/WFC) of the optimized 2018 version. Edwin Jakobs made a [Kotlin library](https://github.com/edwinRNDR/wfc) that supports [3d examples](https://www.youtube.com/watch?v=g4Ih8wxBh1E).\n* [Kevin Chapelier](https://github.com/kchapelier) made a [JavaScript port](http://www.kchapelier.com/wfc-example/overlapping-model.html).\n* Oskar St√•lberg programmed a 3d tiled model, a 2d tiled model for irregular grids on a sphere and is building beautiful 3d tilesets for them: [1](https://twitter.com/OskSta/status/787319655648100352), [2](https://twitter.com/OskSta/status/784847588893814785), [3](https://twitter.com/OskSta/status/784847933686575104), [4](https://twitter.com/OskSta/status/784848286272327680), [5](https://twitter.com/OskSta/status/793545297376972801), [6](https://twitter.com/OskSta/status/793806535898136576), [7](https://twitter.com/OskSta/status/802496920790777856), [8](https://twitter.com/OskSta/status/804291629561577472), [9](https://twitter.com/OskSta/status/806856212260278272), [10](https://twitter.com/OskSta/status/806904557502464000), [11](https://twitter.com/OskSta/status/818857408848130048), [12](https://twitter.com/OskSta/status/832633189277409280), [13](https://twitter.com/OskSta/status/851170356530475008), [14](https://twitter.com/OskSta/status/858301207936458752), [15](https://twitter.com/OskSta/status/863019585162932224).\n* [Joseph Parker](https://github.com/selfsame) adapted [WFC to Unity](https://selfsame.itch.io/unitywfc) and used it generate skateparks in the [Proc Skater 2016](https://arcadia-clojure.itch.io/proc-skater-2016) game, [fantastic plateaus](https://twitter.com/jplur_/status/929482200034226176) in the 2017 game [Swapland](https://arcadia-clojure.itch.io/swapland) and [platform levels](https://twitter.com/jplur_/status/1053458654454865921) in the 2018 game [Bug with a Gun](https://selfsame.itch.io/bug-with-a-gun).\n* [Martin O'Leary](https://github.com/mewo2) applied a [WFC-like algorithm](https://github.com/mewo2/oisin) to poetry generation: [1](https://twitter.com/mewo2/status/789167437518217216), [2](https://twitter.com/mewo2/status/789177702620114945), [3](https://twitter.com/mewo2/status/789187174683987968), [4](https://twitter.com/mewo2/status/789897712372183041).\n* [Nick Nenov](https://github.com/NNNenov) made a [3d voxel tileset](https://twitter.com/NNNenov/status/789903180226301953) based on my Castle tileset. Nick uses text output option in the tiled model to reconstruct 3d models in Cinema 4D.\n* Sean Leffler implemented the [overlapping model in Rust](https://github.com/sdleffler/collapse).\n* rid5x is making an [OCaml version of WFC](https://twitter.com/rid5x/status/782442620459114496).\n* I made an [interactive version](https://twitter.com/ExUtumno/status/798571284342837249) of the overlapping model, you can download the GUI executable from the [WFC itch.io page](https://exutumno.itch.io/wavefunctioncollapse).\n* [Brian Bucklew](https://github.com/unormal) built a level generation pipeline that applies WFC in multiple passes for the [Caves of Qud](http://store.steampowered.com/app/333640) game: [1](https://twitter.com/unormal/status/805987523596091392), [2](https://twitter.com/unormal/status/808566029387448320), [3](https://twitter.com/unormal/status/808523056259993601), [4](https://twitter.com/unormal/status/808523493994364928), [5](https://twitter.com/unormal/status/808519575264497666), [6](https://twitter.com/unormal/status/808519216185876480), [7](https://twitter.com/unormal/status/808795396508123136), [8](https://twitter.com/unormal/status/808860105093632001), [9](https://twitter.com/unormal/status/809637856432033792), [10](https://twitter.com/unormal/status/810239794433425408), [11](https://twitter.com/unormal/status/811034574973243393), [12](https://twitter.com/unormal/status/811720423419314176), [13](https://twitter.com/unormal/status/811034037259276290), [14](https://twitter.com/unormal/status/810971337309224960), [15](https://twitter.com/unormal/status/811405368777723909), [16](https://twitter.com/ptychomancer/status/812053801544757248), [17](https://twitter.com/unormal/status/812159308263788544), [18](https://twitter.com/unormal/status/812158749838340096), [19](https://twitter.com/unormal/status/814569437181476864), [20](https://twitter.com/unormal/status/814570383189876738), [21](https://twitter.com/unormal/status/819725864623603712), [22](https://twitter.com/unormal/status/984719207156862976).\n* [Danny Wynne](https://github.com/dannywynne) implemented a [3d tiled model](https://twitter.com/dwtw/status/810166761270243328).\n* Arvi Teikari programmed a [texture synthesis algorithm with the entropy heuristic](http://www.hempuli.com/blogblog/archives/1598) in Lua. Headchant [ported](https://github.com/headchant/iga) it to work with L√ñVE.\n* Isaac Karth made a [Python port](https://github.com/ikarth/wfc_python) of the overlapping model.\n* Oskar St√•lberg made an [interactive version](http://oskarstalberg.com/game/wave/wave.html) of the tiled model that runs in the browser.\n* [Matt Rix](https://github.com/MattRix) implemented a 3d tiled model ([1](https://twitter.com/MattRix/status/869403586664570880), [2](https://twitter.com/MattRix/status/870999185167962113), [3](https://twitter.com/MattRix/status/871054734018453505), [4](https://twitter.com/MattRix/status/871056805761359872)) and made a 3-dimensional tiled model where one of the dimensions is time ([1](https://twitter.com/MattRix/status/872674537799913472), [2](https://twitter.com/MattRix/status/872648369625325568), [3](https://twitter.com/MattRix/status/872645716660891648), [4](https://twitter.com/MattRix/status/872641331956518914), [5](https://twitter.com/MattRix/status/979020989181890560)).\n* [Nick Nenov](https://github.com/NNNenov) made a [visual guide](https://www.dropbox.com/s/zeiat1w8zre9ro8/Knots%20breakdown.png?dl=0) to the tile symmetry system.\n* [Isaac Karth](https://github.com/ikarth) and [Adam M. Smith](https://github.com/rndmcnlly) wrote a [paper](https://ieeexplore.ieee.org/document/9421370) ([open access link](https://escholarship.org/uc/item/3rm1w0mn)) in which they examine the role of backtracking and different possible heuristics in WFC, experiment with global constraints and combine WFC with VQ-VAE. Earlier in 2017, the authors wrote a [workshop paper](https://adamsmith.as/papers/wfc_is_constraint_solving_in_the_wild.pdf) where they formulate WFC as an ASP problem, use general constraint solver [clingo](https://github.com/potassco/clingo) to generate bitmaps, trace WFC's history and give a detailed explanation of the algorithm.\n* Sylvain Lefebvre made a [C++ implementation](https://github.com/sylefeb/VoxModSynth) of 3d model synthesis, described the thought process of designing a sample and provided an example where adjacency constraints ensure that the output is connected (walkable).\n* I generalized 3d WFC to work with cube symmetry group and made a tileset that generates [Escheresque scenes](https://twitter.com/ExUtumno/status/895684431477747715).\n* There are many ways to visualize partially observed wave states. In the code, color values of possible options are averaged to produce the resulting color. Oskar St√•lberg [shows](https://twitter.com/OskSta/status/863019585162932224) partially observed states as semi-transparent boxes, where the box is bigger for a state with more options. In the voxel setting I [visualize](https://twitter.com/ExUtumno/status/900395635412787202) wave states with per-voxel voting.\n* Remy Devaux implemented the tiled model in PICO-8 and wrote an [article](https://trasevol.dog/2017/09/01/di19/) about generation of coherent data with an explanation of WFC.\n* For the upcoming game [Bad North](https://www.badnorth.com/) Oskar St√•lberg [uses](https://twitter.com/OskSta/status/917405214638006273) a heuristic that tries to select such tiles\nthat the resulting observed zone is navigable at each step.\n* William Manning [implemented](https://github.com/heyx3/easywfc) the overlapping model in C# with the primary goal of making code readable, and provided it with WPF GUI.\n* [Joseph Parker](https://gist.github.com/selfsame) wrote a WFC [tutorial](http://www.procjam.com/tutorials/wfc/) for Procjam 2017.\n* [Aman Tiwari](https://github.com/aman-tiwari) formulated the connectivity constraint as an [ASP problem](https://gist.github.com/aman-tiwari/8a7b874cb1fd1270adc203b2af293f4c) for clingo.\n* Matvey Khokhlov programmed a [3d overlapping model](https://github.com/MatveyK/Kazimir).\n* [Sylvain Lefebvre](https://github.com/sylefeb), [Li-Yi Wei](https://github.com/1iyiwei) and [Connelly Barnes](https://github.com/connellybarnes) are [investigating](https://hal.archives-ouvertes.fr/hal-01706539/) the possibility of hiding information inside textures. They made a [tool](https://members.loria.fr/Sylvain.Lefebvre/infotexsyn/) that can encode text messages as WFC tilings and decode them back. This technique allows to use WFC tilings as QR codes.\n* [Mathieu Fehr](https://github.com/math-fehr) and [Nathanael Courant](https://github.com/Ekdohibs) significantly [improved](https://github.com/math-fehr/fast-wfc) the running time of WFC, by an order of magnitude for the overlapping model. I [integrated](https://github.com/mxgmn/WaveFunctionCollapse/commit/fad1066b5000f7e9fbda0ef81bbea56799686670) their improvements into the code.\n* Vasu Mahesh [ported](https://github.com/vasumahesh1/WFC_WebGL) 3d tiled model to TypeScript, made a new tileset and [visualised](https://vasumahesh1.github.io/WFC_WebGL) the generation process in WebGL.\n* [Hwanhee Kim](https://github.com/greentec) experimented with 3d WFC and created/adapted many voxel tilesets: [1](https://twitter.com/greentecq/status/1025348928634408960), [2](https://twitter.com/greentecq/status/1004068394553913344), [3](https://twitter.com/greentecq/status/1005835830802305024), [4](https://twitter.com/greentecq/status/1022851327041265664), [5](https://twitter.com/greentecq/status/1011351814216736769), [6](https://twitter.com/greentecq/status/1008210550944387077), [7](https://twitter.com/greentecq/status/1006390606875070464), [8](https://twitter.com/greentecq/status/1015182718810841088).\n* Oskar St√•lberg gave a [talk](https://www.youtube.com/watch?v=0bcZb-SsnrA) about level generation in Bad North at the Everything Procedural Conference 2018.\n* I [wrote](https://twitter.com/ExUtumno/status/1024314661951467521) about how to generate (approximately) unbiased paths between 2 points with WFC and other algorithms. I [implemented](https://github.com/mxgmn/MarkovJunior/blob/main/models/TilePath.xml) this method in MarkovJunior.\n* [Isaac Karth](https://github.com/ikarth) and [Adam M. Smith](https://github.com/rndmcnlly) published a [preprint](https://arxiv.org/abs/1809.04432) where they describe a system based on WFC that learns from both positive and negative examples, and discuss it in a general context of dialogs with example-driven generators.\n* Brendan Anthony [uses](https://steamcommunity.com/games/314230/announcements/detail/3369147113795750369) WFC to generate wall decorations in the game [Rodina](https://store.steampowered.com/app/314230/Rodina/).\n* Tim Kong implemented the [overlapping model in Haxe](https://github.com/Mitim-84/WFC-Gen).\n* In order to generate connected structures, Boris the Brave applied the [chiseling method](https://www.boristhebrave.com/2018/04/28/random-paths-via-chiseling) to WFC. He published a [library](https://boristhebrave.github.io/DeBroglie) that supports hex grids, additional constraints and backtracking.\n* [Marian Kleineberg](https://github.com/marian42) [created](https://twitter.com/marian42_/status/1061785383057440768) an [infinite city generator](https://marian42.itch.io/wfc) based on the tiled model for Procjam 2018. He wrote an [article](https://marian42.de/article/wfc) describing his approaches to setting adjacencies, backtracking and the online variation of WFC.\n* Sol Bekic [programmed](https://github.com/s-ol/gpWFC) the tiled model that runs on GPU using PyOpenCL. Instead of keeping a queue of nodes to propagate from, it propagates from every node on the grid in parallel.\n* Wouter van Oortmerssen [implemented](https://github.com/aardappel/lobster/commit/703f67472bfd80c26bb626e1d5c22ec91047da98) the tiled model in a single C++ function, with a structure similar to a priority queue for faster observation.\n* Robert Hoenig [implemented](https://github.com/roberthoenig/WaveFunctionCollapse.jl) the overlapping model in Julia, with an option to propagate constraints only locally.\n* [Edwin Jakobs](https://github.com/edwinRNDR) applied WFC to [style transfer](https://twitter.com/voorbeeld/status/1073874337248239616) and [dithering](https://twitter.com/voorbeeld/status/1073875725499985926).\n* Breanna Baltaxe-Admony [applied](https://github.com/bbaltaxe/wfc-piano-roll) WFC to music generation.\n* Shawn Ridgeway made a [Go port](https://github.com/shawnridgeway/wfc).\n* For the Global Game Jam 2019, [Andy Wallace](https://github.com/andymasteroffish) made a [game](http://andymakesgames.tumblr.com/post/182363131350/global-game-jam-2019-maureens-chaotic-dungeon) in which the player can interact with WFC-based level generator by resetting portions of the level with various weapons.\n* Stephen Sherratt wrote a [detailed explanation](https://gridbugs.org/wave-function-collapse/) of the overlapping model and made a [Rust library](https://github.com/stevebob/wfc). For the 7DRL Challenge 2019 he made a roguelike [Get Well Soon](https://gridbugs.org/get-well-soon/) that [uses](https://gridbugs.org/7drl2019-day1/) WFC to generate levels.\n* Florian Drux created a [generalization](https://github.com/lamelizard/GraphWaveFunctionCollapse/blob/master/thesis.pdf) that works on graphs with arbitrary local structure and [implemented](https://github.com/lamelizard/GraphWaveFunctionCollapse) it in Python.\n* Bob Burrough [discovered](https://twitter.com/ExUtumno/status/1119996185199116289) a percolation-like phase transition in one of the tilesets that manifests in spiking contradiction rate.\n* Oskar St√•lberg combined WFC with marching cubes on irregular grids and made a town building toy [Townscaper](https://store.steampowered.com/app/1291340/Townscaper/) based on it: [1](https://twitter.com/OskSta/status/1164926304640229376), [2](https://twitter.com/OskSta/status/1168168400155267072), [3](https://twitter.com/OskSta/status/1181464374839521280), [4](https://twitter.com/OskSta/status/1189109278361165825), [5](https://twitter.com/OskSta/status/1189902695303458816), [6](https://www.youtube.com/watch?v=1hqt8JkYRdI). Oskar gave a number of talks and interviews about the mixed initiative town generation in Townscaper: [EPC2021](https://www.youtube.com/watch?v=NOJYZYqY6_M), [SGC21](https://www.youtube.com/watch?v=Uxeo9c-PX-w), [Konsoll 2021](https://www.youtube.com/watch?v=5xrRTOikBBg), [AI and Games](https://www.youtube.com/watch?v=_1fvJ5sHh6A).\n* In his Rust roguelike tutorial, [Herbert Wolverson](https://github.com/thebracket) wrote a [chapter](http://bfnightly.bracketproductions.com/rustbook/chapter_33.html) about implementing the WFC algorithm from scratch.\n* At the [Game Developers Conference 2019](https://www.youtube.com/watch?v=AdCgi9E90jw) and the [Roguelike Celebration 2019](https://www.youtube.com/watch?v=fnFj3dOKcIQ), [Brian Bucklew](https://github.com/unormal) gave talks about WFC and how Freehold Games uses it to generate levels in [Caves of Qud](https://store.steampowered.com/app/333640/Caves_of_Qud/). The talks discuss problems with overfitting and homogeny, level connectedness and combining WFC with constructive procgen methods.\n* [Boris the Brave](https://github.com/boristhebrave) published a [commercial Unity asset](https://assetstore.unity.com/packages/tools/modeling/tessera-procedural-tile-based-generator-155425) based on the tiled model.\n* Steven Casey ported WFC to [Java](https://github.com/sjcasey21/wavefunctioncollapse) and [Clojure](https://github.com/sjcasey21/wavefunctioncollapse-clj).\n* Nu√±o de la Serna implemented the 3d tiled model in an [openFrameworks addon](https://github.com/action-script/ofxWFC3D) that supports tiles with no symmetries.\n* [Paul Ambrosiussen](https://github.com/Ambrosiussen) [integrated](https://github.com/sideeffects/SideFXLabs) the overlapping model into Houdini and gave a [talk](https://vimeo.com/400993662) about the algorithm and his implementation at Houdini HIVE 2020.\n* Keijiro Takahashi [implemented](https://github.com/keijiro/WfcMaze) a 3d tiled model and generated Escheresque scenes with it: [1](https://twitter.com/_kzr/status/1248993799960838144), [2](https://twitter.com/_kzr/status/1248990065327345664), [3](https://twitter.com/_kzr/status/1248884103274827777), [4](https://twitter.com/_kzr/status/1248268624495689728), [5](https://twitter.com/_kzr/status/1249348597549682689).\n* Simon Verstraete published a [tutorial](https://www.sidefx.com/tutorials/wfc-dungeon-generator/) about generating game levels for Unreal Engine 4 using the Houdini WFC tool: [0](https://www.youtube.com/watch?v=-5_FIqTDuzc), [1](https://www.youtube.com/watch?v=c06bSBYsFT8), [2](https://www.youtube.com/watch?v=u4NCs1F6zf8), [3](https://www.youtube.com/watch?v=YDpVUl213yo), [4](https://www.youtube.com/watch?v=ldcsvGuoW24).\n* [√âlie Michel](https://github.com/eliemichel) posted a [twitter thread](https://twitter.com/exppad/status/1267045322116734977) that explains the relationship between the overlapping and the tiled models.\n* [Lionel Radisson](https://github.com/MAKIO135) published an interactive [Observable notebook](https://observablehq.com/@makio135/super-mario-wfc) that generates Mario and Zelda-like levels with the overlapping model: [1](https://twitter.com/MAKIO135/status/1271187284424040449), [2](https://twitter.com/MAKIO135/status/1268308728782045184), [3](https://twitter.com/MAKIO135/status/1271015222321561600), [4](https://twitter.com/MAKIO135/status/1271113760472694784).\n* ≈Åukasz Jakubowski, Maciej Kaszlewicz, Pawe≈Ç Kroll and Stefan Radziuk [implemented](https://github.com/ic-pcg/waveFunctionCollapse) the tiled model in C.\n* [Ivan Donchevskii](https://github.com/yvvan) published a [commercial Unreal Engine plugin](https://www.unrealengine.com/marketplace/en-US/product/procedural-environment-generator-wfc) based on the tiled model.\n* [J√°n Perneck√Ω](https://github.com/janper) and [J√°n T√≥th](https://github.com/yanchith) published a [Grasshopper plugin](https://github.com/subdgtl/Monoceros) that extends the tiled model.\n* Krystian Samp made a [single-file overlapping WFC library in C](https://github.com/krychu/wfc).\n* [Gerald Krystian](https://github.com/amarcolina) made an [interactive tool](https://amarcolina.github.io/WFC-Explorer/) that explores the tiled model where tile adjacencies are induced from edge labels.\n* DeepMind open-ended learning team [used](https://arxiv.org/abs/2107.12808) WFC to generate arenas for reinforcement learning agents.\n* Oskar St√•lberg [made](https://twitter.com/OskSta/status/1447483550257799171) an island generator that combines triangle and quad tiles and uses a custom observation heuristic that doesn't produce local minimums.\n* [Boris the Brave](https://github.com/boristhebrave) [applied](https://www.boristhebrave.com/2021/11/08/infinite-modifying-in-blocks/) [Paul Merrell's](https://github.com/merrell42) modifying in blocks technique to the lazy generation of unbounded tile configurations. Marian Kleineberg has [implemented](https://marian42.de/article/infinite-wfc) this method into his [infinite city generator](https://github.com/marian42/wavefunctioncollapse).\n* Vladimir Pleskonjiƒá created a [single-header WFC library in C](https://github.com/vplesko/libwfc), accompanied by a CLI tool and a basic GUI tool.\n* Rick Dalley [ported](https://github.com/rick-dalley/wfc) WFC to Dart.\n\n## Credits\nCircles tileset is taken from [Mario Klingemann](https://twitter.com/quasimondo/status/778196128957403136). FloorPlan tileset is taken from [Lingdong Huang](https://github.com/LingDong-/ndwfc). Summer tiles were drawn by Hermann Hillmann. Cat overlapping sample is taken from the Nyan Cat video, Water + Forest + Mountains samples are taken from Ultima IV, 3Bricks sample is taken from Dungeon Crawl Stone Soup, Qud sample was made by Brian Bucklew, MagicOffice + Spirals samples - by rid5x, ColoredCity + Link + Link 2 + Mazelike + RedDot + SmileCity samples - by Arvi Teikari, Wall sample - by Arcaniax, NotKnot + Sand + Wrinkles samples - by Krystian Samp, Circle sample - by Noah Buddy. The rest of the examples and tilesets were made by me. Idea of generating integrated circuits was suggested to me by [Moonasaur](https://twitter.com/Moonasaur/status/759890746350731264) and their style was taken from Zachtronics' [Ruckingenur II](http://www.zachtronics.com/ruckingenur-ii/). Voxel models were rendered in [MagicaVoxel](http://ephtracy.github.io/).\n<p align=\"center\"><img alt=\"second collage\" src=\"images/wfc-2.png\"></p>\n<p align=\"center\"><img alt=\"voxel perspective\" src=\"images/castle-3d.png\"></p>\n",
         "AI_DataScience"
        ],
        [
         "32",
         "MDEwOlJlcG9zaXRvcnkyNDM4Mzg5NzM=",
         "[English](./README.md) / [Spanish](./README_es.md) / [Korean](./README_ko.md) / [Chinese](./README_zh.md) / [Bengali](./README_bn.md) / [Indonesian](./README_id.md) / [Italian](./README_it.md) / [Portuguese](./README_pt.md) / [Vietnamese](./README_vn.md) / [Japanese](./README_ja.md)\n\n# The fastai book\n\nThese notebooks cover an introduction to deep learning, [fastai](https://docs.fast.ai/), and [PyTorch](https://pytorch.org/). fastai is a layered API for deep learning; for more information, see [the fastai paper](https://www.mdpi.com/2078-2489/11/2/108). Everything in this repo is copyright Jeremy Howard and Sylvain Gugger, 2020 onwards. A selection of chapters is available to [read online here](https://fastai.github.io/fastbook2e/).\n\nThe notebooks in this repo are used for [a MOOC](https://course.fast.ai) and form the basis of [this book](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527), which is currently available for purchase. It does not have the same GPL restrictions that are on this repository.\n\nThe code in the notebooks and python `.py` files is covered by the GPL v3 license; see the LICENSE file for details. The remainder (including all markdown cells in the notebooks and other prose) is not licensed for any redistribution or change of format or medium, other than making copies of the notebooks or forking this repo for your own private use. No commercial or broadcast use is allowed. We are making these materials freely available to help you learn deep learning, so please respect our copyright and these restrictions.\n\nIf you see someone hosting a copy of these materials somewhere else, please let them know that their actions are not allowed and may lead to legal action. Moreover, they would be hurting the community because we're not likely to release additional materials in this way if people ignore our copyright.\n\n## Colab\n\nInstead of cloning this repo and opening it on your machine, you can read and work with the notebooks using [Google Colab](https://research.google.com/colaboratory/). This is the recommended approach for folks who are just getting started -- there's no need to set up a Python development environment on your own machine, since you can just work directly in your web-browser.\n\nYou can open any chapter of the book in Colab by clicking on one of these links: [Introduction to Jupyter](https://colab.research.google.com/github/fastai/fastbook/blob/master/app_jupyter.ipynb) | [Chapter 1, Intro](https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb) | [Chapter 2, Production](https://colab.research.google.com/github/fastai/fastbook/blob/master/02_production.ipynb) | [Chapter 3, Ethics](https://colab.research.google.com/github/fastai/fastbook/blob/master/03_ethics.ipynb) | [Chapter 4, MNIST Basics](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb) | [Chapter 5, Pet Breeds](https://colab.research.google.com/github/fastai/fastbook/blob/master/05_pet_breeds.ipynb) | [Chapter 6, Multi-Category](https://colab.research.google.com/github/fastai/fastbook/blob/master/06_multicat.ipynb) | [Chapter 7, Sizing and TTA](https://colab.research.google.com/github/fastai/fastbook/blob/master/07_sizing_and_tta.ipynb) | [Chapter 8, Collab](https://colab.research.google.com/github/fastai/fastbook/blob/master/08_collab.ipynb) | [Chapter 9, Tabular](https://colab.research.google.com/github/fastai/fastbook/blob/master/09_tabular.ipynb) | [Chapter 10, NLP](https://colab.research.google.com/github/fastai/fastbook/blob/master/10_nlp.ipynb) | [Chapter 11, Mid-Level API](https://colab.research.google.com/github/fastai/fastbook/blob/master/11_midlevel_data.ipynb) | [Chapter 12, NLP Deep-Dive](https://colab.research.google.com/github/fastai/fastbook/blob/master/12_nlp_dive.ipynb) | [Chapter 13, Convolutions](https://colab.research.google.com/github/fastai/fastbook/blob/master/13_convolutions.ipynb) | [Chapter 14, Resnet](https://colab.research.google.com/github/fastai/fastbook/blob/master/14_resnet.ipynb) | [Chapter 15, Arch Details](https://colab.research.google.com/github/fastai/fastbook/blob/master/15_arch_details.ipynb) | [Chapter 16, Optimizers and Callbacks](https://colab.research.google.com/github/fastai/fastbook/blob/master/16_accel_sgd.ipynb) | [Chapter 17, Foundations](https://colab.research.google.com/github/fastai/fastbook/blob/master/17_foundations.ipynb) | [Chapter 18, GradCAM](https://colab.research.google.com/github/fastai/fastbook/blob/master/18_CAM.ipynb) | [Chapter 19, Learner](https://colab.research.google.com/github/fastai/fastbook/blob/master/19_learner.ipynb) | [Chapter 20, conclusion](https://colab.research.google.com/github/fastai/fastbook/blob/master/20_conclusion.ipynb)\n\n\n## Contributions\n\nIf you make any pull requests to this repo, then you are assigning copyright of that work to Jeremy Howard and Sylvain Gugger. (Additionally, if you are making small edits to spelling or text, please specify the name of the file and a very brief description of what you're fixing. It's difficult for reviewers to know which corrections have already been made. Thank you.)\n\n## Citations\n\nIf you wish to cite the book, you may use the following:\n\n```\n@book{howard2020deep,\ntitle={Deep Learning for Coders with Fastai and Pytorch: AI Applications Without a PhD},\nauthor={Howard, J. and Gugger, S.},\nisbn={9781492045526},\nurl={https://books.google.no/books?id=xd6LxgEACAAJ},\nyear={2020},\npublisher={O'Reilly Media, Incorporated}\n}\n```\n\n",
         "AI_DataScience"
        ],
        [
         "33",
         "MDEwOlJlcG9zaXRvcnkyMjE2NTQ2Nzg=",
         "<div align=\"center\">\n  <a href=\"https://haystack.deepset.ai/\"><img src=\"https://raw.githubusercontent.com/deepset-ai/haystack/main/docs/img/banner.png\" alt=\"Green logo of a stylized white 'H' with the text 'Haystack, by deepset.'¬†Abstract green and yellow diagrams in the background.\"></a>\n\n|         |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| CI/CD   | [![Tests](https://github.com/deepset-ai/haystack/actions/workflows/tests.yml/badge.svg)](https://github.com/deepset-ai/haystack/actions/workflows/tests.yml) [![types - Mypy](https://img.shields.io/badge/types-Mypy-blue.svg)](https://github.com/python/mypy) [![Coverage Status](https://coveralls.io/repos/github/deepset-ai/haystack/badge.svg?branch=main)](https://coveralls.io/github/deepset-ai/haystack?branch=main) [![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff) |\n| Docs    | [![Website](https://img.shields.io/website?label=documentation&up_message=online&url=https%3A%2F%2Fdocs.haystack.deepset.ai)](https://docs.haystack.deepset.ai)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| Package | [![PyPI](https://img.shields.io/pypi/v/haystack-ai)](https://pypi.org/project/haystack-ai/) ![PyPI - Downloads](https://img.shields.io/pypi/dm/haystack-ai?color=blue&logo=pypi&logoColor=gold) ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/haystack-ai?logo=python&logoColor=gold) [![Conda Version](https://img.shields.io/conda/vn/conda-forge/haystack-ai.svg)](https://anaconda.org/conda-forge/haystack-ai) [![GitHub](https://img.shields.io/github/license/deepset-ai/haystack?color=blue)](LICENSE) [![License Compliance](https://github.com/deepset-ai/haystack/actions/workflows/license_compliance.yml/badge.svg)](https://github.com/deepset-ai/haystack/actions/workflows/license_compliance.yml) |\n| Meta    | [![Discord](https://img.shields.io/discord/993534733298450452?logo=discord)](https://discord.com/invite/xYvH6drSmA) [![Twitter Follow](https://img.shields.io/twitter/follow/haystack_ai)](https://twitter.com/haystack_ai)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n</div>\n\n[Haystack](https://haystack.deepset.ai/) is an end-to-end LLM framework that allows you to build applications powered by\nLLMs, Transformer models, vector search and more. Whether you want to perform retrieval-augmented generation (RAG),\ndocument search, question answering or answer generation, Haystack can orchestrate state-of-the-art embedding models\nand LLMs into pipelines to build end-to-end NLP applications and solve your use case.\n\n## Table of Contents\n\n- [Installation](#installation)\n- [Documentation](#documentation)\n- [Features](#features)\n- [Use Cases](#features)\n- [Hayhooks (REST API Deployment)](#-tip-1)\n- [Haystack Enterprise](#haystack-enterprise-best-practices-and-expert-support)\n- [deepset Studio](#-deepset-studio-your-development-environment-for-haystack)\n- [Telemetry](#telemetry)\n- [üññ Community](#-community)\n- [Contributing to Haystack](#contributing-to-haystack)\n- [Who Uses Haystack](#who-uses-haystack)\n\n\n## Installation\n\nThe simplest way to get Haystack is via pip:\n\n```sh\npip install haystack-ai\n```\n\nInstall from the `main` branch to try the newest features:\n```sh\npip install git+https://github.com/deepset-ai/haystack.git@main\n```\n\nHaystack supports multiple installation methods including Docker images. For a comprehensive guide please refer\nto the [documentation](https://docs.haystack.deepset.ai/docs/installation).\n\n## Documentation\n\nIf you're new to the project, check out [\"What is Haystack?\"](https://haystack.deepset.ai/overview/intro) then go\nthrough the [\"Get Started Guide\"](https://haystack.deepset.ai/overview/quick-start) and build your first LLM application\nin a matter of minutes. Keep learning with the [tutorials](https://haystack.deepset.ai/tutorials). For more advanced\nuse cases, or just to get some inspiration, you can browse our Haystack recipes in the\n[Cookbook](https://haystack.deepset.ai/cookbook).\n\nAt any given point, hit the [documentation](https://docs.haystack.deepset.ai/docs/intro) to learn more about Haystack, what can it do for you and the technology behind.\n\n## Features\n\n- **Technology agnostic:** Allow users the flexibility to decide what vendor or technology they want and make it easy to switch out any component for another. Haystack allows you to use and compare models available from OpenAI, Cohere and Hugging Face, as well as your own local models or models hosted on Azure, Bedrock and SageMaker.\n- **Explicit:** Make it transparent how different moving parts can ‚Äútalk‚Äù to each other so it's easier to fit your tech stack and use case.\n- **Flexible:** Haystack provides all tooling in one place: database access, file conversion, cleaning, splitting, training, eval, inference, and more. And whenever custom behavior is desirable, it's easy to create custom components.\n- **Extensible:** Provide a uniform and easy way for the community and third parties to build their own components and foster an open ecosystem around Haystack.\n\nSome examples of what you can do with Haystack:\n\n-   Build **retrieval augmented generation (RAG)** by making use of one of the available vector databases and customizing your LLM interaction, the sky is the limit üöÄ\n-   Perform Question Answering **in natural language** to find granular answers in your documents.\n-   Perform **semantic search** and retrieve documents according to meaning.\n-   Build applications that can make complex decisions making to answer complex queries: such as systems that can resolve complex customer queries, do knowledge search on many disconnected resources and so on.\n-   Scale to millions of docs using retrievers and production-scale components.\n-   Use **off-the-shelf models** or **fine-tune** them to your data.\n-   Use **user feedback** to evaluate, benchmark, and continuously improve your models.\n\n> [!TIP]\n>\n> Would you like to deploy and serve Haystack pipelines as REST APIs yourself? [Hayhooks](https://github.com/deepset-ai/hayhooks) provides a simple way to wrap your pipelines with custom logic and expose them via HTTP endpoints, including OpenAI-compatible chat completion endpoints and compatibility with fully-featured chat interfaces like [open-webui](https://openwebui.com/).\n\n## Haystack Enterprise: Best Practices and Expert Support\n\nGet expert support from the Haystack team, build faster with enterprise-grade templates, and scale securely with deployment guides for cloud and on-prem environments - all with **Haystack Enterprise**. Read more about it our [announcement post](https://haystack.deepset.ai/blog/announcing-haystack-enterprise).\n\nüëâ [Get Haystack Enterprise](https://www.deepset.ai/products-and-services/haystack-enterprise?utm_source=github.com&utm_medium=referral&utm_campaign=haystack_enterprise) \n\n## deepset Studio: Your Development Environment for Haystack\n\nUse **deepset Studio** to visually create, deploy, and test your Haystack pipelines. Learn more about it in our [announcement post](https://haystack.deepset.ai/blog/announcing-studio).\n\n![studio](https://github.com/user-attachments/assets/e4f09746-20b5-433e-8261-eca224ac23b3)\n\nüëâ [Sign up](https://landing.deepset.ai/deepset-studio-signup)!\n\n> [!TIP]\n><img src=\"https://github.com/deepset-ai/haystack/raw/main/docs/img/deepset-platform-logo-alternative.jpeg\"  width=20%>\n>\n> Are you looking for a managed solution that benefits from Haystack? [deepset AI Platform](https://www.deepset.ai/products-and-services/deepset-ai-platform?utm_campaign=developer-relations&utm_source=haystack&utm_medium=readme) is our fully managed, end-to-end platform to integrate LLMs with your data, which uses Haystack for the LLM pipelines architecture.\n\n## Telemetry\n\nHaystack collects **anonymous** usage statistics of pipeline components. We receive an event every time these components are initialized. This way, we know which components are most relevant to our community.\n\nRead more about telemetry in Haystack or how you can opt out in [Haystack docs](https://docs.haystack.deepset.ai/docs/telemetry).\n\n## üññ Community\n\nIf you have a feature request or a bug report, feel free to open an [issue in Github](https://github.com/deepset-ai/haystack/issues). We regularly check these and you can expect a quick response. If you'd like to discuss a topic, or get more general advice on how to make Haystack work for your project, you can start a thread in [Github Discussions](https://github.com/deepset-ai/haystack/discussions) or our [Discord channel](https://discord.com/invite/VBpFzsgRVF). We also check [ùïè (Twitter)](https://twitter.com/haystack_ai) and [Stack Overflow](https://stackoverflow.com/questions/tagged/haystack).\n\n## Contributing to Haystack\n\nWe are very open to the community's contributions - be it a quick fix of a typo, or a completely new feature! You don't need to be a Haystack expert to provide meaningful improvements. To learn how to get started, check out our [Contributor Guidelines](https://github.com/deepset-ai/haystack/blob/main/CONTRIBUTING.md) first.\n\nThere are several ways you can contribute to Haystack:\n- Contribute to the main Haystack project\n- Contribute an integration on [haystack-core-integrations](https://github.com/deepset-ai/haystack-core-integrations)\n\n> [!TIP]\n>üëâ **[Check out the full list of issues that are open to contributions](https://github.com/orgs/deepset-ai/projects/14)**\n\n## Who Uses Haystack\n\nHere's a list of projects and companies using Haystack. Are you also using Haystack? Open a PR or [tell us your story](https://forms.gle/Mm3G1aEST3GAH2rn8).\n\n- Tech & AI Innovators: [Apple](https://www.apple.com/), [Meta](https://www.meta.com/about), [Databricks](https://www.databricks.com/), [NVIDIA](https://developer.nvidia.com/blog/reducing-development-time-for-intelligent-virtual-assistants-in-contact-centers/), [PostHog](https://github.com/PostHog/max-ai#readme)\n- Public Sector: [German Federal Ministry of Research, Technology, and Space (BMFTR)](https://www.deepset.ai/case-studies/german-federal-ministry-research-technology-space-bmftr), [PD, Baden-W√ºrttemberg State](https://www.pd-g.de/)\n- Enterprise & Telecom: [Alcatel-Lucent](https://www.al-enterprise.com/), [Intel](https://github.com/intel/open-domain-question-and-answer#readme), [NOS Portugal](https://www.nos.pt/en/welcome), [TELUS Agriculture & Consumer Goods](https://www.telus.com/agcg/en)\n- Aerospace & Hardware: [Airbus](https://www.deepset.ai/case-studies/airbus), [Infineon](https://www.infineon.com/), [LEGO](https://github.com/larsbaunwall/bricky#readme)\n- Media & Entertainment: [Netflix](https://netflix.com), [Comcast](https://arxiv.org/html/2405.00801v2), [Zeit Online](https://www.deepset.ai/case-studies/zeit-online), [Rakuten](https://www.rakuten.com/)\n- Legal & Publishing: [Manz](https://www.deepset.ai/case-studies/manz), [Oxford University Press](https://corp.oup.com/)\n- Startups & Research: [YPulse](https://www.deepset.ai/case-studies/ypulse), [BetterUp](https://www.betterup.com/), [Intel Labs](https://github.com/IntelLabs/fastRAG#readme)\n",
         "AI_DataScience"
        ],
        [
         "34",
         "MDEwOlJlcG9zaXRvcnkzMDkwNzc3NA==",
         "# LearnOpenCV\n\nThis repository contains code for Computer Vision, Deep learning, and AI research articles shared on our blog [LearnOpenCV.com](https://www.LearnOpenCV.com).\n\nWant to become an expert in AI? [AI Courses by OpenCV](https://opencv.org/courses/) is a great place to start.\n\n<a href=\"https://opencv.org/courses/\">\n\n<p align=\"center\">\n<img src=\"https://learnopencv.com/wp-content/uploads/2023/01/AI-Courses-By-OpenCV-Github.png\">\n</p>\n</a>\n\n## List of Blog Posts\n\n| Blog Post | Code|\n| ------------- |:-------------|\n| [AI Agent in Action: Automating Desktop Tasks with VLMs](https://learnopencv.com/build-ai-agents-using-vlm/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Local-VLM-Agents-in-Action-GUI-Automation-with-Moondream3-and-Gemini) |\n| [Top VLM Evaluation Metrics for Optimal Performance Analysis](https://learnopencv.com/vlm-evaluation-metrics/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VLM_Evaluation_Metrics) |\n|[Getting Started with VLM on Jetson Nano](https://learnopencv.com/vlm-on-jetson-nano/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Getting-Started-with-VLM-on-Jetson-Nano)|\n| [VLM on Edge: Worth the Hype or Just a Novelty?](https://learnopencv.com/vlm-on-edge-devices/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VLM-on-Edge-Worth-the-Hype-or-Just-a-Novelty) |\n| [AnomalyCLIP : Harnessing CLIP for Weakly-Supervised Video Anomaly Recognition](https://learnopencv.com/anomalyclip-video-anomaly-recognition/) | [Code](https://github.com/spmallick/learnopencv/tree/master/AnomalyCLIP_Harnessing_CLIP_for_Weakly_Supervised_Video_Anomaly_Recognition) |\n| [AI_for_Video_Understanding_From_Content_Moderation_to_Summarization](https://learnopencv.com/ai-for-video-understanding/) | [Code](https://github.com/spmallick/learnopencv/tree/master/AI_for_Video_Understanding_From_Content_Moderation_to_Summarization) |\n| [Video-RAG: Training-Free Retrieval for Long-Video LVLMs](https://learnopencv.com/video-rag-for-long-videos/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Video-RAG_Training_Free_Retrieval_for_Long_Video_LVLMs) |\n| [Object Detection and Spatial Understanding with VLMs ft. Qwen2.5-VL](https://learnopencv.com/object-detection-with-vlms-ft-qwen2-5-vl/) | [Code](https://github.com/spmallick/learnopencv/tree/master/object-detection-with-vlms) |\n| [LangGraph: Building Self-Correcting RAG Agent for Code Generation](https://learnopencv.com/langgraph-self-correcting-agent-code-generation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/LangGraph_Building_Self_Correcting_RAG_Agent_for_Code_Generation) |\n| [Inside Sinusoidal Position Embeddings: A Sense of Order](https://learnopencv.com/sinusoidal-position-embeddings/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Sinusoidal_Position_Embeddings) |\n| [Inside RoPE: Rotary Magic into Position Embeddings](https://learnopencv.com/rope-position-embeddings/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Inside_RoPE_Position_Embeddings) |\n| [SimLingo-Vision-Language-Action-Model-for-Autonomous-Driving](https://learnopencv.com/simlingo-vision-language-action-model-for-autonomous-driving/) | [Code](https://github.com/spmallick/learnopencv/tree/master/SimLingo-Vision-Language-Action-Model-for-Autonomous-Driving) |\n| [FineTuning Gemma 3n for Medical VQA on ROCOv2](https://learnopencv.com/finetuning-gemma-3n-medical-vqa/) | [Code](https://github.com/spmallick/learnopencv/tree/master/finetuning-gemma3n) |\n| [SmolLM3 Blueprint: SOTA 3B-Parameter LLM](https://learnopencv.com/smollm3-explained/) | |\n| [LangGraph-A-Visual-Automation-and-Summarization-Pipeline](https://learnopencv.com/langgraph-building-a-visual-web-browser-agent/) | [Code](https://github.com/spmallick/learnopencv/tree/master/LangGraph-A-Visual-Automation-and-Summarization-Pipeline) |\n| [Fine-Tuning AnomalyCLIP: Class-Agnostic Zero-Shot Anomaly Detection](https://learnopencv.com/fine-tuning-anomalyclip-medical-anomaly-clip/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-AnomalyCLIP) |\n| [SigLIP 2: DeepMind‚Äôs Multilingual Vision-Language Model](https://learnopencv.com/siglip-2-deepminds-multilingual-vision-language-model/) | |\n| [MedGemma: Google‚Äôs Medico VLM for Clinical QA, Imaging, and More](https://learnopencv.com/medgemma-explained/) | [Code](https://github.com/spmallick/learnopencv/tree/master/medgemma) |\n| [Nanonets-OCR-s: Enabling Rich, Structured Markdown for Document Understanding](https://learnopencv.com/nanonets-ocr-s/) | |\n| [Optimizing VJEPA-2: Tackling Latency & Context in Real-Time Video Classification Scripts](https://learnopencv.com/optimizing-vjepa-2-in-real-time-video-classification/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VJEPA-2-Video-Classification) |\n| [V-JEPA 2: Meta‚Äôs Breakthrough in AI for the Physical World](https://learnopencv.com/?p=73731&preview_id=73731&preview_nonce=beb70ccf8e&preview=true#heading-7) | [Code](https://github.com/spmallick/learnopencv/tree/master/V-JEPA-2) |\n| [NVIDIA Cosmos Reason1: Video Understanding](https://learnopencv.com/cosmos-reason-vlm-video-vqa/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Cosmos-Reason1-Video-Understanding) |\n| [GR00T N1.5 Explained](https://learnopencv.com/gr00t-n1_5-explained/) |  |\n| [LLaVA](https://learnopencv.com/llava-training-a-visual-assistant/) | [Code](https://github.com/spmallick/learnopencv/tree/master/LLaVA) |\n| [SmolVLA: Affordable & Efficient VLA Robotics on Consumer GPUs](https://learnopencv.com/smolvla-lerobot-vision-language-action-model/) | [Code](https://github.com/spmallick/learnopencv/tree/master/smolvla) |\n| [Fine-Tuning Grounding DINO: Open-Vocabulary Object Detection](https://learnopencv.com/fine-tuning-grounding-dino/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-Grounding-DINO-Open-Vocabulary-Object-Detection) |\n| [Getting Started with Qwen3 ‚Äì The Thinking Expert](https://learnopencv.com/qwen3/) | [Code](https://github.com/spmallick/learnopencv/tree/master/qwen3) |\n| [Inside the GPU: A Comprehensive Guide to Modern Graphics Architecture](https://learnopencv.com/modern-gpu-architecture-explained/) | |\n| [Distributed Parallel Training: PyTorch](https://learnopencv.com/distributed-parallel-training-pytorch-multi-gpu-setup/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Distributed-Training-PyTorch) |\n| [MONAI: The Definitive Framework for Medical Imaging Powered by PyTorch](https://learnopencv.com/monai-medical-imaging-pytorch/) | |\n| [SANA-Sprint: The One-Step Revolution in High-Quality AI Image Synthesis](https://learnopencv.com/sana-sprint-the-one-step-revolution-in-high-quality-ai-image-synthesis/) | |\n| [FramePack-Video-Diffusion-but-feels-like-Image-Diffusion](https://learnopencv.com/framepack-video-diffusion/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FramePack-Video-Diffusion-but-feels-like-Image-Diffusion) |\n| [Model Weights File Formats in Machine Learning](https://learnopencv.com/model-weights-file-formats-in-machine-learning/) | |\n| [Unsloth: A Guide from Basics to Fine-Tuning Vision Models](https://learnopencv.com/unsloth-guide-efficient-llm-fine-tuning/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Unsloth_A_Guide_From_Basics_to_Fine_Tuning_Vision_Models) |\n| [Iterative Closest Point (ICP) Algorithm Explained](https://learnopencv.com/iterative-closest-point-icp-explained/) | [Code](https://github.com/spmallick/learnopencv/blob/master/Iterative-Closest-Point-ICP) |\n| [MedSAM2 Explained: One Prompt to Segment Anything in Medical Imaging](https://learnopencv.com/medsam2-explained/) | [Code](https://github.com/spmallick/learnopencv/blob/master/medsam2-explained) |\n| [Batch Normalization and Dropout as Regularizers](https://learnopencv.com/batch-normalization-and-dropout-as-regularizers/) | |\n| [DINOv2_by_Meta_A_Self-Supervised_foundational_vision_model](https://learnopencv.com/dinov2-self-supervised-vision-transformer/) | [Code](https://github.com/spmallick/learnopencv/blob/master/DINOv2_by_Meta_A_Self-Supervised_foundational_vision_model) |\n| [Beginner's Guide to Embedding Models](https://learnopencv.com/embedding-models-explained/) | |\n| [MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors](https://learnopencv.com/mast3r-slam-realtime-dense-slam-explained/) | [Code](https://github.com/spmallick/learnopencv/blob/master/MASt3R-SLAM) |\n| [Google's A2A Protocol](https://learnopencv.com/googles-a2a-protocol-heres-what-you-need-to-know/) | |\n| [Nvidia SANA : Faster Image Generation](https://learnopencv.com/nvidia-sana-image-generation-model/) | |\n| [Fine-tuning RF-DETR](https://learnopencv.com/rf-detr-object-detection/) | [Code](https://github.com/spmallick/learnopencv/blob/master/Fine-tuning-RF-DETR) |\n| [Qwen2.5-Omni: A Real-Time Multimodal AI](https://learnopencv.com/qwen2.5-omni/) | |\n| [Vision Language Action Models: Robotic Control](https://learnopencv.com/vision-language-action-models-lerobot-policy/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Vision-Language-Action-Models) |\n| [Fine-Tuning Gemma 3 VLM using QLoRA for LaTeX-OCR Dataset](https://learnopencv.com/fine-tuning-gemma-3/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-Gemma-3-VLM-using-QLoRA-for-LaTeX-OCR-Dataset) |\n| [ComfyUI](https://learnopencv.com/introduction-to-comfyui-for-stable-diffusion/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ComfyUI) |\n| [Gemma-3: A Comprehensive Introduction](https://learnopencv.com/gemma-3/) | |\n| [YOLO11 on Raspberry Pi: Optimizing Object Detection for Edge Devices](https://learnopencv.com/yolo11-on-raspberry-pi/) | [Code](https://github.com/spmallick/learnopencv/tree/master/yolo11-on-raspberry-pi) |\n| [VGGT: Visual Geometry Grounded Transformer ‚Äì For Dense 3D Reconstruction](https://learnopencv.com/vggt-visual-geometry-grounded-transformer-3d-reconstruction/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VGGT-3D-Reconstruction) |\n| [DDIM: The Faster, Improved Version of DDPM for Efficient AI Image Generation](https://learnopencv.com/understanding-ddim/) | [Code](https://github.com/spmallick/learnopencv/tree/master/DDIM-The-Faster-Improved-Version-of-DDPM-for-Efficient-AI-Image-Generation) |\n| [Introduction to Model Context Protocol (MCP)](https://learnopencv.com/introduction-to-model-context-protocol/) | |\n| [MASt3R and MASt3R-SfM Explanation: Image Matching and 3D Reconstruction](https://learnopencv.com/mast3r-sfm-grounding-image-matching-3d/) | [Code](https://github.com/spmallick/learnopencv/tree/master/MASt3R-SfM-3D-Reconstruction-Image-Matching) |\n| [MatAnyone Explained: Consistent Memory for Better Video Matting](https://learnopencv.com/matanyone-for-better-video-matting/) | [Code](https://github.com/spmallick/learnopencv/tree/master/MatAnyone-Explained-Consistent-Memory-for-Better-Video-Matting) |\n| [GraphRAG: For Medical Document Analysis](https://learnopencv.com/graphrag-explained-knowledge-graphs-medical/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Graphrag-Medical-Document-Analysis) |\n| [OmniParser: Vision Based GUI Agent](https://learnopencv.com/omniparser-vision-based-gui-agent/) | |\n| [Fine-Tuning-YOLOv12-Comparison-With-YOLOv11-And-YOLOv7-Based-Darknet](https://learnopencv.com/fine-tuning-yolov12/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-YOLOv12-Comparison-With-YOLOv11-And-YOLOv7-Based-Darknet) |\n| [FineTuning RetinaNet for Wildlife Detection with PyTorch: A Step-by-Step Tutorial](https://learnopencv.com/finetuning-retinanet) | [Code](https://github.com/spmallick/learnopencv/tree/master/finetuning-retinanet) |\n| [DUSt3R: Geometric 3D Vision Made Easy :  Explanation and Results](https://learnopencv.com/dust3r-geometric-3d-vision/) | [Code](https://github.com/spmallick/learnopencv/tree/master/DUSt3R-Dense-3D-Reconstruction) |\n| [YOLOv12: Attention Meets Speed](https://learnopencv.com/yolov12) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv12) |\n| [Video Generation: A Diffusion based approach](https://learnopencv.com/video-generation-models/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Video-Generation-A-Diffusion-based-approach) |\n| [Agentic AI: A Comprehensive Introduction](https://learnopencv.com/agentic-ai/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Agentic-AI-A-Comprehensive-Introduction) |\n| [Finetuning SAM2 for Leaf Disease Segmentation](https://learnopencv.com/finetuning-sam2/) | [Code](https://github.com/spmallick/learnopencv/tree/master/finetuning-sam2) |\n| [Object Insertion in Gaussian Splatting: Paper Explained and Training Code for MCMC and Bilateral Grid](https://learnopencv.com/object-insertion-in-gaussian-splatting/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Object-Insertion-in-Gaussian-Splatting) |\n| [Depth Pro: Sharp Monocular Metric Depth](https://learnopencv.com/depth-pro-monocular-metric-depth) | [Code](https://github.com/spmallick/learnopencv/tree/master/DepthPro-Monocular-Metric-Depth) |\n| [Fine-tuning-Stable-Diffusion-3_5-UI-images](https://learnopencv.com/fine-tuning-stable-diffusion-3-5m/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-tuning-Stable-Diffusion-3_5-UI-images) |\n| [SimSiam: Streamlining SSL with Stop-Gradient Mechanism](https://learnopencv.com/simsiam/) | [Code](https://github.com/spmallick/learnopencv/tree/master/SimSiam-Streamlining-SSL-with-Stop-Gradient-Mechanism) |\n| [Image Captioning using ResNet and LSTM](https://learnopencv.com/image-captioning/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Image-Captioning-using-ResNet-and-LSTM) |\n| [Molmo VLM: Paper Explanation and Demo](https://learnopencv.com/molmo-vlm) | [Code](https://github.com/spmallick/learnopencv/tree/master/Molmo-VLM-SAM2) |\n| [3D Gaussian Splatting Paper Explanation: Training Custom Datasets with NeRF-Studio Gsplats](https://learnopencv.com/3d-gaussian-splatting/) | [Code](https://github.com/spmallick/learnopencv/tree/master/3D-Gaussian-Splatting-Code) |\n| [FLUX Image Generation: Experimenting with the Parameters](https://learnopencv.com/flux-ai-image-generator/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Flux-Image-Generation) |\n| [Contrastive-Learning-SimCLR-and-BYOL(With Code Example)](https://learnopencv.com/contrastive-learning-simclr-and-byol-with-code-example/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Contrastive-Learning-SimCLR-and-BYOL) |\n| [The Annotated NeRF : Training on Custom Dataset from Scratch in Pytorch](https://learnopencv.com/annotated-nerf-pytorch/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Annotated-NeRF) |\n| [Stable Diffusion 3 and 3.5: Paper Explanation and Inference](https://learnopencv.com/stable-diffusion-3/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Stable-Diffusion-3) |\n| [LightRAG - Legal Document Analysis](https://learnopencv.com/lightrag/) | [Code](https://github.com/spmallick/learnopencv/tree/master/LightRAG-Legal) |\n| [NVIDIA AI Summit 2024 ‚Äì India Overview](https://learnopencv.com/nvidia-ai-summit-2024-india-overview/) | |\n| [Introduction to Speech to Speech: Most Efficient Form of NLP](https://learnopencv.com/speech-to-speech/) | [Code](https://github.com/spmallick/learnopencv/tree/master/speech-to-speech) |\n| [Training 3D U-Net for Brain Tumor Segmentation (BraTS-GLI)](https://learnopencv.com/3d-u-net-brats/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Training_3D_U-Net_Brain_Tumor_Seg) |\n| [DETR: Overview and Inference](https://learnopencv.com/detr-overview-and-inference/) | [Code](https://github.com/spmallick/learnopencv/tree/master/DETR-Overview_and_Inference) |\n| [YOLO11: Faster Than You Can Imagine!](https://learnopencv.com/yolo11/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLO11) |\n| [Exploring DINO: Self-Supervised Transformers for Road Segmentation with ResNet50 and U-Net](https://learnopencv.com/fine-tune-dino-self-supervised-learning-segmentation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Exploring-DINO-dino-road-segmentation) |\n| [Sapiens: Foundation for Human Vision Models by Meta](https://learnopencv.com/sapiens-human-vision-models) | [Code](https://github.com/spmallick/learnopencv/tree/master/Sapiens-Human-Vision-Model-Meta) |\n| [Multimodal RAG with ColPali and Gemini](https://learnopencv.com/multimodal-rag-with-colpali) | [Code](https://github.com/spmallick/learnopencv/tree/master/Multimodal-RAG-with-ColPali-Gemini) |\n| [Building Autonomous Vehicle in Carla: Path Following with PID Control & ROS 2](https://learnopencv.com/pid-controller-ros-2-carla/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Building_Autonomous_Vehicle_in_Carla_Path_Following_with_PID_Control_ROS2) |\n| [Handwritten Text Recognition using OCR](https://learnopencv.com/handwritten-text-recognition-using-ocr/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Handwritten_Text_Recognition_using_OCR) |\n| [Training CLIP from Sratch for Image Retrieval](https://learnopencv.com/clip-model) | [Code](https://github.com/spmallick/learnopencv/tree/master/Training-CLIP-from-Scratch-for-Image-Retrieval) |\n| [Introduction to LiDAR SLAM: LOAM and LeGO-LOAM Paper and Code Explanation with ROS 2 Implementation](https://learnopencv.com/lidar-slam-with-ros2) | [Code](https://github.com/spmallick/learnopencv/tree/master/LeGO-LOAM-ROS2) |\n| [Recommendation System using Vector Search](https://learnopencv.com/recommendation-system-using-vector-search) | [Code](https://github.com/spmallick/learnopencv/tree/master/Recommendation-System-using-Vector-Search) |\n| [Fine Tuning Whisper on Custom Dataset](https://learnopencv.com/fine-tuning-whisper-on-custom-dataset/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-Whisper-on-Custom-Dataset) |\n| [SAM 2 ‚Äì Promptable Segmentation for Images and Videos](https://learnopencv.com/sam-2/) | [Code](https://github.com/spmallick/learnopencv/tree/master/SAM_2_Segment_Anything_Model_2) |\n| [Introduction to Feature Matching Using Neural Networks](https://learnopencv.com/feature-matching/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Feature-Matching-Using-Neural-Networks) |\n| [Introduction to ROS2 (Robot Operating System 2): Tutorial on ROS2 Working, DDS, ROS1 RMW, Topics, Nodes, Publisher, Subscriber in Python](https://learnopencv.com/robot-operating-system-introduction) | [Code](https://github.com/spmallick/learnopencv/tree/master/Introduction-to-ROS2-in-python) |\n| [CVPR 2024 Research Papers - Part- 2](https://learnopencv.com/cvpr-2024-research-papers) | [Code](https://github.com/spmallick/learnopencv/tree/master/cvpr-2024-research-papers-part2) |\n| [CVPR 2024: An Overview and Key Papers](https://learnopencv.com/cvpr2024/) | [Code](https://github.com/spmallick/learnopencv/tree/master/CVPR-2024) |\n| [Object Detection on Edge Device - OAK-D-Lite](https://learnopencv.com/object-detection-on-edge-device) | [Code](https://github.com/spmallick/learnopencv/tree/master/Object-Detection-on-Edge-Devices) |\n| [Fine-Tuning YOLOv10 Models on Custom Dataset](https://learnopencv.com/fine-tuning-yolov10/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-YOLOv10-Models-Custom-Dataset) |\n| [ROS2 and Carla Setup Guide for Ubuntu 22.04](https://learnopencv.com/ros2-and-carla-setup-guide/) |  |\n| [Understanding Visual SLAM for Robotics Perception: Building Monocular SLAM from Scratch in Python](https://learnopencv.com/monocular-slam-in-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Monocular%20SLAM%20for%20Robotics%20implementation%20in%20python) |\n| [Enhancing Image Segmentation using U2-Net: An Approach to Efficient Background Removal](https://learnopencv.com/u2-net-image-segmentation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Efficient-Background-Removal-using-U2-Net) |\n| [YOLOv10: The Dual-Head OG of YOLO Series](https://learnopencv.com/yolov10/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv10) |\n| [Fine-tuning Faster R-CNN on Sea Rescue Dataset](https://learnopencv.com/fine-tuning-faster-r-cnn/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-tuning-Faster-R-CNN-on-SeaRescue-Dataset) |\n| [Mastering Recommendation System: A Complete Guide](https://learnopencv.com/recommendation-system/) | |\n| [Automatic Speech Recognition with Diarization : Speech-to-Text](https://learnopencv.com/automatic-speech-recognition/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Automatic-Speech-Recognition-with-Diarization-Speech-to-Text) |\n| [Building MobileViT Image Classification Model from Scratch In Keras 3](https://learnopencv.com/mobilevit-keras-3/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Building%20MobileViT%20from%20Scratch%20in%20Keras%203) |\n| [SDXL Inpainting: Fusing Image Inpainting with Stable Diffusion](https://learnopencv.com/sdxl-inpainting/) | [Code](https://github.com/spmallick/learnopencv/tree/master/SDXL-inpainting) |\n| [YOLOv9 Instance Segmentation on Medical Dataset](https://learnopencv.com/yolov9-instance-segmentation-on-medical-dataset/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv9-Instance-Segmentation-on-Medical-Dataset) |\n| [A Comprehensive Guide to Robotics](https://learnopencv.com/a-comprehensive-guide-to-robotics/) | |\n| [Integrating Gradio with OpenCV DNN](https://learnopencv.com/integrating-gradio-with-opencv-dnn/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Integrating-Gradio-with-OpenCV-DNN) |\n| [Fine-Tuning YOLOv9 on Custom Dataset](https://learnopencv.com/fine-tuning-yolov9/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-YOLOv9-Models-Custom-Dataset) |\n| [Dreambooth using Diffusers](https://learnopencv.com/dreambooth-using-diffusers/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Dreambooth_using_Diffusers) |\n| [Introduction to Hugging Face Diffusers](https://learnopencv.com/hugging-face-diffusers/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Introduction_to_Diffusers) |\n| [Introduction to Ultralytics Explorer API](https://learnopencv.com/ultralytics-explorer-api/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Introduction-to-Ultralytics-Explorer-API) |\n| [YOLOv9: Advancing the YOLO Legacy](https://learnopencv.com/yolov9-advancing-the-yolo-legacy/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv9-Advancing-the-YOLO-Legacy) |\n| [Fine-Tuning LLMs using PEFT](https://learnopencv.com/fine-tuning-llms-using-peft/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-LLMs-using-PEFT) |\n| [Depth Anything: Accelerating Monocular Depth Perception](https://learnopencv.com/deciphering-llms/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Depth-Anything) |\n| [Deciphering LLMs: From Transformers to Quantization](https://learnopencv.com/deciphering-llms/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Deciphering-LLMs) |\n| [YOLO Loss Function Part 2: GFL and VFL Loss](https://learnopencv.com/yolo-loss-function-gfl-vfl-loss/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLO-Loss-Functions-Part2) |\n| [YOLOv8-Object-Tracking-and-Counting-with-OpenCV](https://learnopencv.com/yolov8-object-tracking-and-counting-with-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv8-Object-Tracking-and-Counting-with-OpenCV) |\n| [Stereo Vision in ADAS: Pioneering Depth Perception Beyond LiDAR](https://learnopencv.com/adas-stereo-vision/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ADAS-Stereo-Vision) |\n| [YOLO Loss Function Part 1: SIoU and Focal Loss](https://learnopencv.com/yolo-loss-function-siou-focal-loss/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLO-Loss-Functions-Part1) |\n| [Moving Object Detection with OpenCV](https://learnopencv.com/moving-object-detection-with-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Moving-Object-Detection-with-OpenCV) |\n| [Integrating ADAS with Keypoint Feature Pyramid Network for 3D LiDAR Object Detection](https://learnopencv.com/3d-lidar-object-detection/) | [Code](https://www.dropbox.com/scl/fi/3n1s68jtfkjmw2f5e5ctv/3D-LiDAR-Object-Detection.zip?rlkey=d8q6xvlxis4oxso4qki87omvc&dl=1) |\n| [Mastering All YOLO Models from YOLOv1 to YOLO-NAS: Papers Explained (2024)](https://learnopencv.com/mastering-all-yolo-models) | |\n| [GradCAM: Enhancing Neural Network Interpretability in the Realm of Explainable AI](https://learnopencv.com/intro-to-gradcam/) | [Code](https://www.dropbox.com/scl/fo/3p3sg5fnvhrvi9vp00i0w/h?rlkey=1x01uz5o7esex7p6c8r534iyn&dl=1) |\n| [Text Summarization using T5: Fine-Tuning and Building Gradio App](https://learnopencv.com/text-summarization-using-t5/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Text-Summarization-using-T5-Fine-Tuning-and-Building-Gradio-App) |\n| [3D LiDAR Visualization using Open3D: A Case Study on 2D KITTI Depth Frames for Autonomous Driving](https://learnopencv.com/3d-lidar-visualization/) | [Code](https://github.com/spmallick/learnopencv/tree/master/3D-LiDAR-Perception) |\n| [Fine Tuning T5: Text2Text Transfer Transformer for Building a Stack Overflow Tag Generator](https://learnopencv.com/fine-tuning-t5/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-T5-Text2Text-Transformer-for-Strack-Overflow-Tag-Generation) |\n| [SegFormer ü§ó : Fine-Tuning for Improved Lane Detection in Autonomous Vehicles](https://learnopencv.com/segformer-fine-tuning-for-lane-detection) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-SegFormer-For-Lane-Detection) |\n| [Fine-Tuning BERT using Hugging Face Transformers](https://learnopencv.com/fine-tuning-bert) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-BERT-using-Hugging-Face-Transformers) |\n| [YOLO-NAS Pose](https://learnopencv.com/yolo-nas-pose) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLO-NAS-Pose) |\n| [BERT: Bidirectional Encoder Representations from Transformers](https://learnopencv.com/bert-bidirectional-encoder-representations-from-transformers/) | [Code](https://github.com/spmallick/learnopencv/tree/master/BERT-Bidirectional-Encoder-Representations-from-Transformers) |\n| [Comparing KerasCV YOLOv8 Models on the Global Wheat Data 2020](https://learnopencv.com/comparing-kerascv-yolov8-models/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Comparing-KerasCV-YOLOv8-Models-on-the-Global-Wheat-Data-2020) |\n| [Top 5 AI papers of September 2023](https://learnopencv.com/top-5-ai-papers-of-september-2023/) | |\n| [Empowering Drivers: The Rise and Role of Advanced Driver Assistance Systems](https://learnopencv.com/advanced-driver-assistance-systems/) | |\n| [Semantic Segmentation using KerasCV DeepLabv3+](https://learnopencv.com/kerascv-deeplabv3-plus-semantic-segmentation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Semantic-Segmentation-using-KerasCV-with-DeepLabv3-Plus) |\n| [Object Detection using KerasCV YOLOv8](https://learnopencv.com/object-detection-using-kerascv-yolov8/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Object-Detection-using-KerasCV-YOLOv8) |\n| [Fine-tuning YOLOv8 Pose Models for Animal Pose Estimation](https://learnopencv.com/animal-pose-estimation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-tuning-YOLOv8-Pose-Models-for-Animal-Pose-Estimation) |\n| [Top 5 AI papers of August 2023](https://learnopencv.com/top-5-ai-papers-of-august-2023/) | |\n| [Fine Tuning TrOCR - Training TrOCR to Recognize Curved Text](https://learnopencv.com/fine-tuning-trocr-training-trocr-to-recognize-curved-text/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-TrOCR) |\n| [TrOCR - Getting Started with Transformer Based OCR](https://learnopencv.com/trocr-getting-started-with-transformer-based-ocr/) | [Code](https://github.com/spmallick/learnopencv/tree/master/TrOCR-Getting-Started-with-Transformer-Based-OCR) |\n| [Facial Emotion Recognition](https://learnopencv.com/facial-emotion-recognition/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Facial-Emotion-Recognition) |\n| [Object Keypoint Similarity in Keypoint Detection](https://learnopencv.com/object-keypoint-similarity/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Object-Keypoint-Similarity-in-Keypoint-Detection) |\n| [Real Time Deep SORT with Torchvision Detectors](https://learnopencv.com/real-time-deep-sort-with-torchvision-detectors/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Real_Time_Deep_SORT_using_Torchvision_Detectors) |\n| [Top 5 AI papers of July 2023](https://learnopencv.com/top-5-ai-papers-of-july-2023/) | |\n| [Medical Image Segmentation](https://learnopencv.com/medical-image-segmentation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Medical-Image-Segmentation-Using-HuggingFace-&-PyTorch) |\n| [Weighted Boxes Fusion in Object Detection: A Comparison with Non-Maximum Suppression](https://learnopencv.com/weighted-boxes-fusion/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Weighted-Boxes-Fusion-in-Object-Detection) |\n| [Medical Multi-label Classification with PyTorch & Lightning](https://learnopencv.com/medical-multi-label/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Medical_Multi-label_Classification_with_PyTorch_&_Lightning) |\n| [Getting Started with PaddlePaddle: Exploring Object Detection, Segmentation, and Keypoints](https://learnopencv.com/paddlepaddle/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Introduction-to-PaddlePaddle) |\n| [Drone Programming With Computer Vision A Beginners Guide](https://learnopencv.com/drone-programming-with-computer-vision/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Drone-Programming-With-Computer-Vision-A-Beginners-Guide) |\n| [How to Build a Pip Installable Package & Upload to PyPi](https://learnopencv.com/building-pip-installable-package-pypi/) | |\n| [IoU Loss Functions for Faster & More Accurate Object Detection](https://learnopencv.com/iou-loss-functions-object-detection/) | |\n| [Exploring Slicing Aided Hyper Inference for Small Object Detection](https://learnopencv.com/slicing-aided-hyper-inference/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Exploring-Slicing-Aided-Hyper-Inference) |\n| [Advancements in Face Recognition Models, Toolkit and Datasets](https://learnopencv.com/face-recognition-models/) | |\n| [Train YOLO NAS on Custom Dataset](https://learnopencv.com/train-yolo-nas-on-custom-dataset/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Train-YOLO-NAS-on-Custom-Dataset) |\n| [Train YOLOv8 Instance Segmentation on Custom Data](https://learnopencv.com/train-yolov8-instance-segmentation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Train-YOLOv8-Instance-Segmentation-on-Custom-Data) |\n| [YOLO-NAS: New Object Detection Model Beats YOLOv6 & YOLOv8](https://learnopencv.com/yolo-nas/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLO-NAS_Introduction) |\n| [Segment Anything ‚Äì A Foundation Model for Image Segmentation](https://learnopencv.com/segment-anything/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Segment-Anything-A-Foundation-Model-for-Image-Segmentation) |\n|[Build a Video to Slides Converter Application using the Power of Background Estimation and Frame Differencing in OpenCV](https://learnopencv.com/video-to-slides-converter-using-background-subtraction/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Build-a-Video-to-Slides-Converter-Application-using-the-Power-of-Background-Estimation-and-Frame-Differencing-in-OpenCV)|\n|[A Closer Look at CVAT: Perfecting Your Annotations](https://learnopencv.com/a-closer-look-at-cvat-perfecting-your-annotations/)|[YouTube](https://www.youtube.com/watch?v=yxX_0-zr-2U&list=PLfYPZalDvZDLvFhjuflhrxk_lLplXUqqB)|\n| [ControlNet - Achieving Superior Image Generation Results](https://learnopencv.com/controlnet/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ControlNet-Achieving-Superior-Image-Generation-Results) |\n| [InstructPix2Pix - Edit Images With Prompts](https://learnopencv.com/instructpix2pix/) | [Code](https://github.com/spmallick/learnopencv/tree/master/InstructPix2Pix-Edit-Images-With-Prompts) |\n| [NVIDIA Spring GTC 2023 Day 4: Ending on a High Note with Top Moments from the Finale!](https://learnopencv.com/nvidia-spring-gtc-2023-day-4/) | |\n| [NVIDIA Spring GTC 2023 Day 3: Digging deeper into Deep Learning, Semiconductors & more!](https://learnopencv.com/nvidia-spring-gtc-2023-day-3-digging-deeper-into-deep-learning-semiconductors-more/) | |\n| [NVIDIA Spring GTC 2023 Day 2: Jensen‚Äôs keynote & the iPhone moment of AI is here!](https://learnopencv.com/nvidia-spring-gtc-2023-day-2-jensens-keynote-the-iphone-moment-of-ai-is-here/) | |\n| [NVIDIA Spring GTC 2023 Day 1: Welcome to the future!](https://learnopencv.com/nvidia-spring-gtc-2023-day-1-highlights-welcome-to-the-future/) | |\n| [NVIDIA GTC Spring 2023 Curtain Raiser](https://learnopencv.com/nvidia-gtc-spring-2023-curtain-raiser/) | |\n| [Stable Diffusion - A New Paradigm in Generative AI](https://learnopencv.com/stable-diffusion-generative-ai/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Stable-Diffusion-A-New-Paradigm-in-Generative-AI) |\n| [OpenCV Face Recognition ‚Äì Does Face Recognition Work on AI-Generated Images?](https://learnopencv.com/opencv-face-recognition-api/) | |\n|[An In-Depth Guide to Denoising Diffusion Probabilistic Models ‚Äì From Theory to Implementation](https://learnopencv.com/denoising-diffusion-probabilistic-models/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Guide-to-training-DDPMs-from-Scratch)|\n|[From Pixels to Paintings: The Rise of Midjourney AI Art](https://learnopencv.com/rise-of-midjourney-ai-art/)| |\n|[Mastering DALL¬∑E 2: A Breakthrough in AI Art Generation](https://learnopencv.com/mastering-dall-e-2/)| |\n|[Top 10 AI Art Generation Tools using Diffusion Models](https://learnopencv.com/ai-art-generation-tools/)| |\n|[The Future of Image Recognition is Here: PyTorch Vision Transformer](https://learnopencv.com/the-future-of-image-recognition-is-here-pytorch-vision-transformer/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Vision_Transformer_PyTorch)|\n|[Understanding Attention Mechanism in Transformer Neural Networks](https://learnopencv.com/attention-mechanism-in-transformer-neural-networks/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Attention_Mechanism_Introduction)|\n| [Deploying a Deep Learning Model using Hugging Face Spaces and Gradio](https://learnopencv.com/deploy-deep-learning-model-huggingface-spaces/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Deploying-a-Deep-Learning-Model-using-Hugging-Face-Spaces-and-Gradio) |\n| [Train YOLOv8 on Custom Dataset ‚Äì A Complete Tutorial](https://learnopencv.com/train-yolov8-on-custom-dataset/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Train-YOLOv8-on-Custom-Dataset-A-Complete-Tutorial) |\n| [Introduction to Diffusion Models for Image Generation](https://learnopencv.com/image-generation-using-diffusion-models/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Introduction-to-Diffusion-Models-for-Image-Generation) |\n| [Building An Automated Image Annotation Tool: PyOpenAnnotate](https://learnopencv.com/building-automated-image-annotation-tool-pyopenannotate/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Building-An-Automated-Image-Annotation-Tool-PyOpenAnnotate/) |\n| [Ultralytics YOLOv8: State-of-the-Art YOLO Models](https://learnopencv.com/ultralytics-yolov8/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Ultralytics-YOLOv8-State-of-the-Art-YOLO-Models) |\n| [Getting Started with YOLOv5 Instance Segmentation](https://learnopencv.com/getting-started-with-yolov5-instance-segmentation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Getting-Started-with-YOLOv5-Instance-Segmentation) |\n|[The Ultimate Guide To DeepLabv3 - With PyTorch Inference](https://learnopencv.com/deeplabv3-ultimate-guide/)|[Code](https://github.com/spmallick/learnopencv/tree/master/The-ultimate-guide-to-deeplabv3)|\n|[AI Fitness Trainer using MediaPipe: Squats Analysis](https://learnopencv.com/ai-fitness-trainer-using-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/AI-Fitness-Trainer-Using-MediaPipe-Analyzing-Squats)|\n|[YoloR - Paper Explanation & Inference -An In-Depth Analysis](https://learnopencv.com/yolor-paper-explanation-inference-an-in-depth-analysis/)|[Code](https://github.com/spmallick/learnopencv/tree/master/YoloR-paper-explanation-analysis)|\n|[Roadmap To an Automated Image Annotation Tool Using Python](https://learnopencv.com/automated-image-annotation-tool-using-opencv-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Roadmap-To-an-Automated-Image-Annotation-Tool-Using-Python)|\n|[Performance Comparison of YOLO Object Detection Models ‚Äì An Intensive Study](https://learnopencv.com/performance-comparison-of-yolo-models/)||\n|[FCOS - Anchor Free Object Detection Explained](https://learnopencv.com/fcos-anchor-free-object-detection-explained/)|[Code](https://github.com/spmallick/learnopencv/tree/master/FCOS-Inference-using-PyTorch)|\n| [YOLOv6 Custom Dataset Training ‚Äì Underwater Trash Detection](https://learnopencv.com/yolov6-custom-dataset-training/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv6-Custom-Dataset-Training-Underwater-Trash-Detection) |\n|[What is EXIF Data in Images?](https://www.learnopencv.com/what-is-exif-data-in-images/)|[Code](https://github.com/spmallick/learnopencv/tree/master/What-is-EXIF-Data-in-Images)|\n|[t-SNE: T-Distributed Stochastic Neighbor Embedding Explained](https://learnopencv.com/t-sne-t-distributed-stochastic-neighbor-embedding-explained/)|[Code](https://github.com/spmallick/learnopencv/tree/master/t-SNE-with-Tensorboard)|\n|[CenterNet: Objects as Points ‚Äì Anchor-free Object Detection Explained](https://learnopencv.com/centernet-anchor-free-object-detection-explained/)|[Code](https://github.com/spmallick/learnopencv/tree/master/centernet-with-tf-hub)|\n|[YOLOv7 Pose vs MediaPipe in Human Pose Estimation](https://learnopencv.com/yolov7-pose-vs-mediapipe-in-human-pose-estimation/)|[Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv7-Pose-vs-MediaPipe-in-Human-Pose-Estimation)|\n|[YOLOv6 Object Detection ‚Äì Paper Explanation and Inference](https://learnopencv.com/yolov6-object-detection/)|[Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv6-Object-Detection-Paper-Explanation-and-Inference)|\n|[YOLOX Object Detector Paper Explanation and Custom Training](https://learnopencv.com/yolox-object-detector-paper-explanation-and-custom-training/)|[Code](https://github.com/spmallick/learnopencv/tree/master/YOLOX-Object-Detection-Paper-Explanation-and-Custom-Training)|\n|[Driver Drowsiness Detection Using Mediapipe In Python](https://learnopencv.com/driver-drowsiness-detection-using-mediapipe-in-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Driver-Drowsiness-detection-using-Mediapipe-in-Python)|\n|[GTC 2022 Big Bang AI announcements: Everything you need to know](https://learnopencv.com/gtc-2022-big-bang-ai-announcements-everything-you-need-to-know/)||\n|[NVIDIA GTC 2022 : The most important AI event this Fall](https://learnopencv.com/nvidia-gtc-2022-the-most-important-ai-event-this-fall/)||\n|[Object Tracking and Reidentification with FairMOT](https://learnopencv.com/object-tracking-and-reidentification-with-fairmot/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Object-Tracking-and-Reidentification-with-FairMOT) |\n|[What is Face Detection? ‚Äì The Ultimate Guide for 2022](https://learnopencv.com/what-is-face-detection-the-ultimate-guide/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Face-Detection-Ultimate-Guide) |\n|[Document Scanner: Custom Semantic Segmentation using PyTorch-DeepLabV3](https://learnopencv.com/custom-document-segmentation-using-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Document-Scanner-Custom-Semantic-Segmentation-using-PyTorch-DeepLabV3)|\n|[Fine Tuning YOLOv7 on Custom Dataset](https://learnopencv.com/fine-tuning-yolov7-on-custom-dataset/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Fine-Tuning-YOLOv7)|\n|[Center Stage for Zoom Calls using MediaPipe](https://learnopencv.com/Center-Stage-for-zoom-call-using-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/CenterStage)|\n|[Mean Average Precision (mAP) in Object Detection](https://learnopencv.com/mean-average-precision-map-object-detection-model-evaluation-metric/)||\n|[YOLOv7 Object Detection Paper Explanation and Inference](https://learnopencv.com/yolov7-object-detection-paper-explanation-and-inference/)|[Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv7-Object-Detection-Paper-Explanation-and-Inference)|\n|[Pothole Detection using YOLOv4 and Darknet](https://learnopencv.com/pothole-detection-using-yolov4-and-darknet/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Pothole-Detection-using-YOLOv4-and-Darknet)|\n|[Automatic Document Scanner using OpenCV](https://learnopencv.com/automatic-document-scanner-using-opencv/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Automatic-Document-Scanner)|\n|[Demystifying GPU architectures for deep learning: Part 2](https://learnopencv.com/demystifying-gpu-architectures-for-deep-learning-part-2/)|[Code](https://github.com/spmallick/learnopencv/tree/master/gpu_arch_and_CUDA)|\n|[Demystifying GPU Architectures For Deep Learning](https://learnopencv.com/demystifying-gpu-architectures-for-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/gpu_arch_and_CUDA)|\n|[Intersection-over-Union(IoU)-in-Object-Detection-and-Segmentation](https://learnopencv.com/intersection-over-unioniou-in-object-detection-and-segmentation/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Intersection-over-Union-IoU-in-Object-Detection-and-Segmentation)|\n|[Understanding Multiple Object Tracking using DeepSORT](https://learnopencv.com/understanding-multiple-object-tracking-using-deepsort/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Understanding-Multiple-Object-Tracking-using-DeepSORT)|\n|[Optical Character Recognition using PaddleOCR](https://learnopencv.com/optical-character-recognition-using-paddleocr/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Optical-Character-Recognition-using-PaddleOCR)|\n|[Gesture Control in Zoom Call using Mediapipe](https://learnopencv.com/gesture-control-in-zoom-call-using-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/zoom-gestures)|\n|[A Deep Dive into Tensorflow Model Optimization](https://learnopencv.com/deep-dive-into-tensorflow-model-optimization-toolkit/)|[Code](https://github.com/spmallick/learnopencv/tree/master/A-Deep-Dive-into-Tensorflow-Model-Optimization)|\n|[DepthAI Pipeline Overview: Creating a Complex Pipeline](https://learnopencv.com/depthai-pipeline-overview-creating-a-complex-pipeline/)|[Code](https://github.com/spmallick/learnopencv/tree/master/OAK-DepthAi-Pipeline-Overview)|\n|[TensorFlow Lite Model Maker: Create Models for On-Device Machine Learning](https://learnopencv.com/tensorflow-lite-model-maker-create-models-for-on-device-machine-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Tensorflow-Lite-Model-Maker-Create-Models-for-On-Device-ML)|\n|[TensorFlow Lite: Model Optimization for On Device Machine Learning](https://learnopencv.com/tensorflow-lite-model-optimization-for-on-device-machine-learning)|[Code](https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Lite-Model-Optimization-for-On-Device-MachineLearning)|\n|[Object detection with depth measurement using pre-trained models with OAK-D](https://learnopencv.com/object-detection-with-depth-measurement-with-oak-d/)|[Code](https://github.com/spmallick/learnopencv/tree/master/OAK-Object-Detection-with-Depth)|\n|[Custom Object Detection Training using YOLOv5](https://learnopencv.com/custom-object-detection-training-using-yolov5/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Custom-Object-Detection-Training-using-YOLOv5)|\n|[Object Detection using Yolov5 and OpenCV DNN (C++/Python)](https://learnopencv.com/object-detection-using-yolov5-and-opencv-dnn-in-c-and-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python)|\n|[Create Snapchat/Instagram filters using Mediapipe](https://learnopencv.com/create-snapchat-instagram-filters-using-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Create-AR-filters-using-Mediapipe)|\n|[AUTOSAR C++ compliant deep learning inference with TensorRT](https://learnopencv.com/autosar-c-compliant-deep-learning-inference-with-tensorrt/)|[Code](https://github.com/spmallick/learnopencv/tree/master/industrial_cv_TensorRT_cpp)|\n|[NVIDIA GTC 2022 Day 4 Highlights: Meet the new Jetson Orin](https://learnopencv.com/nvidia-gtc-2022-day-4-highlights-meet-the-new-jetson-orin/)||\n|[NVIDIA GTC 2022 Day 3 Highlights: Deep Dive into Hopper architecture](https://learnopencv.com/nvidia-gtc-2022-day-3-highlights-deep-dive-into-hopper-architecture/)||\n|[NVIDIA GTC 2022 Day 2 Highlights: Jensen‚Äôs Keynote](https://learnopencv.com/nvidia-gtc-2022-day-2-highlights/)||\n|[NVIDIA GTC 2022 Day 1 Highlights: Brilliant Start](https://learnopencv.com/gtc-day-1-highlights/)||\n|[Automatic License Plate Recognition using Python](https://learnopencv.com/automatic-license-plate-recognition-using-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/ALPR)|\n|[Building a Poor Body Posture Detection and Alert System using MediaPipe](https://learnopencv.com/building-a-body-posture-analysis-system-using-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Posture-analysis-system-using-MediaPipe-Pose)|\n|[Introduction to MediaPipe](https://learnopencv.com/introduction-to-mediapipe/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Introduction-to-MediaPipe)|\n|[Disparity Estimation using Deep Learning](https://learnopencv.com/disparity-estimation-using-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Disparity-Estimation-Using-Deep-Learning)|\n|[How to build Chrome Dino game bot using OpenCV Feature Matching](https://learnopencv.com/how-to-build-chrome-dino-game-bot-using-opencv-feature-matching/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Chrome-Dino-Bot-using-OpenCV-feature-matching)|\n|[Top 10 Sources to Find Computer Vision and AI Models](https://learnopencv.com/top-10-sources-to-find-computer-vision-and-ai-models/)||\n|[Multi-Attribute and Graph-based Object Detection](https://learnopencv.com/multi-attribute-and-graph-based-object-detection/)||\n|[Plastic Waste Detection with Deep Learning](https://learnopencv.com/plastic-waste-detection-with-deep-learning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Plastic-Waste-Detection-with-Deep-Learning)|\n|[Ensemble Deep Learning-based Defect Classification and Detection in SEM Images](https://learnopencv.com/ensemble-deep-learning-based-defect-classification-and-detection-in-sem-images/)||\n|[Building Industrial embedded deep learning inference pipelines with TensorRT](https://learnopencv.com/building-industrial-embedded-deep-learning-inference-pipelines-with-tensorrt/)|[Code](https://github.com/spmallick/learnopencv/tree/master/industrial_cv_TensorRT_python)|\n|[Transfer Learning for Medical Images](https://learnopencv.com/transfer-learning-for-medical-images/)||\n|[Stereo Vision and Depth Estimation using OpenCV AI Kit](https://learnopencv.com/stereo-vision-and-depth-estimation-using-opencv-ai-kit/)|[Code](https://github.com/spmallick/learnopencv/tree/master/oak-getting-started)|\n|[Introduction to OpenCV AI Kit and DepthAI](https://learnopencv.com/introduction-to-opencv-ai-kit-and-depthai/)|[Code](https://github.com/spmallick/learnopencv/tree/master/oak-getting-started)|\n|[WeChat QR Code Scanner in OpenCV](https://learnopencv.com/wechat-qr-code-scanner-in-opencv)|[Code](https://github.com/spmallick/learnopencv/tree/master/WeChat-QRCode-Scanner-OpenCV)|\n|[AI behind the Diwali 2021 ‚ÄòNot just a Cadbury ad‚Äô](https://learnopencv.com/ai-behind-the-diwali-2021-not-just-a-cadbury-ad/)| |\n|[Model Selection and Benchmarking with Modelplace.AI](https://learnopencv.com/model-selection-and-benchmarking-with-modelplace-ai/)|[Model Zoo](https://modelplace.ai/)|\n|[Real-time style transfer in a zoom meeting](https://learnopencv.com/real-time-style-transfer-in-a-zoom-meeting/)|[Code](https://github.com/spmallick/learnopencv/tree/master/style-transfer-zoom)|\n| [Introduction to OpenVino Deep Learning Workbench](https://learnopencv.com/introduction-to-openvino-deep-learning-workbench/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Introduction-to-OpenVino-Deep-Learning-Workbench) |\n| [Running OpenVino Models on Intel Integrated GPU](https://learnopencv.com/running-openvino-models-on-intel-integrated-gpu/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Running-OpenVino-Models-on-Intel-Integrated-GPU) |\n|[Post Training Quantization with OpenVino Toolkit](https://learnopencv.com/post-training-quantization-with-openvino-toolkit/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Post-Training-Quantization-with-OpenVino-Toolkit)|\n|[Introduction to Intel OpenVINO Toolkit](https://learnopencv.com/introduction-to-intel-openvino-toolkit/)||\n|[Human Action Recognition using Detectron2 and LSTM](https://learnopencv.com/human-action-recognition-using-detectron2-and-lstm/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Human-Action-Recognition-Using-Detectron2-And-Lstm)|\n|[Pix2Pix:Image-to-Image Translation in PyTorch & TensorFlow](https://learnopencv.com/paired-image-to-image-translation-pix2pix/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Image-to-Image-Translation-with-GAN)|\n|[Conditional GAN (cGAN) in PyTorch and TensorFlow](https://learnopencv.com/conditional-gan-cgan-in-pytorch-and-tensorflow/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Conditional-GAN-PyTorch-TensorFlow)|\n|[Deep Convolutional GAN in PyTorch and TensorFlow](https://learnopencv.com/deep-convolutional-gan-in-pytorch-and-tensorflow/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Deep-Convolutional-GAN)|\n|[Introduction to Generative Adversarial Networks (GANs)](https://learnopencv.com/introduction-to-generative-adversarial-networks/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Intro-to-Generative-Adversarial-Network)|\n|[Human Pose Estimation using Keypoint RCNN in PyTorch](https://learnopencv.com/human-pose-estimation-using-keypoint-rcnn-in-pytorch/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Keypoint-RCNN)|\n|[Non Maximum Suppression: Theory and Implementation in PyTorch](https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch)|[Code](https://github.com/spmallick/learnopencv/tree/master/Non-Maximum-Suppression)|\n|[MRNet ‚Äì The Multi-Task Approach](https://learnopencv.com/mrnet-multitask-approach/)| [Code](https://github.com/spmallick/learnopencv/tree/master/MRnet-MultiTask-Approach) |\n|[Generative and Discriminative Models](https://learnopencv.com/generative-and-discriminative-models/)| |\n|[Playing Chrome's T-Rex Game with Facial Gestures](https://learnopencv.com/playing-chromes-t-rex-game-with-facial-gestures/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Playing-Chrome-TRex-Game-with-Facial-Gestures) |\n|[Variational Autoencoder in TensorFlow](https://learnopencv.com/variational-autoencoder-in-tensorflow/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Variational-Autoencoder-TensorFlow) |\n|[Autoencoder in TensorFlow 2: Beginner‚Äôs Guide](https://learnopencv.com/autoencoder-in-tensorflow-2-beginners-guide/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Autoencoder-in-TensorFlow) |\n|[Deep Learning with OpenCV DNN Module: A Definitive Guide](https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Deep-Learning-with-OpenCV-DNN-Module) |\n|[Depth perception using stereo camera (Python/C++)](https://learnopencv.com/depth-perception-using-stereo-camera-python-c/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Depth-Perception-Using-Stereo-Camera) |\n|[Contour Detection using OpenCV (Python/C++)](https://learnopencv.com/contour-detection-using-opencv-python-c/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Contour-Detection-using-OpenCV) |\n|[Super Resolution in OpenCV](https://learnopencv.com/super-resolution-in-opencv/)| [Code](https://github.com/spmallick/learnopencv/blob/master/Super-Resolution-in-OpenCV) |\n|[Improving Illumination in Night Time Images](https://learnopencv.com/improving-illumination-in-night-time-images/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Improving-Illumination-in-Night-Time-Images) |\n|[Video Classification and Human Activity Recognition](https://learnopencv.com/introduction-to-video-classification-and-human-activity-recognition/) | [Code](https://github.com/spmallick/learnopencv/tree/master/video-classification-and-human-activity-recognition) |\n|[How to use OpenCV DNN Module with Nvidia GPU on Windows](https://learnopencv.com/how-to-use-opencv-dnn-module-with-nvidia-gpu-on-windows) | [Code](https://github.com/spmallick/learnopencv/tree/master/OpenCV-dnn-gpu-support-Windows) |\n|[How to use OpenCV DNN Module with NVIDIA GPUs](https://learnopencv.com/opencv-dnn-with-gpu-support/) | [Code](https://github.com/spmallick/learnopencv/tree/master/OpenCV-dnn-gpu-support-Linux) |\n|[Code OpenCV in Visual Studio](https://learnopencv.com/code-opencv-in-visual-studio/) | |\n|[Install OpenCV on Windows ‚Äì C++ / Python](https://learnopencv.com/install-opencv-on-windows/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Install-OpenCV-Windows-exe) |\n|[Face Recognition with ArcFace](https://www.learnopencv.com/face-recognition-with-arcface/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Face-Recognition-with-ArcFace)|\n|[Background Subtraction with OpenCV and BGS Libraries](https://www.learnopencv.com/background-subtraction-with-opencv-and-bgs-libraries/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Background-Subtraction) |\n|[RAFT: Optical Flow estimation using Deep Learning](https://learnopencv.com/optical-flow-using-deep-learning-raft/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Optical-Flow-Estimation-using-Deep-Learning-RAFT)|\n|[Making A Low-Cost Stereo Camera Using OpenCV](https://www.learnopencv.com/making-a-low-cost-stereo-camera-using-opencv/)|[Code](https://github.com/spmallick/learnopencv/tree/master/stereo-camera)|\n|[Optical Flow in OpenCV (C++/Python)](https://www.learnopencv.com/optical-flow-in-opencv)|[Code](https://github.com/spmallick/learnopencv/tree/master/Optical-Flow-in-OpenCV)|\n|[Introduction to Epipolar Geometry and Stereo Vision](https://www.learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/)|[Code](https://github.com/spmallick/learnopencv/tree/master/EpipolarGeometryAndStereoVision)|\n|[Classification With Localization: Convert any keras Classifier to a Detector](https://www.learnopencv.com/classification-with-localization/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Classification-with-localization-convert-any-keras-classifier-into-a-detector/README.md) |\n|[Photoshop Filters in OpenCV](https://www.learnopencv.com/photoshop-filters-in-opencv/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Photoshop-Filters-in-OpenCV)|\n|[Tetris Game using OpenCV Python](https://www.learnopencv.com/tetris-with-opencv-python)|[Code](https://github.com/spmallick/learnopencv/tree/master/Tetris)|\n|[Image Classification with OpenCV for Android](https://www.learnopencv.com/image-classification-with-opencv-for-android/) | [Code](https://github.com/spmallick/learnopencv/tree/master/DNN-OpenCV-Classification-Android) |\n|[Image Classification with OpenCV Java](https://www.learnopencv.com/image-classification-with-opencv-java)|[Code](https://github.com/spmallick/learnopencv/tree/master/DNN-OpenCV-Classification-with-Java) |\n|[PyTorch to Tensorflow Model Conversion](https://www.learnopencv.com/pytorch-to-tensorflow-model-conversion/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-to-TensorFlow-Model-Conversion) |\n|[Snake Game with OpenCV Python](https://www.learnopencv.com/snake-game-with-opencv-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/SnakeGame) |\n|[Stanford MRNet Challenge: Classifying Knee MRIs](https://www.learnopencv.com/stanford-mrnet-challenge-classifying-knee-mris/)|[Code](https://github.com/spmallick/learnopencv/tree/master/MRNet-Single-Model) |\n|[Experiment Logging with TensorBoard and wandb](https://www.learnopencv.com/experiment-logging-with-tensorboard-and-wandb)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Vision-Experiment-Logging) |\n|[Understanding Lens Distortion](https://www.learnopencv.com/understanding-lens-distortion/)|[Code](https://github.com/spmallick/learnopencv/tree/master/UnderstandingLensDistortion) |\n|[Image Matting with state-of-the-art Method ‚ÄúF, B, Alpha Matting‚Äù](https://www.learnopencv.com/image-matting-with-state-of-the-art-method-f-b-alpha-matting/)|[Code](https://github.com/spmallick/learnopencv/tree/master/FBAMatting) |\n|[Bag Of Tricks For Image Classification - Let's check if it is working or not](https://www.learnopencv.com/bag-of-tricks-for-image-classification-lets-check-if-it-is-working-or-not/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Bag-Of-Tricks-For-Image-Classification) |\n|[Getting Started with OpenCV CUDA Module](https://www.learnopencv.com/getting-started-opencv-cuda-module/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Getting-Started-OpenCV-CUDA-Module) |\n|[Training a Custom Object Detector with DLIB & Making Gesture Controlled Applications](https://www.learnopencv.com/training-a-custom-object-detector-with-dlib-making-gesture-controlled-applications/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Training_a_custom_hand_detector_with_dlib) |\n|[How To Run Inference Using TensorRT C++ API](https://www.learnopencv.com/how-to-run-inference-using-tensorrt-c-api/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-ONNX-TensorRT-CPP) |\n|[Using Facial Landmarks for Overlaying Faces with Medical Masks](https://www.learnopencv.com/using-facial-landmarks-for-overlaying-faces-with-masks/)|[Code](https://github.com/spmallick/learnopencv/tree/master/FaceMaskOverlay) |\n|[Tensorboard with PyTorch Lightning](https://www.learnopencv.com/tensorboard-with-pytorch-lightning)|[Code](https://github.com/spmallick/learnopencv/tree/master/TensorBoard-With-Pytorch-Lightning) |\n|[Otsu's Thresholding with OpenCV](https://www.learnopencv.com/otsu-thresholding-with-opencv/)|[Code](https://github.com/spmallick/learnopencv/tree/master/otsu-method) |\n|[PyTorch-to-CoreML-model-conversion](https://www.learnopencv.com/pytorch-to-coreml-model-conversion/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-to-CoreML-model-conversion) |\n|[Playing Rock, Paper, Scissors with AI](https://www.learnopencv.com/playing-rock-paper-scissors-with-ai/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Playing-rock-paper-scissors-with-AI) |\n|[CNN Receptive Field Computation Using Backprop with TensorFlow](https://www.learnopencv.com/cnn-receptive-field-computation-using-backprop-with-tensorflow/)|[Code](https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Receptive-Field-With-Backprop)|\n|[CNN Fully Convolutional Image Classification with TensorFlow](https://www.learnopencv.com/cnn-fully-convolutional-image-classification-with-tensorflow) | [Code](https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Fully-Convolutional-Image-Classification) |\n|[How to convert a model from PyTorch to TensorRT and speed up inference](https://www.learnopencv.com/how-to-convert-a-model-from-pytorch-to-tensorrt-and-speed-up-inference/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-ONNX-TensorRT) |\n|[Efficient image loading](https://www.learnopencv.com/efficient-image-loading/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Efficient-image-loading) |\n|[Graph Convolutional Networks: Model Relations In Data](https://www.learnopencv.com/graph-convolutional-networks-model-relations-in-data/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Graph-Convolutional-Networks-Model-Relations-In-Data)|\n|[Getting Started with Federated Learning with PyTorch and PySyft](https://www.learnopencv.com/federated-learning-using-pytorch-and-pysyft/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Federated-Learning-Intro)|\n|[Creating a Virtual Pen & Eraser](http://www.learnopencv.com/creating-a-virtual-pen-and-eraser-with-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Creating-a-Virtual-Pen-and-Eraser) |\n|[Getting Started with PyTorch Lightning](https://www.learnopencv.com/getting-started-with-pytorch-lightning/)|[Code](https://github.com/spmallick/learnopencv/tree/master/Pytorch-Lightning)|\n|[Multi-Label Image Classification with PyTorch: Image Tagging](https://www.learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Multi-Label-Image-Classification-Image-Tagging)|\n|[Funny Mirrors Using OpenCV](https://www.learnopencv.com/Funny-Mirrors-Using-OpenCV/)|[code](https://github.com/spmallick/learnopencv/tree/master/FunnyMirrors)|\n|[t-SNE for ResNet feature visualization](https://www.learnopencv.com/t-sne-for-feature-visualization/)|[Code](https://github.com/spmallick/learnopencv/tree/master/TSNE)|\n|[Multi-Label Image Classification with Pytorch](https://www.learnopencv.com/multi-label-image-classification-with-pytorch/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Multi-Label-Image-Classification)|\n|[CNN Receptive Field Computation Using Backprop](https://www.learnopencv.com/cnn-receptive-field-computation-using-backprop/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Receptive-Field-With-Backprop)|\n|[CNN Receptive Field Computation Using Backprop with TensorFlow](https://www.learnopencv.com/cnn-receptive-field-computation-using-backprop-with-tensorflow/)|[Code](https://github.com/spmallick/learnopencv/tree/master/TensorFlow-Receptive-Field-With-Backprop)|\n|[Augmented Reality using AruCo Markers in OpenCV(C++ and Python)](https://www.learnopencv.com/augmented-reality-using-aruco-markers-in-opencv-(c++-python)/) |[Code](https://github.com/spmallick/learnopencv/tree/master/AugmentedRealityWithArucoMarkers)|\n|[Fully Convolutional Image Classification on Arbitrary Sized Image](https://www.learnopencv.com/fully-convolutional-image-classification-on-arbitrary-sized-image/)|[Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Fully-Convolutional-Image-Classification)|\n|[Camera Calibration using OpenCV](https://www.learnopencv.com/camera-calibration-using-opencv/) |[Code](https://github.com/spmallick/learnopencv/tree/master/CameraCalibration)|\n|[Geometry of Image Formation](https://www.learnopencv.com/geometry-of-image-formation/) ||\n|[Ensuring Training Reproducibility in Pytorch](https://www.learnopencv.com/ensuring-training-reproducibility-in-pytorch) ||\n|[Gaze Tracking](https://www.learnopencv.com/gaze-tracking/) ||\n|[Simple Background Estimation in Videos Using OpenCV](https://www.learnopencv.com/simple-background-estimation-in-videos-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VideoBackgroundEstimation)|\n|[Applications of Foreground-Background separation with Semantic Segmentation](https://www.learnopencv.com/applications-of-foreground-background-separation-with-semantic-segmentation/) | [Code](https://github.com/spmallick/learnopencv/tree/master/app-seperation-semseg) |\n|[EfficientNet: Theory + Code](https://www.learnopencv.com/efficientnet-theory-code) | [Code](https://github.com/spmallick/learnopencv/tree/master/EfficientNet) |\n|[PyTorch for Beginners: Mask R-CNN Instance Segmentation with PyTorch](https://www.learnopencv.com/mask-r-cnn-instance-segmentation-with-pytorch/) | [Code](./PyTorch-Mask-RCNN) |\n|[PyTorch for Beginners: Faster R-CNN Object Detection with PyTorch](https://www.learnopencv.com/faster-r-cnn-object-detection-with-pytorch) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-faster-RCNN) |\n|[PyTorch for Beginners: Semantic Segmentation using torchvision](https://www.learnopencv.com/pytorch-for-beginners-semantic-segmentation-using-torchvision/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-Segmentation-torchvision) |\n|[PyTorch for Beginners: Comparison of pre-trained models for Image Classification](https://www.learnopencv.com/image-classification-using-pre-trained-models-using-pytorch/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Image-classification-pre-trained-models/Image_Classification_using_pre_trained_models.ipynb) |\n|[PyTorch for Beginners: Basics](https://www.learnopencv.com/pytorch-for-beginners-basics/) | [Code](https://github.com/spmallick/learnopencv/tree/master/PyTorch-for-Beginners/PyTorch_for_Beginners.ipynb) |\n|[PyTorch Model Inference using ONNX and Caffe2](https://www.learnopencv.com/pytorch-model-inference-using-onnx-and-caffe2/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Inference-for-PyTorch-Models/ONNX-Caffe2) |\n|[Image Classification Using Transfer Learning in PyTorch](https://www.learnopencv.com/image-classification-using-transfer-learning-in-pytorch/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Image-Classification-in-PyTorch) |\n|[Hangman: Creating games in OpenCV](https://www.learnopencv.com/hangman-creating-games-in-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Hangman) |\n|[Image Inpainting with OpenCV (C++/Python)](https://www.learnopencv.com/image-inpainting-with-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Image-Inpainting) |\n|[Hough Transform with OpenCV (C++/Python)](https://www.learnopencv.com/hough-transform-with-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Hough-Transform) |\n|[Xeus-Cling: Run C++ code in Jupyter Notebook](https://www.learnopencv.com/xeus-cling-run-c-code-in-jupyter-notebook/) | [Code](https://github.com/spmallick/learnopencv/tree/master/XeusCling) |\n|[Gender & Age Classification using OpenCV Deep Learning ( C++/Python )](https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/AgeGender) |\n|[Invisibility Cloak using Color Detection and Segmentation with OpenCV](https://www.learnopencv.com/invisibility-cloak-using-color-detection-and-segmentation-with-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/InvisibilityCloak) |\n|[Fast Image Downloader for Open Images V4 (Python)](https://www.learnopencv.com/fast-image-downloader-for-open-images-v4/) | [Code](https://github.com/spmallick/learnopencv/tree/master/downloadOpenImages) |\n|[Deep Learning based Text Detection Using OpenCV (C++/Python)](https://www.learnopencv.com/deep-learning-based-text-detection-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/TextDetectionEAST) |\n|[Video Stabilization Using Point Feature Matching in OpenCV](https://www.learnopencv.com/video-stabilization-using-point-feature-matching-in-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VideoStabilization) |\n|[Training YOLOv3 : Deep Learning based Custom Object Detector](https://www.learnopencv.com/training-yolov3-deep-learning-based-custom-object-detector/) | [Code](https://github.com/spmallick/learnopencv/tree/master/YOLOv3-Training-Snowman-Detector ) |\n|[Using OpenVINO with OpenCV](https://www.learnopencv.com/using-openvino-with-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/OpenVINO-OpenCV) |\n|[Duplicate Search on Quora Dataset](https://www.learnopencv.com/duplicate-search-on-quora-dataset/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Quora-Dataset-Duplicate-Search) |\n|[Shape Matching using Hu Moments (C++/Python)](https://www.learnopencv.com/shape-matching-using-hu-moments-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/HuMoments) |\n|[Install OpenCV 4 on CentOS (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-centos-7/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-centos.sh) |\n|[Install OpenCV 3.4.4 on CentOS (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-centos-7/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-centos.sh) |\n|[Install OpenCV 3.4.4 on Red Hat (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-red-hat/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-red-hat.sh) |\n|[Install OpenCV 4 on Red Hat (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-red-hat/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-on-red-hat.sh) |\n|[Install OpenCV 4 on macOS (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-macos/) | [Code](https://github.com/spmallick/learnopencv/tree/master/InstallScripts/installOpenCV-4-macos.sh) |\n|[Install OpenCV 3.4.4 on Raspberry Pi](https://www.learnopencv.com/install-opencv-3-4-4-on-raspberry-pi/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-raspberry-pi.sh) |\n|[Install OpenCV 3.4.4 on macOS (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-macos/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-macos.sh) |\n|[OpenCV QR Code Scanner (C++ and Python)](https://www.learnopencv.com/opencv-qr-code-scanner-c-and-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/QRCode-OpenCV) |\n|[Install OpenCV 3.4.4 on Windows (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-windows/) | [Code](https://github.com/spmallick/learnopencv/tree/master/InstallScripts/Windows-3) |\n|[Install OpenCV 3.4.4 on Ubuntu 16.04 (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-ubuntu-16-04/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-Ubuntu-16-04.sh) |\n|[Install OpenCV 3.4.4 on Ubuntu 18.04 (C++ and Python)](https://www.learnopencv.com/install-opencv-3-4-4-on-ubuntu-18-04/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-3-on-Ubuntu-18-04.sh) |\n|[Universal Sentence Encoder](https://www.learnopencv.com/universal-sentence-encoder) | [Code](https://github.com/spmallick/learnopencv/blob/master/Universal-Sentence-Encoder) |\n|[Install OpenCV 4 on Raspberry Pi](https://www.learnopencv.com/install-opencv-4-on-raspberry-pi/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-raspberry-pi.sh) |\n|[Install OpenCV 4 on Windows (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-windows/) | [Code](https://github.com/spmallick/learnopencv/tree/master/InstallScripts/Windows-4) |\n|[Face Detection ‚Äì Dlib, OpenCV, and Deep Learning ( C++ / Python )](https://learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/FaceDetectionComparison)|\n|[Hand Keypoint Detection using Deep Learning and OpenCV](https://www.learnopencv.com/hand-keypoint-detection-using-deep-learning-and-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/HandPose)|\n|[Deep learning based Object Detection and Instance Segmentation using Mask R-CNN in OpenCV (Python / C++)](https://www.learnopencv.com/deep-learning-based-object-detection-and-instance-segmentation-using-mask-r-cnn-in-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Mask-RCNN) |\n|[Install OpenCV 4 on Ubuntu 18.04 (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-ubuntu-18-04/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-on-Ubuntu-18-04.sh) |\n|[Install OpenCV 4 on Ubuntu 16.04 (C++ and Python)](https://www.learnopencv.com/install-opencv-4-on-ubuntu-16-04/) | [Code](https://github.com/spmallick/learnopencv/blob/master/InstallScripts/installOpenCV-4-on-Ubuntu-16-04.sh) |\n|[Multi-Person Pose Estimation in OpenCV using OpenPose](https://www.learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/) | [Code](https://github.com/spmallick/learnopencv/tree/master/OpenPose-Multi-Person) |\n|[Heatmap for Logo Detection using OpenCV (Python)](https://www.learnopencv.com/heatmap-for-logo-detection-using-opencv-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/heatmap)|\n|[Deep Learning based Object Detection using YOLOv3 with OpenCV ( Python / C++ )](https://www.learnopencv.com/deep-learning-based-object-detection-using-yolov3-with-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ObjectDetection-YOLO)|\n|[Convex Hull using OpenCV in Python and C++](https://www.learnopencv.com/convex-hull-using-opencv-in-python-and-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ConvexHull)|\n|[MultiTracker : Multiple Object Tracking using OpenCV (C++/Python)](https://www.learnopencv.com/multitracker-multiple-object-tracking-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/MultiObjectTracker) |\n|[Convolutional Neural Network based Image Colorization using OpenCV](https://www.learnopencv.com/convolutional-neural-network-based-image-colorization-using-opencv/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Colorization)|\n|[SVM using scikit-learn](https://www.learnopencv.com/svm-using-scikit-learn-in-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/SVM-using-Python)|\n|[GOTURN: Deep Learning based Object Tracking](https://www.learnopencv.com/goturn-deep-learning-based-object-tracking/) | [Code](https://github.com/spmallick/learnopencv/tree/master/GOTURN)|\n|[Find the Center of a Blob (Centroid) using OpenCV (C++/Python)](https://www.learnopencv.com/find-center-of-blob-centroid-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/CenterofBlob)|\n|[Support Vector Machines (SVM)](https://www.learnopencv.com/support-vector-machines-svm/)|[Code](https://github.com/spmallick/learnopencv/tree/master/SVM-using-Python)|\n|[Batch Normalization in Deep Networks](https://www.learnopencv.com/batch-normalization-in-deep-networks/) | [Code](https://github.com/spmallick/learnopencv/tree/master/BatchNormalization)|\n|[Deep Learning based Character Classification using Synthetic Dataset](https://www.learnopencv.com/deep-learning-character-classification-using-synthetic-dataset/) | [Code](https://github.com/spmallick/learnopencv/tree/master/CharClassification)|\n|[Image Quality Assessment : BRISQUE](https://www.learnopencv.com/image-quality-assessment-brisque/)| [Code](https://github.com/spmallick/learnopencv/tree/master/ImageMetrics)|\n|[Understanding AlexNet](https://www.learnopencv.com/understanding-alexnet/)||\n|[Deep Learning based Text Recognition (OCR) using Tesseract and OpenCV](https://www.learnopencv.com/deep-learning-based-text-recognition-ocr-using-tesseract-and-opencv/)| [Code](https://github.com/spmallick/learnopencv/tree/master/OCR)|\n|[Deep Learning based Human Pose Estimation using OpenCV ( C++ / Python )](https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/OpenPose)|\n|[Number of Parameters and Tensor Sizes in a Convolutional Neural Network (CNN)](https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/)| |\n|[How to convert your OpenCV C++ code into a Python module](https://www.learnopencv.com/how-to-convert-your-opencv-c-code-into-a-python-module/)|[Code](https://github.com/spmallick/learnopencv/tree/master/pymodule)|\n|[CV4Faces : Best Project Award 2018](https://www.learnopencv.com/cv4faces-best-project-award-2018/)| |\n|[Facemark : Facial Landmark Detection using OpenCV](https://www.learnopencv.com/facemark-facial-landmark-detection-using-opencv/)|[Code](https://github.com/spmallick/learnopencv/tree/master/FacialLandmarkDetection)|\n|[Image Alignment (Feature Based) using OpenCV (C++/Python)](https://www.learnopencv.com/image-alignment-feature-based-using-opencv-c-python/)| [Code](https://github.com/spmallick/learnopencv/tree/master/ImageAlignment-FeatureBased)|\n|[Barcode and QR code Scanner using ZBar and OpenCV](https://www.learnopencv.com/barcode-and-qr-code-scanner-using-zbar-and-opencv/)| [Code](https://github.com/spmallick/learnopencv/tree/master/barcode-QRcodeScanner)|\n|[Keras Tutorial : Fine-tuning using pre-trained models](https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Keras-Fine-Tuning)|\n|[OpenCV Transparent API](https://www.learnopencv.com/opencv-transparent-api/)| |\n|[Face Reconstruction using EigenFaces (C++/Python)](https://www.learnopencv.com/face-reconstruction-using-eigenfaces-cpp-python/)|[Code](https://github.com/spmallick/learnopencv/tree/master/ReconstructFaceUsingEigenFaces) |\n|[Eigenface using OpenCV (C++/Python)](https://www.learnopencv.com/eigenface-using-opencv-c-python/)| [Code](https://github.com/spmallick/learnopencv/tree/master/EigenFace)|\n|[Principal Component Analysis](https://www.learnopencv.com/principal-component-analysis/)| |\n|[Keras Tutorial : Transfer Learning using pre-trained models](https://www.learnopencv.com/keras-tutorial-transfer-learning-using-pre-trained-models/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Keras-Transfer-Learning) |\n|[Keras Tutorial : Using pre-trained Imagenet models](https://www.learnopencv.com/keras-tutorial-using-pre-trained-imagenet-models/)| [Code](https://github.com/spmallick/learnopencv/tree/master/Keras-ImageNet-Models) |\n|[Technical Aspects of a Digital SLR](https://www.learnopencv.com/technical-aspects-of-a-digital-slr/) | |\n|[Using Harry Potter interactive wand with OpenCV to create magic](https://www.learnopencv.com/using-harry-potter-interactive-wand-with-opencv-to-create-magic/)| |\n|[Install OpenCV 3 and Dlib on Windows ( Python only )](https://www.learnopencv.com/install-opencv-3-and-dlib-on-windows-python-only/)| |\n|[Image Classification using Convolutional Neural Networks in Keras](https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras)      | [Code](https://github.com/spmallick/learnopencv/tree/master/KerasCNN-CIFAR)|\n|[Understanding Autoencoders using Tensorflow (Python)](https://www.learnopencv.com/understanding-autoencoders-using-tensorflow-python/)      | [Code](https://github.com/spmallick/learnopencv/tree/master/DenoisingAutoencoder)|\n|[Best Project Award : Computer Vision for Faces](https://www.learnopencv.com/best-project-award-computer-vision-for-faces/) | |\n|[Understanding Activation Functions in Deep Learning](https://www.learnopencv.com/understanding-activation-functions-in-deep-learning/)      | |\n|[Image Classification using Feedforward Neural Network in Keras](https://www.learnopencv.com/image-classification-using-feedforward-neural-network-in-keras/)      | [Code](https://github.com/kromydas/learnopencv/tree/master/Keras-MLP-MNIST-Classification)|\n|[Exposure Fusion using OpenCV (C++/Python)](https://www.learnopencv.com/exposure-fusion-using-opencv-cpp-python/)      | [Code](https://github.com/spmallick/learnopencv/tree/master/ExposureFusion)|\n|[Understanding Feedforward Neural Networks](https://www.learnopencv.com/understanding-feedforward-neural-networks/)      | |\n|[High Dynamic Range (HDR) Imaging using OpenCV (C++/Python)](http://www.learnopencv.com/high-dynamic-range-hdr-imaging-using-opencv-cpp-python)      | [Code](https://github.com/spmallick/learnopencv/tree/master/hdr)|\n|[Deep learning using Keras ‚Äì The Basics](http://www.learnopencv.com/deep-learning-using-keras-the-basics)      | [Code](https://github.com/kromydas/learnopencv/tree/master/Keras-Linear-Regression)|\n|[Selective Search for Object Detection (C++ / Python)](http://www.learnopencv.com/selective-search-for-object-detection-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/SelectiveSearch) |\n|[Installing Deep Learning Frameworks on Ubuntu with CUDA support](http://www.learnopencv.com/installing-deep-learning-frameworks-on-ubuntu-with-cuda-support/) | |\n|[Parallel Pixel Access in OpenCV using forEach](http://www.learnopencv.com/parallel-pixel-access-in-opencv-using-foreach/) | [Code](https://github.com/spmallick/learnopencv/tree/master/forEach) |\n|[cvui: A GUI lib built on top of OpenCV drawing primitives](http://www.learnopencv.com/cvui-gui-lib-built-on-top-of-opencv-drawing-primitives/) | [Code](https://github.com/spmallick/learnopencv/tree/master/UI-cvui) |\n|[Install Dlib on Windows](http://www.learnopencv.com/install-dlib-on-windows/) | |\n|[Install Dlib on Ubuntu](http://www.learnopencv.com/install-dlib-on-ubuntu/) | |\n|[Install OpenCV3 on Ubuntu](http://www.learnopencv.com/install-opencv3-on-ubuntu/) | |\n|[Read, Write and Display a video using OpenCV ( C++/ Python )](http://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/VideoReadWriteDisplay) |\n|[Install Dlib on MacOS](http://www.learnopencv.com/install-dlib-on-macos/) | |\n|[Install OpenCV 3 on MacOS](http://www.learnopencv.com/install-opencv3-on-macos/) | |\n|[Install OpenCV 3 on Windows](http://www.learnopencv.com/install-opencv3-on-windows/) | |\n|[Get OpenCV Build Information ( getBuildInformation )](http://www.learnopencv.com/get-opencv-build-information-getbuildinformation/) | |\n|[Color spaces in OpenCV (C++ / Python)](http://www.learnopencv.com/color-spaces-in-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ColorSpaces)|\n|[Neural Networks : A 30,000 Feet View for Beginners](http://www.learnopencv.com/neural-networks-a-30000-feet-view-for-beginners/) | |\n|[Alpha Blending using OpenCV (C++ / Python)](http://www.learnopencv.com/alpha-blending-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/AlphaBlending) |\n|[User stories : How readers of this blog are applying their knowledge to build applications](http://www.learnopencv.com/user-stories-how-readers-of-this-blog-are-applying-their-knowledge-to-build-applications/) | |\n|[How to select a bounding box ( ROI ) in OpenCV (C++/Python) ?](http://www.learnopencv.com/how-to-select-a-bounding-box-roi-in-opencv-cpp-python/) | |\n|[Automatic Red Eye Remover using OpenCV (C++ / Python)](http://www.learnopencv.com/automatic-red-eye-remover-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/RedEyeRemover) |\n|[Bias-Variance Tradeoff in Machine Learning](http://www.learnopencv.com/bias-variance-tradeoff-in-machine-learning/) | |\n|[Embedded Computer Vision: Which device should you choose?](http://www.learnopencv.com/embedded-computer-vision-which-device-should-you-choose/) | |\n|[Object Tracking using OpenCV (C++/Python)](http://www.learnopencv.com/object-tracking-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/tracking) |\n|[Handwritten Digits Classification : An OpenCV ( C++ / Python ) Tutorial](http://www.learnopencv.com/handwritten-digits-classification-an-opencv-c-python-tutorial/) | [Code](https://github.com/spmallick/learnopencv/tree/master/digits-classification) |\n|[Training a better Haar and LBP cascade based Eye Detector using OpenCV](http://www.learnopencv.com/training-better-haar-lbp-cascade-eye-detector-opencv/) | |\n|[Deep Learning Book Gift Recipients](http://www.learnopencv.com/deep-learning-book-gift-recipients/) | |\n|[Minified OpenCV Haar and LBP Cascades](http://www.learnopencv.com/minified-opencv-haar-and-lbp-cascades/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ninjaEyeDetector)|\n|[Deep Learning Book Gift](http://www.learnopencv.com/deep-learning-book-gift/) | |\n|[Histogram of Oriented Gradients](http://www.learnopencv.com/histogram-of-oriented-gradients/) | |\n|[Image Recognition and Object Detection : Part 1](http://www.learnopencv.com/image-recognition-and-object-detection-part1/) | |\n|[Head Pose Estimation using OpenCV and Dlib](http://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/) | [Code](https://github.com/spmallick/learnopencv/tree/master/HeadPose) |\n|[Live CV : A Computer Vision Coding Application](http://www.learnopencv.com/live-cv/) | |\n|[Approximate Focal Length for Webcams and Cell Phone Cameras](http://www.learnopencv.com/approximate-focal-length-for-webcams-and-cell-phone-cameras/) | |\n|[Configuring Qt for OpenCV on OSX](http://www.learnopencv.com/configuring-qt-for-opencv-on-osx/) | [Code](https://github.com/spmallick/learnopencv/tree/master/qt-test) |\n|[Rotation Matrix To Euler Angles](http://www.learnopencv.com/rotation-matrix-to-euler-angles/) | [Code](https://github.com/spmallick/learnopencv/tree/master/RotationMatrixToEulerAngles) |\n|[Speeding up Dlib‚Äôs Facial Landmark Detector](http://www.learnopencv.com/speeding-up-dlib-facial-landmark-detector/) | |\n|[Warp one triangle to another using OpenCV ( C++ / Python )](http://www.learnopencv.com/warp-one-triangle-to-another-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/WarpTriangle) |\n|[Average Face : OpenCV ( C++ / Python ) Tutorial](http://www.learnopencv.com/average-face-opencv-c-python-tutorial/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FaceAverage) |\n|[Face Swap using OpenCV ( C++ / Python )](http://www.learnopencv.com/face-swap-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FaceSwap) |\n|[Face Morph Using OpenCV ‚Äî C++ / Python](http://www.learnopencv.com/face-morph-using-opencv-cpp-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FaceMorph) |\n|[Deep Learning Example using NVIDIA DIGITS 3 on EC2](http://www.learnopencv.com/deep-learning-example-using-nvidia-digits-3-on-ec2/) | |\n|[NVIDIA DIGITS 3 on EC2](http://www.learnopencv.com/nvidia-digits-3-on-ec2/) | |\n|[Homography Examples using OpenCV ( Python / C ++ )](http://www.learnopencv.com/homography-examples-using-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Homography) |\n|[Filling holes in an image using OpenCV ( Python / C++ )](http://www.learnopencv.com/filling-holes-in-an-image-using-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Holes) |\n|[How to find frame rate or frames per second (fps) in OpenCV ( Python / C++ ) ?](http://www.learnopencv.com/how-to-find-frame-rate-or-frames-per-second-fps-in-opencv-python-cpp/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FPS) |\n|[Delaunay Triangulation and Voronoi Diagram using OpenCV ( C++ / Python)](http://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Delaunay) |\n|[OpenCV (C++ vs Python) vs MATLAB for Computer Vision](http://www.learnopencv.com/opencv-c-vs-python-vs-matlab-for-computer-vision/) | |\n|[Facial Landmark Detection](http://www.learnopencv.com/facial-landmark-detection/) | |\n|[Why does OpenCV use BGR color format ?](http://www.learnopencv.com/why-does-opencv-use-bgr-color-format/) | |\n|[Computer Vision for Predicting Facial Attractiveness](http://www.learnopencv.com/computer-vision-for-predicting-facial-attractiveness/) | [Code](https://github.com/spmallick/learnopencv/tree/master/FacialAttractiveness) |\n|[applyColorMap for pseudocoloring in OpenCV ( C++ / Python )](http://www.learnopencv.com/applycolormap-for-pseudocoloring-in-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Colormap) |\n|[Image Alignment (ECC) in OpenCV ( C++ / Python )](http://www.learnopencv.com/image-alignment-ecc-in-opencv-c-python/) | [Code](https://github.com/spmallick/learnopencv/tree/master/ImageAlignment) |\n|[How to find OpenCV version in Python and C++ ?](http://www.learnopencv.com/how-to-find-opencv-version-python-cpp/) | |\n|[Baidu banned from ILSVRC 2015](http://www.learnopencv.com/baidu-banned-from-ilsvrc-2015/) | |\n|[OpenCV Transparent API](http://www.learnopencv.com/opencv-transparent-api/) | |\n|[How Computer Vision Solved the Greatest Soccer Mystery of All Time](http://www.learnopencv.com/how-computer-vision-solved-the-greatest-soccer-mystery-of-all-times/) | |\n|[Embedded Vision Summit 2015](http://www.learnopencv.com/embedded-vision-summit-2015/) | |\n|[Read an Image in OpenCV ( Python, C++ )](http://www.learnopencv.com/read-an-image-in-opencv-python-cpp/) | [Code](https://github.com/spmallick/learnopencv/tree/master/imread) |\n|[Non-Photorealistic Rendering using OpenCV ( Python, C++ )](http://www.learnopencv.com/non-photorealistic-rendering-using-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/NonPhotorealisticRendering) |\n|[Seamless Cloning using OpenCV ( Python , C++ )](http://www.learnopencv.com/seamless-cloning-using-opencv-python-cpp/) | [Code](https://github.com/spmallick/learnopencv/tree/master/SeamlessCloning) |\n|[OpenCV Threshold ( Python , C++ )](http://www.learnopencv.com/opencv-threshold-python-cpp/) | [Code](https://github.com/spmallick/learnopencv/tree/master/Threshold) |\n|[Blob Detection Using OpenCV ( Python, C++ )](http://www.learnopencv.com/blob-detection-using-opencv-python-c/) | [Code](https://github.com/spmallick/learnopencv/tree/master/BlobDetector) |\n|[Turn your OpenCV Code into a Web API in under 10 minutes ‚Äî Part 1](http://www.learnopencv.com/turn-your-opencv-Code-into-a-web-api-in-under-10-minutes-part-1/) | |\n|[How to compile OpenCV sample Code ?](http://www.learnopencv.com/how-to-compile-opencv-sample-Code/) | |\n|[Install OpenCV 3 on Yosemite ( OSX 10.10.x )](http://www.learnopencv.com/install-opencv-3-on-yosemite-osx-10-10-x/) | |\n",
         "AI_DataScience"
        ],
        [
         "35",
         "MDEwOlJlcG9zaXRvcnkxMzYyMDI2OTU=",
         "<h1 align=\"center\" style=\"border-bottom: none\">\n    <a href=\"https://mlflow.org/\">\n        <img alt=\"MLflow logo\" src=\"https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/logo.svg\" width=\"200\" />\n    </a>\n</h1>\n<h2 align=\"center\" style=\"border-bottom: none\">Open-Source Platform for Productionizing AI</h2>\n\nMLflow is an open-source developer platform to build AI/LLM applications and models with confidence. Enhance your AI applications with end-to-end **experiment tracking**, **observability**, and **evaluations**, all in one integrated platform.\n\n<div align=\"center\">\n\n[![Python SDK](https://img.shields.io/pypi/v/mlflow)](https://pypi.org/project/mlflow/)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/mlflow)](https://pepy.tech/projects/mlflow)\n[![License](https://img.shields.io/github/license/mlflow/mlflow)](https://github.com/mlflow/mlflow/blob/main/LICENSE)\n<a href=\"https://twitter.com/intent/follow?screen_name=mlflow\" target=\"_blank\">\n<img src=\"https://img.shields.io/twitter/follow/mlflow?logo=X&color=%20%23f5f5f5\"\n      alt=\"follow on X(Twitter)\"></a>\n<a href=\"https://www.linkedin.com/company/mlflow-org/\" target=\"_blank\">\n<img src=\"https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&logoColor=fff\"\n      alt=\"follow on LinkedIn\"></a>\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/mlflow/mlflow)\n\n</div>\n\n<div align=\"center\">\n   <div>\n      <a href=\"https://mlflow.org/\"><strong>Website</strong></a> ¬∑\n      <a href=\"https://mlflow.org/docs/latest/index.html\"><strong>Docs</strong></a> ¬∑\n      <a href=\"https://github.com/mlflow/mlflow/issues/new/choose\"><strong>Feature Request</strong></a> ¬∑\n      <a href=\"https://mlflow.org/blog\"><strong>News</strong></a> ¬∑\n      <a href=\"https://www.youtube.com/@mlflowoss\"><strong>YouTube</strong></a> ¬∑\n      <a href=\"https://lu.ma/mlflow?k=c\"><strong>Events</strong></a>\n   </div>\n</div>\n\n<br>\n\n## üöÄ Installation\n\nTo install the MLflow Python package, run the following command:\n\n```\npip install mlflow\n```\n\n## üì¶ Core Components\n\nMLflow is **the only platform that provides a unified solution for all your AI/ML needs**, including LLMs, Agents, Deep Learning, and traditional machine learning.\n\n### üí° For LLM / GenAI Developers\n\n<table>\n  <tr>\n    <td>\n    <img src=\"https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-tracing.png\" alt=\"Tracing\" width=100%>\n    <div align=\"center\">\n        <br>\n        <a href=\"https://mlflow.org/docs/latest/llms/tracing/index.html\"><strong>üîç Tracing / Observability</strong></a>\n        <br><br>\n        <div>Trace the internal states of your LLM/agentic applications for debugging quality issues and monitoring performance with ease.</div><br>\n        <a href=\"https://mlflow.org/docs/latest/genai/tracing/quickstart/python-openai/\">Getting Started ‚Üí</a>\n        <br><br>\n    </div>\n    </td>\n    <td>\n    <img src=\"https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-llm-eval.png\" alt=\"LLM Evaluation\" width=100%>\n    <div align=\"center\">\n        <br>\n        <a href=\"https://mlflow.org/docs/latest/genai/eval-monitor/\"><strong>üìä LLM Evaluation</strong></a>\n        <br><br>\n        <div>A suite of automated model evaluation tools, seamlessly integrated with experiment tracking to compare across multiple versions.</div><br>\n        <a href=\"https://mlflow.org/docs/latest/genai/eval-monitor/\">Getting Started ‚Üí</a>\n        <br><br>\n    </div>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <img src=\"https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-prompt.png\" alt=\"Prompt Management\">\n    <div align=\"center\">\n        <br>\n        <a href=\"https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-registry/\"><strong>ü§ñ Prompt Management</strong></a>\n        <br><br>\n        <div>Version, track, and reuse prompts across your organization, helping maintain consistency and improve collaboration in prompt development.</div><br>\n        <a href=\"https://mlflow.org/docs/latest/genai/prompt-registry/create-and-edit-prompts/\">Getting Started ‚Üí</a>\n        <br><br>\n    </div>\n    </td>\n    <td>\n      <img src=\"https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-logged-model.png\" alt=\"MLflow Hero\">\n    <div align=\"center\">\n        <br>\n        <a href=\"https://mlflow.org/docs/latest/genai/prompt-version-mgmt/version-tracking/\"><strong>üì¶ App Version Tracking</strong></a>\n        <br><br>\n        <div>MLflow keeps track of many moving parts in your AI applications, such as models, prompts, tools, and code, with end-to-end lineage.</div><br>\n        <a href=\"https://mlflow.org/docs/latest/genai/version-tracking/quickstart/\">Getting Started ‚Üí</a>\n        <br><br>\n    </div>\n    </td>\n  </tr>\n</table>\n\n### üéì For Data Scientists\n\n<table>\n  <tr>\n    <td colspan=\"2\" align=\"center\" >\n      <img src=\"https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-experiment.png\" alt=\"Tracking\" width=50%>\n    <div align=\"center\">\n        <br>\n        <a href=\"https://mlflow.org/docs/latest/ml/tracking/\"><strong>üìù Experiment Tracking</strong></a>\n        <br><br>\n        <div>Track your models, parameters, metrics, and evaluation results in ML experiments and compare them using an interactive UI.</div><br>\n        <a href=\"https://mlflow.org/docs/latest/ml/tracking/quickstart/\">Getting Started ‚Üí</a>\n        <br><br>\n    </div>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      <img src=\"https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-model-registry.png\" alt=\"Model Registry\" width=100%>\n    <div align=\"center\">\n        <br>\n        <a href=\"https://mlflow.org/docs/latest/ml/model-registry/\"><strong>üíæ Model Registry</strong></a>\n        <br><br>\n        <div> A centralized model store designed to collaboratively manage the full lifecycle and deployment of machine learning models.</div><br>\n        <a href=\"https://mlflow.org/docs/latest/ml/model-registry/tutorial/\">Getting Started ‚Üí</a>\n        <br><br>\n    </div>\n    </td>\n    <td>\n      <img src=\"https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-deployment.png\" alt=\"Deployment\" width=100%>\n    <div align=\"center\">\n        <br>\n        <a href=\"https://mlflow.org/docs/latest/ml/deployment/\"><strong>üöÄ Deployment</strong></a>\n        <br><br>\n        <div> Tools for seamless model deployment to batch and real-time scoring on platforms like Docker, Kubernetes, Azure ML, and AWS SageMaker.</div><br>\n        <a href=\"https://mlflow.org/docs/latest/ml/deployment/\">Getting Started ‚Üí</a>\n        <br><br>\n    </div>\n    </td>\n  </tr>\n</table>\n\n## üåê Hosting MLflow Anywhere\n\n<div align=\"center\" >\n  <img src=\"https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-providers.png\" alt=\"Providers\" width=100%>\n</div>\n\nYou can run MLflow in many different environments, including local machines, on-premise servers, and cloud infrastructure.\n\nTrusted by thousands of organizations, MLflow is now offered as a managed service by most major cloud providers:\n\n- [Amazon SageMaker](https://aws.amazon.com/sagemaker-ai/experiments/)\n- [Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow?view=azureml-api-2)\n- [Databricks](https://www.databricks.com/product/managed-mlflow)\n- [Nebius](https://nebius.com/services/managed-mlflow)\n\nFor hosting MLflow on your own infrastructure, please refer to [this guidance](https://mlflow.org/docs/latest/ml/tracking/#tracking-setup).\n\n## üó£Ô∏è Supported Programming Languages\n\n- [Python](https://pypi.org/project/mlflow/)\n- [TypeScript / JavaScript](https://www.npmjs.com/package/mlflow-tracing)\n- [Java](https://mvnrepository.com/artifact/org.mlflow/mlflow-client)\n- [R](https://cran.r-project.org/web/packages/mlflow/readme/README.html)\n\n## üîó Integrations\n\nMLflow is natively integrated with many popular machine learning frameworks and GenAI libraries.\n\n![Integrations](https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-integrations.png)\n\n## Usage Examples\n\n### Experiment Tracking ([Doc](https://mlflow.org/docs/latest/ml/tracking/))\n\nThe following examples trains a simple regression model with scikit-learn, while enabling MLflow's [autologging](https://mlflow.org/docs/latest/tracking/autolog.html) feature for experiment tracking.\n\n```python\nimport mlflow\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Enable MLflow's automatic experiment tracking for scikit-learn\nmlflow.sklearn.autolog()\n\n# Load the training dataset\ndb = load_diabetes()\nX_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n\nrf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n# MLflow triggers logging automatically upon model fitting\nrf.fit(X_train, y_train)\n```\n\nOnce the above code finishes, run the following command in a separate terminal and access the MLflow UI via the printed URL. An MLflow **Run** should be automatically created, which tracks the training dataset, hyper parameters, performance metrics, the trained model, dependencies, and even more.\n\n```\nmlflow ui\n```\n\n### Evaluating Models ([Doc](https://mlflow.org/docs/latest/model-evaluation/index.html))\n\nThe following example runs automatic evaluation for question-answering tasks with several built-in metrics.\n\n```python\nimport mlflow\nimport pandas as pd\n\n# Evaluation set contains (1) input question (2) model outputs (3) ground truth\ndf = pd.DataFrame(\n    {\n        \"inputs\": [\"What is MLflow?\", \"What is Spark?\"],\n        \"outputs\": [\n            \"MLflow is an innovative fully self-driving airship powered by AI.\",\n            \"Sparks is an American pop and rock duo formed in Los Angeles.\",\n        ],\n        \"ground_truth\": [\n            \"MLflow is an open-source platform for productionizing AI.\",\n            \"Apache Spark is an open-source, distributed computing system.\",\n        ],\n    }\n)\neval_dataset = mlflow.data.from_pandas(\n    df, predictions=\"outputs\", targets=\"ground_truth\"\n)\n\n# Start an MLflow Run to record the evaluation results to\nwith mlflow.start_run(run_name=\"evaluate_qa\"):\n    # Run automatic evaluation with a set of built-in metrics for question-answering models\n    results = mlflow.evaluate(\n        data=eval_dataset,\n        model_type=\"question-answering\",\n    )\n\nprint(results.tables[\"eval_results_table\"])\n```\n\n### Observability ([Doc](https://mlflow.org/docs/latest/llms/tracing/index.html))\n\nMLflow Tracing provides LLM observability for various GenAI libraries such as OpenAI, LangChain, LlamaIndex, DSPy, AutoGen, and more. To enable auto-tracing, call `mlflow.xyz.autolog()` before running your models. Refer to the documentation for customization and manual instrumentation.\n\n```python\nimport mlflow\nfrom openai import OpenAI\n\n# Enable tracing for OpenAI\nmlflow.openai.autolog()\n\n# Query OpenAI LLM normally\nresponse = OpenAI().chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[{\"role\": \"user\", \"content\": \"Hi!\"}],\n    temperature=0.1,\n)\n```\n\nThen navigate to the \"Traces\" tab in the MLflow UI to find the trace records OpenAI query.\n\n## üí≠ Support\n\n- For help or questions about MLflow usage (e.g. \"how do I do X?\") visit the [documentation](https://mlflow.org/docs/latest/index.html).\n- In the documentation, you can ask the question to our AI-powered chat bot. Click on the **\"Ask AI\"** button at the right bottom.\n- Join the [virtual events](https://lu.ma/mlflow?k=c) like office hours and meetups.\n- To report a bug, file a documentation issue, or submit a feature request, please [open a GitHub issue](https://github.com/mlflow/mlflow/issues/new/choose).\n- For release announcements and other discussions, please subscribe to our mailing list (mlflow-users@googlegroups.com)\n  or join us on [Slack](https://mlflow.org/slack).\n\n## ü§ù Contributing\n\nWe happily welcome contributions to MLflow!\n\n- Submit [bug reports](https://github.com/mlflow/mlflow/issues/new?template=bug_report_template.yaml) and [feature requests](https://github.com/mlflow/mlflow/issues/new?template=feature_request_template.yaml)\n- Contribute for [good-first-issues](https://github.com/mlflow/mlflow/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) and [help-wanted](https://github.com/mlflow/mlflow/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22)\n- Writing about MLflow and sharing your experience\n\nPlease see our [contribution guide](CONTRIBUTING.md) to learn more about contributing to MLflow.\n\n## ‚≠êÔ∏è Star History\n\n<a href=\"https://star-history.com/#mlflow/mlflow&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=mlflow/mlflow&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=mlflow/mlflow&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=mlflow/mlflow&type=Date\" />\n </picture>\n</a>\n\n## ‚úèÔ∏è Citation\n\nIf you use MLflow in your research, please cite it using the \"Cite this repository\" button at the top of the [GitHub repository page](https://github.com/mlflow/mlflow), which will provide you with citation formats including APA and BibTeX.\n\n## üë• Core Members\n\nMLflow is currently maintained by the following core members with significant contributions from hundreds of exceptionally talented community members.\n\n- [Ben Wilson](https://github.com/BenWilson2)\n- [Corey Zumar](https://github.com/dbczumar)\n- [Daniel Lok](https://github.com/daniellok-db)\n- [Gabriel Fu](https://github.com/gabrielfu)\n- [Harutaka Kawamura](https://github.com/harupy)\n- [Serena Ruan](https://github.com/serena-ruan)\n- [Tomu Hirata](https://github.com/TomeHirata)\n- [Weichen Xu](https://github.com/WeichenXu123)\n- [Yuki Watanabe](https://github.com/B-Step62)\n",
         "AI_DataScience"
        ],
        [
         "36",
         "MDEwOlJlcG9zaXRvcnk2MzQ3NzUxNQ==",
         "# The Algorithms - C # {#mainpage}\n<!-- the suffix in the above line is required for doxygen to consider this as the index page of the generated documentation site -->\n\n[![Gitpod Ready-to-Code](https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/TheAlgorithms/C)\n[![CodeQL CI](https://github.com/TheAlgorithms/C/actions/workflows/codeql.yml/badge.svg)](https://github.com/TheAlgorithms/C/actions/workflows/codeql_analysis.yml)\n[![Gitter chat](https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&logo=gitter&style=flat-square)](https://gitter.im/TheAlgorithms)\n[![contributions welcome](https://img.shields.io/static/v1.svg?label=Contributions&message=Welcome&color=0059b3&style=flat-square)](https://github.com/TheAlgorithms/C/blob/master/CONTRIBUTING.md)\n![GitHub repo size](https://img.shields.io/github/repo-size/TheAlgorithms/C?color=red&style=flat-square)\n[![Doxygen CI](https://github.com/TheAlgorithms/C/workflows/Doxygen%20CI/badge.svg)](https://TheAlgorithms.github.io/C)\n[![Awesome CI](https://github.com/TheAlgorithms/C/workflows/Awesome%20CI%20Workflow/badge.svg)](https://github.com/TheAlgorithms/C/actions?query=workflow%3A%22Awesome+CI+Workflow%22)\n[![Income](https://img.shields.io/liberapay/receives/TheAlgorithms.svg?logo=liberapay)](https://liberapay.com/TheAlgorithms)\n[![Discord chat](https://img.shields.io/discord/808045925556682782.svg?logo=discord&colorB=5865F2)](https://the-algorithms.com/discord/)\n[![Donate](https://liberapay.com/assets/widgets/donate.svg)](https://liberapay.com/TheAlgorithms/donate)\n\n## Overview\n\nThe repository is a collection of open-source implementations of a variety of algorithms implemented in C and licensed under [GPLv3 License](https://github.com/TheAlgorithms/C/blob/master/LICENSE). The algorithms span a variety of topics from computer science, mathematics and statistics, data science, machine learning, engineering, etc.. The implementations and their associated documentations are meant to provide a learning resource for educators and students. Hence, one may find more than one implementation for the same objective but using different algorithm strategies and optimizations.\n\n## Features\n\n* The repository provides implementations of various algorithms in one of the most fundamental general purpose languages - [C](https://en.wikipedia.org/wiki/C_(programming_language)).\n* Well documented source code with detailed explanations provide a valuable resource for educators and students alike.\n* Each source code is atomic using standard C library [`libc`](https://en.wikipedia.org/wiki/C_standard_library) and _no external libraries_ are required for their compilation and execution. Thus the fundamentals of the algorithms can be studied in much depth.\n* Source codes are [compiled and tested](https://github.com/TheAlgorithms/C/actions?query=workflow%3A%22Awesome+CI+Workflow%22) for every commit on the latest versions of two major operating systems viz., MacOS and Ubuntu (Linux) using AppleClang 14.0.0 and GNU 11.3.0 respectively.\n* Strict adherence to [C11](https://en.wikipedia.org/wiki/C11_(C_standard_revision)) standard ensures portability of code to embedded systems as well like ESP32, ARM Cortex, etc. with little to no changes.\n* Self-checks within programs ensure correct implementations with confidence.\n* Modular implementations and OpenSource licensing enable the functions to be utilized conveniently in other applications.\n\n## Documentation\n\n[Online Documentation](https://TheAlgorithms.github.io/C) is generated from the repository source codes directly. The documentation contains all resources including source code snippets, details on execution of the programs, diagrammatic representation of program flow, and links to external resources where necessary.\nClick on [Files menu](https://TheAlgorithms.github.io/C/files.html) to see the list of all the files documented with the code.\n\n[Documentation of Algorithms in C](https://thealgorithms.github.io/C) by [The Algorithms Contributors](https://github.com/TheAlgorithms/C/graphs/contributors) is licensed under [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/?ref=chooser-v1)<br/>\n<a href=\"https://creativecommons.org/licenses/by-sa/4.0\"><img alt=\"Creative Commons License\" style=\"height:22px!important;margin-left: 3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg\" /><img  alt=\"Credit must be given to the creator\" style=\"height:22px!important;margin-left: 3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg\" /><img alt=\"Adaptations must be shared under the same terms\" style=\"height:22px!important;margin-left: 3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg\" /></a>\n\n## Contributions\n\nAs a community developed and maintained repository, we welcome new un-plagiarized quality contributions. Please read our [Contribution Guidelines](https://github.com/TheAlgorithms/C/blob/master/CONTRIBUTING.md).\n",
         "AI_DataScience"
        ],
        [
         "37",
         "MDEwOlJlcG9zaXRvcnkxNDQ4NjM1MjU=",
         "[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)\n[![X](https://img.shields.io/badge/X-%23000000?logo=X&logoColor=white)](https://twitter.com/EthicalML)\n\n# Awesome Production Machine Learning\n\nThis repository contains a curated list of awesome open source libraries that will help you deploy, monitor, version, scale, and secure your production machine learning üöÄ\n\nYou can keep up to date by watching this github repo to get a summary of the new production ML libraries added every month [via releases](https://github.com/EthicalML/awesome-production-machine-learning/releases) ü§©\n\nAdditionally, we provide a [search toolkit](https://huggingface.co/spaces/zhiminy/Awesome-Production-Machine-Learning-Search) that helps you quickly navigate through the toolchain.\n\n## Quick links to sections on this page\n\n| | | |\n|-|-|-|\n| [üîß AutoML](#automl) | [üßÆ Computation & Communication Optimisation](#computation-and-communication-optimisation) | [üè∑Ô∏è Data Annotation & Synthesis](#data-annotation-and-synthesis) |\n| [üßµ Data Pipeline](#data-pipeline) | [üìì Data Science Notebook](#data-science-notebook) | [üíæ Data Storage Optimisation](#data-storage-optimisation) |\n| [üí∏ Data Stream Processing](#data-stream-processing) | [üí™ Deployment & Serving](#deployment-and-serving) | [üìà Evaluation & Monitoring](#evaluation-and-monitoring) |\n| [üîç Explainability & Fairness](#explainability-and-fairness) | [üéÅ Feature Store](#feature-store) | [üî¥ Industry-strength Anomaly Detection](#industry-strength-anomaly-detection) |\n| [üëÅÔ∏è Industry-strength Computer Vision](#industry-strength-computer-vision) | [üî• Industry-strength Information Retrieval](#industry-strength-information-retrieval) | [üî† Industry-strength Natural Language Processing](#industry-strength-nlp) |\n| [üôå Industry-strength Recommender System](#industry-strength-recommender-system) | [üçï Industry-strength Reinforcement Learning](#industry-strength-reinforcement-learning) | [üìä Industry-strength Visualisation](#industry-strength-visualisation) |\n| [üìÖ Metadata Management](#metadata-management) | [üìú Model, Data & Experiment Management](#model-data-and-experiment-management) | [üî© Model Storage Optimisation](#model-storage-optimisation) |\n| [üèÅ Model Training & Orchestration](#model-training-and-orchestration) | [üîè Privacy & Safety](#privacy-and-safety) |\n\n## Contributing to the list\n\nPlease review our [CONTRIBUTING.md](https://github.com/EthicalML/awesome-production-machine-learning/blob/master/CONTRIBUTING.md) requirements when submitting a PR to help us keep the list clean and up-to-date - thank you to the community for supporting its steady growth üöÄ\n\n<picture>\n  <source\n    media=\"(prefers-color-scheme: dark)\"\n    srcset=\"\n      https://api.star-history.com/svg?repos=EthicalML/awesome-production-machine-learning&type=Date&theme=dark\n    \"\n  />\n  <source\n    media=\"(prefers-color-scheme: light)\"\n    srcset=\"\n      https://api.star-history.com/svg?repos=EthicalML/awesome-production-machine-learning&type=Date\n    \"\n  />\n  <img\n    alt=\"Star History Chart\"\n    src=\"https://api.star-history.com/svg?repos=EthicalML/awesome-production-machine-learning&type=Date\"\n  />\n</picture>\n\n## 10 Min Video Overview\n\n<table>\n  <tr>\n    <td width=\"30%\">\n        This <a href=\"https://www.youtube.com/watch?v=Ynb6X0KZKxY\">10 minute video</a> provides an overview of the motivations for machine learning operations as well as a high level overview on some of the tools in this repo. This <a href=\"https://www.youtube.com/watch?v=NycftytgPnk\">newer video</a> covers the an updated 2024 version of the state of MLOps.\n    </td>\n    <td width=\"70%\">\n        <a href=\"https://www.youtube.com/watch?v=Ynb6X0KZKxY\"><img src=\"images/video.png\"></a>\n    </td>\n  </tr>\n</table>\n\n## Want to receive recurrent updates on this repo and other advancements?\n\n<table>\n  <tr>\n    <td width=\"30%\">\n         You can join the <a href=\"https://ethical.institute/mle.html\">Machine Learning Engineer</a> newsletter. Join over 70,000 ML professionals and enthusiasts who receive weekly curated articles & tutorials on production Machine Learning.\n    </td>\n    <td width=\"70%\">\n        <a href=\"https://ethical.institute/mle.html\"><img src=\"images/mleng.png\"></a>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"30%\">\n         Also check out the <a href=\"https://github.com/EthicalML/awesome-production-genai/\">Awesome Production GenAI</a> List, where we aim to map a curated list of awesome open source libraries to deploy, monitor, version and scale your generative artificial intelligence applications and systems.\n    </td>\n    <td width=\"70%\">\n        <a href=\"https://github.com/EthicalML/awesome-production-genai/\"><img src=\"images/list.jpg\"></a>\n    </td>\n  </tr>\n</table>\n\n# Main Content\n\n## AutoML\n* [AutoGluon](https://github.com/autogluon/autogluon) ![](https://img.shields.io/github/stars/autogluon/autogluon.svg?style=social) - Automated feature, model, and hyperparameter selection for tabular, image, and text data on top of popular machine learning libraries (Scikit-Learn, LightGBM, CatBoost, PyTorch, MXNet).\n* [Autokeras](https://github.com/keras-team/autokeras) ![](https://img.shields.io/github/stars/keras-team/autokeras.svg?style=social) - AutoML library for Keras based on [\"Auto-Keras: Efficient Neural Architecture Search with Network Morphism\"](https://arxiv.org/abs/1806.10282).\n* [auto-sklearn](https://github.com/automl/auto-sklearn) ![](https://img.shields.io/github/stars/automl/auto-sklearn.svg?style=social) - Framework to automate algorithm and hyperparameter tuning for sklearn.\n* [EvalML](https://github.com/alteryx/evalml) ![](https://img.shields.io/github/stars/alteryx/evalml.svg?style=social) - EvalML is an AutoML library which builds, optimizes, and evaluates machine learning pipelines using domain-specific objective functions.\n* [Feature Engine](https://github.com/feature-engine/feature_engine) ![](https://img.shields.io/github/stars/feature-engine/feature_engine.svg?style=social) - Feature-engine is a Python library that contains several transformers to engineer features for use in machine learning models.\n* [Featuretools](https://github.com/alteryx/featuretools) ![](https://img.shields.io/github/stars/alteryx/featuretools.svg?style=social) - An open source framework for automated feature engineering.\n* [FLAML](https://github.com/microsoft/FLAML) ![](https://img.shields.io/github/stars/microsoft/FLAML.svg?style=social) - FLAML is a fast library for automated machine learning & tuning.\n* [HEBO](https://github.com/huawei-noah/HEBO) ![](https://img.shields.io/github/stars/huawei-noah/HEBO.svg?style=social) - Set of open-source hyperparameter optimization frameworks, including the winning submission to the [NeurIPS 2020 Black-Box Optimisation Challenge](https://bbochallenge.com/leaderboard) tested on hyperparameter tuning tasks. \n* [Katib](https://github.com/kubeflow/katib) ![](https://img.shields.io/github/stars/kubeflow/katib.svg?style=social) - A Kubernetes-based system for Hyperparameter Tuning and Neural Architecture Search.\n* [keras-tuner](https://github.com/keras-team/keras-tuner) ![](https://img.shields.io/github/stars/keras-team/keras-tuner.svg?style=social) - Keras Tuner is an easy-to-use, distributable hyperparameter optimisation framework that solves the pain points of performing a hyperparameter search. Keras Tuner makes it easy to define a search space and leverage included algorithms to find the best hyperparameter values.\n* [Optuna](https://github.com/optuna/optuna) ![](https://img.shields.io/github/stars/optuna/optuna.svg?style=social) - Optuna is an automatic hyperparameter optimisation software framework, particularly designed for machine learning.\n* [OSS Vizier](https://github.com/google/vizier) ![](https://img.shields.io/github/stars/google/vizier.svg?style=social) - OSS Vizier is a Python-based service for black-box optimisation and research, one of the first hyperparameter tuning services designed to work at scale.\n* [TPOT](https://github.com/epistasislab/tpot) ![](https://img.shields.io/github/stars/epistasislab/tpot.svg?style=social) - Automation of sklearn pipeline creation (including feature selection, pre-processor, etc.).\n* [tsfresh](https://github.com/blue-yonder/tsfresh) ![](https://img.shields.io/github/stars/blue-yonder/tsfresh.svg?style=social) - Automatic extraction of relevant features from time series.\n\n## Computation and Communication Optimisation\n\n* [Accelerate](https://github.com/huggingface/accelerate) ![](https://img.shields.io/github/stars/huggingface/accelerate.svg?style=social) - Accelerate abstracts exactly and only the boilerplate code related to multi-GPU/TPU/mixed-precision and leaves the rest of your code unchanged.\n* [Adapters](https://github.com/adapter-hub/adapters) ![](https://img.shields.io/github/stars/adapter-hub/adapters.svg?style=social) - Adapters is a unified library for parameter-efficient and modular transfer learning.\n* [BitBLAS](https://github.com/microsoft/BitBLAS) ![](https://img.shields.io/github/stars/microsoft/BitBLAS.svg?style=social) - BitBLAS is a library to support mixed-precision BLAS operations on GPUs\n* [Colossal-AI](https://github.com/hpcaitech/ColossalAI) ![](https://img.shields.io/github/stars/hpcaitech/ColossalAI.svg?style=social) - A unified deep learning system for big model era, which helps users to efficiently and quickly deploy large AI model training and inference.\n* [Composer](https://github.com/mosaicml/composer) ![](https://img.shields.io/github/stars/mosaicml/composer.svg?style=social) - Composer is a PyTorch library that enables you to train neural networks faster, at lower cost, and to higher accuracy.\n* [CuDF](https://github.com/rapidsai/cudf) ![](https://img.shields.io/github/stars/rapidsai/cudf.svg?style=social) - Built based on the Apache Arrow columnar memory format, cuDF is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data.\n* [CuML](https://github.com/rapidsai/cuml) ![](https://img.shields.io/github/stars/rapidsai/cuml.svg?style=social) - cuML is a suite of libraries that implement machine learning algorithms and mathematical primitives functions that share compatible APIs with other RAPIDS projects.\n* [CuPy](https://github.com/cupy/cupy) ![](https://img.shields.io/github/stars/cupy/cupy.svg?style=social) - An implementation of NumPy-compatible multi-dimensional array on CUDA. CuPy consists of the core multi-dimensional array class, cupy.ndarray, and many functions on it.\n* [DEAP](https://github.com/DEAP/deap) ![](https://img.shields.io/github/stars/DEAP/deap.svg?style=social) - A novel evolutionary computation framework for rapid prototyping and testing of ideas. It seeks to make algorithms explicit and data structures transparent. It works in perfect harmony with parallelisation mechanisms such as multiprocessing and SCOOP.\n* [DeepEP](https://github.com/deepseek-ai/DeepEP) ![](https://img.shields.io/github/stars/deepseek-ai/DeepEP.svg?style=social) - DeepEP is a communication library tailored for Mixture-of-Experts (MoE) and expert parallelism (EP). It provides high-throughput and low-latency all-to-all GPU kernels, which are also known as MoE dispatch and combine. The library also supports low-precision operations, including FP8.\n* [DGL](https://github.com/dmlc/dgl) ![](https://img.shields.io/github/stars/dmlc/dgl.svg?style=social) - DGL is an easy-to-use, high performance and scalable Python package for deep learning on graphs.\n* [DLRover](https://github.com/intelligent-machine-learning/dlrover) ![](https://img.shields.io/github/stars/intelligent-machine-learning/dlrover.svg?style=social) - DLRover makes the distributed training of large AI models easy, stable, fast and green.\n* [Dask](https://github.com/dask/dask) ![](https://img.shields.io/github/stars/dask/dask.svg?style=social) - Distributed parallel processing framework for Pandas and NumPy computations.\n* [DeepSpeed](https://github.com/deepspeedai/DeepSpeed) ![](https://img.shields.io/github/stars/deepspeedai/DeepSpeed.svg?style=social) - DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.\n* [FlagGems](https://github.com/FlagOpen/FlagGems) ![](https://img.shields.io/github/stars/FlagOpen/FlagGems.svg?style=social) - FlagGems is a high-performance general operator library implemented in OpenAI Triton. It builds on a collection of backend neutral kernels that aims to accelerate LLM training and inference across diverse hardware platforms.\n* [Flashlight](https://github.com/flashlight/flashlight) ![](https://img.shields.io/github/stars/flashlight/flashlight.svg?style=social) - A fast, flexible machine learning library written entirely in C++ from the Facebook AI Research and the creators of Torch, TensorFlow, Eigen and Deep Speech.\n* [Flax](https://github.com/google/flax) ![](https://img.shields.io/github/stars/google/flax.svg?style=social) - A neural network library and ecosystem for JAX designed for flexibility.\n* [GPUStack](https://github.com/gpustack/gpustack) ![](https://img.shields.io/github/stars/gpustack/gpustack.svg?style=social) - GPUStack is an open-source GPU cluster manager for running AI models.\n* [Hivemind](https://github.com/learning-at-home/hivemind) ![](https://img.shields.io/github/stars/learning-at-home/hivemind.svg?style=social) - Decentralized deep learning in PyTorch.\n* [Horovod](https://github.com/horovod/horovod) ![](https://img.shields.io/github/stars/horovod/horovod.svg?style=social) - Uber's distributed training framework for TensorFlow, Keras, and PyTorch.\n* [Jax](https://github.com/jax-ml/jax) ![](https://img.shields.io/github/stars/jax-ml/jax.svg?style=social) - Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more.\n* [Kompute](https://github.com/lava-nc/lava) ![](https://img.shields.io/github/stars/lava-nc/lava.svg?style=social) - Blazing fast, lightweight and mobile phone-enabled Vulkan compute framework optimized for advanced GPU data processing usecases.\n* [Lava](https://github.com/KomputeProject/kompute) ![](https://img.shields.io/github/stars/KomputeProject/kompute.svg?style=social) - Lava is an open source framework to develop applications for neuromorphic hardware architectures.\n* [Liger Kernel](https://github.com/linkedin/Liger-Kernel) ![](https://img.shields.io/github/stars/linkedin/Liger-Kernel.svg?style=social) - Liger Kernel is a collection of Triton kernels designed specifically for LLM training.\n* [LightGBM](https://github.com/microsoft/LightGBM) ![](https://img.shields.io/github/stars/microsoft/LightGBM.svg?style=social) - LightGBM is a gradient boosting framework that uses tree based learning algorithms.\n* [MLX](https://github.com/ml-explore/mlx) ![](https://img.shields.io/github/stars/ml-explore/mlx.svg?style=social) - MLX is an array framework for machine learning on Apple silicon.\n* [Modin](https://github.com/modin-project/modin) ![](https://img.shields.io/github/stars/modin-project/modin.svg?style=social) - Speed up your Pandas workflows by changing a single line of code.\n* [NVIDIA TensorRT](https://github.com/NVIDIA/TensorRT) ![](https://img.shields.io/github/stars/NVIDIA/TensorRT.svg?style=social) - TensorRT is a C++ library for high-performance inference on NVIDIA GPUs and deep learning accelerators.\n* [Nevergrad](https://github.com/facebookresearch/nevergrad) ![](https://img.shields.io/github/stars/facebookresearch/nevergrad.svg?style=social) - Nevergrad is a gradient-free optimisation platform.\n* [Norse](https://github.com/norse/norse) ![](https://img.shields.io/github/stars/norse/norse.svg?style=social) - Norse aims to exploit the advantages of bio-inspired neural components, which are sparse and event-driven - a fundamental difference from artificial neural networks.\n* [Numba](https://github.com/numba/numba) ![](https://img.shields.io/github/stars/numba/numba.svg?style=social)  - A compiler for Python array and numerical functions.\n* [Optimum](https://github.com/huggingface/optimum) ![](https://img.shields.io/github/stars/huggingface/optimum.svg?style=social) - Optimum is an extension of Transformers and Diffusers, providing a set of optimization tools enabling maximum efficiency to train and run models on targeted hardware while keeping things easy to use.\n* [PEFT](https://github.com/huggingface/peft) ![](https://img.shields.io/github/stars/huggingface/peft.svg?style=social) - Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation of pre-trained language models (PLMs) to various downstream applications without fine-tuning all the model's parameters.\n* [PaddlePaddle](https://github.com/PaddlePaddle/Paddle) ![](https://img.shields.io/github/stars/PaddlePaddle/Paddle.svg?style=social) - PaddlePaddle is a framework to perform large-scale deep network training, using data sources distributed across hundreds of nodes. \n* [PyG](https://github.com/pyg-team/pytorch_geometric) ![](https://img.shields.io/github/stars/pyg-team/pytorch_geometric.svg?style=social) - PyG (PyTorch Geometric) is a library built upon PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data.\n* [PyTorch Lightning](https://github.com/Lightning-AI/pytorch-lightning) ![](https://img.shields.io/github/stars/Lightning-AI/pytorch-lightning.svg?style=social) - PyTorch Lightning pretrains, finetunes and deploys AI models on multiple GPUs, TPUs with zero code changes.\n* [PyTorch](https://github.com/pytorch/pytorch) ![](https://img.shields.io/github/stars/pytorch/pytorch.svg?style=social) - PyTorch is a library to develop and train neural network based deep learning models.\n* [Ray](https://github.com/ray-project/ray) ![](https://img.shields.io/github/stars/ray-project/ray.svg?style=social) - Ray is a flexible, high-performance distributed execution framework for machine learning.\n* [SetFit](https://github.com/huggingface/setfit) ![](https://img.shields.io/github/stars/huggingface/setfit.svg?style=social) - SetFit is an efficient and prompt-free framework for few-shot fine-tuning of Sentence Transformers.\n* [Sonnet](https://github.com/google-deepmind/sonnet) ![](https://img.shields.io/github/stars/google-deepmind/sonnet.svg?style=social) - Sonnet is a library built on top of TensorFlow 2 designed to provide simple, composable abstractions for machine learning research.\n* [Streaming](https://github.com/mosaicml/streaming) ![](https://img.shields.io/github/stars/mosaicml/streaming.svg?style=social) - A Data Streaming Library for Efficient Neural Network Training.\n* [TensorFlow](https://github.com/tensorflow/tensorflow) ![](https://img.shields.io/github/stars/tensorflow/tensorflow.svg?style=social) - TensorFlow is a leading library designed for developing and deploying state-of-the-art  machine learning applications.\n* [ThunderKittens](https://github.com/HazyResearch/ThunderKittens) ![](https://img.shields.io/github/stars/HazyResearch/ThunderKittens.svg?style=social) ThunderKittens is a framework to make it easy to write fast deep learning kernels in CUDA.\n* [TorchOpt](https://github.com/metaopt/torchopt) ![](https://img.shields.io/github/stars/metaopt/torchopt.svg?style=social) - TorchOpt is an efficient library for differentiable optimization built upon PyTorch.\n* [Triton](https://github.com/triton-lang/triton) ![](https://img.shields.io/github/stars/triton-lang/triton.svg?style=social) - Triton is a language and compiler for writing highly efficient custom Deep-Learning primitives. The aim of Triton is to provide an open-source environment to write fast code at higher productivity than CUDA, but also with higher flexibility than other existing DSLs.\n* [Vaex](https://github.com/vaexio/vaex) ![](https://img.shields.io/github/stars/vaexio/vaex.svg?style=social) Vaex is a high performance Python library for lazy Out-of-Core DataFrames (similar to Pandas), to visualize and explore big tabular datasets. Vaex uses memory mapping, zero memory copy policy and lazy computations for best performance (no memory wasted).\n* [Vowpal Wabbit](https://github.com/VowpalWabbit/vowpal_wabbit) ![](https://img.shields.io/github/stars/VowpalWabbit/vowpal_wabbit.svg?style=social) Vowpal Wabbit is a machine learning system which pushes the frontier of machine learning with techniques such as online, hashing, allreduce, reductions, learning2search, active, and interactive learning.\n* [XGBoost](https://github.com/dmlc/xgboost) ![](https://img.shields.io/github/stars/dmlc/xgboost.svg?style=social) - XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable.\n* [YDF](https://github.com/google/yggdrasil-decision-forests) ![](https://img.shields.io/github/stars/google/yggdrasil-decision-forests.svg?style=social) - YDF (Yggdrasil Decision Forests) is a library to train, evaluate, interpret, and serve Random Forest, Gradient Boosted Decision Trees, CART and Isolation forest models.\n* [bitsandbytes](https://github.com/bitsandbytes-foundation/bitsandbytes) ![](https://img.shields.io/github/stars/bitsandbytes-foundation/bitsandbytes.svg?style=social) - Bitsandbytes library is a lightweight Python wrapper around CUDA custom functions, in particular 8-bit optimizers, matrix multiplication (LLM.int8()), and 8 & 4-bit quantization functions.\n* [einops](https://github.com/arogozhnikov/einops) ![](https://img.shields.io/github/stars/arogozhnikov/einops.svg?style=social) - Flexible and powerful tensor operations for readable and reliable code.\n* [scikit-learn](https://github.com/scikit-learn/scikit-learn) ![](https://img.shields.io/github/stars/scikit-learn/scikit-learn.svg?style=social) - Scikit-learn is a powerful machine learning library that provides a wide variety of modules for data access, data preparation and statistical model building. \n* [snnTorch](https://github.com/jeshraghian/snntorch) ![](https://img.shields.io/github/stars/jeshraghian/snntorch.svg?style=social) - snnTorch is a deep and online learning library with spiking neural networks.\n* [torchdistill](https://github.com/yoshitomo-matsubara/torchdistill) ![](https://img.shields.io/github/stars/yoshitomo-matsubara/torchdistill.svg?style=social) - torchdistill offers various state-of-the-art knowledge distillation methods and enables you to design (new) experiments simply by editing a declarative yaml config file instead of Python code.\n* [torchkeras](https://github.com/lyhue1991/torchkeras?tab=readme-ov-file) ![](https://img.shields.io/github/stars/lyhue1991/torchkeras?tab=readme-ov-file.svg?style=social) The torchkeras library is a simple tool for training neural network in pytorch jusk in a keras style.\n* [veScale](https://github.com/volcengine/veScale) ![](https://img.shields.io/github/stars/volcengine/veScale.svg?style=social) - veScale is a PyTorch native LLM training framework.\n* [yellowbrick](https://github.com/DistrictDataLabs/yellowbrick) ![](https://img.shields.io/github/stars/DistrictDataLabs/yellowbrick.svg?style=social) - yellowbrick is a matplotlib-based model evaluation plots for scikit-learn and other machine learning libraries.\n\n## Data Annotation and Synthesis\n* [Argilla](https://github.com/argilla-io/argilla) ![](https://img.shields.io/github/stars/argilla-io/argilla.svg?style=social) - Argilla helps domain experts and data teams to build better NLP datasets in less time.\n* [cleanlab](https://github.com/cleanlab/cleanlab) ![](https://img.shields.io/github/stars/cleanlab/cleanlab.svg?style=social) - Python library for data-centric AI. Can automatically: find mislabeled data, detect outliers, estimate consensus + annotator-quality for multi-annotator datasets, suggest which data is best to (re)label next.\n* [COCO Annotator](https://github.com/jsbroks/coco-annotator) ![](https://img.shields.io/github/stars/jsbroks/coco-annotator.svg?style=social) - Web-based image segmentation tool for object detection, localization and keypoints\n* [CVAT](https://github.com/cvat-ai/cvat) ![](https://img.shields.io/github/stars/cvat-ai/cvat.svg?style=social) - CVAT (Computer Vision Annotation Tool) is OpenCV's web-based annotation tool for both videos and images for computer algorithms.\n* [Doccano](https://github.com/doccano/doccano) ![](https://img.shields.io/github/stars/doccano/doccano.svg?style=social) - Open source text annotation tools for humans, providing functionality for sentiment analysis, named entity recognition, and machine translation.\n* [Gretel Synthetics](https://github.com/gretelai/gretel-synthetics) ![](https://img.shields.io/github/stars/gretelai/gretel-synthetics.svg?style=social) - Gretel Synthetics is a synthetic data generators for structured and unstructured text, featuring differentially private learning.\n* [Label Studio](https://github.com/HumanSignal/label-studio) ![](https://img.shields.io/github/stars/HumanSignal/label-studio.svg?style=social) - Multi-domain data labeling and annotation tool with standardized output format.\n* [NeMo Curator](https://github.com/NVIDIA/NeMo-Curator) ![](https://img.shields.io/github/stars/NVIDIA/NeMo-Curator.svg?style=social) - NeMo Curator is a GPU-accelerated framework for efficient large language model data curation.\n* [refinery](https://github.com/code-kern-ai/refinery) ![](https://img.shields.io/github/stars/code-kern-ai/refinery.svg?style=social) - The data scientist's open-source choice to scale, assess and maintain natural language data.\n* [SDV](https://github.com/sdv-dev/SDV) ![](https://img.shields.io/github/stars/sdv-dev/SDV.svg?style=social) - Synthetic Data Vault (SDV) is a Synthetic Data Generation ecosystem of libraries that allows users to easily learn single-table, multi-table and timeseries datasets to later on generate new Synthetic Data that has the same format and statistical properties as the original dataset.\n* [Semantic Segmentation Editor](https://github.com/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor) ![](https://img.shields.io/github/stars/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor.svg?style=social) - Hitachi's Open source tool for labelling camera and LIDAR data.\n* [synthcity](https://github.com/vanderschaarlab/synthcity) ![](https://img.shields.io/github/stars/vanderschaarlab/synthcity.svg?style=social) - synthcity is a library for generating and evaluating synthetic tabular data.\n* [ViPE](https://github.com/nv-tlabs/vipe) ![](https://img.shields.io/github/stars/nv-tlabs/vipe.svg?style=social) - ViPE is a spatial AI tool for annotating camera poses and dense depth maps from raw videos.\n* [YData Synthetic](https://github.com/ydataai/ydata-synthetic) ![](https://img.shields.io/github/stars/ydataai/ydata-synthetic.svg?style=social) - YData Synthetic is a package to generate synthetic tabular and time-series data leveraging the state of the art generative models.\n\n## Data Pipeline\n* [Apache Airflow](https://github.com/apache/airflow) ![](https://img.shields.io/github/stars/apache/airflow.svg?style=social) - Data Pipeline framework built in Python, including scheduler, DAG definition and a UI for visualisation.\n* [Apache Nifi](https://github.com/apache/nifi) ![](https://img.shields.io/github/stars/apache/nifi.svg?style=social) - Apache NiFi was made for dataflow. It supports highly configurable directed graphs of data routing, transformation, and system mediation logic.\n* [Apache Oozie](https://github.com/apache/oozie) ![](https://img.shields.io/github/stars/apache/oozie.svg?style=social) - Workflow scheduler for Hadoop jobs.\n* [Argo Workflows](https://github.com/argoproj/argo-workflows) ![](https://img.shields.io/github/stars/argoproj/argo-workflows.svg?style=social) - Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition).\n* [Couler](https://github.com/couler-proj/couler) ![](https://img.shields.io/github/stars/couler-proj/couler.svg?style=social) - Unified interface for constructing and managing machine learning workflows on different workflow engines, such as Argo Workflows, Tekton Pipelines, and Apache Airflow.\n* [DataTrove](https://github.com/huggingface/datatrove) ![](https://img.shields.io/github/stars/huggingface/datatrove.svg?style=social) - DataTrove is a library to process, filter and deduplicate text data at a very large scale.\n* [Dagster](https://github.com/dagster-io/dagster) ![](https://img.shields.io/github/stars/dagster-io/dagster.svg?style=social) - A data orchestrator for machine learning, analytics, and ETL.\n* [DBT](https://github.com/dbt-labs/dbt-core) ![](https://img.shields.io/github/stars/dbt-labs/dbt-core.svg?style=social) - ETL tool for running transformations inside data warehouses.\n* [Flyte](https://github.com/flyteorg/flyte) ![](https://img.shields.io/github/stars/flyteorg/flyte.svg?style=social) - Lyft‚Äôs Cloud Native Machine Learning and Data Processing Platform - [(Demo)](https://youtu.be/KdUJGSP1h9U?t=1451).\n* [Genie](https://github.com/Netflix/genie) ![](https://img.shields.io/github/stars/Netflix/genie.svg?style=social) - Job orchestration engine to interface and trigger the execution of jobs from Hadoop-based systems.\n* [Hamilton](https://github.com/dagworks-inc/hamilton) ![](https://img.shields.io/github/stars/dagworks-inc/hamilton.svg?style=social) - Hamilton is a micro-orchestration framework for defining dataflows. Runs anywhere python runs (e.g. jupyter, fastAPI, spark, ray, dask). Brings software engineering best practices without you knowing it. Use it to define feature engineering transforms, end-to-end model pipelines, and LLM workflows. It complements macro-orchestration systems (e.g. kedro, luigi, airflow, dbt, etc.) as it replaces the code within those macro tasks. Comes with a self-hostable UI that captures lineage & provenance, execution telemetry & data summaries, and builds a self-populating catalog; usable in development as well as production.\n* [Instill VDP](https://github.com/instill-ai/instill-core) ![](https://img.shields.io/github/stars/instill-ai/instill-core.svg?style=social) - Instill VDP (Versatile Data Pipeline) aims to streamline the data processing pipelines from inception to completion.\n* [Instructor](https://github.com/instructor-ai/instructor) ![](https://img.shields.io/github/stars/instructor-ai/instructor.svg?style=social) - Instructor makes it easy to get structured data like JSON from LLMs like GPT-3.5, GPT-4, GPT-4-Vision, and open-source models.\n* [Kedro](https://github.com/kedro-org/kedro) ![](https://img.shields.io/github/stars/kedro-org/kedro.svg?style=social) - Kedro is a workflow development tool that helps you build data pipelines that are robust, scalable, deployable, reproducible and versioned.\n* [Luigi](https://github.com/spotify/luigi) ![](https://img.shields.io/github/stars/spotify/luigi.svg?style=social) - Luigi is a Python module that helps you build complex pipelines of batch jobs, handling dependency resolution, workflow management, visualisation, etc..\n* [Metaflow](https://github.com/Netflix/metaflow) ![](https://img.shields.io/github/stars/Netflix/metaflow.svg?style=social) - A framework for data scientists to easily build and manage real-life data science projects.\n* [Pachyderm](https://github.com/pachyderm/pachyderm) ![](https://img.shields.io/github/stars/pachyderm/pachyderm.svg?style=social) - Open source distributed processing framework build on Kubernetes focused mainly on dynamic building of production machine learning pipelines - [(Video)](https://www.youtube.com/watch?v=LamKVhe2RSM).\n* [Ploomber](https://github.com/ploomber/ploomber) ![](https://img.shields.io/github/stars/ploomber/ploomber.svg?style=social) - The fastest way to build data pipelines. Develop iteratively, deploy anywhere.\n* [Prefect Core](https://github.com/PrefectHQ/prefect) ![](https://img.shields.io/github/stars/PrefectHQ/prefect.svg?style=social) - Workflow management system that makes it easy to take your data pipelines and add semantics like retries, logging, dynamic mapping, caching, failure notifications, and more.\n* [SeqIO](https://github.com/google/seqio) ![](https://img.shields.io/github/stars/google/seqio.svg?style=social) - SeqIO is a library for processing sequential data to be fed into downstream sequence models.\n* [Snakemake](https://github.com/snakemake/snakemake) ![](https://img.shields.io/github/stars/snakemake/snakemake.svg?style=social) - Workflow management system for reproducible and scalable data analyses.\n* [Towhee](https://github.com/towhee-io/towhee) ![](https://img.shields.io/github/stars/towhee-io/towhee.svg?style=social) - General-purpose machine learning pipeline for generating embedding vectors using one or many ML models.\n* [unstructured](https://github.com/Unstructured-IO/unstructured) ![](https://img.shields.io/github/stars/Unstructured-IO/unstructured.svg?style=social) - unstructured streamlines and optimizes the data processing workflow for LLMs, ingesting and pre-processing images and text documents, such as PDFs, HTML, Word docs, and many more. \n* [ZenML](https://github.com/zenml-io/zenml) ![](https://img.shields.io/github/stars/zenml-io/zenml.svg?style=social) - ZenML is an extensible, open-source MLOps framework to create reproducible ML pipelines with a focus on automated metadata tracking, caching, and many integrations to other tools.\n\n## Data Science Notebook\n* [Apache Zeppelin](https://github.com/apache/zeppelin) ![](https://img.shields.io/github/stars/apache/zeppelin.svg?style=social) - Web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala and more.\n* [Jupyter Notebooks](https://github.com/jupyter/notebook) ![](https://img.shields.io/github/stars/jupyter/notebook.svg?style=social) - Web interface python sandbox environments for reproducible development\n* [Marimo](https://github.com/marimo-team/marimo) ![](https://img.shields.io/github/stars/marimo-team/marimo.svg?style=social) - Reactive Python notebook ‚Äî run reproducible experiments, execute as a script, deploy as an app, and version with git.\n* [.NET Interactive](https://github.com/dotnet/interactive) ![](https://img.shields.io/github/stars/dotnet/interactive.svg?style=social) - .NET Interactive takes the power of .NET and embeds it into your interactive experiences.\n* [Papermill](https://github.com/nteract/papermill) ![](https://img.shields.io/github/stars/nteract/papermill.svg?style=social) - Papermill is a library for parameterizing notebooks and executing them like Python scripts.\n* [Polynote](https://github.com/polynote/polynote) ![](https://img.shields.io/github/stars/polynote/polynote.svg?style=social) - Polynote is an experimental polyglot notebook environment. Currently, it supports Scala and Python (with or without Spark), SQL, and Vega.\n* [RMarkdown](https://github.com/rstudio/rmarkdown) ![](https://img.shields.io/github/stars/rstudio/rmarkdown.svg?style=social) - The rmarkdown package is a next generation implementation of R Markdown based on Pandoc.\n* [Stencila](https://github.com/stencila/stencila) ![](https://img.shields.io/github/stars/stencila/stencila.svg?style=social) - Stencila is a platform for creating, collaborating on, and sharing data driven content. Content that is transparent and reproducible.\n* [Voil√†](https://github.com/voila-dashboards/voila) ![](https://img.shields.io/github/stars/voila-dashboards/voila.svg?style=social) - Voil√† turns Jupyter notebooks into standalone web applications that can e.g. be used as dashboards.\n\n## Data Storage Optimisation\n* [AIStore](https://github.com/NVIDIA/aistore) ![](https://img.shields.io/github/stars/NVIDIA/aistore.svg?style=social) - AIStore is a lightweight object storage system with the capability to linearly scale out with each added storage node and a special focus on petascale deep learning.\n* [Alluxio](https://github.com/Alluxio/alluxio) ![](https://img.shields.io/github/stars/Alluxio/alluxio.svg?style=social) - A virtual distributed storage system that bridges the gab between computation frameworks and storage systems.\n* [Apache Arrow](https://github.com/apache/arrow) ![](https://img.shields.io/github/stars/apache/arrow.svg?style=social) - In-memory columnar representation of data compatible with Pandas, Hadoop-based systems, etc..\n* [Apache Druid](https://github.com/apache/druid) ![](https://img.shields.io/github/stars/apache/druid.svg?style=social) - A high performance real-time analytics database. Check this [article](https://towardsdatascience.com/introduction-to-druid-4bf285b92b5a) for introduction.\n* [Apache Hudi](https://github.com/apache/hudi) ![](https://img.shields.io/github/stars/apache/hudi.svg?style=social) - Hudi is a transactional data lake platform that brings core warehouse and database functionality directly to a data lake. Hudi is great for streaming workloads, and also allows creation of efficient incremental batch pipelines. Supports popular query engines including Spark, Flink, Presto, Trino, Hive, etc. More info [here](https://hudi.apache.org/).\n* [Apache Iceberg](https://github.com/apache/iceberg) ![](https://img.shields.io/github/stars/apache/iceberg.svg?style=social) - Iceberg is an ACID-compliant, high-performance format built for huge analytic tables (containing tens of petabytes of data), and it brings the reliability and simplicity of SQL tables to big data, while making it possible for engines like Spark, Trino, Flink, Presto, Hive and Impala to safely work with the same tables, at the same time. More info [here](https://iceberg.apache.org/).\n* [Apache Ignite](https://github.com/apache/ignite) ![](https://img.shields.io/github/stars/apache/ignite.svg?style=social) - A memory-centric distributed database, caching, and processing platform for transactional, analytical, and streaming workloads delivering in-memory speeds at petabyte scale - [Demo](https://www.youtube.com/watch?v=Xt4PWQ__YPw).\n* [Apache Parquet](https://github.com/apache/parquet-java) ![](https://img.shields.io/github/stars/apache/parquet-java.svg?style=social) - On-disk columnar representation of data compatible with Pandas, Hadoop-based systems, etc..\n* [Apache Pinot](https://github.com/apache/pinot) ![](https://img.shields.io/github/stars/apache/pinot.svg?style=social) - A realtime distributed OLAP datastore. Comparison of the open source OLAP systems for big data: ClickHouse, Druid, and Pinot is found [here](https://medium.com/@leventov/comparison-of-the-open-source-olap-systems-for-big-data-clickhouse-druid-and-pinot-8e042a5ed1c7).\n* [Casibase](https://github.com/casibase/casibase) ![](https://img.shields.io/github/stars/casibase/casibase.svg?style=social) - Casibase is a LangChain-like RAG (Retrieval-Augmented Generation) knowledge database with web UI and Enterprise SSO.\n* [Chroma](https://github.com/chroma-core/chroma) ![](https://img.shields.io/github/stars/chroma-core/chroma.svg?style=social) - Chroma is an open-source embedding database.\n* [ClickHouse](https://github.com/ClickHouse/ClickHouse) ![](https://img.shields.io/github/stars/ClickHouse/ClickHouse.svg?style=social) - ClickHouse is an open source column oriented database management system.\n* [Delta Lake](https://github.com/delta-io/delta) ![](https://img.shields.io/github/stars/delta-io/delta.svg?style=social) - Delta Lake is a storage layer that brings scalable, ACID transactions to Apache Spark and other big-data engines.\n* [EdgeDB](https://github.com/geldata/gel) ![](https://img.shields.io/github/stars/geldata/gel.svg?style=social) - Gel supercharges Postgres with a modern data model, graph queries, Auth & AI solutions, and much more.\n* [GPTCache](https://github.com/zilliztech/GPTCache) ![](https://img.shields.io/github/stars/zilliztech/GPTCache.svg?style=social) - GPTCache is a library for creating semantic cache for large language model queries.\n* [InfluxDB](https://github.com/influxdata/influxdb) ![](https://img.shields.io/github/stars/influxdata/influxdb.svg?style=social) Scalable datastore for metrics, events, and real-time analytics.\n* [Milvus](https://github.com/milvus-io/milvus) ![](https://img.shields.io/github/stars/milvus-io/milvus.svg?style=social) Milvus is a cloud-native, open-source vector database built to manage embedding vectors generated by machine learning models and neural networks.\n* [Marqo](https://github.com/marqo-ai/marqo) ![](https://img.shields.io/github/stars/marqo-ai/marqo.svg?style=social) Marqo is an end-to-end vector search engine.\n* [pgvector](https://github.com/pgvector/pgvector) ![](https://img.shields.io/github/stars/pgvector/pgvector.svg?style=social) pgvector helps with vector similarity search for Postgres.\n* [PostgresML](https://github.com/postgresml/postgresml) ![](https://img.shields.io/github/stars/postgresml/postgresml.svg?style=social) PostgresML is a machine learning extension for PostgreSQL that enables you to perform training and inference on text and tabular data using SQL queries.\n* [Safetensors](https://github.com/huggingface/safetensors) ![](https://img.shields.io/github/stars/huggingface/safetensors.svg?style=social) Simple, safe way to store and distribute tensors.\n* [TimescaleDB](https://github.com/timescale/timescaledb) ![](https://img.shields.io/github/stars/timescale/timescaledb.svg?style=social) An open-source time-series SQL database optimized for fast ingest and complex queries packaged as a PostgreSQL extension - [(Video)](https://www.youtube.com/watch?v=zbjub8BQPyE).\n* [Weaviate](https://github.com/weaviate/weaviate) ![](https://img.shields.io/github/stars/weaviate/weaviate.svg?style=social) - A low-latency vector search engine (GraphQL, RESTful) with out-of-the-box support for different media types. Modules include Semantic Search, Q&A, Classification, Customizable Models (PyTorch/TensorFlow/Keras), and more.\n* [Zarr](https://github.com/zarr-developers/zarr-python) ![](https://img.shields.io/github/stars/zarr-developers/zarr-python.svg?style=social) - Python implementation of chunked, compressed, N-dimensional arrays designed for use in parallel computing.\n\n## Data Stream Processing\n* [Apache Beam](https://github.com/apache/beam) ![](https://img.shields.io/github/stars/apache/beam.svg?style=social) Apache Beam is a unified programming model for Batch and Streaming.\n* [Apache Flink](https://github.com/apache/flink) ![](https://img.shields.io/github/stars/apache/flink.svg?style=social) - Open source stream processing framework with powerful stream and batch processing capabilities.\n* [Apache Kafka](https://github.com/apache/kafka) ![](https://img.shields.io/github/stars/apache/kafka.svg?style=social) - Kafka client library for building applications and microservices where the input and output are stored in kafka clusters.\n* [Apache Samza](https://github.com/apache/samza) ![](https://img.shields.io/github/stars/apache/samza.svg?style=social) - Distributed stream processing framework. It uses Apache Kafka for messaging, and Apache Hadoop YARN to provide fault tolerance, processor isolation, security, and resource management.\n* [Apache Spark](https://github.com/apache/spark) ![](https://img.shields.io/github/stars/apache/spark.svg?style=social) - Micro-batch processing for streams using the apache spark framework as a backend supporting stateful exactly-once semantics.\n* [Bytewax](https://github.com/bytewax/bytewax) ![](https://img.shields.io/github/stars/bytewax/bytewax.svg?style=social) - Flexible Python-centric stateful stream processing framework built on top of Rust engine.\n* [FastStream](https://github.com/airtai/faststream) ![](https://img.shields.io/github/stars/airtai/faststream.svg?style=social) - A modern broker-agnostic streaming Python framework supporting Apache Kafka, RabbitMQ and NATS protocols, inspired by FastAPI and easily integratable with other web frameworks.\n* [MOA](https://github.com/Waikato/moa) ![](https://img.shields.io/github/stars/Waikato/moa.svg?style=social) - MOA (Massive Online Analysis) is an open source framework for Big Data stream mining.\n* [TensorStore](https://github.com/google/tensorstore) ![](https://img.shields.io/github/stars/google/tensorstore.svg?style=social) - Library for reading and writing large multi-dimensional arrays.\n\n## Deployment and Serving\n* [Agenta](https://github.com/Agenta-AI/agenta) ![](https://img.shields.io/github/stars/Agenta-AI/agenta.svg?style=social) - Agenta provides end-to-end tools for the entire LLMOps workflow: building (LLM playground, evaluation), deploying (prompt and configuration management), and  (LLM observability and tracing).\n* [AirLLM](https://github.com/lyogavin/airllm) ![](https://img.shields.io/github/stars/lyogavin/airllm.svg?style=social) - AirLLM optimizes inference memory usage, allowing 70B large language models to run inference on a single 4GB GPU card without quantization, distillation and pruning.\n* [AITemplate](https://github.com/facebookincubator/AITemplate) ![](https://img.shields.io/github/stars/facebookincubator/AITemplate.svg?style=social) - AITemplate (AIT) is a Python framework that transforms deep neural networks into CUDA (NVIDIA GPU) / HIP (AMD GPU) C++ code for lightning-fast inference serving.\n* [BentoML](https://github.com/bentoml/BentoML) ![](https://img.shields.io/github/stars/bentoml/BentoML.svg?style=social) - BentoML is an open source framework for high performance ML model serving.\n* [BISHENG](https://github.com/dataelement/bisheng) ![](https://img.shields.io/github/stars/dataelement/bisheng.svg?style=social) - BISHENG is an open LLM application devops platform, focusing on enterprise scenarios.\n* [DeepDetect](https://github.com/jolibrain/deepdetect) ![](https://img.shields.io/github/stars/jolibrain/deepdetect.svg?style=social) - Machine Learning production server for TensorFlow, XGBoost and Cafe models written in C++ and maintained by Jolibrain.\n* [Dynamo](https://github.com/ai-dynamo/dynamo) ![](https://img.shields.io/github/stars/ai-dynamo/dynamo.svg?style=social) - NVIDIA Dynamo is a high-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.\n* [exo](https://github.com/exo-explore/exo) ![](https://img.shields.io/github/stars/exo-explore/exo.svg?style=social) - exo helps you run your AI cluster at home with everyday devices.\n* [Genkit](https://github.com/firebase/genkit) ![](https://img.shields.io/github/stars/firebase/genkit.svg?style=social) - Genkit is an open source framework for building AI-powered apps with familiar code-centric patterns. Genkit makes it easy to develop, integrate, and test AI features with observability and evaluations.\n* [Inference](https://github.com/roboflow/inference) ![](https://img.shields.io/github/stars/roboflow/inference.svg?style=social) - A fast, production-ready inference server for computer vision supporting deployment of many popular model architectures and fine-tuned models. With Inference, you can deploy models such as YOLOv5, YOLOv8, CLIP, SAM, and CogVLM on your own hardware using Docker.\n* [Infinity](https://github.com/michaelfeil/infinity) ![](https://img.shields.io/github/stars/michaelfeil/infinity.svg?style=social) - Infinity is a high-throughput, low-latency REST API for serving text-embeddings, reranking models and clip. \n* [IPEX-LLM](https://github.com/intel/ipex-llm) ![](https://img.shields.io/github/stars/intel/ipex-llm.svg?style=social) - IPEX-LLM is a PyTorch library for running LLM on Intel CPU and GPU (e.g., local PC with iGPU, discrete GPU such as Arc, Flex and Max) with very low latency.\n* [Jina-serve](https://github.com/jina-ai/serve) ![](https://img.shields.io/github/stars/jina-ai/serve.svg?style=social) - Jina-serve is a framework for building and deploying AI services that communicate via gRPC, HTTP and WebSockets.\n* [Kiln](https://github.com/kiln-ai/kiln) ![](https://img.shields.io/github/stars/kiln-ai/kiln.svg?style=social) - Kiln is an OSS tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.\n* [KServe](https://github.com/kserve/kserve) ![](https://img.shields.io/github/stars/kserve/kserve.svg?style=social) - KServe provides a Kubernetes Custom Resource Definition for serving predictive and generative ML.\n* [KTransformers](https://github.com/kvcache-ai/ktransformers) ![](https://img.shields.io/github/stars/kvcache-ai/ktransformers.svg?style=social) - KTransformers is a flexible framework for experiencing cutting-edge LLM inference optimizations.\n* [Langtrace](https://github.com/Scale3-Labs/langtrace) ![](https://img.shields.io/github/stars/Scale3-Labs/langtrace.svg?style=social) - Langtrace is an open-source, Open Telemetry based end-to-end observability tool for LLM applications, providing real-time tracing, evaluations and metrics for popular LLMs, LLM frameworks, vectorDBs and more.\n* [Lepton AI](https://github.com/leptonai/leptonai) ![](https://img.shields.io/github/stars/leptonai/leptonai.svg?style=social) - LeptonAI Python library allows you to build an AI service from Python code with ease.\n* [LightLLM](https://github.com/ModelTC/lightllm) ![](https://img.shields.io/github/stars/ModelTC/lightllm.svg?style=social) - LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its * [llama.cpp](https://github.com/ggml-org/llama.cpp) ![](https://img.shields.io/github/stars/ggml-org/llama.cpp.svg?style=social) - llama.cpp is an open source software library that performs inference on various large language models such as Llama.\n* [LMDeploy](https://github.com/InternLM/lmdeploy) ![](https://img.shields.io/github/stars/InternLM/lmdeploy.svg?style=social) - LMDeploy is a toolkit for compressing, deploying, and serving LLM.\n* [LM Studio](https://github.com/lmstudio-ai/lms) ![](https://img.shields.io/github/stars/lmstudio-ai/lms.svg?style=social) - LM Studio is a tool for deploying LLM models locally on the computer, even on a relatively modest machine, provided it meets the minimum requirements.\n* [LocalAI](https://github.com/mudler/LocalAI) ![](https://img.shields.io/github/stars/mudler/LocalAI.svg?style=social) - LocalAI is a drop-in replacement REST API that's compatible with OpenAI API specifications for local inferencing.\n* [MindsDB](https://github.com/mindsdb/mindsdb) ![](https://img.shields.io/github/stars/mindsdb/mindsdb.svg?style=social) - MindsDB is the platform to create, serve, and fine-tune models in real-time from your database, vector store, and application data.\n* [MLRun](https://github.com/mlrun/mlrun)![](https://img.shields.io/github/stars/mlrun/mlrun.svg?style=social)- MLRun is an open MLOps framework for quickly building and managing continuous ML and generative AI applications across their lifecycle.\n* [MLServer](https://github.com/SeldonIO/mlserver) ![](https://img.shields.io/github/stars/SeldonIO/mlserver.svg?style=social) - An inference server for your machine learning models, including support for multiple frameworks, multi-model serving and more.\n* [Mosec](https://github.com/mosecorg/mosec) ![](https://img.shields.io/github/stars/mosecorg/mosec.svg?style=social) - A rust-powered and multi-stage pipelined model server which offers dynamic batching and more. Super easy to implement and deploy as micro-services.\n* [Nuclio](https://github.com/nuclio/nuclio) ![](https://img.shields.io/github/stars/nuclio/nuclio.svg?style=social) - A high-performance \"serverless\" framework focused on data, I/O, and compute-intensive workloads. It is well integrated with popular data science tools, such as Jupyter and Kubeflow; supports a variety of data and streaming sources; and supports execution over CPUs and GPUs.\n* [OpenLLM](https://github.com/bentoml/OpenLLM) ![](https://img.shields.io/github/stars/bentoml/OpenLLM.svg?style=social) - OpenLLM allows developers to run any open-source LLMs (Llama 3.1, Qwen2, Phi3 and more) or custom models as OpenAI-compatible APIs with a single command.\n* [OpenVINO](https://github.com/openvinotoolkit/openvino) ![](https://img.shields.io/github/stars/openvinotoolkit/openvino.svg?style=social) - OpenVINO is an open-source toolkit for optimizing and deploying AI inference.\n* [Open WebUI](https://github.com/open-webui/open-webui) ![](https://img.shields.io/github/stars/open-webui/open-webui.svg?style=social) - Open WebUI is an extensible, feature-rich, and user-friendly self-hosted AI platform designed to operate entirely offline. It supports various LLM runners like Ollama and OpenAI-compatible APIs, with built-in inference engine for RAG, making it a powerful AI deployment solution.\n* [PowerInfer](https://github.com/SJTU-IPADS/PowerInfer) ![](https://img.shields.io/github/stars/SJTU-IPADS/PowerInfer.svg?style=social) - PowerInfer is a CPU/GPU LLM inference engine leveraging activation locality for your device.\n* [Prompt2Model](https://github.com/neulab/prompt2model) ![](https://img.shields.io/github/stars/neulab/prompt2model.svg?style=social) - Prompt2Model is a system that takes a natural language task description (like the prompts used for LLMs such as ChatGPT) to train a small special-purpose model that is conducive for deployment.\n* [Seldon Core](https://github.com/SeldonIO/seldon-core) ![](https://img.shields.io/github/stars/SeldonIO/seldon-core.svg?style=social) - Open source platform for deploying and  machine learning models in Kubernetes - [(Video)](https://www.youtube.com/watch?v=pDlapGtecbY).\n* [SGLang](https://github.com/sgl-project/sglang) ![](https://img.shields.io/github/stars/sgl-project/sglang.svg?style=social) - SGLang is a fast serving framework for large language models and vision language models.\n* [SkyPilot](https://github.com/skypilot-org/skypilot) ![](https://img.shields.io/github/stars/skypilot-org/skypilot.svg?style=social) - SkyPilot is a framework for running LLMs, AI, and batch jobs on any cloud, offering maximum cost savings, highest GPU availability, and managed execution.\n* [Tensorflow Serving](https://github.com/tensorflow/serving) ![](https://img.shields.io/github/stars/tensorflow/serving.svg?style=social) - High-performant framework to serve Tensorflow models via grpc protocol able to handle 100k requests per second per core.\n* [text-generation-inference](https://github.com/huggingface/text-generation-inference) ![](https://img.shields.io/github/stars/huggingface/text-generation-inference.svg?style=social) - Large Language Model Text Generation Inference.\n* [TorchServe](https://github.com/pytorch/serve) ![](https://img.shields.io/github/stars/pytorch/serve.svg?style=social) - TorchServe is a flexible and easy to use tool for serving PyTorch models.\n* [Transformer Lab](https://github.com/transformerlab/transformerlab-app) ![](https://img.shields.io/github/stars/transformerlab/transformerlab-app.svg?style=social) - Transformer Lab is an open-source LLM workspace for finetuning, evaluating, exporting, and testing models locally across inference engines and platforms.\n* [Triton Inference Server](https://github.com/triton-inference-server/server) ![](https://img.shields.io/github/stars/triton-inference-server/server.svg?style=social) - Triton is a high performance open source serving software to deploy AI models from any framework on GPU & CPU while maximizing utilization.\n* [Vercel AI](https://github.com/vercel/ai) ![](https://img.shields.io/github/stars/vercel/ai.svg?style=social) - Vercel AI is a TypeScript toolkit designed to help you build AI-powered applications using popular frameworks like Next.js, React, Svelte, Vue and runtimes like Node.js.\n* [Vespa](https://github.com/vespa-engine/vespa) ![](https://img.shields.io/github/stars/vespa-engine/vespa.svg?style=social) - Search, make inferences in and organize vectors, tensors, text and structured data, at serving time and any scale.\n* [vLLM](https://github.com/vllm-project/vllm) ![](https://img.shields.io/github/stars/vllm-project/vllm.svg?style=social) - vLLM is a high-throughput and memory-efficient inference and serving engine for LLMs.\n\n## Evaluation and Monitoring\n* [AlpacaEval](https://github.com/tatsu-lab/alpaca_eval) ![](https://img.shields.io/github/stars/tatsu-lab/alpaca_eval.svg?style=social) - AlpacaEval is an automatic evaluator for instruction-following language models.\n* [ANN-Benchmarks](https://github.com/erikbern/ann-benchmarks) ![](https://img.shields.io/github/stars/erikbern/ann-benchmarks.svg?style=social) - ANN-Benchmarks is a benchmarking environment for approximate nearest neighbor algorithms search.\n* [ARES](https://github.com/stanford-futuredata/ARES) ![](https://img.shields.io/github/stars/stanford-futuredata/ARES.svg?style=social) - ARES is a framework for automatically evaluating Retrieval-Augmented Generation (RAG) models.\n* [BEIR](https://github.com/beir-cellar/beir) ![](https://img.shields.io/github/stars/beir-cellar/beir.svg?style=social) - BEIR is a heterogeneous benchmark containing diverse IR tasks. It also provides a common and easy framework for evaluation of your NLP-based retrieval models within the benchmark.\n* [Code Generation LM Evaluation Harness](https://github.com/bigcode-project/bigcode-evaluation-harness) ![](https://img.shields.io/github/stars/bigcode-project/bigcode-evaluation-harness.svg?style=social) - Code Generation LM Evaluation Harness is a framework for the evaluation of code generation models.\n* [COMET](https://github.com/Unbabel/COMET) ![](https://img.shields.io/github/stars/Unbabel/COMET.svg?style=social) - COMET is an open-source framework for machine learning evaluation.\n* [Deepchecks](https://github.com/deepchecks/deepchecks) ![](https://img.shields.io/github/stars/deepchecks/deepchecks.svg?style=social) - Deepchecks is a holistic open-source solution for all of your AI & ML validation needs, enabling you to test your data and models from research to production thoroughly.\n* [DeepEval](https://github.com/confident-ai/deepeval) ![](https://img.shields.io/github/stars/confident-ai/deepeval.svg?style=social) - DeepEval is a simple-to-use, open-source evaluation framework for LLM applications.\n* [DomainBed](https://github.com/facebookresearch/DomainBed) ![](https://img.shields.io/github/stars/facebookresearch/DomainBed.svg?style=social) - DomainBed is a test suite containing benchmark datasets and algorithms for domain generalization\n* [EvalAI](https://github.com/Cloud-CV/EvalAI) ![](https://img.shields.io/github/stars/Cloud-CV/EvalAI.svg?style=social) - EvalAI is an open-source platform for evaluating and comparing AI algorithms at scale.\n* [EvalPlus](https://github.com/evalplus/evalplus) ![](https://img.shields.io/github/stars/evalplus/evalplus.svg?style=social) - EvalPlus is a robust evaluation framework for LLM4Code, featuring expanded HumanEval+ and MBPP+ benchmarks, efficiency assessment (EvalPerf), and a secure, extensible evaluation toolkit.\n* [Evals](https://github.com/openai/evals) ![](https://img.shields.io/github/stars/openai/evals.svg?style=social) - Evals is a framework for evaluating OpenAI models and an open-source registry of benchmarks.\n* [EvalScope](https://github.com/modelscope/evalscope) ![](https://img.shields.io/github/stars/modelscope/evalscope.svg?style=social) - EvalScope is a streamlined and customizable framework for efficient large model evaluation and performance benchmarking.\n* [Evaluate](https://github.com/huggingface/evaluate) ![](https://img.shields.io/github/stars/huggingface/evaluate.svg?style=social) - Evaluate is a library that makes evaluating and comparing models and reporting their performance easier and more standardized.\n* [Evidently](https://github.com/evidentlyai/evidently) ![](https://img.shields.io/github/stars/evidentlyai/evidently.svg?style=social) - Evidently is an open-source framework to evaluate, test and monitor ML and LLM-powered systems.\n* [GAOKAO-Bench](https://github.com/OpenLMLab/GAOKAO-Bench) ![](https://img.shields.io/github/stars/OpenLMLab/GAOKAO-Bench.svg?style=social) - GAOKAO-Bench is an evaluation framework that uses Chinese National College Entrance Examination (GAOKAO) questions as a dataset to assess large models' language comprehension and logical reasoning abilities.\n* [Giskard](https://github.com/Giskard-AI/giskard)![](https://img.shields.io/github/stars/Giskard-AI/giskard.svg?style=social) - Giskard is an open-source Python library that automatically detects performance, bias & security issues in AI applications.\n* [HumanEval](https://github.com/openai/human-eval)![](https://img.shields.io/github/stars/openai/human-eval.svg?style=social) - HumanEval is a benchmark for evaluating the functional correctness of code generation models using Python programming problems with unit tests.\n* [Helicone](https://github.com/Helicone/helicone) ![](https://img.shields.io/github/stars/Helicone/helicone.svg?style=social) - Helicone is the all-in-one, open-source LLM developer platform.\n* [HELM](https://github.com/stanford-crfm/helm) ![](https://img.shields.io/github/stars/stanford-crfm/helm.svg?style=social) - HELM (Holistic Evaluation of Language Models) provides tools for the holistic evaluation of language models, including standardized datasets, a unified API for various models, diverse metrics, r, and fairness perturbations, a prompt construction framework, and a proxy server for unified model access.\n* [Inspect](https://github.com/UKGovernmentBEIS/inspect_ai) ![](https://img.shields.io/github/stars/UKGovernmentBEIS/inspect_ai.svg?style=social) - Inspect is a framework for large language model evaluations.\n* [JiWER](https://github.com/jitsi/jiwer) ![](https://img.shields.io/github/stars/jitsi/jiwer.svg?style=social) - JiWER is a simple and fast python package to evaluate an automatic speech recognition system. \n* [Laminar](https://github.com/lmnr-ai/lmnr) ![](https://img.shields.io/github/stars/lmnr-ai/lmnr.svg?style=social) - Laminar is an open-source platform to trace, evaluate, label, and analyze LLM data for AI products.\n* [Langfuse](https://github.com/langfuse/langfuse) ![](https://img.shields.io/github/stars/langfuse/langfuse.svg?style=social) - Langfuse is an observability & analytics solution for LLM-based applications.\n* [LangTest](https://github.com/JohnSnowLabs/langtest) ![](https://img.shields.io/github/stars/JohnSnowLabs/langtest.svg?style=social) - LangTest is a comprehensive evaluation toolkit for NLP models.\n* [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness) ![](https://img.shields.io/github/stars/EleutherAI/lm-evaluation-harness.svg?style=social) - Language Model Evaluation Harness is a framework to test generative language models on a large number of different evaluation tasks.\n* [LangWatch](https://github.com/langwatch/langwatch) ![](https://img.shields.io/github/stars/langwatch/langwatch.svg?style=social) - LangWatch is a visual interface for DSPy and a complete LLM Ops platform for monitoring, experimenting, measuring and improving LLM pipelines, with a fair-code distribution model.\n* [LightEval](https://github.com/huggingface/lighteval) ![](https://img.shields.io/github/stars/huggingface/lighteval.svg?style=social) - LightEval is a lightweight LLM evaluation suite.\n* [LLMonitor](https://github.com/lunary-ai/lunary) ![](https://img.shields.io/github/stars/lunary-ai/lunary.svg?style=social) - LLMonitor is an observability & analytics for AI apps and agents.\n* [LLMPerf](https://github.com/ray-project/llmperf) ![](https://img.shields.io/github/stars/ray-project/llmperf.svg?style=social) - LLMPerf is a tool for evaluating the performance of LLM APIs.\n* [lmms-eval](https://github.com/EvolvingLMMs-Lab/lmms-eval) ![](https://img.shields.io/github/stars/EvolvingLMMs-Lab/lmms-eval.svg?style=social) - lmms-eval is an evaluation framework meticulously crafted for consistent and efficient evaluation of LMM.\n* [Melting Pot](https://github.com/google-deepmind/meltingpot) ![](https://img.shields.io/github/stars/google-deepmind/meltingpot.svg?style=social) - Melting Pot is a suite of test scenarios for multi-agent reinforcement learning.\n* [Meta-World](https://github.com/Farama-Foundation/Metaworld) ![](https://img.shields.io/github/stars/Farama-Foundation/Metaworld.svg?style=social) - Meta-World is an open-source simulated benchmark for meta-reinforcement learning and multi-task learning consisting of 50 distinct robotic manipulation tasks.\n* [mir_eval](https://github.com/mir-evaluation/mir_eval) ![](https://img.shields.io/github/stars/mir-evaluation/mir_eval.svg?style=social) - mir_eval is a Python library which provides a transparent, standardized, and straightforward way to evaluate Music Information Retrieval systems.\n* [MLPerf Inference](https://github.com/mlcommons/inference) ![](https://img.shields.io/github/stars/mlcommons/inference.svg?style=social) - MLPerf Inference is a benchmark suite for measuring how fast systems can run models in a variety of deployment scenarios.\n* [Massive Text Embedding Benchmark](https://github.com/mlcommons/inference) ![](https://img.shields.io/github/stars/mlcommons/inference.svg?style=social) - Massive Text Embedding Benchmark (MTEB) is a comprehensive evaluation framework that assesses the performance of text embedding models across diverse tasks and languages, encompassing 8 embedding tasks, 58 datasets, and 112 languages.\n* [NannyML](https://github.com/NannyML/nannyml) ![](https://img.shields.io/github/stars/NannyML/nannyml.svg?style=social) - NannyML is a library that allows you to estimate post-deployment model performance (without access to targets), detect data drift, and intelligently link data drift alerts back to changes in model performance.\n* [OGB](https://github.com/snap-stanford/ogb) ![](https://img.shields.io/github/stars/snap-stanford/ogb.svg?style=social) - The Open Graph Benchmark (OGB) is a collection of benchmark datasets, data loaders, and evaluators for graph machine learning.\n* [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) ![](https://img.shields.io/github/stars/dezoito/ollama-grid-search.svg?style=social) - Ollama Grid Search automates the process of selecting the best models, prompts, or inference parameters for a given use-case, allowing you to iterate over their combinations and to visually inspect the results.\n* [OpenCompass](https://github.com/open-compass/OpenCompass) ![](https://img.shields.io/github/stars/open-compass/OpenCompass.svg?style=social) - OpenCompass is an LLM evaluation platform, supporting a wide range of models (LLaMA, LLaMa2, ChatGLM2, ChatGPT, Claude, etc) over 50+ datasets.\n* [OpenLIT](https://github.com/openlit/openlit) ![](https://img.shields.io/github/stars/openlit/openlit.svg?style=social) - OpenLIT is an open-source AI engineering platform that simplifies LLM workflows with observability, monitoring, guardrails, evaluations, and seamless integrations. \n* [OpenLLMetry](https://github.com/traceloop/openllmetry) ![](https://img.shields.io/github/stars/traceloop/openllmetry.svg?style=social) - OpenLLMetry provides developers with deep visibility into Large Language Model applications through performance monitoring, execution tracing, and debugging capabilities.\n* [Opik](https://github.com/comet-ml/opik) ![](https://img.shields.io/github/stars/comet-ml/opik.svg?style=social) - Opik is an open-source platform for evaluating, testing and monitoring LLM applications.\n* [Overcooked-AI](https://github.com/HumanCompatibleAI/overcooked_ai) ![](https://img.shields.io/github/stars/HumanCompatibleAI/overcooked_ai.svg?style=social) - Overcooked-AI is a benchmark environment for fully cooperative human-AI task performance, based on the wildly popular video game Overcooked.\n* [Phoenix](https://github.com/Arize-ai/phoenix) ![](https://img.shields.io/github/stars/Arize-ai/phoenix.svg?style=social) - Phoenix is an open-source AI observability platform designed for experimentation, evaluation, and troubleshooting.\n* [PromptBench](https://github.com/microsoft/promptbench) ![](https://img.shields.io/github/stars/microsoft/promptbench.svg?style=social) - PromptBench is a unified evaluation framework for large language models\n* [Prometheus-Eval](https://github.com/prometheus-eval/prometheus-eval) ![](https://img.shields.io/github/stars/prometheus-eval/prometheus-eval.svg?style=social) - RagaAI Catalyst is a comprehensive platform designed to enhance the management and optimization of LLM projects. \n* [RagaAI Catalyst](https://github.com/raga-ai-hub/RagaAI-Catalyst) ![](https://img.shields.io/github/stars/raga-ai-hub/RagaAI-Catalyst.svg?style=social) - Prometheus-Eval is a collection of tools for training, evaluating, and using language models specialized in evaluating other language models.\n* [Ragas](https://github.com/explodinggradients/ragas) ![](https://img.shields.io/github/stars/explodinggradients/ragas.svg?style=social) - Ragas is a framework to evaluate RAG pipelines.\n* [RAGChecker](https://github.com/amazon-science/RAGChecker) ![](https://img.shields.io/github/stars/amazon-science/RAGChecker.svg?style=social) - RAGChecker is an advanced automatic evaluation framework designed to assess and diagnose Retrieval-Augmented Generation (RAG) systems.\n* [RewardBench](https://github.com/allenai/reward-bench) ![](https://img.shields.io/github/stars/allenai/reward-bench.svg?style=social) - RewardBench is a benchmark designed to evaluate the capabilities and safety of reward models.\n* [RLBench](https://github.com/stepjam/RLBench) ![](https://img.shields.io/github/stars/stepjam/RLBench.svg?style=social) - RLBench is an ambitious large-scale benchmark and learning environment designed to facilitate research in a number of vision-guided manipulation research areas, including: reinforcement learning, imitation learning, multi-task learning, geometric computer vision, and in particular, few-shot learning.\n* [SimplerEnv](https://github.com/simpler-env/SimplerEnv) ![](https://img.shields.io/github/stars/simpler-env/SimplerEnv.svg?style=social) - SimplerEnv is a simulated manipulation policy evaluation environments for real robot setups.\n* [SwanLab](https://github.com/SwanHubX/SwanLab) ![](https://img.shields.io/github/stars/SwanHubX/SwanLab.svg?style=social) - SwanLab is an AI training tracking and visualization tool.\n* [Speech-to-Text Benchmark](https://github.com/Picovoice/speech-to-text-benchmark) ![](https://img.shields.io/github/stars/Picovoice/speech-to-text-benchmark.svg?style=social) - Speech-to-Text Benchmark is a minimalist and extensible framework for benchmarking different speech-to-text engines.\n* [TensorFlow Model Analysis](https://github.com/tensorflow/model-analysis) ![](https://img.shields.io/github/stars/tensorflow/model-analysis.svg?style=social) - TensorFlow Model Analysis (TFMA) is a library for evaluating TensorFlow models on large amounts of data in a distributed manner, using the same metrics defined in their trainer.\n* [TorchBench](https://github.com/pytorch/benchmark) ![](https://img.shields.io/github/stars/pytorch/benchmark.svg?style=social) - TorchBench is a collection of open source benchmarks used to evaluate PyTorch performance.\n* [TruLens](https://github.com/truera/trulens) ![](https://img.shields.io/github/stars/truera/trulens.svg?style=social) - TruLens provides a set of tools for evaluating and tracking LLM experiments.\n* [TrustLLM](https://github.com/HowieHwong/TrustLLM) ![](https://img.shields.io/github/stars/HowieHwong/TrustLLM.svg?style=social) - TrustLLM is a comprehensive framework to evaluate the trustworthiness of large language models, which includes principles, surveys, and benchmarks.\n* [VBench](https://github.com/Vchitect/VBench) ![](https://img.shields.io/github/stars/Vchitect/VBench.svg?style=social) - VBench is a comprehensive benchmark suite for video generative models.\n* [VLMEvalKit](https://github.com/open-compass/VLMEvalKit) ![](https://img.shields.io/github/stars/open-compass/VLMEvalKit.svg?style=social) - VLMEvalKit is an open-source evaluation toolkit of large vision-language models (LVLMs).\n\n## Explainability and Fairness\n* [Aequitas](https://github.com/dssg/aequitas) ![](https://img.shields.io/github/stars/dssg/aequitas.svg?style=social) - An open-source bias audit toolkit for data scientists, machine learning researchers, and policymakers to audit machine learning models for discrimination and bias, and to make informed and equitable decisions around developing and deploying predictive risk-assessment tools.\n* [AI Explainability 360](https://github.com/Trusted-AI/AIX360) ![](https://img.shields.io/github/stars/Trusted-AI/AIX360.svg?style=social) - Interpretability and explainability of data and machine learning models including a comprehensive set of algorithms that cover different dimensions of explanations along with proxy explainability metrics.\n* [AI Fairness 360](https://github.com/Trusted-AI/AIF360) ![](https://img.shields.io/github/stars/Trusted-AI/AIF360.svg?style=social) - A comprehensive set of fairness metrics for datasets and machine learning models, explanations for these metrics, and algorithms to mitigate bias in datasets and models.\n* [Alibi](https://github.com/SeldonIO/alibi) ![](https://img.shields.io/github/stars/SeldonIO/alibi.svg?style=social) - Alibi is an open source Python library aimed at machine learning model inspection and interpretation. The initial focus on the library is on black-box, instance based model explanations.\n* [captum](https://github.com/pytorch/captum) ![](https://img.shields.io/github/stars/pytorch/captum.svg?style=social) - model interpretability and understanding library for PyTorch developed by Facebook. It contains general purpose implementations of integrated gradients, saliency maps, smoothgrad, vargrad and others for PyTorch models.\n* [Fairlearn](https://github.com/fairlearn/fairlearn) ![](https://img.shields.io/github/stars/fairlearn/fairlearn.svg?style=social) - Fairlearn is a python toolkit to assess and mitigate unfairness in machine learning models.\n* [InterpretML](https://github.com/interpretml/interpret) ![](https://img.shields.io/github/stars/interpretml/interpret.svg?style=social) - InterpretML is an open-source package for training interpretable models and explaining blackbox systems.\n* [Lightly](https://github.com/lightly-ai/lightly) ![](https://img.shields.io/github/stars/lightly-ai/lightly.svg?style=social) - A python framework for self-supervised learning on images. The learned representations can be used to analyze the distribution in unlabeled data and rebalance datasets.\n* [LOFO Importance](https://github.com/aerdem4/lofo-importance) ![](https://img.shields.io/github/stars/aerdem4/lofo-importance.svg?style=social) - LOFO (Leave One Feature Out) Importance calculates the importances of a set of features based on a metric of choice, for a model of choice, by iteratively removing each feature from the set, and evaluating the performance of the model, with a validation scheme of choice, based on the chosen metric.\n* [mljar-supervised](https://github.com/mljar/mljar-supervised) ![](https://img.shields.io/github/stars/mljar/mljar-supervised.svg?style=social) - A Python package for AutoML on tabular data with feature engineering, hyper-parameters tuning, explanations and automatic documentation.\n* [Quantus](https://github.com/understandable-machine-intelligence-lab/Quantus) ![](https://img.shields.io/github/stars/understandable-machine-intelligence-lab/Quantus.svg?style=social) - Quantus is an eXplainable AI toolkit for responsible evaluation of neural network explanations\n* [SHAP](https://github.com/shap/shap) ![](https://img.shields.io/github/stars/shap/shap.svg?style=social) - SHapley Additive exPlanations is a unified approach to explain the output of any machine learning model.\n* [SHAPash](https://github.com/MAIF/shapash) ![](https://img.shields.io/github/stars/MAIF/shapash.svg?style=social) - Shapash is a Python library that provides several types of visualization that display explicit labels that everyone can understand.\n* [WhatIf](https://github.com/pair-code/what-if-tool) ![](https://img.shields.io/github/stars/pair-code/what-if-tool.svg?style=social) - An easy-to-use interface for expanding understanding of a black-box classification or regression ML model.\n\n## Feature Store\n* [FEAST](https://github.com/feast-dev/feast)  ![](https://img.shields.io/github/stars/feast-dev/feast.svg?style=social) - Feast (Feature Store) is an open source feature store for machine learning. Feast is the fastest path to manage existing infrastructure to productionize analytic data for model training and online inference.\n* [Featureform](https://github.com/featureform/featureform) ![](https://img.shields.io/github/stars/featureform/featureform.svg?style=social) - A virtual featurestore. Plug-&-play with your existing infra. Data Scientist approved. Discovery, Governance, Lineage, & Collaboration just a pip install away. Supports pandas, Python, spark, SQL + integrations with major cloud vendors. \n* [Hopsworks Feature Store](https://github.com/logicalclocks/hopsworks) ![](https://img.shields.io/github/stars/logicalclocks/hopsworks.svg?style=social) - Offline/Online Feature Store for ML [(Video)](https://www.youtube.com/watch?v=N1BjPk1smdg).\n\n## Industry-strength Anomaly Detection\n* [Alibi Detect](https://github.com/SeldonIO/alibi-detect) ![](https://img.shields.io/github/stars/SeldonIO/alibi-detect.svg?style=social) - alibi-detect is a Python package focused on outlier, adversarial and concept drift detection.\n* [Darts](https://github.com/unit8co/darts) ![](https://img.shields.io/github/stars/unit8co/darts.svg?style=social) - Darts is a library for user-friendly forecasting and anomaly detection on time series.\n* [Deequ](https://github.com/awslabs/deequ) ![](https://img.shields.io/github/stars/awslabs/deequ.svg?style=social) - A library built on top of Apache Spark for defining \"unit tests for data\", which measure data quality in large datasets.\n* [PyOD](https://github.com/yzhao062/pyod) ![](https://img.shields.io/github/stars/yzhao062/pyod.svg?style=social) - A Python Toolbox for Scalable Outlier Detection (Anomaly Detection).\n* [TFDV](https://github.com/tensorflow/data-validation) ![](https://img.shields.io/github/stars/tensorflow/data-validation.svg?style=social) - TFDV (Tensorflow Data Validation) is a library for exploring and validating machine learning data.\n\n## Industry Strength Computer Vision\n* [Deep Lake](https://github.com/activeloopai/deeplake) ![](https://img.shields.io/github/stars/activeloopai/deeplake.svg?style=social) - Deep Lake is a data infrastructure optimized for computer vision.\n* [Detectron2](https://github.com/facebookresearch/detectron2) ![](https://img.shields.io/github/stars/facebookresearch/detectron2.svg?style=social) - Detectron2 is Facebook AI Research's next generation library that provides state-of-the-art detection and segmentation algorithms.\n* [KerasCV](https://github.com/keras-team/keras-cv) ![](https://img.shields.io/github/stars/keras-team/keras-cv.svg?style=social) - KerasCV is a library of modular computer vision oriented Keras components.\n* [LAVIS](https://github.com/salesforce/LAVIS) ![](https://img.shields.io/github/stars/salesforce/LAVIS.svg?style=social) - LAVIS is a deep learning library for LAnguage-and-VISion intelligence research and applications.\n* [libcom](https://github.com/bcmi/libcom) ![](https://img.shields.io/github/stars/bcmi/libcom.svg?style=social) - libcom is an image composition toolbox.\n* [LightlyTrain](https://github.com/lightly-ai/lightly-train) ![](https://img.shields.io/github/stars/lightly-ai/lightly-train.svg?style=social) - Pretrain computer vision models on unlabeled data for industrial applications.\n* [MMCV](https://github.com/open-mmlab/mmcv) ![](https://img.shields.io/github/stars/open-mmlab/mmcv.svg?style=social) - MMCV is a foundational computer vision library from OpenMMLab that provides essential functionalities like image and video processing, data transformation and augmentation, CNN architectures, and optimized CUDA operations.\n* [SuperGradients](https://github.com/Deci-AI/super-gradients) ![](https://img.shields.io/github/stars/Deci-AI/super-gradients.svg?style=social) - SuperGradients is an open-source library for training PyTorch-based computer vision models.\n* [supervision](https://github.com/roboflow/supervision) ![](https://img.shields.io/github/stars/roboflow/supervision.svg?style=social) - Supervision is a Python library designed for efficient computer vision pipeline management, providing tools for annotation, visualization, and monitoring of models.\n* [VideoSys](https://github.com/NUS-HPC-AI-Lab/VideoSys) ![](https://img.shields.io/github/stars/NUS-HPC-AI-Lab/VideoSys.svg?style=social) - VideoSys supports many diffusion models with our various acceleration techniques, enabling these models to run faster and consume less memory.\n\n## Industry Strength Information Retrieval\n* [AutoRAG](https://github.com/Marker-Inc-Korea/AutoRAG) ![](https://img.shields.io/github/stars/Marker-Inc-Korea/AutoRAG.svg?style=social) - AutoRAG is a RAG AutoML tool for automatically finds an optimal RAG pipeline for your data.\n* [BGE](https://github.com/FlagOpen/FlagEmbedding) ![](https://img.shields.io/github/stars/FlagOpen/FlagEmbedding.svg?style=social) - BGE builds one-stop retrieval toolkit for search and RAG.\n* [Cognita](https://github.com/truefoundry/cognita) ![](https://img.shields.io/github/stars/truefoundry/cognita.svg?style=social) - Cognita is a RAG framework for building modular and production-ready applications.\n* [DocArray](https://github.com/docarray/docarray) ![](https://img.shields.io/github/stars/docarray/docarray.svg?style=social) - DocArray is a library for nested, unstructured, multimodal data in transit, including text, image, audio, video, 3D mesh, etc. It allows deep-learning engineers to efficiently process, embed, search, recommend, store, and transfer multimodal data with a Pythonic API.\n* [Faiss](https://github.com/facebookresearch/faiss) ![](https://img.shields.io/github/stars/facebookresearch/faiss.svg?style=social) - Faiss is a library for efficient similarity search and clustering of dense vectors.\n* [fastRAG](https://github.com/IntelLabs/fastRAG) ![](https://img.shields.io/github/stars/IntelLabs/fastRAG.svg?style=social) - fastRAG is a research framework for efficient and optimized retrieval augmented generative pipelines, incorporating state-of-the-art LLMs and Information Retrieval.\n* [GraphRAG](https://github.com/microsoft/graphrag) ![](https://img.shields.io/github/stars/microsoft/graphrag.svg?style=social) - GraphRAG is a data pipeline and transformation suite that is designed to extract meaningful, structured data from unstructured text using the power of LLMs.\n* [HippoRAG](https://github.com/OSU-NLP-Group/HippoRAG) ![](https://img.shields.io/github/stars/OSU-NLP-Group/HippoRAG.svg?style=social) - HippoRAG is a novel retrieval augmented generation (RAG) framework inspired by the neurobiology of human long-term memory that enables LLMs to continuously integrate knowledge across external documents.\n* [JamAI Base](https://github.com/EmbeddedLLM/JamAIBase) ![](https://img.shields.io/github/stars/EmbeddedLLM/JamAIBase.svg?style=social) - JamAI Base is an open-source RAG (Retrieval-Augmented Generation) backend platform that integrates an embedded database (SQLite) and an embedded vector database (LanceDB) with managed memory and RAG capabilities. It features built-in LLM, vector embeddings, and reranker orchestration and management, all accessible through a convenient, intuitive, spreadsheet-like UI and a simple REST API.\n* [LangExtract](https://github.com/google/langextract) ![](https://img.shields.io/github/stars/google/langextract.svg?style=social) - LangExtract is a Python library that uses LLMs to extract structured information from unstructured text documents based on user-defined instructions. It processes materials such as clinical notes or reports, identifying and organizing key details while ensuring the extracted data corresponds to the source text.\n* [LightRAG](https://github.com/HKUDS/LightRAG) ![](https://img.shields.io/github/stars/HKUDS/LightRAG.svg?style=social) - A simple and fast retrieval-augmented generation framework.\n* [llmware](https://github.com/llmware-ai/llmware) ![](https://img.shields.io/github/stars/llmware-ai/llmware.svg?style=social) - llmware provides a unified framework for building LLM-based applications (e.g, RAG, Agents), using small, specialized models that can be deployed privately, integrated with enterprise knowledge sources safely and securely, and cost-effectively tuned and adapted for any business process.\n* [Mem0](https://github.com/mem0ai/mem0) ![](https://img.shields.io/github/stars/mem0ai/mem0.svg?style=social) - Mem0 enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions.\n* [NGT](https://github.com/yahoojapan/NGT) ![](https://img.shields.io/github/stars/yahoojapan/NGT.svg?style=social) - NGT provides commands and a library for performing high-speed approximate nearest neighbor searches against a large volume of data in high dimensional vector data space.\n* [NMSLIB](https://github.com/nmslib/nmslib) ![](https://img.shields.io/github/stars/nmslib/nmslib.svg?style=social) - Non-Metric Space Library (NMSLIB): An efficient similarity search library and a toolkit for evaluation of k-NN methods for generic non-metric spaces.\n* [Qdrant](https://github.com/qdrant/qdrant) ![](https://img.shields.io/github/stars/qdrant/qdrant.svg?style=social) - An open source vector similarity search engine with extended filtering support.\n* [R2R](https://github.com/SciPhi-AI/R2R) ![](https://img.shields.io/github/stars/SciPhi-AI/R2R.svg?style=social) - R2R (RAG to Riches) is a comprehensive platform for building, deploying, and scaling RAG applications with hybrid search, multimodal support, and advanced observability.\n* [RAGFlow](https://github.com/infiniflow/ragflow) ![](https://img.shields.io/github/stars/infiniflow/ragflow.svg?style=social) - RAGFlow is a RAG engine based on deep document understanding.\n* [RAGxplorer](https://github.com/gabrielchua/RAGxplorer) ![](https://img.shields.io/github/stars/gabrielchua/RAGxplorer.svg?style=social) - RAGxplorer is a tool to build RAG visualisations.\n* [RAG-FiT](https://github.com/IntelLabs/RAG-FiT) ![](https://img.shields.io/github/stars/IntelLabs/RAG-FiT.svg?style=social) - RAG-FiT is a library designed to improve LLMs ability to use external information by fine-tuning models on specially created RAG-augmented datasets.\n* [TextWorld](https://github.com/microsoft/TextWorld) ![](https://img.shields.io/github/stars/microsoft/TextWorld.svg?style=social) - TextWorld is a text-based game generator and extensible sandbox learning environment for training and testing reinforcement learning (RL) agents.\n* [Vanna](https://github.com/vanna-ai/vanna) ![](https://img.shields.io/github/stars/vanna-ai/vanna.svg?style=social) - Vanna is a RAG framework for SQL generation and related functionality.\n\n## Industry Strength Natural Language Processing\n* [aisuite](https://github.com/andrewyng/aisuite) ![](https://img.shields.io/github/stars/andrewyng/aisuite.svg?style=social) - aisuite is a simple, unified interface to multiple generative AI providers.\n* [Align-Anything](https://github.com/PKU-Alignment/align-anything) ![](https://img.shields.io/github/stars/PKU-Alignment/align-anything.svg?style=social) - Align-Anything aims to align any modality large models (any-to-any models), including LLMs, VLMs, and others, with human intentions and values\n* [BERTopic](https://github.com/MaartenGr/BERTopic) ![](https://img.shields.io/github/stars/MaartenGr/BERTopic.svg?style=social) - BERTopic is a topic modeling technique that leverages transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\n* [Burr](https://github.com/dagworks-inc/burr) ![](https://img.shields.io/github/stars/dagworks-inc/burr.svg?style=social) - Burr helps you develop applications that make decisions (chatbot, agent, simulation). It comes with production-ready features (telemetry, persistence, deployment, etc.) and the open-source, free, and local-first Burr UI.\n* [CodeTF](https://github.com/salesforce/CodeTF) ![](https://img.shields.io/github/stars/salesforce/CodeTF.svg?style=social) - CodeTF is a one-stop Python transformer-based library for code large language models (Code LLMs) and code intelligence, provides a seamless interface for training and inferencing on code intelligence tasks like code summarization, translation, code generation and so on. \n* [Dify](https://github.com/langgenius/dify) ![](https://img.shields.io/github/stars/langgenius/dify.svg?style=social) - Dify is an open-source LLM app development platform whose intuitive interface combines agentic AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.\n* [dspy](https://github.com/stanfordnlp/dspy) ![](https://img.shields.io/github/stars/stanfordnlp/dspy.svg?style=social) - A framework for programming with foundation models.\n* [Dust](https://github.com/dust-tt/dust) ![](https://img.shields.io/github/stars/dust-tt/dust.svg?style=social) - Dust assists in the design and deployment of large language model apps.\n* [ESPnet](https://github.com/espnet/espnet) ![](https://img.shields.io/github/stars/espnet/espnet.svg?style=social) - ESPnet is an end-to-end speech processing toolkit.\n* [FastChat](https://github.com/lm-sys/FastChat) ![](https://img.shields.io/github/stars/lm-sys/FastChat.svg?style=social) - FastChat is an open platform for training, serving, and evaluating large language model based chatbots.\n* [Flair](https://github.com/flairNLP/flair) ![](https://img.shields.io/github/stars/flairNLP/flair.svg?style=social) - Simple framework for state-of-the-art NLP developed by Zalando which builds directly on PyTorch.\n* [Gensim](https://github.com/piskvorky/gensim) ![](https://img.shields.io/github/stars/piskvorky/gensim.svg?style=social) - Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora.\n* [h2oGPT](https://github.com/h2oai/h2ogpt) ![](https://img.shields.io/github/stars/h2oai/h2ogpt.svg?style=social) - h2oGPT is an open source generative AI, gives organizations like yours the power to own large language models while preserving your data ownership.\n* [Haystack](https://github.com/deepset-ai/haystack) ![](https://img.shields.io/github/stars/deepset-ai/haystack.svg?style=social) - Haystack is an open source NLP framework to interact with your data using Transformer models and LLMs (GPT-3 and alike). Haystack offers production-ready tools to quickly build ChatGPT-like question answering, semantic search, text generation, and more.\n* [Interactive Composition Explorer](https://github.com/oughtinc/ice) ![](https://img.shields.io/github/stars/oughtinc/ice.svg?style=social) - ICE is a Python library and trace visualizer for language model programs.\n* [Lamini](https://github.com/lamini-ai/lamini) ![](https://img.shields.io/github/stars/lamini-ai/lamini.svg?style=social) - Lamini is an LLM engine for rapidly customizing models.\n* [LangChain](https://github.com/langchain-ai/langchain) ![](https://img.shields.io/github/stars/langchain-ai/langchain.svg?style=social) - LangChain assists in building applications with LLMs through composability.\n* [LlamaIndex](https://github.com/run-llama/llama_index) ![](https://img.shields.io/github/stars/run-llama/llama_index.svg?style=social) - LlamaIndex (GPT Index) is a data framework for your LLM application.\n* [LLaMA](https://github.com/meta-llama/llama) ![](https://img.shields.io/github/stars/meta-llama/llama.svg?style=social) - LLaMA is intended as a minimal, hackable and readable example to load LLaMA (arXiv) models and run inference.\n* [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) ![](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory.svg?style=social) - LLaMA-Factory makes it easy to fine-tunes 100+ large language models with zero-code CLI and Web UI\n* [LLMBox](https://github.com/Alpha-VLLM/LLaMA2-Accessory) ![](https://img.shields.io/github/stars/Alpha-VLLM/LLaMA2-Accessory.svg?style=social) - LLMBox is a comprehensive library for implementing LLMs, including a unified training pipeline and comprehensive model evaluation.\n* [LLaMA2-Accessory](https://github.com/RUCAIBox/LLMBox) ![](https://img.shields.io/github/stars/RUCAIBox/LLMBox.svg?style=social) - LLaMA2-Accessory is an open-source toolkit for pretraining, finetuning and deployment of Large Language Models (LLMs) and multimodal LLMs.\n* [LMFlow](https://github.com/OptimalScale/LMFlow) ![](https://img.shields.io/github/stars/OptimalScale/LMFlow.svg?style=social) - LMFlow is an extensible, convenient, and efficient toolbox for finetuning large machine learning models.\n* [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) ![](https://img.shields.io/github/stars/NVIDIA/Megatron-LM.svg?style=social) - Megatron-LM is a highly optimized and efficient library for training large language models.\n* [MindNLP](https://github.com/mindspore-lab/mindnlp) ![](https://img.shields.io/github/stars/mindspore-lab/mindnlp.svg?style=social) - MindNLP is an easy-to-use and high-performance NLP and LLM framework based on MindSpore, compatible with models and datasets of Huggingface.\n* [MLC LLM](https://github.com/mlc-ai/mlc-llm) ![](https://img.shields.io/github/stars/mlc-ai/mlc-llm.svg?style=social) - MLC LLM is a universal solution that allows any language models to be deployed natively on a diverse set of hardware backends and native applications, plus a productive framework for everyone to further optimize model performance for their own use cases.\n* [Ollama](https://github.com/ollama/ollama) ![](https://img.shields.io/github/stars/ollama/ollama.svg?style=social) - Get up and running with large language models, locally.\n* [olmOCR](https://github.com/allenai/olmocr) ![](https://img.shields.io/github/stars/allenai/olmocr.svg?style=social) - olmOCR is a toolkit for training language models to work with PDF documents in the wild.\n* [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) ![](https://img.shields.io/github/stars/PaddlePaddle/PaddleNLP.svg?style=social) - PaddleNLP is a Large Language Model (LLM) development suite based on the PaddlePaddle deep learning framework, supporting efficient large model training, lossless compression, and high-performance inference on various hardware devices.\n* [PyLLMs](https://github.com/kagisearch/pyllms) ![](https://img.shields.io/github/stars/kagisearch/pyllms.svg?style=social) - PyLLMs is a minimal Python library to connect to various Language Models (LLMs) with a built-in model performance benchmark.\n* [Semantic Kernel](https://github.com/microsoft/semantic-kernel) ![](https://img.shields.io/github/stars/microsoft/semantic-kernel.svg?style=social) - Semantic Kernel is an SDK that integrates Large Language Models (LLMs) like OpenAI, Azure OpenAI, and Hugging Face with conventional programming languages like C#, Python, and Java. Semantic Kernel achieves this by allowing you to define plugins that can be chained together in just a few lines of code.\n* [Sentence Transformers](https://github.com/UKPLab/sentence-transformers) ![](https://img.shields.io/github/stars/UKPLab/sentence-transformers.svg?style=social) - Sentence Transformers provides an easy method to compute dense vector representations for sentences, paragraphs, and images.\n* [SpaCy](https://github.com/explosion/spaCy) ![](https://img.shields.io/github/stars/explosion/spaCy.svg?style=social) - spaCy is a library for advanced Natural Language Processing in Python and Cython.\n* [SWIFT](https://github.com/modelscope/ms-swift) ![](https://img.shields.io/github/stars/modelscope/ms-swift.svg?style=social) - SWIFT is a scalable lightweight infrastructure for deep learning model fine-tuning.\n* [Tensorflow Lingvo](https://github.com/tensorflow/lingvo) ![](https://img.shields.io/github/stars/tensorflow/lingvo.svg?style=social) - A [framework](https://blog.tensorflow.org/2019/02/lingvo-tensorflow-framework-for-sequence-modeling.html) for building neural networks in Tensorflow, particularly sequence models.\n* [Tensorflow Text](https://github.com/tensorflow/text) ![](https://img.shields.io/github/stars/tensorflow/text.svg?style=social) - TensorFlow Text provides a collection of text related classes and ops ready to use with TensorFlow 2.0.\n* [ToolBench](https://github.com/OpenBMB/ToolBench) ![](https://img.shields.io/github/stars/OpenBMB/ToolBench.svg?style=social) - ToolBench is an open platform for training, serving, and evaluating large language model for tool learning.\n* [Transformers](https://github.com/huggingface/transformers) ![](https://img.shields.io/github/stars/huggingface/transformers.svg?style=social) - Huggingface's library of state-of-the-art pretrained models for Natural Language Processing (NLP).\n\n## Industry Strength Recommender System\n* [EasyRec](https://github.com/alibaba/EasyRec) ![](https://img.shields.io/github/stars/alibaba/EasyRec.svg?style=social) - EasyRec is a framework for large scale recommendation algorithms.\n* [Gorse](https://github.com/gorse-io/gorse) ![](https://img.shields.io/github/stars/gorse-io/gorse.svg?style=social) - Gorse aims to be a universal open-source recommender system that can be quickly introduced into a wide variety of online services.\n* [Merlin](https://github.com/NVIDIA-Merlin/Merlin) ![](https://img.shields.io/github/stars/NVIDIA-Merlin/Merlin.svg?style=social) - NVIDIA Merlin is an open source library providing end-to-end GPU-accelerated recommender systems, from feature engineering and preprocessing to training deep learning models and running inference in production.\n* [Recommenders](https://github.com/recommenders-team/recommenders) ![](https://img.shields.io/github/stars/recommenders-team/recommenders.svg?style=social) - Recommenders contains benchmark and best practices for building recommendation systems, provided as Jupyter notebooks.\n\n## Industry Strength Reinforcement Learning\n* [Acme](https://github.com/google-deepmind/acme) ![](https://img.shields.io/github/stars/google-deepmind/acme.svg?style=social) - Acme is a library of reinforcement learning (RL) building blocks that strives to expose simple, efficient, and readable agents.\n* [CleanRL](https://github.com/vwxyzjn/cleanrl) ![](https://img.shields.io/github/stars/vwxyzjn/cleanrl.svg?style=social) - CleanRL is a Deep Reinforcement Learning library that provides high-quality single-file implementation with research-friendly features. The implementation is clean and simple, yet we can scale it to run thousands of experiments using AWS Batch.\n* [CompilerGym](https://github.com/facebookresearch/CompilerGym) ![](https://img.shields.io/github/stars/facebookresearch/CompilerGym.svg?style=social) - CompilerGym is a library of easy to use and performant reinforcement learning environments for compiler tasks.\n* [d3rlpy](https://github.com/takuseno/d3rlpy) ![](https://img.shields.io/github/stars/takuseno/d3rlpy.svg?style=social) - d3rlpy is an offline deep reinforcement learning library for practitioners and researchers.\n* [D4RL](https://github.com/Farama-Foundation/D4RL) ![](https://img.shields.io/github/stars/Farama-Foundation/D4RL.svg?style=social) - D4RL is an open-source benchmark for offline reinforcement learning.\n* [Dopamine](https://github.com/google/dopamine) ![](https://img.shields.io/github/stars/google/dopamine.svg?style=social) - Dopamine is a research framework for fast prototyping of reinforcement learning algorithms. It aims to fill the need for a small, easily grokked codebase in which users can freely experiment with wild ideas (speculative research).\n* [EvoTorch](https://github.com/nnaisense/evotorch) ![](https://img.shields.io/github/stars/nnaisense/evotorch.svg?style=social) - EvoTorch is an open source evolutionary computation library developed at NNAISENSE, built on top of PyTorch.\n* [FinRL](https://github.com/AI4Finance-Foundation/FinRL) ![](https://img.shields.io/github/stars/AI4Finance-Foundation/FinRL.svg?style=social) - FinRL is the first open-source framework to demonstrate the great potential of financial reinforcement learning.\n* [Gymnasium](https://github.com/Farama-Foundation/Gymnasium) ![](https://img.shields.io/github/stars/Farama-Foundation/Gymnasium.svg?style=social) - Gymnasium is an open source Python library for developing and comparing reinforcement learning algorithms by providing a standard API to communicate between learning algorithms and environments, as well as a standard set of environments compliant with that API.\n* [Gymnasium-Robotics](https://github.com/Farama-Foundation/Gymnasium-Robotics) ![](https://img.shields.io/github/stars/Farama-Foundation/Gymnasium-Robotics.svg?style=social) - Gymnasium-Robotics contains a collection of Reinforcement Learning robotic environments that use the Gymansium API. The environments run with the MuJoCo physics engine and the maintained mujoco python bindings.\n* [Jumanji](https://github.com/instadeepai/jumanji) ![](https://img.shields.io/github/stars/instadeepai/jumanji.svg?style=social) - Jumanji is a suite of Reinforcement Learning (RL) environments written in JAX providing clean, hardware-accelerated environments for industry-driven research.\n* [MARLlib](https://github.com/Replicable-MARL/MARLlib) ![](https://img.shields.io/github/stars/Replicable-MARL/MARLlib.svg?style=social) - MARLlib is a comprehensive Multi-Agent Reinforcement Learning algorithm library based on RLlib. It provides MARL research community with a unified platform for building, training, and evaluating MARL algorithms.\n* [Mava](https://github.com/instadeepai/Mava) ![](https://img.shields.io/github/stars/instadeepai/Mava.svg?style=social) - Mava is a framework for distributed multi-agent reinforcement learning in JAX.\n* [Melting Pot](https://github.com/google-deepmind/meltingpot) ![](https://img.shields.io/github/stars/google-deepmind/meltingpot.svg?style=social) - Melting Pot is a suite of test scenarios for multi-agent reinforcement learning.\n* [MetaDrive](https://github.com/metadriverse/metadrive) ![](https://img.shields.io/github/stars/metadriverse/metadrive.svg?style=social) - MetaDrive is a driving simulator that composes diverse driving scenarios for generalizable RL.\n* [Minigrid](https://github.com/Farama-Foundation/Minigrid) ![](https://img.shields.io/github/stars/Farama-Foundation/Minigrid.svg?style=social) - The Minigrid library contains a collection of discrete grid-world environments to conduct research on Reinforcement Learning. The environments follow the Gymnasium standard API and they are designed to be lightweight, fast, and easily customizable.\n* [MiniWorld](https://github.com/Farama-Foundation/Miniworld) ![](https://img.shields.io/github/stars/Farama-Foundation/Miniworld.svg?style=social) - MiniWorld is a minimalistic 3D interior environment simulator for reinforcement learning & robotics research.\n* [ML-Agents](https://github.com/Unity-Technologies/ml-agents) ![](https://img.shields.io/github/stars/Unity-Technologies/ml-agents.svg?style=social) - ML-Agents is an open-source project that enables games and simulations to serve as environments for training reinforcement learning intelligent agents.\n* [MushroomRL](https://github.com/MushroomRL/mushroom-rl) ![](https://img.shields.io/github/stars/MushroomRL/mushroom-rl.svg?style=social) - MushroomRL is a Python reinforcement learning (RL) library whose modularity allows to easily use well-known Python libraries for tensor computation (e.g. PyTorch, Tensorflow) and RL benchmarks (e.g. OpenAI Gym, PyBullet, Deepmind Control Suite).\n* [OmniSafe](https://github.com/PKU-Alignment/omnisafe) ![](https://img.shields.io/github/stars/PKU-Alignment/omnisafe.svg?style=social) - OmniSafe is an infrastructural framework designed to accelerate safe reinforcement learning (RL) research.\n* [PARL](https://github.com/PaddlePaddle/PARL) ![](https://img.shields.io/github/stars/PaddlePaddle/PARL.svg?style=social) - PARL is a flexible and high-efficient reinforcement learning framework.\n* [PettingZoo](https://github.com/Farama-Foundation/PettingZoo) ![](https://img.shields.io/github/stars/Farama-Foundation/PettingZoo.svg?style=social) - PettingZoo is a Python library for conducting research in multi-agent reinforcement learning, akin to a multi-agent version of Gymnasium.\n* [ranx](https://github.com/AmenRa/ranx) ![](https://img.shields.io/github/stars/AmenRa/ranx.svg?style=social) - ranx is a library of fast ranking evaluation metrics implemented in Python, leveraging Numba for high-speed vector operations and automatic parallelization.\n* [RL4CO](https://github.com/ai4co/rl4co) ![](https://img.shields.io/github/stars/ai4co/rl4co.svg?style=social) - RL4CO is a PyTorch library for all things reinforcement learning for combinatorial optimization (CO).\n* [rLLM](https://github.com/agentica-project/rllm) ![](https://img.shields.io/github/stars/agentica-project/rllm.svg?style=social) - rLLM is an open-source framework for post-training language agents via reinforcement learning\n* [skrl](https://github.com/Toni-SM/skrl) ![](https://img.shields.io/github/stars/Toni-SM/skrl.svg?style=social) - skrl is an open-source modular library for Reinforcement Learning written in Python (using PyTorch) and designed with a focus on readability, simplicity, and transparency of algorithm implementation.\n* [Stable Baselines](https://github.com/DLR-RM/stable-baselines3) ![](https://img.shields.io/github/stars/DLR-RM/stable-baselines3.svg?style=social) - A fork of OpenAI Baselines, implementations of reinforcement learning algorithms.\n* [TF-Agents](https://github.com/tensorflow/agents) ![](https://img.shields.io/github/stars/tensorflow/agents.svg?style=social) - A reliable, scalable and easy to use TensorFlow library for contextual bandits and reinforcement learning.\n* [TRL](https://github.com/huggingface/trl) ![](https://img.shields.io/github/stars/huggingface/trl.svg?style=social) - Train transformer language models with reinforcement learning. \n* [veRL](https://github.com/volcengine/veRL) ![](https://img.shields.io/github/stars/volcengine/veRL.svg?style=social) - veRL (HybridFlow) is a flexible, efficient and industrial-level RL(HF) training framework designed for LLMs. \n\n## Industry Strength Visualisation\n* [Apache ECharts](https://github.com/apache/echarts) ![](https://img.shields.io/github/stars/apache/echarts.svg?style=social) - Apache ECharts is a powerful, interactive charting and data visualization library for browser.\n* [Apache Superset](https://github.com/apache/superset) ![](https://img.shields.io/github/stars/apache/superset.svg?style=social) - A modern, enterprise-ready business intelligence web application.\n* [Bokeh](https://github.com/bokeh/bokeh) ![](https://img.shields.io/github/stars/bokeh/bokeh.svg?style=social) - Bokeh is an interactive visualization library for Python that enables beautiful and meaningful visual presentation of data in modern web browsers.\n* [Data Formulator](https://github.com/microsoft/data-formulator) ![](https://img.shields.io/github/stars/microsoft/data-formulator.svg?style=social) - Transform data and create rich visualizations iteratively with AI.\n* [ggplot2](https://github.com/tidyverse/ggplot2) ![](https://img.shields.io/github/stars/tidyverse/ggplot2.svg?style=social) - An implementation of the grammar of graphics for R.\n* [gradio](https://github.com/gradio-app/gradio) ![](https://img.shields.io/github/stars/gradio-app/gradio.svg?style=social) - Quickly create and share demos of models - by only writing Python. Debug models interactively in your browser, get feedback from collaborators, and generate public links without deploying anything.\n* [Kangas](https://github.com/comet-ml/kangas) ![](https://img.shields.io/github/stars/comet-ml/kangas.svg?style=social) - Kangas is a tool for exploring, analyzing, and visualizing large-scale multimedia data. It provides a straightforward Python API for logging large tables of data, along with an intuitive visual interface for performing complex queries against your dataset.\n* [matplotlib](https://github.com/matplotlib/matplotlib) ![](https://img.shields.io/github/stars/matplotlib/matplotlib.svg?style=social) - A Python 2D plotting library which produces publication-quality figures in a variety of hardcopy formats and interactive environments across platforms.\n* [Netron](https://github.com/lutzroeder/netron) ![](https://img.shields.io/github/stars/lutzroeder/netron.svg?style=social) - Netron is a viewer for neural network, deep learning and machine learning models.\n* [Perspective](https://github.com/finos/perspective) ![](https://img.shields.io/github/stars/finos/perspective.svg?style=social) Streaming pivot visualization via WebAssembly.\n* [Plotly](https://github.com/plotly/plotly.py) ![](https://img.shields.io/github/stars/plotly/plotly.py.svg?style=social) - An interactive, open source, and browser-based graphing library for Python.\n* [Redash](https://github.com/getredash/redash) ![](https://img.shields.io/github/stars/getredash/redash.svg?style=social) - Redash is anopen source visualisation framework that is built to allow easy access to big datasets leveraging multiple backends.\n* [seaborn](https://github.com/mwaskom/seaborn) ![](https://img.shields.io/github/stars/mwaskom/seaborn.svg?style=social) - Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.\n* [Spotlight](https://github.com/Renumics/spotlight) ![](https://img.shields.io/github/stars/Renumics/spotlight.svg?style=social) - Spotlight helps you to identify critical data segments and model failure modes. It enables you to build and maintain reliable machine learning models by curating high-quality datasets.\n* [Streamlit](https://github.com/streamlit/streamlit) ![](https://img.shields.io/github/stars/streamlit/streamlit.svg?style=social) - Streamlit lets you create apps for your machine learning projects with deceptively simple Python scripts. It supports hot-reloading, so your app updates live as you edit and save your file.\n* [tensorboardX](https://github.com/lanpa/tensorboardX) ![](https://img.shields.io/github/stars/lanpa/tensorboardX.svg?style=social) - Write TensorBoard events with simple function call.\n* [TensorBoard](https://github.com/tensorflow/tensorboard) ![](https://img.shields.io/github/stars/tensorflow/tensorboard.svg?style=social) - TensorBoard is a visualization toolkit for machine learning experimentation that makes it easy to host, track, and share ML experiments.\n* [Transformer Explainer](https://github.com/poloclub/transformer-explainer) ![](https://img.shields.io/github/stars/poloclub/transformer-explainer.svg?style=social) - Transformer Explainer is an interactive visualization tool designed to help anyone learn how Transformer-based models like GPT work.\n* [Vega-Altair](https://github.com/vega/altair) ![](https://img.shields.io/github/stars/vega/altair.svg?style=social) - Vega-Altair is a declarative statistical visualization library for Python.\n* [ydata-profiling](https://github.com/ydataai/ydata-profiling) ![](https://img.shields.io/github/stars/ydataai/ydata-profiling.svg?style=social) - ydata-profiling provides a one-line Exploratory Data Analysis (EDA) experience in a consistent and fast solution.\n\n## Metadata Management\n* [Amundsen](https://github.com/amundsen-io/amundsen) ![](https://img.shields.io/github/stars/amundsen-io/amundsen.svg?style=social) - Amundsen is a metadata driven application for improving the productivity of data analysts, data scientists and engineers when interacting with data.\n* [Apache Atlas](https://github.com/apache/atlas) ![](https://img.shields.io/github/stars/apache/atlas.svg?style=social) - Apache Atlas framework is an extensible set of core foundational governance services ‚Äì enabling enterprises to effectively and efficiently meet their compliance requirements within Hadoop and allows integration with the whole enterprise data ecosystem.\n* [DataHub](https://github.com/datahub-project/datahub) ![](https://img.shields.io/github/stars/datahub-project/datahub.svg?style=social) - DataHub is LinkedIn's generalized metadata search & discovery tool.\n* [Marquez](https://github.com/MarquezProject/marquez) ![](https://img.shields.io/github/stars/MarquezProject/marquez.svg?style=social) - Marquez is an open source metadata service for the collection, aggregation, and visualization of a data ecosystem's metadata.\n* [Metacat](https://github.com/Netflix/metacat) ![](https://img.shields.io/github/stars/Netflix/metacat.svg?style=social) - Metacat is a unified metadata exploration API service. Metacat focuses on solving these problems: 1) federated views of metadata systems; 2) arbitrary metadata storage about data sets; 3) metadata discovery.\n* [ML Metadata](https://github.com/google/ml-metadata) ![](https://img.shields.io/github/stars/google/ml-metadata.svg?style=social) - a library for recording and retrieving metadata associated with ML developer and data scientist workflows.\n\n## Model, Data and Experiment Management\n* [Aim](https://github.com/aimhubio/aim) ![](https://img.shields.io/github/stars/aimhubio/aim.svg?style=social) - A super-easy way to record, search and compare AI experiments.\n* [ClearML](https://github.com/clearml/clearml) ![](https://img.shields.io/github/stars/clearml/clearml.svg?style=social) - Auto-Magical Experiment Manager & Version Control for AI (previously Trains).\n* [DataHub](https://github.com/datahub-project/datahub) ![](https://img.shields.io/github/stars/datahub-project/datahub.svg?style=social) - DataHub is an open-source data catalog for the modern data stack.\n* [Dolt](https://github.com/dolthub/dolt) ![](https://img.shields.io/github/stars/dolthub/dolt.svg?style=social) - Dolt is a SQL database that you can fork, clone, branch, merge, push and pull just like a git repository.\n* [DVC](https://github.com/iterative/dvc) ![](https://img.shields.io/github/stars/iterative/dvc.svg?style=social) - DVC (Data Version Control) is a git fork that allows for version management of models.\n* [HuggingFace Model Downloader](https://github.com/bodaay/HuggingFaceModelDownloader) ![](https://img.shields.io/github/stars/bodaay/HuggingFaceModelDownloader.svg?style=social) - HuggingFace Model Downloader is a utility tool for downloading models and datasets from the HuggingFace website. It offers multithreaded downloading for LFS files and ensures the integrity of downloaded models with SHA256 checksum verification.\n* [Keepsake](https://github.com/replicate/keepsake) ![](https://img.shields.io/github/stars/replicate/keepsake.svg?style=social) - Version control for machine learning.\n* [KitOps](https://github.com/jozu-ai/kitops) ![](https://img.shields.io/github/stars/jozu-ai/kitops.svg?style=social) - KitOps is an open and standards-based packaging and versioning system for AI/ML projects that works with all the AI/ML, development, and DevOps tools you are already using.\n* [lakeFS](https://github.com/treeverse/lakeFS) ![](https://img.shields.io/github/stars/treeverse/lakeFS.svg?style=social) - Repeatable, atomic and versioned data lake on top of object storage.\n* [MLflow](https://github.com/mlflow/mlflow) ![](https://img.shields.io/github/stars/mlflow/mlflow.svg?style=social) - Open source platform to manage the ML lifecycle, including experimentation, reproducibility and deployment.\n* [Neptune](https://github.com/neptune-ai/neptune-client) ![](https://img.shields.io/github/stars/neptune-ai/neptune-client.svg?style=social) - Neptune is a scalable experiment tracker for teams that train foundation models.\n* [Polyaxon](https://github.com/polyaxon/polyaxon) ![](https://img.shields.io/github/stars/polyaxon/polyaxon.svg?style=social) - A platform for reproducible and scalable machine learning and deep learning on kubernetes - [(Video)](https://www.youtube.com/watch?v=Iexwrka_hys).\n* [Quilt](https://github.com/quiltdata/quilt) ![](https://img.shields.io/github/stars/quiltdata/quilt.svg?style=social) - Versioning, reproducibility and deployment of data and models.\n* [Sacred](https://github.com/IDSIA/sacred) ![](https://img.shields.io/github/stars/IDSIA/sacred.svg?style=social) - Tool to help you configure, organize, log and reproduce machine learning experiments.\n* [TerminusDB](https://github.com/terminusdb/terminusdb) ![](https://img.shields.io/github/stars/terminusdb/terminusdb.svg?style=social) - A graph database management system that stores data like git.\n* [Weights & Biases](https://github.com/wandb/wandb) ![](https://img.shields.io/github/stars/wandb/wandb.svg?style=social) - Weights & Biase is a machine learning experiment tracking, dataset versioning, hyperparameter search, visualization, and collaboration.\n\n## Model Training and Orchestration\n\n* [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced) ![](https://img.shields.io/github/stars/huggingface/autotrain-advanced.svg?style=social) - AutoTrain Advanced is a no-code solution that allows you to train machine learning models in just a few clicks.\n* [Avalanche](https://github.com/ContinualAI/avalanche) ![](https://img.shields.io/github/stars/ContinualAI/avalanche.svg?style=social) - Avalanche is an end-to-end Continual Learning library to provide a shared and collaborative open-source (MIT licensed) codebase for fast prototyping, training and reproducible evaluation of continual learning algorithms.\n* [Axolotl](https://github.com/axolotl-ai-cloud/axolotl) ![](https://img.shields.io/github/stars/axolotl-ai-cloud/axolotl.svg?style=social) - Axolotl is a tool designed to streamline the fine-tuning of various AI models, offering support for multiple configurations and architectures.\n* [BindsNET](https://github.com/BindsNET/bindsnet) ![](https://img.shields.io/github/stars/BindsNET/bindsnet.svg?style=social) - BindsNET is a spiking neural network simulation library geared towards the development of biologically inspired algorithms for machine learning.\n* [CML](https://github.com/iterative/cml) ![](https://img.shields.io/github/stars/iterative/cml.svg?style=social) - Continuous Machine Learning (CML) is an open-source library for implementing continuous integration & delivery (CI/CD) in machine learning projects.\n* [CoreNet](https://github.com/apple/corenet) ![](https://img.shields.io/github/stars/apple/corenet.svg?style=social) - CoreNet is a deep neural network toolkit that allows researchers and engineers to train standard and novel small and large-scale models for variety of tasks, including foundation models (e.g., CLIP and LLM), object classification, object detection, and semantic segmentation.\n* [Determined](https://github.com/determined-ai/determined) ![](https://img.shields.io/github/stars/determined-ai/determined.svg?style=social) - Deep learning training platform with integrated support for distributed training, hyperparameter tuning, and model management (supports Tensorflow and Pytorch).\n* [dstack](https://github.com/dstackai/dstack) ![](https://img.shields.io/github/stars/dstackai/dstack.svg?style=social) - dstack is an open-source container orchestrator that simplifies workload orchestration and drives GPU utilization for ML teams.\n* [Fairseq](https://github.com/facebookresearch/fairseq) ![](https://img.shields.io/github/stars/facebookresearch/fairseq.svg?style=social) - Fairseq(-py) is a sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling and other text generation tasks.\n* [Fire-Flyer File System](https://github.com/deepseek-ai/3FS) ![](https://img.shields.io/github/stars/deepseek-ai/3FS.svg?style=social) - The Fire-Flyer File System (3FS) is a high-performance distributed file system designed to address the challenges of AI training and inference workloads. It leverages modern SSDs and RDMA networks to provide a shared storage layer that simplifies development of distributed applications.\n* [H2O-3](https://github.com/h2oai/h2o-3) ![](https://img.shields.io/github/stars/h2oai/h2o-3.svg?style=social) - Fast scalable Machine Learning platform for smarter applications: Deep Learning, Gradient Boosting & XGBoost, Random Forest, Generalized Linear Modeling (Logistic Regression, Elastic Net), K-Means, PCA, Stacked Ensembles, Automatic Machine Learning (AutoML), etc..\n* [Hopsworks](https://github.com/logicalclocks/hopsworks) ![](https://img.shields.io/github/stars/logicalclocks/hopsworks.svg?style=social) - Hopsworks is a data-intensive platform for the design and operation of machine learning pipelines.\n* [Ignite](https://github.com/pytorch/ignite) ![](https://img.shields.io/github/stars/pytorch/ignite.svg?style=social) - Ignite is a high-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.\n* [Kubeflow](https://github.com/kubeflow/kubeflow) ![](https://img.shields.io/github/stars/kubeflow/kubeflow.svg?style=social) - A cloud-native platform for machine learning based on Google‚Äôs internal machine learning pipelines.\n* [Ludwig](https://github.com/ludwig-ai/ludwig) ![](https://img.shields.io/github/stars/ludwig-ai/ludwig.svg?style=social) - Ludwig is a low-code framework for building custom AI models like LLMs and other deep neural networks.\n* [MFTCoder](https://github.com/codefuse-ai/MFTCoder) ![](https://img.shields.io/github/stars/codefuse-ai/MFTCoder.svg?style=social) - MFTCoder is an open-source project of CodeFuse for accurate and efficient Multi-task Fine-tuning(MFT) on Large Language Models(LLMs), especially on Code-LLMs(large language model for code tasks).\n* [MLeap](https://github.com/combust/mleap) ![](https://img.shields.io/github/stars/combust/mleap.svg?style=social) - Standardisation of pipeline and model serialization for Spark, Tensorflow and sklearn.\n* [Nanotron](https://github.com/huggingface/nanotron) ![](https://img.shields.io/github/stars/huggingface/nanotron.svg?style=social) - Nanotron provides distributed primitives to train a variety of models efficiently using 3D parallelism.\n* [NeMo](https://github.com/NVIDIA/NeMo) ![](https://img.shields.io/github/stars/NVIDIA/NeMo.svg?style=social) - NVIDIA NeMo is a scalable and cloud-native generative AI framework built for researchers and PyTorch developers working on Large Language Models (LLMs), Multimodal Models (MMs), Automatic Speech Recognition (ASR), Text to Speech (TTS), and Computer Vision (CV) domains. It is designed to help you efficiently create, customize, and deploy new generative AI models by leveraging existing code and pre-trained model checkpoints.\n* [Prime](https://github.com/PrimeIntellect-ai/prime) ![](https://img.shields.io/github/stars/PrimeIntellect-ai/prime.svg?style=social) - Prime is a framework for efficient, globally distributed training of AI models over the internet.\n* [PyCaret](https://github.com/pycaret/pycaret) ![](https://img.shields.io/github/stars/pycaret/pycaret.svg?style=social)) - low-code library for training and deploying models (scikit-learn, XGBoost, LightGBM, spaCy)\n* [Sematic](https://github.com/sematic-ai/sematic) ![](https://img.shields.io/github/stars/sematic-ai/sematic.svg?style=social) - Platform to build resource-intensive pipelines with simple Python.\n* [Skaffold](https://github.com/GoogleContainerTools/skaffold) ![](https://img.shields.io/github/stars/GoogleContainerTools/skaffold.svg?style=social) - Skaffold is a command line tool that facilitates continuous development for Kubernetes applications. You can iterate on your application source code locally then deploy to local or remote Kubernetes clusters.\n* [TFX](https://github.com/tensorflow/tfx) ![](https://img.shields.io/github/stars/tensorflow/tfx.svg?style=social) - Tensorflow Extended (TFX) is a production oriented configuration framework for ML based on TensorFlow, incl. monitoring and model version management.\n* [envd](https://github.com/tensorchord/envd) ![](https://img.shields.io/github/stars/tensorchord/envd.svg?style=social) - Machine learning development environment for data science and AI/ML engineering teams.\n\n## Model Storage Optimisation\n* [AutoAWQ](https://github.com/casper-hansen/AutoAWQ) ![](https://img.shields.io/github/stars/casper-hansen/AutoAWQ.svg?style=social) - AutoAWQ is an easy-to-use package for 4-bit quantized models.\n* [AutoGPTQ](https://github.com/AutoGPTQ/AutoGPTQ) ![](https://img.shields.io/github/stars/AutoGPTQ/AutoGPTQ.svg?style=social) - An easy-to-use LLMs quantization package with user-friendly apis, based on GPTQ algorithm.\n* [AWQ](https://github.com/mit-han-lab/llm-awq) ![](https://img.shields.io/github/stars/mit-han-lab/llm-awq.svg?style=social) - Activation-aware Weight Quantization for LLM Compression and Acceleration.\n* [GGML](https://github.com/ggml-org/ggml) ![](https://img.shields.io/github/stars/ggml-org/ggml.svg?style=social) - GGML is a high-performance, tensor library for machine learning that enables efficient inference on CPUs, particularly optimized for large language models.\n* [neural-compressor](https://github.com/intel/neural-compressor) ![](https://img.shields.io/github/stars/intel/neural-compressor.svg?style=social) - Intel¬Æ Neural Compressor aims to provide popular model compression techniques such as quantization, pruning (sparsity), distillation, and neural architecture search on mainstream frameworks.\n* [NNEF](https://www.khronos.org/nnef) - Neural Network Exchange Format (NNEF) is an open standard for representing neural network models to enable interoperability and portability across different machine learning frameworks and platforms.\n* [ONNX](https://github.com/onnx/onnx) ![](https://img.shields.io/github/stars/onnx/onnx.svg?style=social) - ONNX (Open Neural Network Exchange) is an open-source format designed to facilitate interoperability and portability of machine learning models across different frameworks and platforms.\n* [PFA](https://dmg.org/pfa) - PFA (Portable Format for Analytics) format is a standard for representing and exchanging predictive models and analytics workflows in a portable, JSON-based format.\n* [PMML](https://dmg.org/pmml) - PMML (Predictive Model Markup Language) is an XML-based standard for representing and sharing predictive models between different applications.\n* [Quanto](https://github.com/huggingface/optimum-quanto) ![](https://img.shields.io/github/stars/huggingface/optimum-quanto.svg?style=social) - Quanto aims to simplify quantizing deep learning models.\n\n## Privacy and Safety\n* [ART](https://github.com/Trusted-AI/adversarial-robustness-toolbox) ![](https://img.shields.io/github/stars/Trusted-AI/adversarial-robustness-toolbox.svg?style=social) - ART (Adversarial Robustness Toolbox) provides tools that enable developers and researchers to defend and evaluate Machine Learning models and applications against the adversarial threats of Evasion, Poisoning, Extraction, and Inference.\n* [CipherChat](https://github.com/RobustNLP/CipherChat) ![](https://img.shields.io/github/stars/RobustNLP/CipherChat.svg?style=social) - CipherChat is a framework to evaluate the generalization capability of safety alignment for LLMs\n* [DeepTeam](https://github.com/confident-ai/deepteam) ![](https://img.shields.io/github/stars/confident-ai/deepteam.svg?style=social) - DeepTeam is a simple-to-use, open-source LLM red teaming framework, for penetration testing and safe guarding large-language model systems.\n* [FATE](https://github.com/FederatedAI/FATE) ![](https://img.shields.io/github/stars/FederatedAI/FATE.svg?style=social) - FATE (Federated AI Technology Enabler) is the world's first industrial grade federated learning open source framework to enable enterprises and institutions to collaborate on data while protecting data security and privacy.\n* [FedML](https://github.com/FedML-AI/FedML) ![](https://img.shields.io/github/stars/FedML-AI/FedML.svg?style=social) - FedML provides a research and production integrated edge-cloud platform for Federated/Distributed Machine Learning at anywhere at any scale.\n* [Flower](https://github.com/adap/flower) ![](https://img.shields.io/github/stars/adap/flower.svg?style=social) - Flower is a Federated Learning Framework with a unified approach. It enables the federation of any ML workload, with any ML framework, and any programming language.\n* [Google's Differential Privacy](https://github.com/google/differential-privacy) ![](https://img.shields.io/github/stars/google/differential-privacy.svg?style=social) - This is a C++ library of Œµ-differentially private algorithms, which can be used to produce aggregate statistics over numeric data sets containing private or sensitive information.\n* [Guardrails](https://github.com/guardrails-ai/guardrails) ![](https://img.shields.io/github/stars/guardrails-ai/guardrails.svg?style=social) - Guardrails is a package that lets a user add structure, type and quality guarantees to the outputs of large language models.\n* [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails) ![](https://img.shields.io/github/stars/NVIDIA/NeMo-Guardrails.svg?style=social) - NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems.\n* [OpenFL](https://github.com/securefederatedai/openfl)  ![](https://img.shields.io/github/stars/securefederatedai/openfl.svg?style=social) - OpenFL is a Python framework for Federated Learning. OpenFL is designed to be a _flexible_, _extensible_ and _easily learnable_ tool for data scientists. OpenFL is developed by Intel Internet of Things Group (IOTG) and Intel Labs.\n* [PySyft](https://github.com/OpenMined/PySyft) ![](https://img.shields.io/github/stars/OpenMined/PySyft.svg?style=social) - A Python library for secure, private Deep Learning. PySyft decouples private data from model training, using Multi-Party (MPC) within PyTorch.\n* [Tensorflow Privacy](https://github.com/tensorflow/privacy) ![](https://img.shields.io/github/stars/tensorflow/privacy.svg?style=social) - A Python library that includes implementations of TensorFlow optimizers for training machine learning models with differential privacy.\n* [TF Encrypted](https://github.com/tf-encrypted/tf-encrypted) ![](https://img.shields.io/github/stars/tf-encrypted/tf-encrypted.svg?style=social) - A Framework for Confidential Machine Learning on Encrypted Data in TensorFlow.\n",
         "AI_DataScience"
        ],
        [
         "38",
         "MDEwOlJlcG9zaXRvcnkxMjM4NzAzMTU=",
         "# TensorFlow.js\n\nTensorFlow.js is an open-source hardware-accelerated JavaScript library for\ntraining and deploying machine learning models.\n\n\n**Develop ML in the Browser** <br/>\nUse flexible and intuitive APIs to build models from scratch using the low-level\nJavaScript linear algebra library or the high-level layers API.\n\n**Develop ML in Node.js** <br/>\nExecute native TensorFlow with the same TensorFlow.js API under the Node.js\nruntime.\n\n**Run Existing models** <br/>\nUse TensorFlow.js model converters to run pre-existing TensorFlow models right\nin the browser.\n\n**Retrain Existing models** <br/>\nRetrain pre-existing ML models using sensor data connected to the browser or\nother client-side data.\n\n## About this repo\n\nThis repository contains the logic and scripts that combine\nseveral packages.\n\nAPIs:\n- [TensorFlow.js Core](/tfjs-core),\n  a flexible low-level API for neural networks and numerical computation.\n- [TensorFlow.js Layers](/tfjs-layers),\n  a high-level API which implements functionality similar to\n  [Keras](https://keras.io/).\n- [TensorFlow.js Data](/tfjs-data),\n  a simple API to load and prepare data analogous to\n  [tf.data](https://www.tensorflow.org/guide/datasets).\n- [TensorFlow.js Converter](/tfjs-converter),\n  tools to import a TensorFlow SavedModel to TensorFlow.js\n- [TensorFlow.js Vis](/tfjs-vis),\n  in-browser visualization for TensorFlow.js models\n- [TensorFlow.js AutoML](/tfjs-automl),\n  Set of APIs to load and run models produced by\n  [AutoML Edge](https://cloud.google.com/vision/automl/docs/edge-quickstart).\n\n\nBackends/Platforms:\n- [TensorFlow.js CPU Backend](/tfjs-backend-cpu), pure-JS backend for Node.js and the browser.\n- [TensorFlow.js WebGL Backend](/tfjs-backend-webgl), WebGL backend for the browser.\n- [TensorFlow.js WASM Backend](/tfjs-backend-wasm), WebAssembly backend for the browser.\n- [TensorFlow.js WebGPU](/tfjs-backend-webgpu), WebGPU backend for the browser.\n- [TensorFlow.js Node](/tfjs-node), Node.js platform via TensorFlow C++ adapter.\n- [TensorFlow.js React Native](/tfjs-react-native), React Native platform via expo-gl adapter.\n\nIf you care about bundle size, you can import those packages individually.\n\nIf you are looking for Node.js support, check out the [TensorFlow.js Node directory](/tfjs-node).\n\n## Examples\n\nCheck out our\n[examples repository](https://github.com/tensorflow/tfjs-examples)\nand our [tutorials](https://js.tensorflow.org/tutorials/).\n\n## Gallery\n\nBe sure to check out [the gallery](GALLERY.md) of all projects related to TensorFlow.js.\n\n## Pre-trained models\n\nBe sure to also check out our [models repository](https://github.com/tensorflow/tfjs-models) where we host pre-trained models\non NPM.\n\n## Benchmarks\n\n* [Local benchmark tool](https://tfjs-benchmarks.web.app/). Use this webpage tool to collect the performance related metrics (speed, memory, etc) of TensorFlow.js models and kernels **on your local device** with CPU, WebGL or WASM backends. You can benchmark custom models by following this [guide](https://github.com/tensorflow/tfjs/blob/master/e2e/benchmarks/local-benchmark/README.md).\n* [Multi-device benchmark tool](https://github.com/tensorflow/tfjs/tree/master/e2e/benchmarks/browserstack-benchmark/README.md). Use this tool to collect the same performance related metrics **on a collection of remote devices**.\n\n## Getting started\n\nThere are two main ways to get TensorFlow.js in your JavaScript project:\nvia <a href=\"https://developer.mozilla.org/en-US/docs/Learn/HTML/Howto/Use_JavaScript_within_a_webpage\" target=\"_blank\">script tags</a> <strong>or</strong> by installing it from <a href=\"https://www.npmjs.com/\" target=\"_blank\">NPM</a>\nand using a build tool like <a href=\"https://parceljs.org/\" target=\"_blank\">Parcel</a>,\n<a href=\"https://webpack.js.org/\" target=\"_blank\">WebPack</a>, or <a href=\"https://rollupjs.org/guide/en\" target=\"_blank\">Rollup</a>.\n\n### via Script Tag\n\nAdd the following code to an HTML file:\n\n```html\n<html>\n  <head>\n    <!-- Load TensorFlow.js -->\n    <script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js\"> </script>\n\n\n    <!-- Place your code in the script tag below. You can also use an external .js file -->\n    <script>\n      // Notice there is no 'import' statement. 'tf' is available on the index-page\n      // because of the script tag above.\n\n      // Define a model for linear regression.\n      const model = tf.sequential();\n      model.add(tf.layers.dense({units: 1, inputShape: [1]}));\n\n      // Prepare the model for training: Specify the loss and the optimizer.\n      model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n      // Generate some synthetic data for training.\n      const xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);\n      const ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);\n\n      // Train the model using the data.\n      model.fit(xs, ys).then(() => {\n        // Use the model to do inference on a data point the model hasn't seen before:\n        // Open the browser devtools to see the output\n        model.predict(tf.tensor2d([5], [1, 1])).print();\n      });\n    </script>\n  </head>\n\n  <body>\n  </body>\n</html>\n```\n\nOpen up that HTML file in your browser, and the code should run!\n\n### via NPM\n\nAdd TensorFlow.js to your project using <a href=\"https://yarnpkg.com/en/\" target=\"_blank\">yarn</a> <em>or</em> <a href=\"https://docs.npmjs.com/cli/npm\" target=\"_blank\">npm</a>. <b>Note:</b> Because\nwe use ES2017 syntax (such as `import`), this workflow assumes you are using a modern browser or a bundler/transpiler\nto convert your code to something older browsers understand. See our\n<a href='https://github.com/tensorflow/tfjs-examples' target=\"_blank\">examples</a>\nto see how we use <a href=\"https://parceljs.org/\" target=\"_blank\">Parcel</a> to build\nour code. However, you are free to use any build tool that you prefer.\n\n\n\n```js\nimport * as tf from '@tensorflow/tfjs';\n\n// Define a model for linear regression.\nconst model = tf.sequential();\nmodel.add(tf.layers.dense({units: 1, inputShape: [1]}));\n\n// Prepare the model for training: Specify the loss and the optimizer.\nmodel.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n// Generate some synthetic data for training.\nconst xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);\nconst ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);\n\n// Train the model using the data.\nmodel.fit(xs, ys).then(() => {\n  // Use the model to do inference on a data point the model hasn't seen before:\n  model.predict(tf.tensor2d([5], [1, 1])).print();\n});\n```\n\nSee our <a href=\"https://js.tensorflow.org/tutorials/\" target=\"_blank\">tutorials</a>, <a href=\"https://github.com/tensorflow/tfjs-examples\" target=\"_blank\">examples</a>\nand <a href=\"https://js.tensorflow.org/api/latest/\">documentation</a> for more details.\n\n## Importing pre-trained models\n\nWe support porting pre-trained models from:\n- [TensorFlow SavedModel](https://www.tensorflow.org/js/tutorials/conversion/import_saved_model)\n- [Keras](https://js.tensorflow.org/tutorials/import-keras.html)\n\n## Various ops supported in different backends\n\nPlease refer below :\n- [TFJS Ops Matrix](https://docs.google.com/spreadsheets/d/1D25XtWaBrmUEErbGQB0QmNhH-xtwHo9LDl59w0TbxrI/edit#gid=0)\n\n## Find out more\n\n[TensorFlow.js](https://js.tensorflow.org) is a part of the\n[TensorFlow](https://www.tensorflow.org) ecosystem. For more info:\n- For help from the community, use the `tfjs` tag on the [TensorFlow Forum](https://discuss.tensorflow.org/tag/tfjs).\n- [TensorFlow.js Website](https://js.tensorflow.org)\n- [Tutorials](https://js.tensorflow.org/tutorials)\n- [API reference](https://js.tensorflow.org/api/latest/)\n- [TensorFlow.js Blog](https://blog.tensorflow.org/search?label=TensorFlow.js)\n\nThanks, <a href=\"https://www.browserstack.com/\">BrowserStack</a>, for providing testing support.\n",
         "AI_DataScience"
        ],
        [
         "39",
         "R_kgDONDewpg",
         "<p align=\"center\">\n  <a href=\"https://trendshift.io/repositories/12800\">\n    <img src=\"assets/TRENDING-BADGE.png\" alt=\"Trending Badge\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <img src=\"assets/ai-eng-hub.gif\" alt=\"AI Engineering Hub Banner\">\n</p>\n\n---\n\n# AI Engineering Hub üöÄ\nWelcome to the **AI Engineering Hub**!\n\n## üåü Why This Repo?\nAI Engineering is advancing rapidly, and staying at the forefront requires both deep understanding and hands-on experience. Here, you will find:\n- In-depth tutorials on **LLMs and RAGs**\n- Real-world **AI agent** applications\n- Examples to implement, adapt, and scale in your projects\n\nWhether you‚Äôre a beginner, practitioner, or researcher, this repo provides resources for all skill levels to experiment and succeed in AI engineering.\n\n---\n\n## üì¨ Stay Updated with Our Newsletter!\n**Get a FREE Data Science eBook** üìñ with 150+ essential lessons in Data Science when you subscribe to our newsletter! Stay in the loop with the latest tutorials, insights, and exclusive resources. [Subscribe now!](https://join.dailydoseofds.com)\n\n[![Daily Dose of Data Science Newsletter](https://github.com/patchy631/ai-engineering/blob/main/resources/join_ddods.png)](https://join.dailydoseofds.com)\n\n---\n\n## üì¢ Contribute to the AI Engineering Hub!\nWe welcome contributors! Whether you want to add new tutorials, improve existing code, or report issues, your contributions make this community thrive. Here‚Äôs how to get involved:\n1. **Fork** the repository.\n2. Create a new branch for your contribution.\n3. Submit a **Pull Request** and describe the improvements.\n\n---\n\n## üìú License\nThis repository is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## üí¨ Connect\nFor discussions, suggestions, and more, feel free to [create an issue](https://github.com/patchy631/ai-engineering/issues) or reach out directly!\n\nHappy Coding! üéâ\n",
         "AI_DataScience"
        ],
        [
         "40",
         "MDEwOlJlcG9zaXRvcnkxNTY5Mzk2NzI=",
         "<p align=\"center\"><img width=\"50%\" src=\"docs/images/ONNX_Runtime_logo_dark.png\" /></p>\n\n**ONNX Runtime is a cross-platform inference and training machine-learning accelerator**.\n\n**ONNX Runtime inference** can enable faster customer experiences and lower costs, supporting models from deep learning frameworks such as PyTorch and TensorFlow/Keras as well as classical machine learning libraries such as scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different hardware, drivers, and operating systems, and provides optimal performance by leveraging hardware accelerators where applicable alongside graph optimizations and transforms. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-inferencing)\n\n**ONNX Runtime training** can accelerate the model training time on multi-node NVIDIA GPUs for transformer models with a one-line addition for existing PyTorch training scripts. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-training)\n\n## Get Started & Resources\n\n* **General Information**: [onnxruntime.ai](https://onnxruntime.ai)\n\n* **Usage documentation and tutorials**: [onnxruntime.ai/docs](https://onnxruntime.ai/docs)\n\n* **YouTube video tutorials**: [youtube.com/@ONNXRuntime](https://www.youtube.com/@ONNXRuntime)\n\n* [**Upcoming Release Roadmap**](https://onnxruntime.ai/roadmap)\n\n* **Companion sample repositories**:\n  - ONNX Runtime Inferencing: [microsoft/onnxruntime-inference-examples](https://github.com/microsoft/onnxruntime-inference-examples)\n  - ONNX Runtime Training: [microsoft/onnxruntime-training-examples](https://github.com/microsoft/onnxruntime-training-examples)\n\n## Releases\n\nThe current release and past releases can be found here: https://github.com/microsoft/onnxruntime/releases.\n\nFor details on the upcoming release, including release dates, announcements, features, and guidance on submitting feature requests, please visit the release roadmap: https://onnxruntime.ai/roadmap.\n\n## Data/Telemetry\n\nWindows distributions of this project may collect usage data and send it to Microsoft to help improve our products and services. See the [privacy statement](docs/Privacy.md) for more details.\n\n## Contributions and Feedback\n\nWe welcome contributions! Please see the [contribution guidelines](CONTRIBUTING.md).\n\nFor feature requests or bug reports, please file a [GitHub Issue](https://github.com/Microsoft/onnxruntime/issues).\n\nFor general discussion or questions, please use [GitHub Discussions](https://github.com/microsoft/onnxruntime/discussions).\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n\nThis project is licensed under the [MIT License](LICENSE).\n",
         "AI_DataScience"
        ],
        [
         "41",
         "MDEwOlJlcG9zaXRvcnk0NzE4NDMwNA==",
         "# awesome-nlp\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\nA curated list of resources dedicated to Natural Language Processing\n\n![Awesome NLP Logo](/images/logo.jpg)\n\nRead this in [English](./README.md), [Traditional Chinese](./README-ZH-TW.md)\n\n_Please read the [contribution guidelines](contributing.md) before contributing. Please add your favourite NLP resource by raising a [pull request](https://github.com/keonkim/awesome-nlp/pulls)_\n\n## Contents\n\n* [Research Summaries and Trends](#research-summaries-and-trends)\n* [Prominent NLP Research Labs](#prominent-nlp-research-labs)\n* [Tutorials](#tutorials)\n  * [Reading Content](#reading-content)\n  * [Videos and Courses](#videos-and-online-courses)\n  * [Books](#books)\n* [Libraries](#libraries)\n  * [Node.js](#node-js)\n  * [Python](#python)\n  * [C++](#c++)\n  * [Java](#java)\n  * [Kotlin](#kotlin)\n  * [Scala](#scala)\n  * [R](#R)\n  * [Clojure](#clojure)\n  * [Ruby](#ruby)\n  * [Rust](#rust)\n  * [NLP++](#NLP++)\n  * [Julia](#julia)\n* [Services](#services)\n* [Annotation Tools](#annotation-tools)\n* [Datasets](#datasets)\n* [NLP in Korean](#nlp-in-korean)\n* [NLP in Arabic](#nlp-in-arabic)\n* [NLP in Chinese](#nlp-in-chinese)\n* [NLP in German](#nlp-in-german)\n* [NLP in Polish](#nlp-in-polish)\n* [NLP in Spanish](#nlp-in-spanish)\n* [NLP in Indic Languages](#nlp-in-indic-languages)\n* [NLP in Thai](#nlp-in-thai)\n* [NLP in Danish](#nlp-in-danish)\n* [NLP in Vietnamese](#nlp-in-vietnamese)\n* [NLP for Dutch](#nlp-for-dutch)\n* [NLP in Indonesian](#nlp-in-indonesian)\n* [NLP in Urdu](#nlp-in-urdu)\n* [NLP in Persian](#nlp-in-persian)\n* [NLP in Ukrainian](#nlp-in-ukrainian)\n* [NLP in Hungarian](#nlp-in-hungarian)\n* [NLP in Portuguese](#nlp-in-portuguese)\n* [Other Languages](#other-languages)\n* [Credits](#credits)\n\n## Research Summaries and Trends\n\n* [NLP-Overview](https://nlpoverview.com/) is an up-to-date overview of deep learning techniques applied to NLP, including theory, implementations, applications, and state-of-the-art results. This is a great Deep NLP Introduction for researchers.\n* [NLP-Progress](https://nlpprogress.com/) tracks the progress in Natural Language Processing, including the datasets and the current state-of-the-art for the most common NLP tasks\n* [NLP's ImageNet moment has arrived](https://thegradient.pub/nlp-imagenet/)\n* [ACL 2018 Highlights: Understanding Representation and Evaluation in More Challenging Settings](http://ruder.io/acl-2018-highlights/)\n* [Four deep learning trends from ACL 2017. Part One: Linguistic Structure and Word Embeddings](https://www.abigailsee.com/2017/08/30/four-deep-learning-trends-from-acl-2017-part-1.html)\n* [Four deep learning trends from ACL 2017. Part Two: Interpretability and Attention](https://www.abigailsee.com/2017/08/30/four-deep-learning-trends-from-acl-2017-part-2.html)\n* [Highlights of EMNLP 2017: Exciting Datasets, Return of the Clusters, and More!](http://blog.aylien.com/highlights-emnlp-2017-exciting-datasets-return-clusters/)\n* [Deep Learning for Natural Language Processing (NLP): Advancements & Trends](https://tryolabs.com/blog/2017/12/12/deep-learning-for-nlp-advancements-and-trends-in-2017/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI)\n* [Survey of the State of the Art in Natural Language Generation](https://arxiv.org/abs/1703.09902)\n\n## Prominent NLP Research Labs\n[Back to Top](#contents)\n\n* [The Berkeley NLP Group](http://nlp.cs.berkeley.edu/index.shtml) - Notable contributions include a tool to reconstruct long dead languages, referenced [here](https://www.bbc.com/news/science-environment-21427896) and by taking corpora from 637 languages currently spoken in Asia and the Pacific and recreating their descendant.\n* [Language Technologies Institute, Carnegie Mellon University](http://www.cs.cmu.edu/~nasmith/nlp-cl.html) - Notable projects include [Avenue Project](http://www.cs.cmu.edu/~avenue/), a syntax driven machine translation system for endangered languages like Quechua and Aymara and previously, [Noah's Ark](http://www.cs.cmu.edu/~ark/) which created [AQMAR](http://www.cs.cmu.edu/~ark/AQMAR/) to improve NLP tools for Arabic.\n* [NLP research group, Columbia University](http://www1.cs.columbia.edu/nlp/index.cgi) - Responsible for creating BOLT ( interactive error handling for speech translation systems) and an un-named project to characterize laughter in dialogue.\n* [The Center or Language and Speech Processing, John Hopkins University](http://clsp.jhu.edu/) - Recently in the news for developing speech recognition software to create a diagnostic test or Parkinson's Disease, [here](https://www.clsp.jhu.edu/2019/03/27/speech-recognition-software-and-machine-learning-tools-are-being-used-to-create-diagnostic-test-for-parkinsons-disease/#.XNFqrIkzYdU).\n* [Computational Linguistics and Information Processing Group, University of Maryland](https://wiki.umiacs.umd.edu/clip/index.php/Main_Page) - Notable contributions include [Human-Computer Cooperation or Word-by-Word Question Answering](http://www.umiacs.umd.edu/~jbg/projects/IIS-1652666) and modeling development of phonetic representations. \n* [Penn Natural Language Processing, University of Pennsylvania](https://nlp.cis.upenn.edu/)- Famous for creating the [Penn Treebank](https://www.seas.upenn.edu/~pdtb/).\n* [The Stanford Nautral Language Processing Group](https://nlp.stanford.edu/)- One of the top NLP research labs in the world, notable for creating [Stanford CoreNLP](https://nlp.stanford.edu/software/corenlp.shtml) and their [coreference resolution system](https://nlp.stanford.edu/software/dcoref.shtml)\n\n\n## Tutorials\n[Back to Top](#contents)\n\n### Reading Content\n\nGeneral Machine Learning\n\n* [Machine Learning 101](https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/edit?usp=sharing) from Google's Senior Creative Engineer explains Machine Learning for engineer's and executives alike\n* [AI Playbook](https://aiplaybook.a16z.com/) - a16z AI playbook is a great link to forward to your managers or content for your presentations\n* [Ruder's Blog](http://ruder.io/#open) by [Sebastian Ruder](https://twitter.com/seb_ruder) for commentary on the best of NLP Research\n* [How To Label Data](https://www.lighttag.io/how-to-label-data/) guide to managing larger linguistic annotation projects\n* [Depends on the Definition](https://www.depends-on-the-definition.com/) collection of blog posts covering a wide array of NLP topics with detailed implementation\n\nIntroductions and Guides to NLP\n\n* [Understand & Implement Natural Language Processing](https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/)\n* [NLP in Python](http://github.com/NirantK/nlp-python-deep-learning) - Collection of Github notebooks\n* [Natural Language Processing: An Introduction](https://academic.oup.com/jamia/article/18/5/544/829676) - Oxford\n* [Deep Learning for NLP with Pytorch](https://pytorch.org/tutorials/beginner/deep_learning_nlp_tutorial.html)\n* [Hands-On NLTK Tutorial](https://github.com/hb20007/hands-on-nltk-tutorial) - NLTK Tutorials, Jupyter notebooks\n* [Natural Language Processing with Python ‚Äì Analyzing Text with the Natural Language Toolkit](https://www.nltk.org/book/) - An online and print book introducing NLP concepts using NLTK. The book's authors also wrote the NLTK library.\n* [Train a new language model from scratch](https://huggingface.co/blog/how-to-train) - Hugging Face ü§ó\n* [The Super Duper NLP Repo (SDNLPR)](https://notebooks.quantumstat.com/): Collection of Colab notebooks covering a wide array of NLP task implementations.\n\nBlogs and Newsletters\n\n* [Deep Learning, NLP, and Representations](https://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)\n* [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/) and [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n* [Natural Language Processing](https://nlpers.blogspot.com/) by Hal Daum√© III\n* [arXiv: Natural Language Processing (Almost) from Scratch](https://arxiv.org/pdf/1103.0398.pdf)\n* [Karpathy's The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness)\n* [Machine Learning Mastery: Deep Learning for Natural Language Processing](https://machinelearningmastery.com/category/natural-language-processing)\n* [Visual NLP Paper Summaries](https://amitness.com/categories/#nlp)\n\n### Videos and Online Courses\n[Back to Top](#contents)\n\n* [Advanced Natural Language Processing](https://people.cs.umass.edu/~miyyer/cs685_f20/) - CS 685, UMass Amherst CS\n* [Deep Natural Language Processing](https://github.com/oxford-cs-deepnlp-2017/lectures) - Lectures series from Oxford\n* [Deep Learning for Natural Language Processing (cs224-n)](https://web.stanford.edu/class/cs224n/) - Richard Socher and Christopher Manning's Stanford Course\n* [Neural Networks for NLP](http://phontron.com/class/nn4nlp2017/) - Carnegie Mellon Language Technology Institute there\n* [Deep NLP Course](https://github.com/yandexdataschool/nlp_course) by Yandex Data School, covering important ideas from text embedding to machine translation including sequence modeling, language models and so on.\n* [fast.ai Code-First Intro to Natural Language Processing](https://www.fast.ai/2019/07/08/fastai-nlp/) - This covers a blend of traditional NLP topics (including regex, SVD, naive bayes, tokenization) and recent neural network approaches (including RNNs, seq2seq, GRUs, and the Transformer), as well as addressing urgent ethical issues, such as bias and disinformation. Find the Jupyter Notebooks [here](https://github.com/fastai/course-nlp)\n* [Machine Learning University - Accelerated Natural Language Processing](https://www.youtube.com/playlist?list=PL8P_Z6C4GcuWfAq8Pt6PBYlck4OprHXsw) - Lectures go from introduction to NLP and text processing to Recurrent Neural Networks and Transformers.\nMaterial can be found [here](https://github.com/aws-samples/aws-machine-learning-university-accelerated-nlp).\n* [Applied Natural Language Processing](https://www.youtube.com/playlist?list=PLH-xYrxjfO2WyR3pOAB006CYMhNt4wTqp)- Lecture series from IIT Madras taking from the basics all the way to autoencoders and everything. The github notebooks for this course are also available [here](https://github.com/Ramaseshanr/anlp)\n\n\n### Books\n\n* [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/) - free, by Prof. Dan Jurafsy\n* [Natural Language Processing](https://github.com/jacobeisenstein/gt-nlp-class) - free, NLP notes by Dr. Jacob Eisenstein at GeorgiaTech\n* [NLP with PyTorch](https://github.com/joosthub/PyTorchNLPBook) - Brian & Delip Rao\n* [Text Mining in R](https://www.tidytextmining.com)\n* [Natural Language Processing with Python](https://www.nltk.org/book/)\n* [Practical Natural Language Processing](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/)\n* [Natural Language Processing with Spark NLP](https://www.oreilly.com/library/view/natural-language-processing/9781492047759/)\n* [Deep Learning for Natural Language Processing](https://www.manning.com/books/deep-learning-for-natural-language-processing) by Stephan Raaijmakers\n* [Real-World Natural Language Processing](https://www.manning.com/books/real-world-natural-language-processing) - by Masato Hagiwara\n* [Natural Language Processing in Action, Second Edition](https://www.manning.com/books/natural-language-processing-in-action-second-edition) - by Hobson Lane and Maria Dyshel\n## Libraries\n\n[Back to Top](#contents)\n\n* <a id=\"node-js\">**Node.js and Javascript** - Node.js Libaries for NLP</a> | [Back to Top](#contents)\n  * [Twitter-text](https://github.com/twitter/twitter-text) - A JavaScript implementation of Twitter's text processing library\n  * [Knwl.js](https://github.com/benhmoore/Knwl.js) - A Natural Language Processor in JS\n  * [Retext](https://github.com/retextjs/retext) - Extensible system for analyzing and manipulating natural language\n  * [NLP Compromise](https://github.com/spencermountain/compromise) - Natural Language processing in the browser\n  * [Natural](https://github.com/NaturalNode/natural) - general natural language facilities for node\n  * [Poplar](https://github.com/synyi/poplar) - A web-based annotation tool for natural language processing (NLP)\n  * [NLP.js](https://github.com/axa-group/nlp.js) - An NLP library for building bots\n  * [node-question-answering](https://github.com/huggingface/node-question-answering) - Fast and production-ready question answering w/ DistilBERT in Node.js\n\n* <a id=\"python\"> **Python** - Python NLP Libraries</a> | [Back to Top](#contents)\n  - [sentimental-onix](https://github.com/sloev/sentimental-onix) Sentiment models for spacy using onnx\n  - [TextAttack](https://github.com/QData/TextAttack) - Adversarial attacks, adversarial training, and data augmentation in NLP\n  - [TextBlob](http://textblob.readthedocs.org/) - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of [Natural Language Toolkit (NLTK)](https://www.nltk.org/) and [Pattern](https://github.com/clips/pattern), and plays nicely with both :+1:\n  - [spaCy](https://github.com/explosion/spaCy) - Industrial strength NLP with Python and Cython :+1:\n  - [Speedster](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/speedster) - Automatically apply SOTA optimization techniques to achieve the maximum inference speed-up on your hardware\n    - [textacy](https://github.com/chartbeat-labs/textacy) - Higher level NLP built on spaCy\n  - [gensim](https://radimrehurek.com/gensim/index.html) - Python library to conduct unsupervised semantic modelling from plain text :+1:\n  - [scattertext](https://github.com/JasonKessler/scattertext) - Python library to produce d3 visualizations of how language differs between corpora\n  - [GluonNLP](https://github.com/dmlc/gluon-nlp) - A deep learning toolkit for NLP, built on MXNet/Gluon, for research prototyping and industrial deployment of state-of-the-art models on a wide range of NLP tasks.\n  - [AllenNLP](https://github.com/allenai/allennlp) - An NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.\n  - [PyTorch-NLP](https://github.com/PetrochukM/PyTorch-NLP) - NLP research toolkit designed to support rapid prototyping with better data loaders, word vector loaders, neural network layer representations, common NLP metrics such as BLEU\n  - [Rosetta](https://github.com/columbia-applied-data-science/rosetta) - Text processing tools and wrappers (e.g. Vowpal Wabbit)\n  - [PyNLPl](https://github.com/proycon/pynlpl) - Python Natural Language Processing Library. General purpose NLP library for Python, handles some specific formats like ARPA language models, Moses phrasetables, GIZA++ alignments.\n  - [foliapy](https://github.com/proycon/foliapy) - Python library for working with [FoLiA](https://proycon.github.io/folia/), an XML format for linguistic annotation.\n  - [PySS3](https://github.com/sergioburdisso/pyss3) - Python package that implements a novel white-box machine learning model for text classification, called SS3. Since SS3 has the ability to visually explain its rationale, this package also comes with easy-to-use interactive visualizations tools ([online demos](http://tworld.io/ss3/)).\n  - [jPTDP](https://github.com/datquocnguyen/jPTDP) - A toolkit for joint part-of-speech (POS) tagging and dependency parsing. jPTDP provides pre-trained models for 40+ languages.\n  - [BigARTM](https://github.com/bigartm/bigartm) - a fast library for topic modelling\n  - [Snips NLU](https://github.com/snipsco/snips-nlu) - A production ready library for intent parsing\n  - [Chazutsu](https://github.com/chakki-works/chazutsu) - A library for downloading&parsing standard NLP research datasets\n  - [Word Forms](https://github.com/gutfeeling/word_forms) - Word forms can accurately generate all possible forms of an English word\n  - [Multilingual Latent Dirichlet Allocation (LDA)](https://github.com/ArtificiAI/Multilingual-Latent-Dirichlet-Allocation-LDA) - A multilingual and extensible document clustering pipeline\n  - [Natural Language Toolkit (NLTK)](https://www.nltk.org/) - A library containing a wide variety of NLP functionality, supporting over 50 corpora.\n  - [NLP Architect](https://github.com/NervanaSystems/nlp-architect) - A library for exploring the state-of-the-art deep learning topologies and techniques for NLP and NLU\n  - [Flair](https://github.com/zalandoresearch/flair) - A very simple framework for state-of-the-art multilingual NLP built on PyTorch. Includes BERT, ELMo and Flair embeddings.\n  - [Kashgari](https://github.com/BrikerMan/Kashgari) - Simple, Keras-powered multilingual NLP framework, allows you to build your models in 5 minutes for named entity recognition (NER), part-of-speech tagging (PoS) and text classification tasks. Includes BERT and word2vec embedding.\n  - [FARM](https://github.com/deepset-ai/FARM) - Fast & easy transfer learning for NLP. Harvesting language models for the industry. Focus on Question Answering.\n  - [Haystack](https://github.com/deepset-ai/haystack) - End-to-end Python framework for building natural language search interfaces to data. Leverages Transformers and the State-of-the-Art of NLP. Supports DPR, Elasticsearch, HuggingFace‚Äôs Modelhub, and much more!\n  - [Rita DSL](https://github.com/zaibacu/rita-dsl) - a DSL, loosely based on [RUTA on Apache UIMA](https://uima.apache.org/ruta.html). Allows to define language patterns (rule-based NLP) which are then translated into [spaCy](https://spacy.io/), or if you prefer less features and lightweight - regex patterns.\n  - [Transformers](https://github.com/huggingface/transformers) - Natural Language Processing for TensorFlow 2.0 and PyTorch.\n  - [Tokenizers](https://github.com/huggingface/tokenizers) - Tokenizers optimized for Research and Production.\n  - [fairSeq](https://github.com/pytorch/fairseq) Facebook AI Research implementations of SOTA seq2seq models in Pytorch. \n  - [corex_topic](https://github.com/gregversteeg/corex_topic) - Hierarchical Topic Modeling with Minimal Domain Knowledge\n  - [Sockeye](https://github.com/awslabs/sockeye) - Neural Machine Translation (NMT) toolkit that powers Amazon Translate.\n  - [DL Translate](https://github.com/xhlulu/dl-translate) - A deep learning-based translation library for 50 languages, built on `transformers` and Facebook's mBART Large.\n  - [Jury](https://github.com/obss/jury) - Evaluation of NLP model outputs offering various automated metrics.\n  - [python-ucto](https://github.com/proycon/python-ucto) - Unicode-aware regular-expression based tokenizer for various languages. Python binding to C++ library, supports [FoLiA format](https://proycon.github.io/folia).\n\n- <a id=\"c++\">**C++** - C++ Libraries</a> | [Back to Top](#contents)\n  - [InsNet](https://github.com/chncwang/InsNet) - A neural network library for building instance-dependent NLP models with padding-free dynamic batching.\n  - [MIT Information Extraction Toolkit](https://github.com/mit-nlp/MITIE) - C, C++, and Python tools for named entity recognition and relation extraction\n  - [CRF++](https://taku910.github.io/crfpp/) - Open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data & other Natural Language Processing tasks.\n  - [CRFsuite](http://www.chokkan.org/software/crfsuite/) - CRFsuite is an implementation of Conditional Random Fields (CRFs) for labeling sequential data.\n  - [BLLIP Parser](https://github.com/BLLIP/bllip-parser) - BLLIP Natural Language Parser (also known as the Charniak-Johnson parser)\n  - [colibri-core](https://github.com/proycon/colibri-core) - C++ library, command line tools, and Python binding for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.\n  - [ucto](https://github.com/LanguageMachines/ucto) - Unicode-aware regular-expression based tokenizer for various languages. Tool and C++ library. Supports FoLiA format.\n  - [libfolia](https://github.com/LanguageMachines/libfolia) - C++ library for the [FoLiA format](https://proycon.github.io/folia/)\n  - [frog](https://github.com/LanguageMachines/frog) - Memory-based NLP suite developed for Dutch: PoS tagger, lemmatiser, dependency parser, NER, shallow parser, morphological analyzer.\n  - [MeTA](https://github.com/meta-toolkit/meta) - [MeTA : ModErn Text Analysis](https://meta-toolkit.org/) is a C++ Data Sciences Toolkit that facilitates mining big text data.\n  - [Mecab (Japanese)](https://taku910.github.io/mecab/)\n  - [Moses](http://statmt.org/moses/)\n  - [StarSpace](https://github.com/facebookresearch/StarSpace) - a library from Facebook for creating embeddings of word-level, paragraph-level, document-level and for text classification\n\n- <a id=\"java\">**Java** - Java NLP Libraries</a> | [Back to Top](#contents)\n  - [Stanford NLP](https://nlp.stanford.edu/software/index.shtml)\n  - [OpenNLP](https://opennlp.apache.org/)\n  - [NLP4J](https://emorynlp.github.io/nlp4j/)\n  - [Word2vec in Java](https://deeplearning4j.org/docs/latest/deeplearning4j-nlp-word2vec)\n  - [ReVerb](https://github.com/knowitall/reverb/) Web-Scale Open Information Extraction\n  - [OpenRegex](https://github.com/knowitall/openregex) An efficient and flexible token-based regular expression language and engine.\n  - [CogcompNLP](https://github.com/CogComp/cogcomp-nlp) - Core libraries developed in the U of Illinois' Cognitive Computation Group.\n  - [MALLET](http://mallet.cs.umass.edu/) - MAchine Learning for LanguagE Toolkit - package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text.\n  - [RDRPOSTagger](https://github.com/datquocnguyen/RDRPOSTagger) - A robust POS tagging toolkit available (in both Java & Python) together with pre-trained models for 40+ languages.\n\n- <a id=\"kotlin\">**Kotlin** - Kotlin NLP Libraries</a> | [Back to Top](#contents)\n  - [Lingua](https://github.com/pemistahl/lingua/) A language detection library for Kotlin and Java, suitable for long and short text alike\n  - [Kotidgy](https://github.com/meiblorn/kotidgy) ‚Äî an index-based text data generator written in Kotlin\n\n- <a id=\"scala\">**Scala** - Scala NLP Libraries</a> | [Back to Top](#contents)\n  - [Saul](https://github.com/CogComp/saul) - Library for developing NLP systems, including built in modules like SRL, POS, etc.\n  - [ATR4S](https://github.com/ispras/atr4s) - Toolkit with state-of-the-art [automatic term recognition](https://en.wikipedia.org/wiki/Terminology_extraction) methods.\n  - [tm](https://github.com/ispras/tm) - Implementation of topic modeling based on regularized multilingual [PLSA](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis).\n  - [word2vec-scala](https://github.com/Refefer/word2vec-scala) - Scala interface to word2vec model; includes operations on vectors like word-distance and word-analogy.\n  - [Epic](https://github.com/dlwh/epic) - Epic is a high performance statistical parser written in Scala, along with a framework for building complex structured prediction models.\n  - [Spark NLP](https://github.com/JohnSnowLabs/spark-nlp) - Spark NLP is a natural language processing library built on top of Apache Spark ML that provides simple, performant & accurate NLP annotations for machine learning pipelines that scale easily in a distributed environment.\n\n- <a id=\"R\">**R** - R NLP Libraries</a> | [Back to Top](#contents)\n  - [text2vec](https://github.com/dselivanov/text2vec) - Fast vectorization, topic modeling, distances and GloVe word embeddings in R.\n  - [wordVectors](https://github.com/bmschmidt/wordVectors) - An R package for creating and exploring word2vec and other word embedding models\n  - [RMallet](https://github.com/mimno/RMallet) - R package to interface with the Java machine learning tool MALLET\n  - [dfr-browser](https://github.com/agoldst/dfr-browser) - Creates d3 visualizations for browsing topic models of text in a web browser.\n  - [dfrtopics](https://github.com/agoldst/dfrtopics) - R package for exploring topic models of text.\n  - [sentiment_classifier](https://github.com/kevincobain2000/sentiment_classifier) - Sentiment Classification using Word Sense Disambiguation and WordNet Reader\n  - [jProcessing](https://github.com/kevincobain2000/jProcessing) - Japanese Natural Langauge Processing Libraries, with Japanese sentiment classification\n  - [corporaexplorer](https://kgjerde.github.io/corporaexplorer/) - An R package for dynamic exploration of text collections\n  - [tidytext](https://github.com/juliasilge/tidytext) - Text mining using tidy tools\n  - [spacyr](https://github.com/quanteda/spacyr) - R wrapper to spaCy NLP\n  - [CRAN Task View: Natural Language Processing](https://github.com/cran-task-views/NaturalLanguageProcessing/)\n\n- <a id=\"clojure\">**Clojure**</a> | [Back to Top](#contents)\n  - [Clojure-openNLP](https://github.com/dakrone/clojure-opennlp) - Natural Language Processing in Clojure (opennlp)\n  - [Infections-clj](https://github.com/r0man/inflections-clj) - Rails-like inflection library for Clojure and ClojureScript\n  - [postagga](https://github.com/fekr/postagga) - A library to parse natural language in Clojure and ClojureScript\n\n- <a id=\"ruby\">**Ruby**</a> | [Back to Top](#contents)\n  - Kevin Dias's [A collection of Natural Language Processing (NLP) Ruby libraries, tools and software](https://github.com/diasks2/ruby-nlp)\n  - [Practical Natural Language Processing done in Ruby](https://github.com/arbox/nlp-with-ruby)\n\n- <a id=\"rust\">**Rust**</a> | [Back to Top](#contents)\n  - [whatlang](https://github.com/greyblake/whatlang-rs) ‚Äî Natural language recognition library based on trigrams\n  - [snips-nlu-rs](https://github.com/snipsco/snips-nlu-rs) - A production ready library for intent parsing\n  - [rust-bert](https://github.com/guillaume-be/rust-bert) - Ready-to-use NLP pipelines and Transformer-based models\n\n- <a id=\"NLP++\">**NLP++** - NLP++ Language</a> | [Back to Top](#contents)\n  - [VSCode Language Extension](https://marketplace.visualstudio.com/items?itemName=dehilster.nlp) - NLP++ Language Extension for VSCode\n  - [nlp-engine](https://github.com/VisualText/nlp-engine) - NLP++ engine to run NLP++ code on Linux including a full English parser\n  - [VisualText](http://visualtext.org) - Homepage for the NLP++ Language\n  - [NLP++ Wiki](http://wiki.naturalphilosophy.org/index.php?title=NLP%2B%2B) - Wiki entry for the NLP++ language\n\n- <a id=\"julia\">**Julia**</a> | [Back to Top](#contents)\n  - [CorpusLoaders](https://github.com/JuliaText/CorpusLoaders.jl) - A variety of loaders for various NLP corpora\n  - [Languages](https://github.com/JuliaText/Languages.jl) - A package for working with human languages\n  - [TextAnalysis](https://github.com/JuliaText/TextAnalysis.jl) - Julia package for text analysis\n  - [TextModels](https://github.com/JuliaText/TextModels.jl) - Neural Network based models for Natural Language Processing\n  - [WordTokenizers](https://github.com/JuliaText/WordTokenizers.jl) - High performance tokenizers for natural language processing and other related tasks\n  - [Word2Vec](https://github.com/JuliaText/Word2Vec.jl) - Julia interface to word2vec\n\n### Services\n\nNLP as API with higher level functionality such as NER, Topic tagging and so on | [Back to Top](#contents)\n\n- [Wit-ai](https://github.com/wit-ai/wit) - Natural Language Interface for apps and devices\n- [IBM Watson's Natural Language Understanding](https://github.com/watson-developer-cloud/natural-language-understanding-nodejs) - API and Github demo\n- [Amazon Comprehend](https://aws.amazon.com/comprehend/) - NLP and ML suite covers most common tasks like NER, tagging, and sentiment analysis\n- [Google Cloud Natural Language API](https://cloud.google.com/natural-language/) - Syntax Analysis, NER, Sentiment Analysis, and Content tagging in atleast 9 languages include English and Chinese (Simplified and Traditional).\n- [ParallelDots](https://www.paralleldots.com/text-analysis-apis) - High level Text Analysis API Service ranging from Sentiment Analysis to Intent Analysis\n- [Microsoft Cognitive Service](https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/)\n- [TextRazor](https://www.textrazor.com/)\n- [Rosette](https://www.rosette.com/)\n- [Textalytic](https://www.textalytic.com) - Natural Language Processing in the Browser with sentiment analysis, named entity extraction, POS tagging, word frequencies, topic modeling, word clouds, and more\n- [NLP Cloud](https://nlpcloud.io) - SpaCy NLP models (custom and pre-trained ones) served through a RESTful API for named entity recognition (NER), POS tagging, and more.\n- [Cloudmersive](https://cloudmersive.com/nlp-api) - Unified and free NLP APIs that perform actions such as speech tagging, text rephrasing, language translation/detection, and sentence parsing\n\n### Annotation Tools\n\n- [GATE](https://gate.ac.uk/overview.html) - General Architecture and Text Engineering is 15+ years old, free and open source\n- [Anafora](https://github.com/weitechen/anafora) is free and open source, web-based raw text annotation tool\n- [brat](https://brat.nlplab.org/) - brat rapid annotation tool is an online environment for collaborative text annotation\n- [doccano](https://github.com/chakki-works/doccano) - doccano is free, open-source, and provides annotation features for text classification, sequence labeling and sequence to sequence\n- [INCEpTION](https://inception-project.github.io) - A semantic annotation platform offering intelligent assistance and knowledge management\n- [tagtog](https://www.tagtog.net/), team-first web tool to find, create, maintain, and share datasets - costs $\n- [prodigy](https://prodi.gy/) is an annotation tool powered by active learning, costs $\n- [LightTag](https://lighttag.io) - Hosted and managed text annotation tool for teams, costs $\n- [rstWeb](https://corpling.uis.georgetown.edu/rstweb/info/) - open source local or online tool for discourse tree annotations\n- [GitDox](https://corpling.uis.georgetown.edu/gitdox/) - open source server annotation tool with GitHub version control and validation for XML data and collaborative spreadsheet grids\n- [Label Studio](https://www.heartex.ai/) - Hosted and managed text annotation tool for teams, freemium based, costs $\n- [Datasaur](https://datasaur.ai/) support various NLP tasks for individual or teams, freemium based\n- [Konfuzio](https://konfuzio.com/en/) - team-first hosted and on-prem text, image and PDF annotation tool powered by active learning, freemium based, costs $\n- [UBIAI](https://ubiai.tools/) - Easy-to-use text annotation tool for teams with most comprehensive auto-annotation features. Supports NER, relations and document classification as well as OCR annotation for invoice labeling, costs $\n- [Shoonya](https://github.com/AI4Bharat/Shoonya-Backend) - Shoonya is free and open source data annotation platform with wide varities of organization and workspace level management system. Shoonya is data agnostic, can be used by teams to annotate data with various level of verification stages at scale.\n- [Annotation Lab](https://www.johnsnowlabs.com/annotation-lab/) - Free End-to-End No-Code platform for text annotation and DL model training/tuning. Out-of-the-box support for Named Entity Recognition, Classification, Relation extraction and Assertion Status Spark NLP models. Unlimited support for users, teams, projects, documents. Not FOSS. \n- [FLAT](https://github.com/proycon/flat) - FLAT is a web-based linguistic annotation environment based around the [FoLiA format](http://proycon.github.io/folia), a rich XML-based format for linguistic annotation. Free and open source.\n\n\n## Techniques\n\n### Text Embeddings\n\n#### Word Embeddings\n\n- Thumb Rule: **fastText >> GloVe > word2vec**\n\n- [word2vec](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) - [implementation](https://code.google.com/archive/p/word2vec/) - [explainer blog](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)\n- [glove](https://nlp.stanford.edu/pubs/glove.pdf) - [explainer blog](https://blog.acolyer.org/2016/04/22/glove-global-vectors-for-word-representation/)\n- fasttext - [implementation](https://github.com/facebookresearch/fastText) - [paper](https://arxiv.org/abs/1607.04606) - [explainer blog](https://towardsdatascience.com/fasttext-under-the-hood-11efc57b2b3)\n\n#### Sentence and Language Model Based Word Embeddings\n\n[Back to Top](#contents)\n\n- ElMo - [Deep Contextualized Word Representations](https://arxiv.org/abs/1802.05365) - [PyTorch implmentation](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md) - [TF Implementation](https://github.com/allenai/bilm-tf)\n- ULMFiT - [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146) by Jeremy Howard and Sebastian Ruder\n- InferSent - [Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](https://arxiv.org/abs/1705.02364) by facebook\n- CoVe - [Learned in Translation: Contextualized Word Vectors](https://arxiv.org/abs/1708.00107)\n- Pargraph vectors - from [Distributed Representations of Sentences and Documents](https://cs.stanford.edu/~quocle/paragraph_vector.pdf). See [doc2vec tutorial at gensim](https://rare-technologies.com/doc2vec-tutorial/)\n- [sense2vec](https://arxiv.org/abs/1511.06388) - on word sense disambiguation\n- [Skip Thought Vectors](https://arxiv.org/abs/1506.06726) - word representation method\n- [Adaptive skip-gram](https://arxiv.org/abs/1502.07257) - similar approach, with adaptive properties\n- [Sequence to Sequence Learning](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) - word vectors for machine translation\n\n### Question Answering and Knowledge Extraction\n\n[Back to Top](#contents)\n\n- [DrQA](https://github.com/facebookresearch/DrQA) - Open Domain Question Answering work by Facebook Research on Wikipedia data\n- [Document-QA](https://github.com/allenai/document-qa) - Simple and Effective Multi-Paragraph Reading Comprehension by AllenAI\n- [Template-Based Information Extraction without the Templates](https://www.usna.edu/Users/cs/nchamber/pubs/acl2011-chambers-templates.pdf)\n- [Privee: An Architecture for Automatically Analyzing Web Privacy Policies](https://www.sebastianzimmeck.de/zimmeckAndBellovin2014Privee.pdf)\n\n## Datasets\n\n[Back to Top](#contents)\n\n- [nlp-datasets](https://github.com/niderhoff/nlp-datasets) great collection of nlp datasets\n- [gensim-data](https://github.com/RaRe-Technologies/gensim-data) - Data repository for pretrained NLP models and NLP corpora.\n- [tiny_qa_benchmark_pp](https://github.com/vincentkoc/tiny_qa_benchmark_pp/) - Repository of tiny NLP multi-lingual QA datasets and library to generate your own synthetic copies.\n\n## Multilingual NLP Frameworks\n\n[Back to Top](#contents)\n\n- [UDPipe](https://github.com/ufal/udpipe) is a trainable pipeline for tokenizing, tagging, lemmatizing and parsing Universal Treebanks and other CoNLL-U files. Primarily written in C++, offers a fast and reliable solution for multilingual NLP processing.\n- [NLP-Cube](https://github.com/adobe/NLP-Cube) : Natural Language Processing Pipeline - Sentence Splitting, Tokenization, Lemmatization, Part-of-speech Tagging and Dependency Parsing. New platform, written in Python with Dynet 2.0. Offers standalone (CLI/Python bindings) and server functionality (REST API).\n- [UralicNLP](https://github.com/mikahama/uralicNLP) is an NLP library mostly for many endangered Uralic languages such as Sami languages, Mordvin languages, Mari languages, Komi languages and so on. Also some non-endangered languages are supported such as Finnish together with non-Uralic languages such as Swedish and Arabic. UralicNLP can do morphological analysis, generation, lemmatization and disambiguation.\n\n## NLP in Korean\n\n[Back to Top](#contents)\n\n### Libraries\n\n- [KoNLPy](http://konlpy.org) - Python package for Korean natural language processing.\n- [Mecab (Korean)](https://eunjeon.blogspot.com/) - C++ library for Korean NLP\n- [KoalaNLP](https://koalanlp.github.io/koalanlp/) - Scala library for Korean Natural Language Processing.\n- [KoNLP](https://cran.r-project.org/package=KoNLP) - R package for Korean Natural language processing\n\n### Blogs and Tutorials\n\n- [dsindex's blog](https://dsindex.github.io/)\n- [Kangwon University's NLP course in Korean](http://cs.kangwon.ac.kr/~leeck/NLP/)\n\n### Datasets\n\n- [KAIST Corpus](http://semanticweb.kaist.ac.kr/home/index.php/KAIST_Corpus) - A corpus from the Korea Advanced Institute of Science and Technology in Korean.\n- [Naver Sentiment Movie Corpus in Korean](https://github.com/e9t/nsmc/)\n- [Chosun Ilbo archive](http://srchdb1.chosun.com/pdf/i_archive/) - dataset in Korean from one of the major newspapers in South Korea, the Chosun Ilbo.\n- [Chat data](https://github.com/songys/Chatbot_data) - Chatbot data in Korean\n- [Petitions](https://github.com/akngs/petitions) - Collect expired petition data from the Blue House National Petition Site.\n- [Korean Parallel corpora](https://github.com/j-min/korean-parallel-corpora) - Neural Machine Translation(NMT) Dataset for **Korean to French** & **Korean to English**\n- [KorQuAD](https://korquad.github.io/) - Korean SQuAD dataset with Wiki HTML source. Mentions both v1.0 and v2.1 at the time of adding to Awesome NLP\n\n## NLP in Arabic\n\n[Back to Top](#contents)\n\n### Libraries\n\n- [goarabic](https://github.com/01walid/goarabic) - Go package for Arabic text processing\n- [jsastem](https://github.com/ejtaal/jsastem) - Javascript for Arabic stemming\n- [PyArabic](https://pypi.org/project/PyArabic/) - Python libraries for Arabic\n- [RFTokenizer](https://github.com/amir-zeldes/RFTokenizer) - trainable Python segmenter for Arabic, Hebrew and Coptic\n\n### Datasets\n\n- [Multidomain Datasets](https://github.com/hadyelsahar/large-arabic-sentiment-analysis-resouces) - Largest Available Multi-Domain Resources for Arabic Sentiment Analysis\n- [LABR](https://github.com/mohamedadaly/labr) - LArge Arabic Book Reviews dataset\n- [Arabic Stopwords](https://github.com/mohataher/arabic-stop-words) - A list of Arabic stopwords from various resources\n\n## NLP in Chinese\n\n[Back to Top](#contents)\n\n### Libraries\n\n- [jieba](https://github.com/fxsjy/jieba#jieba-1) - Python package for Words Segmentation Utilities in Chinese\n- [SnowNLP](https://github.com/isnowfy/snownlp) - Python package for Chinese NLP\n- [FudanNLP](https://github.com/FudanNLP/fnlp) - Java library for Chinese text processing\n- [HanLP](https://github.com/hankcs/HanLP) - The multilingual NLP library\n\n### Anthology\n- [funNLP](https://github.com/fighting41love/funNLP) - Collection of NLP tools and resources mainly for Chinese\n\n## NLP in German\n\n- [German-NLP](https://github.com/adbar/German-NLP) - Curated list of open-access/open-source/off-the-shelf resources and tools developed with a particular focus on German\n\n## NLP in Polish\n\n- [Polish-NLP](https://github.com/ksopyla/awesome-nlp-polish) - A curated list of resources dedicated to Natural Language Processing (NLP) in polish. Models, tools, datasets.\n\n## NLP in Spanish\n\n[Back to Top](#contents)\n\n### Libraries\n\n- [spanlp](https://github.com/jfreddypuentes/spanlp) - Python library to detect, censor and clean profanity, vulgarities, hateful words, racism, xenophobia and bullying in texts written in Spanish. It contains data of 21 Spanish-speaking countries.\n\n### Data\n\n- [Columbian Political Speeches](https://github.com/dav009/LatinamericanTextResources)\n- [Copenhagen Treebank](https://mbkromann.github.io/copenhagen-dependency-treebank/)\n- [Spanish Billion words corpus with Word2Vec embeddings](https://github.com/crscardellino/sbwce)\n- [Compilation of Spanish Unannotated Corpora](https://github.com/josecannete/spanish-unannotated-corpora)\n\n### Word and Sentence Embeddings\n- [Spanish Word Embeddings Computed with Different Methods and from Different Corpora](https://github.com/dccuchile/spanish-word-embeddings)\n- [Spanish Word Embeddings Computed from Large Corpora and Different Sizes Using fastText](https://github.com/BotCenter/spanishWordEmbeddings)\n- [Spanish Sentence Embeddings Computed from Large Corpora Using sent2vec](https://github.com/BotCenter/spanishSent2Vec)\n- [Beto - BERT for Spanish](https://github.com/dccuchile/beto)\n\n\n## NLP in Indic languages\n\n[Back to Top](#contents)\n\n### Data, Corpora and Treebanks\n\n- [Hindi Dependency Treebank](https://ltrc.iiit.ac.in/treebank_H2014/) - A multi-representational multi-layered treebank for Hindi and Urdu\n- [Universal Dependencies Treebank in Hindi](https://universaldependencies.org/treebanks/hi_hdtb/index.html)\n  - [Parallel Universal Dependencies Treebank in Hindi](http://universaldependencies.org/treebanks/hi_pud/index.html) - A smaller part of the above-mentioned treebank.\n- [ISI FIRE Stopwords List (Hindi and Bangla)](https://www.isical.ac.in/~fire/data/)\n- [Peter Graham's Stopwords List](https://github.com/6/stopwords-json)\n- [NLTK Corpus](https://www.nltk.org/book/ch02.html) 60k Words POS Tagged, Bangla, Hindi, Marathi, Telugu\n- [Hindi Movie Reviews Dataset](https://github.com/goru001/nlp-for-hindi) ~1k Samples, 3 polarity classes\n- [BBC News Hindi Dataset](https://github.com/NirantK/hindi2vec/releases/tag/bbc-hindi-v0.1) 4.3k Samples, 14 classes\n- [IIT Patna Hindi ABSA Dataset](https://github.com/pnisarg/ABSA) 5.4k Samples, 12 Domains, 4k aspect terms, aspect and sentence level polarity in 4 classes\n- [Bangla ABSA](https://github.com/AtikRahman/Bangla_Datasets_ABSA) 5.5k Samples, 2 Domains, 10 aspect terms\n- [IIT Patna Movie Review Sentiment Dataset](https://www.iitp.ac.in/~ai-nlp-ml/resources.html) 2k Samples, 3 polarity labels\n\n#### Corpora/Datasets that need a login/access can be gained via email\n\n- [SAIL 2015](http://amitavadas.com/SAIL/) Twitter and Facebook labelled sentiment samples in Hindi, Bengali, Tamil, Telugu.\n- [IIT Bombay NLP Resources](http://www.cfilt.iitb.ac.in/Sentiment_Analysis_Resources.html) Sentiwordnet, Movie and Tourism parallel labelled corpora, polarity labelled sense annotated corpus, Marathi polarity labelled corpus.\n- [TDIL-IC aggregates a lot of useful resources and provides access to otherwise gated datasets](https://tdil-dc.in/index.php?option=com_catalogue&task=viewTools&id=83&lang=en)\n\n### Language Models and Word Embeddings\n\n- [Hindi2Vec](https://nirantk.com/hindi2vec/) and [nlp-for-hindi](https://github.com/goru001/nlp-for-hindi) ULMFIT style languge model\n- [IIT Patna Bilingual Word Embeddings Hi-En](https://www.iitp.ac.in/~ai-nlp-ml/resources.html)\n- [Fasttext word embeddings in a whole bunch of languages, trained on Common Crawl](https://fasttext.cc/docs/en/crawl-vectors.html)\n- [Hindi and Bengali Word2Vec](https://github.com/Kyubyong/wordvectors)\n- [Hindi and Urdu Elmo Model](https://github.com/HIT-SCIR/ELMoForManyLangs)\n- [Sanskrit Albert](https://huggingface.co/surajp/albert-base-sanskrit) Trained on Sanskrit Wikipedia and OSCAR corpus\n\n### Libraries and Tooling\n\n- [Multi-Task Deep Morphological Analyzer](https://github.com/Saurav0074/mt-dma) Deep Network based Morphological Parser for Hindi and Urdu\n- [Anoop Kunchukuttan](https://github.com/anoopkunchukuttan/indic_nlp_library) 18 Languages, whole host of features from tokenization to translation\n- [SivaReddy's Dependency Parser](http://sivareddy.in/downloads) Dependency Parser and Pos Tagger for Kannada, Hindi and Telugu. [Python3 Port](https://github.com/CalmDownKarm/sivareddydependencyparser)\n- [iNLTK](https://github.com/goru001/inltk) - A Natural Language Toolkit for Indic Languages (Indian subcontinent languages) built on top of Pytorch/Fastai, which aims to provide out of the box support for common NLP tasks.\n\n## NLP in Thai\n\n[Back to Top](#contents)\n\n### Libraries\n\n- [PyThaiNLP](https://github.com/PyThaiNLP/pythainlp) - Thai NLP in Python Package\n- [JTCC](https://github.com/wittawatj/jtcc) - A character cluster library in Java\n- [CutKum](https://github.com/pucktada/cutkum) - Word segmentation with deep learning in TensorFlow\n- [Thai Language Toolkit](https://pypi.python.org/pypi/tltk/) - Based on a paper by Wirote Aroonmanakun in 2002 with included dataset\n- [SynThai](https://github.com/KenjiroAI/SynThai) - Word segmentation and POS tagging using deep learning in Python\n\n### Data\n\n- [Inter-BEST](https://www.nectec.or.th/corpus/index.php?league=pm) - A text corpus with 5 million words with word segmentation\n- [Prime Minister 29](https://github.com/PyThaiNLP/lexicon-thai/tree/master/thai-corpus/Prime%20Minister%2029) - Dataset containing speeches of the current Prime Minister of Thailand\n\n## NLP in Danish\n\n- [Named Entity Recognition for Danish](https://github.com/ITUnlp/daner)\n- [DaNLP](https://github.com/alexandrainst/danlp) - NLP resources in Danish\n- [Awesome Danish](https://github.com/fnielsen/awesome-danish) - A curated list of awesome resources for Danish language technology\n\n## NLP in Vietnamese\n\n### Libraries\n\n- [underthesea](https://github.com/undertheseanlp/underthesea) - Vietnamese NLP Toolkit\n- [vn.vitk](https://github.com/phuonglh/vn.vitk) - A Vietnamese Text Processing Toolkit\n- [VnCoreNLP](https://github.com/vncorenlp/VnCoreNLP) - A Vietnamese natural language processing toolkit\n- [PhoBERT](https://github.com/VinAIResearch/PhoBERT) - Pre-trained language models for Vietnamese\n- [pyvi](https://github.com/trungtv/pyvi) - Python Vietnamese Core NLP Toolkit\n\n### Data\n\n- [Vietnamese treebank](https://vlsp.hpda.vn/demo/?page=resources&lang=en) - 10,000 sentences for the constituency parsing task\n- [BKTreeBank](https://arxiv.org/pdf/1710.05519.pdf) - a Vietnamese Dependency Treebank\n- [UD_Vietnamese](https://github.com/UniversalDependencies/UD_Vietnamese-VTB) - Vietnamese Universal Dependency Treebank\n- [VIVOS](https://ailab.hcmus.edu.vn/vivos/) - a free Vietnamese speech corpus consisting of 15 hours of recording speech by AILab\n- [VNTQcorpus(big).txt](http://viet.jnlp.org/download-du-lieu-tu-vung-corpus) - 1.75 million sentences in news\n- [ViText2SQL](https://github.com/VinAIResearch/ViText2SQL) - A dataset for Vietnamese Text-to-SQL semantic parsing (EMNLP-2020 Findings)\n- [EVB Corpus](https://github.com/qhungngo/EVBCorpus) - 20,000,000 words (20 million) from 15 bilingual books, 100 parallel English-Vietnamese / Vietnamese-English texts, 250 parallel law and ordinance texts, 5,000 news articles, and 2,000 film subtitles.\n\n\n## NLP for Dutch\n\n[Back to Top](#contents)\n\n- [python-frog](https://github.com/proycon/python-frog) - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER)\n- [SimpleNLG_NL](https://github.com/rfdj/SimpleNLG-NL) - Dutch surface realiser used for Natural Language Generation in Dutch, based on the SimpleNLG implementation for English and French.\n- [Alpino](https://github.com/rug-compling/alpino) - Dependency parser for Dutch (also does PoS tagging and Lemmatisation).\n- [Kaldi NL](https://github.com/opensource-spraakherkenning-nl/Kaldi_NL) - Dutch Speech Recognition models based on [Kaldi](http://kaldi-asr.org/).\n- [spaCy](https://spacy.io/) - [Dutch model](https://spacy.io/models/nl) available. - Industrial strength NLP with Python and Cython. \n\n\n## NLP in Indonesian\n\n### Datasets\n- Kompas and Tempo collections at [ILPS](http://ilps.science.uva.nl/resources/bahasa/)\n- [PANL10N for PoS tagging](http://www.panl10n.net/english/outputs/Indonesia/UI/0802/UI-1M-tagged.zip): 39K sentences and 900K word tokens\n- [IDN for PoS tagging](https://github.com/famrashel/idn-tagged-corpus): This corpus contains 10K sentences and 250K word tokens\n- [Indonesian Treebank](https://github.com/famrashel/idn-treebank) and [Universal Dependencies-Indonesian](https://github.com/UniversalDependencies/UD_Indonesian-GSD)\n- [IndoSum](https://github.com/kata-ai/indosum) for text summarization and classification both\n- [Wordnet-Bahasa](http://wn-msa.sourceforge.net/) - large, free, semantic dictionary\n- IndoBenchmark [IndoNLU](https://github.com/indobenchmark/indonlu) includes pre-trained language model (IndoBERT), FastText model, Indo4B corpus, and several NLU benchmark datasets\n\n### Libraries & Embedding\n- Natural language toolkit [bahasa](https://github.com/kangfend/bahasa)\n- [Indonesian Word Embedding](https://github.com/galuhsahid/indonesian-word-embedding)\n- Pretrained [Indonesian fastText Text Embedding](https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.id.zip) trained on Wikipedia\n- IndoBenchmark [IndoNLU](https://github.com/indobenchmark/indonlu) includes pretrained language model (IndoBERT), FastText model, Indo4B corpus, and several NLU benchmark datasets\n\n## NLP in Urdu\n\n### Datasets\n- [Collection of Urdu datasets](https://github.com/mirfan899/Urdu) for POS, NER and NLP tasks\n\n### Libraries\n- [Natural Language Processing library](https://github.com/urduhack/urduhack) for ( üáµüá∞)Urdu language\n\n## NLP in Persian\n\n[Back to Top](#contents)\n\n### Libraries\n- [Hazm](https://github.com/roshan-research/hazm) - Persian NLP Toolkit.\n- [Parsivar](https://github.com/ICTRC/Parsivar): A Language Processing Toolkit for Persian\n- [Perke](https://github.com/AlirezaTheH/perke): Perke is a Python keyphrase extraction package for Persian language. It provides an end-to-end keyphrase extraction pipeline in which each component can be easily modified or extended to develop new models.\n- [Perstem](https://github.com/jonsafari/perstem): Persian stemmer, morphological analyzer, transliterator, and partial part-of-speech tagger\n- [ParsiAnalyzer](https://github.com/NarimanN2/ParsiAnalyzer): Persian Analyzer For Elasticsearch\n- [virastar](https://github.com/aziz/virastar): Cleaning up Persian text!\n\n### Datasets\n- [Bijankhan Corpus](https://dbrg.ut.ac.ir/ÿ®€å⁄òŸÜ%E2%80%8CÿÆÿßŸÜ/): Bijankhan corpus is a tagged corpus that is suitable for natural language processing research on the Persian (Farsi) language. This collection is gathered form daily news and common texts. In this collection all documents are categorized into different subjects such as political, cultural and so on. Totally, there are 4300 different subjects. The Bijankhan collection contains about 2.6 millions manually tagged words with a tag set that contains 40 Persian POS tags.\n- [Uppsala Persian Corpus (UPC)](https://sites.google.com/site/mojganserajicom/home/upc): Uppsala Persian Corpus (UPC) is a large, freely available Persian corpus. The corpus is a modified version of the Bijankhan corpus with additional sentence segmentation and consistent tokenization containing 2,704,028 tokens and annotated with 31 part-of-speech tags. The part-of-speech tags are listed with explanations in [this table](https://sites.google.com/site/mojganserajicom/home/upc/Table_tag.pdf).\n- [Large-Scale Colloquial Persian](http://hdl.handle.net/11234/1-3195): Large Scale Colloquial Persian Dataset (LSCP) is hierarchically organized in asemantic taxonomy that focuses on multi-task informal Persian language understanding as a comprehensive problem. LSCP includes 120M sentences from 27M casual Persian tweets with its dependency relations in syntactic annotation, Part-of-speech tags, sentiment polarity and automatic translation of original Persian sentences in English (EN), German (DE), Czech (CS), Italian (IT) and Hindi (HI) spoken languages. Learn more about this project at [LSCP webpage](https://iasbs.ac.ir/~ansari/lscp/).\n- [ArmanPersoNERCorpus](https://github.com/HaniehP/PersianNER): The dataset includes 250,015 tokens and 7,682 Persian sentences in total. It is available in 3 folds to be used in turn as training and test sets. Each file contains one token, along with its manually annotated named-entity tag, per line. Each sentence is separated with a newline. The NER tags are in IOB format.\n- [FarsiYar PersianNER](https://github.com/Text-Mining/Persian-NER): The dataset includes about 25,000,000 tokens and about 1,000,000 Persian sentences in total based on [Persian Wikipedia Corpus](https://github.com/Text-Mining/Persian-Wikipedia-Corpus). The NER tags are in IOB format. More than 1000 volunteers contributed tag improvements to this dataset via web panel or android app. They release updated tags every two weeks.\n- [PERLEX](http://farsbase.net/PERLEX.html): The first Persian dataset for relation extraction, which is an expert translated version of the ‚ÄúSemeval-2010-Task-8‚Äù dataset. Link to the relevant publication.\n- [Persian Syntactic Dependency Treebank](http://dadegan.ir/catalog/perdt): This treebank is supplied for free noncommercial use. For commercial uses feel free to contact us. The number of annotated sentences is 29,982 sentences including samples from almost all verbs of the Persian valency lexicon.\n- [Uppsala Persian Dependency Treebank (UPDT)](http://stp.lingfil.uu.se/~mojgan/UPDT.html): Dependency-based syntactically annotated corpus.\n- [Hamshahri](https://dbrg.ut.ac.ir/hamshahri/): Hamshahri collection is a standard reliable Persian text collection that was used at Cross Language Evaluation Forum (CLEF) during years 2008 and 2009 for evaluation of Persian information retrieval systems.\n\n\n## NLP in Ukrainian\n\n[Back to Top](#contents)\n\n- [awesome-ukrainian-nlp](https://github.com/asivokon/awesome-ukrainian-nlp) - a curated list of Ukrainian NLP datasets, models, etc.\n- [UkrainianLT](https://github.com/Helsinki-NLP/UkrainianLT) - another curated list with a focus on machine translation and speech processing\n\n\n## NLP in Hungarian\n\n[Back to Top](#contents)\n\n- [awesome-hungarian-nlp](https://github.com/oroszgy/awesome-hungarian-nlp): A curated list of free resources dedicated to Hungarian Natural Language Processing.\n\n## NLP in Portuguese\n\n[Back to Top](#contents)\n\n- [Portuguese-nlp](https://github.com/ajdavidl/Portuguese-NLP) - a List of resources and tools developed with focus on Portuguese.\n\n## Other Languages\n\n- Russian: [pymorphy2](https://github.com/kmike/pymorphy2) - a good pos-tagger for Russian\n- Asian Languages: Thai, Lao, Chinese, Japanese, and Korean [ICU Tokenizer](https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-icu-tokenizer.html) implementation in ElasticSearch\n- Ancient Languages: [CLTK](https://github.com/cltk/cltk): The Classical Language Toolkit is a Python library and collection of texts for doing NLP in ancient languages\n- Hebrew: [NLPH_Resources](https://github.com/NLPH/NLPH_Resources) - A collection of papers, corpora and linguistic resources for NLP in Hebrew\n\n[Back to Top](#contents)\n\n[Credits](./CREDITS.md) for initial curators and sources\n\n## License\n[License](./LICENSE) - CC0\n",
         "AI_DataScience"
        ],
        [
         "42",
         "MDEwOlJlcG9zaXRvcnk3MzMyODkwNQ==",
         "# torchvision\n\n[![total torchvision downloads](https://pepy.tech/badge/torchvision)](https://pepy.tech/project/torchvision)\n[![documentation](https://img.shields.io/badge/dynamic/json.svg?label=docs&url=https%3A%2F%2Fpypi.org%2Fpypi%2Ftorchvision%2Fjson&query=%24.info.version&colorB=brightgreen&prefix=v)](https://pytorch.org/vision/stable/index.html)\n\nThe torchvision package consists of popular datasets, model architectures, and common image transformations for computer\nvision.\n\n## Installation\n\nPlease refer to the [official\ninstructions](https://pytorch.org/get-started/locally/) to install the stable\nversions of `torch` and `torchvision` on your system.\n\nTo build source, refer to our [contributing\npage](https://github.com/pytorch/vision/blob/main/CONTRIBUTING.md#development-installation).\n\nThe following is the corresponding `torchvision` versions and supported Python\nversions.\n\n| `torch`            | `torchvision`      | Python              |\n| ------------------ | ------------------ | ------------------- |\n| `main` / `nightly` | `main` / `nightly` | `>=3.10`, `<=3.13`   |\n| `2.8`              | `0.23`             | `>=3.9`, `<=3.13`   |\n| `2.7`              | `0.22`             | `>=3.9`, `<=3.13`   |\n| `2.6`              | `0.21`             | `>=3.9`, `<=3.12`   |\n\n<details>\n    <summary>older versions</summary>\n\n| `torch` | `torchvision`     | Python                    |\n|---------|-------------------|---------------------------|\n| `2.5`              | `0.20`             | `>=3.9`, `<=3.12`   |\n| `2.4`              | `0.19`             | `>=3.8`, `<=3.12`   |\n| `2.3`              | `0.18`             | `>=3.8`, `<=3.12`   |\n| `2.2`              | `0.17`             | `>=3.8`, `<=3.11`   |\n| `2.1`              | `0.16`             | `>=3.8`, `<=3.11`   |\n| `2.0`              | `0.15`             | `>=3.8`, `<=3.11`   |\n| `1.13`  | `0.14`            | `>=3.7.2`, `<=3.10`       |\n| `1.12`  | `0.13`            | `>=3.7`, `<=3.10`         |\n| `1.11`  | `0.12`            | `>=3.7`, `<=3.10`         |\n| `1.10`  | `0.11`            | `>=3.6`, `<=3.9`          |\n| `1.9`   | `0.10`            | `>=3.6`, `<=3.9`          |\n| `1.8`   | `0.9`             | `>=3.6`, `<=3.9`          |\n| `1.7`   | `0.8`             | `>=3.6`, `<=3.9`          |\n| `1.6`   | `0.7`             | `>=3.6`, `<=3.8`          |\n| `1.5`   | `0.6`             | `>=3.5`, `<=3.8`          |\n| `1.4`   | `0.5`             | `==2.7`, `>=3.5`, `<=3.8` |\n| `1.3`   | `0.4.2` / `0.4.3` | `==2.7`, `>=3.5`, `<=3.7` |\n| `1.2`   | `0.4.1`           | `==2.7`, `>=3.5`, `<=3.7` |\n| `1.1`   | `0.3`             | `==2.7`, `>=3.5`, `<=3.7` |\n| `<=1.0` | `0.2`             | `==2.7`, `>=3.5`, `<=3.7` |\n\n</details>\n\n## Image Backends\n\nTorchvision currently supports the following image backends:\n\n- torch tensors\n- PIL images:\n    - [Pillow](https://python-pillow.org/)\n    - [Pillow-SIMD](https://github.com/uploadcare/pillow-simd) - a **much faster** drop-in replacement for Pillow with SIMD.\n\nRead more in in our [docs](https://pytorch.org/vision/stable/transforms.html).\n\n# Using the models on C++\n\nRefer to [example/cpp](https://github.com/pytorch/vision/tree/main/examples/cpp).\n\n**DISCLAIMER**: the `libtorchvision` library includes the torchvision\ncustom ops as well as most of the C++ torchvision APIs. Those APIs do not come\nwith any backward-compatibility guarantees and may change from one version to\nthe next. Only the Python APIs are stable and with backward-compatibility\nguarantees. So, if you need stability within a C++ environment, your best bet is\nto export the Python APIs via torchscript.\n\n## Documentation\n\nYou can find the API documentation on the pytorch website: <https://pytorch.org/vision/stable/index.html>\n\n## Contributing\n\nSee the [CONTRIBUTING](CONTRIBUTING.md) file for how to help out.\n\n## Disclaimer on Datasets\n\nThis is a utility library that downloads and prepares public datasets. We do not host or distribute these datasets,\nvouch for their quality or fairness, or claim that you have license to use the dataset. It is your responsibility to\ndetermine whether you have permission to use the dataset under the dataset's license.\n\nIf you're a dataset owner and wish to update any part of it (description, citation, etc.), or do not want your dataset\nto be included in this library, please get in touch through a GitHub issue. Thanks for your contribution to the ML\ncommunity!\n\n## Pre-trained Model License\n\nThe pre-trained models provided in this library may have their own licenses or terms and conditions derived from the\ndataset used for training. It is your responsibility to determine whether you have permission to use the models for your\nuse case.\n\nMore specifically, SWAG models are released under the CC-BY-NC 4.0 license. See\n[SWAG LICENSE](https://github.com/facebookresearch/SWAG/blob/main/LICENSE) for additional details.\n\n## Citing TorchVision\n\nIf you find TorchVision useful in your work, please consider citing the following BibTeX entry:\n\n```bibtex\n@software{torchvision2016,\n    title        = {TorchVision: PyTorch's Computer Vision library},\n    author       = {TorchVision maintainers and contributors},\n    year         = 2016,\n    journal      = {GitHub repository},\n    publisher    = {GitHub},\n    howpublished = {\\url{https://github.com/pytorch/vision}}\n}\n```\n",
         "AI_DataScience"
        ],
        [
         "43",
         "R_kgDOI44gKw",
         "<h1 align=\"center\">\n  DocsGPT  ü¶ñ\n</h1>\n\n<p align=\"center\">\n  <strong>Private AI for agents, assistants and enterprise search</strong>\n</p>\n\n<p align=\"left\">\n  <strong><a href=\"https://www.docsgpt.cloud/\">DocsGPT</a></strong> is an open-source AI platform for building intelligent agents and assistants. Features Agent Builder, deep research tools, document analysis (PDF, Office, web content), Multi-model support (choose your provider or run locally), and rich API connectivity for agents with actionable tools and integrations. Deploy anywhere with complete privacy control.\n</p>\n\n<div align=\"center\">\n  \n  <a href=\"https://github.com/arc53/DocsGPT\">![link to main GitHub showing Stars number](https://img.shields.io/github/stars/arc53/docsgpt?style=social)</a>\n  <a href=\"https://github.com/arc53/DocsGPT\">![link to main GitHub showing Forks number](https://img.shields.io/github/forks/arc53/docsgpt?style=social)</a>\n  <a href=\"https://github.com/arc53/DocsGPT/blob/main/LICENSE\">![link to license file](https://img.shields.io/github/license/arc53/docsgpt)</a>\n  <a href=\"https://www.bestpractices.dev/projects/9907\"><img src=\"https://www.bestpractices.dev/projects/9907/badge\"></a>\n  <a href=\"https://discord.gg/n5BX8dh8rU\">![link to discord](https://img.shields.io/discord/1070046503302877216)</a>\n  <a href=\"https://twitter.com/docsgptai\">![X (formerly Twitter) URL](https://img.shields.io/twitter/follow/docsgptai)</a>\n\n<a href=\"https://docs.docsgpt.cloud/quickstart\">‚ö°Ô∏è Quickstart</a> ‚Ä¢ <a href=\"https://app.docsgpt.cloud/\">‚òÅÔ∏è Cloud Version</a> ‚Ä¢ <a href=\"https://discord.gg/n5BX8dh8rU\">üí¨ Discord</a>\n<br>\n<a href=\"https://docs.docsgpt.cloud/\">üìñ Documentation</a> ‚Ä¢ <a href=\"https://github.com/arc53/DocsGPT/blob/main/CONTRIBUTING.md\">üë´ Contribute</a> ‚Ä¢ <a href=\"https://blog.docsgpt.cloud/\">üóû Blog</a>\n<br>\n\n</div>\n\n<div align=\"center\">\n  <br>\nüéÉ <a href=\"https://github.com/arc53/DocsGPT/blob/main/HACKTOBERFEST.md\"> Hacktoberfest Prizes, Rules & Q&A </a> üéÉ\n  <br>\n  <br>\n</div>\n\n\n<div align=\"center\">\n  <br>\n<img src=\"https://d3dg1063dc54p9.cloudfront.net/videos/demov7.gif\" alt=\"video-example-of-docs-gpt\" width=\"800\" height=\"450\">\n</div>\n<h3 align=\"left\">\n  <strong>Key Features:</strong>\n</h3>\n<ul align=\"left\">\n    <li><strong>üóÇÔ∏è Wide Format Support:</strong> Reads PDF, DOCX, CSV, XLSX, EPUB, MD, RST, HTML, MDX, JSON, PPTX, and images.</li>\n    <li><strong>üåê Web & Data Integration:</strong> Ingests from URLs, sitemaps, Reddit, GitHub and web crawlers.</li>\n    <li><strong>‚úÖ Reliable Answers:</strong> Get accurate, hallucination-free responses with source citations viewable in a clean UI.</li>\n    <li><strong>üîë Streamlined API Keys:</strong>  Generate keys linked to your settings, documents, and models, simplifying chatbot and integration setup.</li>\n    <li><strong>üîó Actionable Tooling:</strong> Connect to APIs, tools, and other services to enable LLM actions.</li>\n    <li><strong>üß© Pre-built Integrations:</strong> Use readily available HTML/React chat widgets, search tools, Discord/Telegram bots, and more.</li>\n    <li><strong>üîå Flexible Deployment:</strong> Works with major LLMs (OpenAI, Google, Anthropic) and local models (Ollama, llama_cpp).</li>\n    <li><strong>üè¢ Secure & Scalable:</strong> Run privately and securely with Kubernetes support, designed for enterprise-grade reliability.</li>\n</ul>\n\n## Roadmap\n\n- [x] Full GoogleAI compatibility (Jan 2025)\n- [x] Add tools (Jan 2025)\n- [x] Manually updating chunks in the app UI (Feb 2025)\n- [x] Devcontainer for easy development (Feb 2025)\n- [x] ReACT agent (March 2025)\n- [x] Chatbots menu re-design to handle tools, agent types, and more (April 2025)\n- [x] New input box in the conversation menu (April 2025)\n- [x] Add triggerable actions / tools (webhook) (April 2025)\n- [x] Agent optimisations (May 2025)\n- [x] Filesystem sources update (July 2025)\n- [x] Json Responses (August 2025)\n- [x] MCP support (August 2025)\n- [x] Google Drive integration (September 2025)\n- [ ] Add OAuth 2.0 authentication for MCP (September 2025)\n- [ ] Sharepoint integration (October 2025)\n- [ ] Deep Agents (October 2025)\n- [ ] Agent scheduling\n\nYou can find our full roadmap [here](https://github.com/orgs/arc53/projects/2). Please don't hesitate to contribute or create issues, it helps us improve DocsGPT!\n\n### Production Support / Help for Companies:\n\nWe're eager to provide personalized assistance when deploying your DocsGPT to a live environment.\n\n[Get a Demo :wave:](https://www.docsgpt.cloud/contact)‚Å†\n\n[Send Email :email:](mailto:support@docsgpt.cloud?subject=DocsGPT%20support%2Fsolutions)\n\n## Join the Lighthouse Program üåü\n\nCalling all developers and GenAI innovators! The **DocsGPT Lighthouse Program** connects technical leaders actively deploying or extending DocsGPT in real-world scenarios. Collaborate directly with our team to shape the roadmap, access priority support, and build enterprise-ready solutions with exclusive community insights.\n\n[Learn More & Apply ‚Üí](https://docs.google.com/forms/d/1KAADiJinUJ8EMQyfTXUIGyFbqINNClNR3jBNWq7DgTE)\n\n## QuickStart\n\n> [!Note]\n> Make sure you have [Docker](https://docs.docker.com/engine/install/) installed\n\nA more detailed [Quickstart](https://docs.docsgpt.cloud/quickstart) is available in our documentation\n\n1. **Clone the repository:**\n\n   ```bash\n   git clone https://github.com/arc53/DocsGPT.git\n   cd DocsGPT\n   ```\n\n**For macOS and Linux:**\n\n2. **Run the setup script:**\n\n   ```bash\n   ./setup.sh\n   ```\n\n**For Windows:**\n\n2. **Run the PowerShell setup script:**\n\n   ```powershell\n   PowerShell -ExecutionPolicy Bypass -File .\\setup.ps1\n   ```\n\nEither script will guide you through setting up DocsGPT. Four options available: using the public API, running locally, connecting to a local inference engine, or using a cloud API provider. Scripts will automatically configure your `.env` file and handle necessary downloads and installations based on your chosen option.\n\n**Navigate to http://localhost:5173/**\n\nTo stop DocsGPT, open a terminal in the `DocsGPT` directory and run:\n\n```bash\ndocker compose -f deployment/docker-compose.yaml down\n```\n\n(or use the specific `docker compose down` command shown after running the setup script).\n\n> [!Note]\n> For development environment setup instructions, please refer to the [Development Environment Guide](https://docs.docsgpt.cloud/Deploying/Development-Environment).\n\n## Contributing\n\nPlease refer to the [CONTRIBUTING.md](CONTRIBUTING.md) file for information about how to get involved. We welcome issues, questions, and pull requests.\n\n## Architecture\n\n![Architecture chart](https://github.com/user-attachments/assets/fc6a7841-ddfc-45e6-b5a0-d05fe648cbe2)\n\n## Project Structure\n\n- Application - Flask app (main application).\n\n- Extensions - Extensions, like react widget or discord bot.\n\n- Frontend - Frontend uses <a href=\"https://vitejs.dev/\">Vite</a> and <a href=\"https://react.dev/\">React</a>.\n\n- Scripts - Miscellaneous scripts.\n\n## Code Of Conduct\n\nWe as members, contributors, and leaders, pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Please refer to the [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) file for more information about contributing.\n\n## Many Thanks To Our Contributors‚ö°\n\n<a href=\"https://github.com/arc53/DocsGPT/graphs/contributors\" alt=\"View Contributors\">\n  <img src=\"https://contrib.rocks/image?repo=arc53/DocsGPT\" alt=\"Contributors\" />\n</a>\n\n## License\n\nThe source code license is [MIT](https://opensource.org/license/mit/), as described in the [LICENSE](LICENSE) file.\n\n<p>This project is supported by:</p>\n<p>\n  <a href=\"https://www.digitalocean.com/?utm_medium=opensource&utm_source=DocsGPT\">\n    <img src=\"https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg\" width=\"201px\">\n  </a>\n</p>\n",
         "AI_DataScience"
        ],
        [
         "44",
         "R_kgDOGoRv1A",
         "# Instant Neural Graphics Primitives ![](https://github.com/NVlabs/instant-ngp/workflows/CI/badge.svg)\n\n<img src=\"docs/assets_readme/fox.gif\" height=\"342\"/> <img src=\"docs/assets_readme/robot5.gif\" height=\"342\"/>\n\nEver wanted to train a NeRF model of a fox in under 5 seconds? Or fly around a scene captured from photos of a factory robot? Of course you have!\n\nHere you will find an implementation of four __neural graphics primitives__, being neural radiance fields (NeRF), signed distance functions (SDFs), neural images, and neural volumes.\nIn each case, we train and render a MLP with multiresolution hash input encoding using the [__tiny-cuda-nn__](https://github.com/NVlabs/tiny-cuda-nn) framework.\n\n> __Instant Neural Graphics Primitives with a Multiresolution Hash Encoding__  \n> [Thomas M√ºller](https://tom94.net), [Alex Evans](https://research.nvidia.com/person/alex-evans), [Christoph Schied](https://research.nvidia.com/person/christoph-schied), [Alexander Keller](https://research.nvidia.com/person/alex-keller)  \n> _ACM Transactions on Graphics (__SIGGRAPH__), July 2022_  \n> __[Project page](https://nvlabs.github.io/instant-ngp)&nbsp;/ [Paper](https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf)&nbsp;/ [Video](https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.mp4)&nbsp;/ [Presentation](https://tom94.net/data/publications/mueller22instant/mueller22instant-gtc.mp4)&nbsp;/ [Real-Time Live](https://tom94.net/data/publications/mueller22instant/mueller22instant-rtl.mp4)&nbsp;/ [BibTeX](https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.bib)__\n\nFor business inquiries, please submit the [NVIDIA research licensing form](https://www.nvidia.com/en-us/research/inquiries/).\n\n\n## Installation\n\nIf you have Windows, download one of the following releases corresponding to your graphics card and extract it. Then, start `instant-ngp.exe`.\n\n- [**RTX 5000 series** and other Blackwell cards](https://github.com/NVlabs/instant-ngp/releases/download/continuous/Instant-NGP-for-RTX-5000.zip)\n- [**RTX 3000 & 4000 series, RTX A4000&ndash;A6000**, and other Ampere & Ada cards](https://github.com/NVlabs/instant-ngp/releases/download/continuous/Instant-NGP-for-RTX-3000-and-4000.zip)\n- [**RTX 2000 series, Titan RTX, Quadro RTX 4000&ndash;8000**, and other Turing cards](https://github.com/NVlabs/instant-ngp/releases/download/continuous/Instant-NGP-for-RTX-2000.zip)\n- [**GTX 1000 series, Titan Xp, Quadro P1000&ndash;P6000**, and other Pascal cards](https://github.com/NVlabs/instant-ngp/releases/download/continuous/Instant-NGP-for-GTX-1000.zip)\n\nKeep reading for a guided tour of the application or, if you are interested in creating your own NeRF, watch [the video tutorial](https://www.youtube.com/watch?v=3TWxO1PftMc) or read the [written instructions](docs/nerf_dataset_tips.md).\n\nIf you use Linux, or want the [developer Python bindings](https://github.com/NVlabs/instant-ngp#python-bindings), or if your GPU is not listed above (e.g. Hopper, Volta, or Maxwell generations), you need to [build __instant-ngp__ yourself](https://github.com/NVlabs/instant-ngp#building-instant-ngp-windows--linux).\n\n\n## Usage\n\n<img src=\"docs/assets_readme/testbed.png\" width=\"100%\"/>\n\n__instant-ngp__ comes with an interactive GUI that includes many features:\n- [comprehensive controls](https://github.com/NVlabs/instant-ngp#keyboard-shortcuts-and-recommended-controls) for interactively exploring neural graphics primitives,\n- [VR mode](https://github.com/NVlabs/instant-ngp#vr-controls) for viewing neural graphics primitives through a virtual-reality headset,\n- saving and loading \"snapshots\" so you can share your graphics primitives on the internet,\n- a camera path editor to create videos,\n- `NeRF->Mesh` and `SDF->Mesh` conversion,\n- camera pose and lens optimization,\n- and many more.\n\n\n### NeRF fox\n\nSimply start `instant-ngp` and drag the `data/nerf/fox` folder into the window. Or, alternatively, use the command line:\n\n```sh\ninstant-ngp$ ./instant-ngp data/nerf/fox\n```\n\n<img src=\"docs/assets_readme/fox.png\"/>\n\nYou can use __any__ NeRF-compatible dataset, e.g. from [original NeRF](https://drive.google.com/drive/folders/1JDdLGDruGNXWnM1eqY1FNL9PlStjaKWi), the [SILVR dataset](https://github.com/IDLabMedia/large-lightfields-dataset), or the [DroneDeploy dataset](https://github.com/nickponline/dd-nerf-dataset). **To create your own NeRF, watch [the video tutorial](https://www.youtube.com/watch?v=3TWxO1PftMc) or read the [written instructions](docs/nerf_dataset_tips.md).**\n\n### SDF armadillo\n\nDrag `data/sdf/armadillo.obj` into the window or use the command:\n\n```sh\ninstant-ngp$ ./instant-ngp data/sdf/armadillo.obj\n```\n\n<img src=\"docs/assets_readme/armadillo.png\"/>\n\n### Image of Einstein\n\nDrag `data/image/albert.exr` into the window or use the command:\n\n```sh\ninstant-ngp$ ./instant-ngp data/image/albert.exr\n```\n\n<img src=\"docs/assets_readme/albert.png\"/>\n\nTo reproduce the gigapixel results, download, for example, [the Tokyo image](https://www.flickr.com/photos/trevor_dobson_inefekt69/29314390837) and convert it to `.bin` using the `scripts/convert_image.py` script. This custom format improves compatibility and loading speed when resolution is high. Now you can run:\n\n```sh\ninstant-ngp$ ./instant-ngp data/image/tokyo.bin\n```\n\n\n### Volume renderer\n\nDownload the [nanovdb volume for the Disney cloud](https://drive.google.com/drive/folders/1SuycSAOSG64k2KLV7oWgyNWyCvZAkafK?usp=sharing), which is derived [from here](https://disneyanimation.com/data-sets/?drawer=/resources/clouds/) ([CC BY-SA 3.0](https://media.disneyanimation.com/uploads/production/data_set_asset/6/asset/License_Cloud.pdf)). Then drag `wdas_cloud_quarter.nvdb` into the window or use the command:\n\n```sh\ninstant-ngp$ ./instant-ngp wdas_cloud_quarter.nvdb\n```\n<img src=\"docs/assets_readme/cloud.png\"/>\n\n\n### Keyboard shortcuts and recommended controls\n\nHere are the main keyboard controls for the __instant-ngp__ application.\n\n| Key             | Meaning       |\n| :-------------: | ------------- |\n| WASD            | Forward / pan left / backward / pan right. |\n| Spacebar / C    | Move up / down. |\n| = or + / - or _ | Increase / decrease camera velocity (first person mode) or zoom in / out (third person mode). |\n| E / Shift+E     | Increase / decrease exposure. |\n| Tab             | Toggle menu visibility. |\n| T               | Toggle training. After around two minutes training tends to settle down, so can be toggled off. |\n| { }             | Go to the first/last training image camera view. |\n| [ ]             | Go to the previous/next training image camera view. |\n| R               | Reload network from file. |\n| Shift+R         | Reset camera. |\n| O               | Toggle visualization or accumulated error map. |\n| G               | Toggle visualization of the ground truth. |\n| M               | Toggle multi-view visualization of layers of the neural model. See the paper's video for a little more explanation. |\n| , / .           | Shows the previous / next visualized layer; hit M to escape. |\n| 1-8             | Switches among various render modes, with 2 being the standard one. You can see the list of render mode names in the control interface. |\n\nThere are many controls in the __instant-ngp__ GUI.\nFirst, note that this GUI can be moved and resized, as can the \"Camera path\" GUI (which first must be expanded to be used).\n\nRecommended user controls in __instant-ngp__ are:\n\n* __Snapshot:__ use \"Save\" to save the trained NeRF, \"Load\" to reload.\n* __Rendering -> DLSS:__ toggling this on and setting \"DLSS sharpening\" to 1.0 can often improve rendering quality.\n* __Rendering -> Crop size:__ trim back the surrounding environment to focus on the model. \"Crop aabb\" lets you move the center of the volume of interest and fine tune. See more about this feature in [our NeRF training & dataset tips](https://github.com/NVlabs/instant-ngp/blob/master/docs/nerf_dataset_tips.md).\n\nThe \"Camera path\" GUI lets you create a camera path for rendering a video.\nThe button \"Add from cam\" inserts keyframes from the current perspective.\nThen, you can render a video `.mp4` of your camera path or export the keyframes to a `.json` file.\nThere is a bit more information about the GUI [in this post](https://developer.nvidia.com/blog/getting-started-with-nvidia-instant-nerfs/) and [in this video guide to creating your own video](https://www.youtube.com/watch?v=3TWxO1PftMc).\n\n\n### VR controls\n\nTo view the neural graphics primitive in VR, first start your VR runtime. This will most likely be either\n- __OculusVR__ if you have an Oculus Rift or Meta Quest (with link cable) headset, and\n- __SteamVR__ if you have another headset.\n- Any OpenXR-compatible runtime will work.\n\nThen, press the __Connect to VR/AR headset__ button in the __instant-ngp__ GUI and put on your headset.\nBefore entering VR, we **strongly** recommend that you first finish training (press \"Stop training\") or load a pre-trained snapshot for maximum performance.\n\nIn VR, you have the following controls.\n\n| Control                | Meaning       |\n| :--------------------: | ------------- |\n| Left stick / trackpad  | Move |\n| Right stick / trackpad | Turn camera |\n| Press stick / trackpad | Erase NeRF around the hand |\n| Grab (one-handed)      | Drag neural graphics primitive |\n| Grab (two-handed)      | Rotate and zoom (like pinch-to-zoom on a smartphone) |\n\n\n## Building instant-ngp (Windows & Linux)\n\n### Requirements\n\n- An __NVIDIA GPU__; tensor cores increase performance when available. All shown results come from an RTX 3090.\n- A __C++14__ capable compiler. The following choices are recommended and have been tested:\n  - __Windows:__ Visual Studio 2019 or 2022\n  - __Linux:__ GCC/G++ 8 or higher\n- A recent version of __[CUDA](https://developer.nvidia.com/cuda-toolkit)__. The following choices are recommended and have been tested:\n  - __Windows:__ CUDA 11.5 or higher\n  - __Linux:__ CUDA 10.2 or higher\n- __[CMake](https://cmake.org/) v3.21 or higher__.\n- __(optional) [Python](https://www.python.org/) 3.7 or higher__ for interactive bindings. Also, run `pip install -r requirements.txt`.\n- __(optional) [OptiX](https://developer.nvidia.com/optix) 7.6 or higher__ for faster mesh SDF training.\n- __(optional) [Vulkan SDK](https://vulkan.lunarg.com/)__ for DLSS support.\n\n\nIf you are using Debian based Linux distribution, install the following packages\n```sh\nsudo apt-get install build-essential git python3-dev python3-pip libopenexr-dev libxi-dev \\\n                     libglfw3-dev libglew-dev libomp-dev libxinerama-dev libxcursor-dev\n```\n\nAlternatively, if you are using Arch or Arch derivatives, install the following packages\n```sh\nsudo pacman -S cuda base-devel cmake openexr libxi glfw openmp libxinerama libxcursor\n```\n\nWe also recommend installing [CUDA](https://developer.nvidia.com/cuda-toolkit) and [OptiX](https://developer.nvidia.com/optix) in `/usr/local/` and adding the CUDA installation to your PATH.\n\nFor example, if you have CUDA 11.4, add the following to your `~/.bashrc`\n```sh\nexport PATH=\"/usr/local/cuda-11.4/bin:$PATH\"\nexport LD_LIBRARY_PATH=\"/usr/local/cuda-11.4/lib64:$LD_LIBRARY_PATH\"\n```\n\n\n### Compilation\n\nBegin by cloning this repository and all its submodules using the following command:\n```sh\n$ git clone --recursive https://github.com/nvlabs/instant-ngp\n$ cd instant-ngp\n```\n\nThen, use CMake to build the project: (on Windows, this must be in a [developer command prompt](https://docs.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-160#developer_command_prompt))\n```sh\ninstant-ngp$ cmake . -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo\ninstant-ngp$ cmake --build build --config RelWithDebInfo -j\n```\n\nIf compilation fails inexplicably or takes longer than an hour, you might be running out of memory. Try running the above command without `-j` in that case.\nIf this does not help, please consult [this list of possible fixes](https://github.com/NVlabs/instant-ngp#troubleshooting-compile-errors) before opening an issue.\n\nIf the build succeeds, you can now run the code via the `./instant-ngp` executable or the `scripts/run.py` script described below.\n\nIf automatic GPU architecture detection fails, (as can happen if you have multiple GPUs installed), set the `TCNN_CUDA_ARCHITECTURES` environment variable for the GPU you would like to use. The following table lists the values for common GPUs. If your GPU is not listed, consult [this exhaustive list](https://developer.nvidia.com/cuda-gpus).\n\n| H100 | 40X0 | 30X0 | A100 | 20X0 | TITAN V / V100 | 10X0 / TITAN Xp | 9X0 | K80 |\n|:----:|:----:|:----:|:----:|:----:|:--------------:|:---------------:|:---:|:---:|\n|   90 |   89 |   86 |   80 |   75 |             70 |              61 |  52 |  37 |\n\n\n## Python bindings\n\nAfter you have built __instant-ngp__, you can use its Python bindings to conduct controlled experiments in an automated fashion.\nAll features from the interactive GUI (and more!) have Python bindings that can be easily instrumented.\nFor an example of how the `./instant-ngp` application can be implemented and extended from within Python, see `./scripts/run.py`, which supports a superset of the command line arguments that `./instant-ngp` does.\n\nIf you would rather build new models from the hash encoding and fast neural networks, consider [__tiny-cuda-nn__'s PyTorch extension](https://github.com/nvlabs/tiny-cuda-nn#pytorch-extension).\n\nHappy hacking!\n\n\n## Additional resources\n\n- [Getting started with NVIDIA Instant NeRF blog post](https://developer.nvidia.com/blog/getting-started-with-nvidia-instant-nerfs/)\n- [SIGGRAPH tutorial for advanced NeRF dataset creation](https://www.nvidia.com/en-us/on-demand/session/siggraph2022-sigg22-s-16/).\n\n\n## Frequently asked questions (FAQ)\n\n__Q:__ The NeRF reconstruction of my custom dataset looks bad; what can I do?\n\n__A:__ There could be multiple issues:\n- COLMAP might have been unable to reconstruct camera poses.\n- There might have been movement or blur during capture. Don't treat capture as an artistic task; treat it as photogrammetry. You want _\\*as little blur as possible\\*_ in your dataset (motion, defocus, or otherwise) and all objects must be _\\*static\\*_ during the entire capture. Bonus points if you are using a wide-angle lens (iPhone wide angle works well), because it covers more space than narrow lenses.\n- The dataset parameters (in particular `aabb_scale`) might have been tuned suboptimally. We recommend starting with `aabb_scale=128` and then increasing or decreasing it by factors of two until you get optimal quality.\n- Carefully read [our NeRF training & dataset tips](https://github.com/NVlabs/instant-ngp/blob/master/docs/nerf_dataset_tips.md).\n\n##\n__Q:__ How can I save the trained model and load it again later?\n\n__A:__ Two options:\n1. Use the GUI's \"Snapshot\" section.\n2. Use the Python bindings `load_snapshot` / `save_snapshot` (see `scripts/run.py` for example usage).\n\n##\n__Q:__ Can this codebase use multiple GPUs at the same time?\n\n__A:__ Only for VR rendering, in which case one GPU is used per eye. Otherwise, no. To select a specific GPU to run on, use the [CUDA_VISIBLE_DEVICES](https://stackoverflow.com/questions/39649102/how-do-i-select-which-gpu-to-run-a-job-on) environment variable. To optimize the _compilation_ for that specific GPU use the [TCNN_CUDA_ARCHITECTURES](https://github.com/NVlabs/instant-ngp#compilation-windows--linux) environment variable.\n\n##\n__Q:__ How can I run __instant-ngp__ in headless mode?\n\n__A:__ Use `./instant-ngp --no-gui` or `python scripts/run.py`. You can also compile without GUI via `cmake -DNGP_BUILD_WITH_GUI=off ...`\n\n##\n__Q:__ Does this codebase run on [Google Colab](https://colab.research.google.com/)?\n\n__A:__ Yes. See [this example](./notebooks/instant_ngp.ipynb) inspired on the notebook created by user [@myagues](https://github.com/NVlabs/instant-ngp/issues/6#issuecomment-1016397579). Caveat: this codebase requires large amounts of GPU RAM and might not fit on your assigned GPU. It will also run slower on older GPUs.\n\n##\n__Q:__ Is there a [Docker container](https://www.docker.com/)?\n\n__A:__ Yes. We bundle a [Visual Studio Code development container](https://code.visualstudio.com/docs/remote/containers), the `.devcontainer/Dockerfile` of which you can also use stand-alone. \n\nIf you want to run the container without using VSCode:\n```\ndocker-compose -f .devcontainer/docker-compose.yml build instant-ngp\nxhost local:root\ndocker-compose -f .devcontainer/docker-compose.yml run instant-ngp /bin/bash\n```\nThen run the build commands above as normal.\n\n##\n__Q:__ How can I edit and train the underlying hash encoding or neural network on a new task?\n\n__A:__ Use [__tiny-cuda-nn__'s PyTorch extension](https://github.com/nvlabs/tiny-cuda-nn#pytorch-extension).\n\n##\n__Q:__ What is the coordinate system convention?\n\n__A:__ See [this helpful diagram](https://github.com/NVlabs/instant-ngp/discussions/153?converting=1#discussioncomment-2187652) by user @jc211.\n\n##\n__Q:__ Why are background colors randomized during NeRF training?\n\n__A:__ Transparency in the training data indicates a desire for transparency in the learned model. Using a solid background color, the model can minimize its loss by simply predicting that background color, rather than transparency (zero density). By randomizing the background colors, the model is _forced_ to learn zero density to let the randomized colors \"shine through\".\n\n##\n__Q:__ How to mask away NeRF training pixels (e.g. for dynamic object removal)?\n\n__A:__ For any training image `xyz.*` with dynamic objects, you can provide a `dynamic_mask_xyz.png` in the same folder. This file must be in PNG format, where _non-zero_ pixel values indicate masked-away regions.\n\n## Troubleshooting compile errors\n\nBefore investigating further, make sure all submodules are up-to-date and try compiling again.\n```sh\ninstant-ngp$ git submodule sync --recursive\ninstant-ngp$ git submodule update --init --recursive\n```\nIf __instant-ngp__ still fails to compile, update CUDA as well as your compiler to the latest versions you can install on your system. It is crucial that you update _both_, as newer CUDA versions are not always compatible with earlier compilers and vice versa.\nIf your problem persists, consult the following table of known issues.\n\n**\\*After each step, delete the `build` folder and let CMake regenerate it before trying again.\\***\n\n| Problem | Resolution |\n|---------|------------|\n| __CMake error:__ No CUDA toolset found / CUDA_ARCHITECTURES is empty for target \"cmTC_0c70f\" | __Windows:__ the Visual Studio CUDA integration was not installed correctly. Follow [these instructions](https://github.com/mitsuba-renderer/mitsuba2/issues/103#issuecomment-618378963) to fix the problem without re-installing CUDA. ([#18](https://github.com/NVlabs/instant-ngp/issues/18)) |\n| | __Linux:__ Environment variables for your CUDA installation are probably incorrectly set. You may work around the issue using ```cmake . -B build -DCMAKE_CUDA_COMPILER=/usr/local/cuda-<your cuda version>/bin/nvcc``` ([#28](https://github.com/NVlabs/instant-ngp/issues/28)) |\n| __CMake error:__ No known features for CXX compiler \"MSVC\" | Reinstall Visual Studio & make sure you run CMake from a developer shell. Make sure you delete the build folder before building again. ([#21](https://github.com/NVlabs/instant-ngp/issues/21)) |\n| __Compile error:__ A single input file is required for a non-link phase when an outputfile is specified | Ensure there no spaces in the path to __instant-ngp__. Some build systems seem to have trouble with those. ([#39](https://github.com/NVlabs/instant-ngp/issues/39) [#198](https://github.com/NVlabs/instant-ngp/issues/198)) |\n| __Compile error:__ undefined references to \"cudaGraphExecUpdate\" / identifier \"cublasSetWorkspace\" is undefined | Update your CUDA installation (which is likely 11.0) to 11.3 or higher. ([#34](https://github.com/NVlabs/instant-ngp/issues/34) [#41](https://github.com/NVlabs/instant-ngp/issues/41) [#42](https://github.com/NVlabs/instant-ngp/issues/42)) |\n| __Compile error:__ too few arguments in function call | Update submodules with the above two `git` commands. ([#37](https://github.com/NVlabs/instant-ngp/issues/37) [#52](https://github.com/NVlabs/instant-ngp/issues/52)) |\n| __Python error:__ No module named 'pyngp' | It is likely that CMake did not detect your Python installation and therefore did not build `pyngp`. Check CMake logs to verify this. If `pyngp` was built in a different folder than `build`, Python will be unable to detect it and you have to supply the full path to the import statement. ([#43](https://github.com/NVlabs/instant-ngp/issues/43)) |\n\nIf you cannot find your problem in the table, try searching [the discussions board](https://github.com/NVlabs/instant-ngp/discussions) and [the issues area](https://github.com/NVlabs/instant-ngp/issues?q=is%3Aissue) for help. If you are still stuck, please [open an issue](https://github.com/NVlabs/instant-ngp/issues/new) and ask for help.\n\n## Thanks\n\nMany thanks to [Jonathan Tremblay](https://research.nvidia.com/person/jonathan-tremblay) and [Andrew Tao](https://developer.nvidia.com/blog/author/atao/) for testing early versions of this codebase and to Arman Toorians and Saurabh Jain for the factory robot dataset.\nWe also thank [Andrew Webb](https://github.com/grey-area) for noticing that one of the prime numbers in the spatial hash was not actually prime; this has been fixed since.\n\nThis project makes use of a number of awesome open source libraries, including:\n* [tiny-cuda-nn](https://github.com/NVlabs/tiny-cuda-nn) for fast CUDA networks and input encodings\n* [tinyexr](https://github.com/syoyo/tinyexr) for EXR format support\n* [tinyobjloader](https://github.com/tinyobjloader/tinyobjloader) for OBJ format support\n* [stb_image](https://github.com/nothings/stb) for PNG and JPEG support\n* [Dear ImGui](https://github.com/ocornut/imgui) an excellent immediate mode GUI library\n* [Eigen](https://eigen.tuxfamily.org/index.php?title=Main_Page) a C++ template library for linear algebra\n* [pybind11](https://github.com/pybind/pybind11) for seamless C++ / Python interop\n* and others! See the `dependencies` folder.\n\nMany thanks to the authors of these brilliant projects!\n\n## License and Citation\n\n```bibtex\n@article{mueller2022instant,\n    author = {Thomas M\\\"uller and Alex Evans and Christoph Schied and Alexander Keller},\n    title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},\n    journal = {ACM Trans. Graph.},\n    issue_date = {July 2022},\n    volume = {41},\n    number = {4},\n    month = jul,\n    year = {2022},\n    pages = {102:1--102:15},\n    articleno = {102},\n    numpages = {15},\n    url = {https://doi.org/10.1145/3528223.3530127},\n    doi = {10.1145/3528223.3530127},\n    publisher = {ACM},\n    address = {New York, NY, USA},\n}\n```\n\nCopyright ¬© 2022, NVIDIA Corporation. All rights reserved.\n\nThis work is made available under the Nvidia Source Code License-NC. Click [here](LICENSE.txt) to view a copy of this license.\n",
         "AI_DataScience"
        ],
        [
         "45",
         "MDEwOlJlcG9zaXRvcnkzODAxOTE3NDk=",
         "# üì∫ ML YouTube Courses\n\nAt DAIR.AI we ‚ù§Ô∏è open AI education. In this repo, we index and organize some of the best and most recent machine learning courses available on YouTube.\n\n**Machine Learning**\n\n- [Caltech CS156: Learning from Data](#caltech-cs156-learning-from-data)\n- [Stanford CS229: Machine Learning](#stanford-cs229-machine-learning)\n- [Making Friends with Machine Learning](#making-friends-with-machine-learning)\n- [Applied Machine Learning](#applied-machine-learning)\n- [Introduction to Machine Learning (T√ºbingen)](#introduction-to-machine-learning-T√ºbingen)\n- [Machine Learning Lecture (Stefan Harmeling)](#machine-learning-lecture-stefan-harmeling)\n- [Statistical Machine Learning (T√ºbingen)](#statistical-machine-learning-T√ºbingen)\n- [Probabilistic Machine Learning](#probabilistic-machine-learning)\n- [MIT 6.S897: Machine Learning for Healthcare (2019)](#mit-6s897-machine-learning-for-healthcare-2019)\n\n**Deep Learning**\n\n- [Neural Networks: Zero to Hero](#neural-networks-zero-to-hero-by-andrej-karpathy)\n- [MIT: Deep Learning for Art, Aesthetics, and Creativity](#mit-deep-learning-for-art-aesthetics-and-creativity)\n- [Stanford CS230: Deep Learning (2018)](#stanford-cs230-deep-learning-2018)\n- [Introduction to Deep Learning (MIT)](#introduction-to-deep-learning)\n- [CMU Introduction to Deep Learning (11-785)](#cmu-introduction-to-deep-learning-11-785)\n- [Deep Learning: CS 182](#deep-learning-cs-182)\n- [Deep Unsupervised Learning](#deep-unsupervised-learning)\n- [NYU Deep Learning SP21](#nyu-deep-learning-sp21)\n- [Foundation Models](#foundation-models)\n- [Deep Learning (T√ºbingen)](#deep-learning-T√ºbingen)\n\n**Scientific Machine Learning**\n\n- [Parallel Computing and Scientific Machine Learning](#parallel-computing-and-scientific-machine-learning)\n\n**Practical Machine Learning**\n\n- [LLMOps: Building Real-World Applications With Large Language Models](#llmops-building-real-world-applications-with-large-language-models)\n- [Evaluating and Debugging Generative AI](#evaluating-and-debugging-generative-ai)\n- [ChatGPT Prompt Engineering for Developers](#chatgpt-prompt-engineering-for-developers)\n- [LangChain for LLM Application Development](#langchain-for-llm-application-development)\n- [LangChain: Chat with Your Data](#langchain-chat-with-your-data)\n- [Building Systems with the ChatGPT API](#building-systems-with-the-chatgpt-api)\n- [LangChain & Vector Databases in Production](#langchain--vector-databases-in-production)\n- [Building LLM-Powered Apps](#building-llm-powered-apps)\n- [Full Stack LLM Bootcamp](#full-stack-llm-bootcamp)\n- [Full Stack Deep Learning](#full-stack-deep-learning)\n- [Practical Deep Learning for Coders](#practical-deep-learning-for-coders)\n- [Stanford MLSys Seminars](#stanford-mlsys-seminars)\n- [Machine Learning Engineering for Production (MLOps)](#machine-learning-engineering-for-production-mlops)\n- [MIT Introduction to Data-Centric AI](#mit-introduction-to-data-centric-ai)\n\n**Natural Language Processing**\n\n- [XCS224U: Natural Language Understanding (2023)](#xcs224u-natural-language-understanding-2023)\n- [Stanford CS25 - Transformers United](#stanford-cs25---transformers-united)\n- [NLP Course (Hugging Face)](#nlp-course-hugging-face)\n- [CS224N: Natural Language Processing with Deep Learning](#cs224n-natural-language-processing-with-deep-learning)\n- [CMU Neural Networks for NLP](#cmu-neural-networks-for-nlp)\n- [CS224U: Natural Language Understanding](#cs224u-natural-language-understanding)\n- [CMU Advanced NLP 2021/2022/2024](#cmu-advanced-nlp)\n- [Multilingual NLP](#multilingual-nlp)\n- [Advanced NLP](#advanced-nlp)\n\n**Computer Vision**\n\n- [CS231N: Convolutional Neural Networks for Visual Recognition](#cs231n-convolutional-neural-networks-for-visual-recognition)\n- [Deep Learning for Computer Vision](#deep-learning-for-computer-vision)\n- [Deep Learning for Computer Vision (DL4CV)](#deep-learning-for-computer-vision-dl4cv)\n- [Deep Learning for Computer Vision (neuralearn.ai)](#deep-learning-for-computer-vision-neuralearnai)\n\n**Reinforcement Learning**\n\n- [Deep Reinforcement Learning](#deep-reinforcement-learning)\n- [Reinforcement Learning Lecture Series (DeepMind)](#reinforcement-learning-lecture-series-deepmind)\n- [Reinforcement Learning (Polytechnique Montreal, Fall 2021)](#reinforcement-learning-polytechnique-montreal-fall-2021)\n- [Foundations of Deep RL](#foundations-of-deep-rl)\n- [Stanford CS234: Reinforcement Learning](#stanford-cs234-reinforcement-learning)\n\n**Graph Machine Learning**\n\n- [Machine Learning with Graphs (Stanford)](#machine-learning-with-graphs-stanford)\n- [AMMI Geometric Deep Learning Course](#ammi-geometric-deep-learning-course)\n\n**Multi-Task Learning**\n\n- [Multi-Task and Meta-Learning (Stanford)](#stanford-cs330-deep-multi-task-and-meta-learning)\n\n**Others**\n\n- [MIT Deep Learning in Life Sciences](#mit-deep-learning-in-life-sciences)\n- [Self-Driving Cars (T√ºbingen)](#self-driving-cars-T√ºbingen)\n- [Advanced Robotics (Berkeley)](#advanced-robotics-uc-berkeley)\n\n---\n\n## Caltech CS156: Learning from Data\n\nAn introductory course in machine learning that covers the basic theory, algorithms, and applications.\n\n- Lecture 1: The Learning Problem\n- Lecture 2: Is Learning Feasible?\n- Lecture 3: The Linear Model I\n- Lecture 4: Error and Noise\n- Lecture 5: Training versus Testing\n- Lecture 6: Theory of Generalization\n- Lecture 7: The VC Dimension\n- Lecture 8: Bias-Variance Tradeoff\n- Lecture 9: The Linear Model II\n- Lecture 10: Neural Networks\n- Lecture 11: Overfitting\n- Lecture 12: Regularization\n- Lecture 13: Validation\n- Lecture 14: Support Vector Machines\n- Lecture 15: Kernel Methods\n- Lecture 16: Radial Basis Functions\n- Lecture 17: Three Learning Principles\n- Lecture 18: Epilogue\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLD63A284B7615313A)\n\n## Stanford CS229: Machine Learning\n\nTo learn some of the basics of ML:\n\n- Linear Regression and Gradient Descent\n- Logistic Regression\n- Naive Bayes\n- SVMs\n- Kernels\n- Decision Trees\n- Introduction to Neural Networks\n- Debugging ML Models\n  ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU)\n\n## Making Friends with Machine Learning\n\nA series of mini lectures covering various introductory topics in ML:\n\n- Explainability in AI\n- Classification vs. Regression\n- Precession vs. Recall\n- Statistical Significance\n- Clustering and K-means\n- Ensemble models\n  ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLRKtJ4IpxJpDxl0NTvNYQWKCYzHNuy2xG)\n\n## Neural Networks: Zero to Hero (by Andrej Karpathy)\n\nCourse providing an in-depth overview of neural networks.\n\n- Backpropagation\n- Spelled-out intro to Language Modeling\n- Activation and Gradients\n- Becoming a Backprop Ninja\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)\n\n## MIT: Deep Learning for Art, Aesthetics, and Creativity\n\nCovers the application of deep learning for art, aesthetics, and creativity.\n\n- Nostalgia -> Art -> Creativity -> Evolution as Data + Direction\n- Efficient GANs\n- Explorations in AI for Creativity\n- Neural Abstractions\n- Easy 3D Content Creation with Consistent Neural Fields\n  ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLCpMvp7ftsnIbNwRnQJbDNRqO6qiN3EyH)\n\n## Stanford CS230: Deep Learning (2018)\n\nCovers the foundations of deep learning, how to build different neural networks(CNNs, RNNs, LSTMs, etc...), how to lead machine learning projects, and career advice for deep learning practitioners.\n\n- Deep Learning Intuition\n- Adversarial examples - GANs\n- Full-cycle of a Deep Learning Project\n- AI and Healthcare\n- Deep Learning Strategy\n- Interpretability of Neural Networks\n- Career Advice and Reading Research Papers\n- Deep Reinforcement Learning\n\nüîó [Link to Course](https://youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb) üîó [Link to Materials](https://cs230.stanford.edu/syllabus/)\n\n## Applied Machine Learning\n\nTo learn some of the most widely used techniques in ML:\n\n- Optimization and Calculus\n- Overfitting and Underfitting\n- Regularization\n- Monte Carlo Estimation\n- Maximum Likelihood Learning\n- Nearest Neighbours\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83)\n\n## Introduction to Machine Learning (T√ºbingen)\n\nThe course serves as a basic introduction to machine learning and covers key concepts in regression, classification, optimization, regularization, clustering, and dimensionality reduction.\n\n- Linear regression\n- Logistic regression\n- Regularization\n- Boosting\n- Neural networks\n- PCA\n- Clustering\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL05umP7R6ij35ShKLDqccJSDntugY4FQT)\n\n## Machine Learning Lecture (Stefan Harmeling)\n\nCovers many fundamental ML concepts:\n\n- Bayes rule\n- From logic to probabilities\n- Distributions\n- Matrix Differential Calculus\n- PCA\n- K-means and EM\n- Causality\n- Gaussian Processes\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLzrCXlf6ypbxS5OYOY3EN_0u2fDuIT6Gt)\n\n## Statistical Machine Learning (T√ºbingen)\n\nThe course covers the standard paradigms and algorithms in statistical machine learning.\n\n- KNN\n- Bayesian decision theory\n- Convex optimization\n- Linear and ridge regression\n- Logistic regression\n- SVM\n- Random Forests\n- Boosting\n- PCA\n- Clustering\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL05umP7R6ij2XCvrRzLokX6EoHWaGA2cC)\n\n## Practical Deep Learning for Coders\n\nThis course covers topics such as how to:\n\n- Build and train deep learning models for computer vision, natural language processing, tabular analysis, and collaborative filtering problems\n- Create random forests and regression models\n- Deploy models\n- Use PyTorch, the world‚Äôs fastest growing deep learning software, plus popular libraries like fastai and Hugging Face\n- Foundations and Deep Dive to Diffusion Models\n- ...\n\nüîó [Link to Course - Part 1](https://www.youtube.com/playlist?list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU)\n\nüîó [Link to Course - Part 2](https://www.youtube.com/watch?v=_7rMfsA24Ls&ab_channel=JeremyHoward)\n\n## Stanford MLSys Seminars\n\nA seminar series on all sorts of topics related to building machine learning systems.\n\nüîó [Link to Lectures](https://www.youtube.com/playlist?list=PLSrTvUm384I9PV10koj_cqit9OfbJXEkq)\n\n## Machine Learning Engineering for Production (MLOps)\n\nSpecialization course on MLOPs by Andrew Ng.\n\nüîó [Link to Lectures](https://www.youtube.com/playlist?list=PLkDaE6sCZn6GMoA0wbpJLi3t34Gd8l0aK)\n\n## MIT Introduction to Data-Centric AI\n\nCovers the emerging science of Data-Centric AI (DCAI) that studies techniques to improve datasets, which is often the best way to improve performance in practical ML applications. Topics include:\n\n- Data-Centric AI vs. Model-Centric AI\n- Label Errors\n- Dataset Creation and Curation\n- Data-centric Evaluation of ML Models\n- Class Imbalance, Outliers, and Distribution Shift\n- ...\n\nüîó [Course Website](https://dcai.csail.mit.edu/)\n\nüîó [Lecture Videos](https://www.youtube.com/watch?v=ayzOzZGHZy4&list=PLnSYPjg2dHQKdig0vVbN-ZnEU0yNJ1mo5)\n\nüîó [Lab Assignments](https://github.com/dcai-course/dcai-lab)\n\n## Machine Learning with Graphs (Stanford)\n\nTo learn some of the latest graph techniques in machine learning:\n\n- PageRank\n- Matrix Factorizing\n- Node Embeddings\n- Graph Neural Networks\n- Knowledge Graphs\n- Deep Generative Models for Graphs\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn)\n\n## Probabilistic Machine Learning\n\nTo learn the probabilistic paradigm of ML:\n\n- Reasoning about uncertainty\n- Continuous Variables\n- Sampling\n- Markov Chain Monte Carlo\n- Gaussian Distributions\n- Graphical Models\n- Tuning Inference Algorithms\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL05umP7R6ij2YE8rRJSb-olDNbntAQ_Bx)\n\n## MIT 6.S897: Machine Learning for Healthcare (2019)\n\nThis course introduces students to machine learning in healthcare, including the nature of clinical data and the use of machine learning for risk stratification, disease progression modeling, precision medicine, diagnosis, subtype discovery, and improving clinical workflows.\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLUl4u3cNGP60B0PQXVQyGNdCyCTDU1Q5j)\n\n## Introduction to Deep Learning\n\nTo learn some of the fundamentals of deep learning:\n\n- Introduction to Deep Learning\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI)\n\n## CMU Introduction to Deep Learning (11-785)\n\nThe course starts off gradually from MLPs (Multi Layer Perceptrons) and then progresses into concepts like attention\nand sequence-to-sequence models.\n\nüîó [Link to Course](https://deeplearning.cs.cmu.edu/F22/index.html) \\\nüîó [Lectures](https://www.youtube.com/playlist?list=PLp-0K3kfddPxRmjgjm0P1WT6H-gTqE8j9) \\\nüîó [Tutorials/Recitations](https://www.youtube.com/playlist?list=PLp-0K3kfddPz8WXg8RqH0sEN6X2L65HUZ)\n\n## Deep Learning: CS 182\n\nTo learn some of the widely used techniques in deep learning:\n\n- Machine Learning Basics\n- Error Analysis\n- Optimization\n- Backpropagation\n- Initialization\n- Batch Normalization\n- Style transfer\n- Imitation Learning\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A)\n\n## Deep Unsupervised Learning\n\nTo learn the latest and most widely used techniques in deep unsupervised learning:\n\n- Autoregressive Models\n- Flow Models\n- Latent Variable Models\n- Self-supervised learning\n- Implicit Models\n- Compression\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP)\n\n## NYU Deep Learning SP21\n\nTo learn some of the advanced techniques in deep learning:\n\n- Neural Nets: rotation and squashing\n- Latent Variable Energy Based Models\n- Unsupervised Learning\n- Generative Adversarial Networks\n- Autoencoders\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI)\n\n## Foundation Models\n\nTo learn about foundation models like GPT-3, CLIP, Flamingo, Codex, and DINO.\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL9t0xVFP90GD8hox0KipBkJcLX_C3ja67)\n\n## Deep Learning (T√ºbingen)\n\nThis course introduces the practical and theoretical principles of deep neural networks.\n\n- Computation graphs\n- Activation functions and loss functions\n- Training, regularization and data augmentation\n- Basic and state-of-the-art deep neural network architectures including convolutional networks and graph neural networks\n- Deep generative models such as auto-encoders, variational auto-encoders and generative adversarial networks\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL05umP7R6ij3NTWIdtMbfvX7Z-4WEXRqD)\n\n## Parallel Computing and Scientific Machine Learning\n\n- The Basics of Scientific Simulators\n- Introduction to Parallel Computing\n- Continuous Dynamics\n- Inverse Problems and Differentiable Programming\n- Distributed Parallel Computing\n- Physics-Informed Neural Networks and Neural Differential Equations\n- Probabilistic Programming, AKA Bayesian Estimation on Programs\n- Globalizing the Understanding of Models\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLCAl7tjCwWyGjdzOOnlbGnVNZk0kB8VSa)\n\n## XCS224U: Natural Language Understanding (2023)\n\nThis course covers topics such as:\n\n- Contextual Word Representations\n- Information Retrieval\n- In-context learning\n- Behavioral Evaluation of NLU models\n- NLP Methods and Metrics\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLoROMvodv4rOwvldxftJTmoR3kRcWkJBp)\n\n## Stanford CS25 - Transformers United\n\nThis course consists of lectures focused on Transformers, providing a deep dive and their applications\n\n- Introduction to Transformers\n- Transformers in Language: GPT-3, Codex\n- Applications in Vision\n- Transformers in RL & Universal\n  Compute Engines\n- Scaling transformers\n- Interpretability with transformers\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM)\n\n## NLP Course (Hugging Face)\n\nLearn about different NLP concepts and how to apply language models and Transformers to NLP:\n\n- What is Transfer Learning?\n- BPE Tokenization\n- Batching inputs\n- Fine-tuning models\n- Text embeddings and semantic search\n- Model evaluation\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o)\n\n## CS224N: Natural Language Processing with Deep Learning\n\nTo learn the latest approaches for deep learning based NLP:\n\n- Dependency parsing\n- Language models and RNNs\n- Question Answering\n- Transformers and pretraining\n- Natural Language Generation\n- T5 and Large Language Models\n- Future of NLP\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ)\n\n## CMU Neural Networks for NLP\n\nTo learn the latest neural network based techniques for NLP:\n\n- Language Modeling\n- Efficiency tricks\n- Conditioned Generation\n- Structured Prediction\n- Model Interpretation\n- Advanced Search Algorithms\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL8PYTP1V4I8AkaHEJ7lOOrlex-pcxS-XV)\n\n## CS224U: Natural Language Understanding\n\nTo learn the latest concepts in natural language understanding:\n\n- Grounded Language Understanding\n- Relation Extraction\n- Natural Language Inference (NLI)\n- NLU and Neural Information Extraction\n- Adversarial testing\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLoROMvodv4rPt5D0zs3YhbWSZA8Q_DyiJ)\n\n## CMU Advanced NLP\n\nTo learn:\n\n- Basics of modern NLP techniques\n- Multi-task, Multi-domain, multi-lingual learning\n- Prompting + Sequence-to-sequence pre-training\n- Interpreting and Debugging NLP Models\n- Learning from Knowledge-bases\n- Adversarial learning\n- ...\n\nüîó [Link to 2021 Edition](https://www.youtube.com/playlist?list=PL8PYTP1V4I8AYSXn_GKVgwXVluCT9chJ6)\n\nüîó [Link to 2022 Edition](https://www.youtube.com/playlist?list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z)\n\nüîó [Link to 2024 Edition](https://www.youtube.com/playlist?list=PL8PYTP1V4I8DZprnWryM4nR8IZl1ZXDjg)\n\n## Multilingual NLP\n\nTo learn the latest concepts for doing multilingual NLP:\n\n- Typology\n- Words, Part of Speech, and Morphology\n- Advanced Text Classification\n- Machine Translation\n- Data Augmentation for MT\n- Low Resource ASR\n- Active Learning\n- ...\n\nüîó [Link to 2020 Course](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5)\n\nüîó [Link to 2022 Course](https://www.youtube.com/playlist?list=PL8PYTP1V4I8BhCpzfdKKdd1OnTfLcyZr7)\n\n## Advanced NLP\n\nTo learn advanced concepts in NLP:\n\n- Attention Mechanisms\n- Transformers\n- BERT\n- Question Answering\n- Model Distillation\n- Vision + Language\n- Ethics in NLP\n- Commonsense Reasoning\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLWnsVgP6CzadmQX6qevbar3_vDBioWHJL)\n\n## CS231N: Convolutional Neural Networks for Visual Recognition\n\nStanford's Famous CS231n course. The videos are only available for the Spring 2017 semester. The course is currently known as Deep Learning for Computer Vision, but the Spring 2017 version is titled Convolutional Neural Networks for Visual Recognition.\n\n- Image Classification\n- Loss Functions and Optimization\n- Introduction to Neural Networks\n- Convolutional Neural Networks\n- Training Neural Networks\n- Deep Learning Software\n- CNN Architectures\n- Recurrent Neural Networks\n- Detection and Segmentation\n- Visualizing and Understanding\n- Generative Models\n- Deep Reinforcement Learning\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv) üîó [Link to Materials](http://cs231n.stanford.edu/2017/)\n\n## Deep Learning for Computer Vision\n\nTo learn some of the fundamental concepts in CV:\n\n- Introduction to deep learning for CV\n- Image Classification\n- Convolutional Networks\n- Attention Networks\n- Detection and Segmentation\n- Generative Models\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)\n\n## Deep Learning for Computer Vision (DL4CV)\n\nTo learn modern methods for computer vision:\n\n- CNNs\n- Advanced PyTorch\n- Understanding Neural Networks\n- RNN, Attention and ViTs\n- Generative Models\n- GPU Fundamentals\n- Self-Supervision\n- Neural Rendering\n- Efficient Architectures\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL_Z2_U9MIJdNgFM7-f2fZ9ZxjVRP_jhJv)\n\n## Deep Learning for Computer Vision (neuralearn.ai)\n\nTo learn modern methods for computer vision:\n\n- Self-Supervised Learning\n- Neural Rendering\n- Efficient Architectures\n- Machine Learning Operations (MLOps)\n- Modern Convolutional Neural Networks\n- Transformers in Vision\n- Model Deployment\n\nüîó [Link to Course](https://www.youtube.com/watch?v=IA3WxTTPXqQ)\n\n## AMMI Geometric Deep Learning Course\n\nTo learn about concepts in geometric deep learning:\n\n- Learning in High Dimensions\n- Geometric Priors\n- Grids\n- Manifolds and Meshes\n- Sequences and Time Warping\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLn2-dEmQeTfSLXW8yXP4q_Ii58wFdxb3C)\n\n## Deep Reinforcement Learning\n\nTo learn the latest concepts in deep RL:\n\n- Intro to RL\n- RL algorithms\n- Real-world sequential decision making\n- Supervised learning of behaviors\n- Deep imitation learning\n- Cost functions and reward functions\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc)\n\n## Reinforcement Learning Lecture Series (DeepMind)\n\nThe Deep Learning Lecture Series is a collaboration between DeepMind and the UCL Centre for Artificial Intelligence.\n\n- Introduction to RL\n- Dynamic Programming\n- Model-free algorithms\n- Deep reinforcement learning\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLqYmG7hTraZDVH599EItlEWsUOsJbAodm)\n\n\n## LLMOps: Building Real-World Applications With Large Language Models\n\nLearn to build modern software with LLMs using the newest tools and techniques in the field.\n\nüîó [Link to Course](https://www.comet.com/site/llm-course/)\n\n## Evaluating and Debugging Generative AI\n\nYou'll learn:\n\n- Instrument A Jupyter Notebook\n- Manage Hyperparameters Config\n- Log Run Metrics\n- Collect artifacts for dataset and model versioning\n- Log experiment results\n- Trace prompts and responses for LLMs\n- ...\n\nüîó [Link to Course](https://www.deeplearning.ai/short-courses/evaluating-debugging-generative-ai/)\n\n## ChatGPT Prompt Engineering for Developers\n\nLearn how to use a large language model (LLM) to quickly build new and powerful applications.\n\nüîó [Link to Course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)\n\n## LangChain for LLM Application Development\n\nYou'll learn:\n\n- Models, Prompt, and Parsers\n- Memories for LLMs\n- Chains\n- Question Answering over Documents\n- Agents\n\nüîó [Link to Course](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)\n\n## LangChain: Chat with Your Data\n\nYou'll learn about:\n\n- Document Loading\n- Document Splitting\n- Vector Stores and Embeddings\n- Retrieval\n- Question Answering\n- Chat\n\nüîó [Link to Course](https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/)\n\n## Building Systems with the ChatGPT API\n\nLearn how to automate complex workflows using chain calls to a large language model.\n\nüîó [Link to Course](https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/)\n\n## LangChain & Vector Databases in Production\n\nLearn how to use LangChain and Vector DBs in Production:\n\n- LLMs and LangChain\n- Learning how to Prompt\n- Keeping Knowledge Organized with Indexes\n- Combining Components Together with Chains\n- ...\n\nüîó [Link to Course](https://learn.activeloop.ai/courses/langchain)\n\n## Building LLM-Powered Apps\n\nLearn how to build LLM-powered applications using LLM APIs\n\n- Unpacking LLM APIs\n- Building a Baseline LLM Application\n- Enhancing and Optimizing LLM Applications\n- ...\n\nüîó [Link to Course](https://www.wandb.courses/courses/building-llm-powered-apps)\n\n## Full Stack LLM Bootcamp\n\nTo learn how to build and deploy LLM-powered applications:\n\n- Learn to Spell: Prompt Engineering\n- LLMOPs\n- UX for Language User Interfaces\n- Augmented Language Models\n- Launch an LLM App in One Hour\n- LLM Foundations\n- Project Walkthrough: askFSDL\n- ...\n\nüîó [Link to Course](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)\n\n## Full Stack Deep Learning\n\nTo learn full-stack production deep learning:\n\n- ML Projects\n- Infrastructure and Tooling\n- Experiment Managing\n- Troubleshooting DNNs\n- Data Management\n- Data Labeling\n- Monitoring ML Models\n- Web deployment\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL1T8fO7ArWlcWg04OgNiJy91PywMKT2lv)\n\n## Introduction to Deep Learning and Deep Generative Models\n\nCovers the fundamental concepts of deep learning\n\n- Single-layer neural networks and gradient descent\n- Multi-layer neural networks and backpropagation\n- Convolutional neural networks for images\n- Recurrent neural networks for text\n- Autoencoders, variational autoencoders, and generative adversarial networks\n- Encoder-decoder recurrent neural networks and transformers\n- PyTorch code examples\n\nüîó [Link to Course](https://www.youtube.com/watch?v=1nqCZqDYPp0&list=PLTKMiZHVd_2KJtIXOW0zFhFfBaJJilH51) üîó [Link to Materials](https://sebastianraschka.com/blog/2021/dl-course.html)\n\n## Self-Driving Cars (T√ºbingen)\n\nCovers the most dominant paradigms of self-driving cars: modular pipeline-based approaches as well as deep-learning based end-to-end driving techniques.\n\n- Camera, lidar and radar-based perception\n- Localization, navigation, path planning\n- Vehicle modeling/control\n- Deep Learning\n- Imitation learning\n- Reinforcement learning\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PL05umP7R6ij321zzKXK6XCQXAaaYjQbzr)\n\n## Reinforcement Learning (Polytechnique Montreal, Fall 2021)\n\nDesigning autonomous decision making systems is one of the longstanding goals of Artificial Intelligence. Such decision making systems, if realized, can have a big impact in machine learning for robotics, game playing, control, health care to name a few. This course introduces Reinforcement Learning as a general framework to design such autonomous decision making systems.\n\n- Introduction to RL\n- Multi-armed bandits\n- Policy Gradient Methods\n- Contextual Bandits\n- Finite Markov Decision Process\n- Dynamic Programming\n- Policy Iteration, Value Iteration\n- Monte Carlo Methods\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLImtCgowF_ES_JdF_UcM60EXTcGZg67Ua) üîó [Link to Materials](https://chandar-lab.github.io/INF8953DE/)\n\n## Foundations of Deep RL\n\nA mini 6-lecture series by Pieter Abbeel.\n\n- MDPs, Exact Solution Methods, Max-ent RL\n- Deep Q-Learning\n- Policy Gradients and Advantage Estimation\n- TRPO and PPO\n- DDPG and SAC\n- Model-based RL\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLwRJQ4m4UJjNymuBM9RdmB3Z9N5-0IlY0)\n\n## Stanford CS234: Reinforcement Learning\n\nCovers topics from basic concepts of Reinforcement Learning to more advanced ones:\n\n- Markov decision processes & planning\n- Model-free policy evaluation\n- Model-free control\n- Reinforcement learning with function approximation & Deep RL\n- Policy Search\n- Exploration\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u) üîó [Link to Materials](https://web.stanford.edu/class/cs234/)\n\n## Stanford CS330: Deep Multi-Task and Meta Learning\n\nThis is a graduate-level course covering different aspects of deep multi-task and meta learning.\n\n- Multi-task learning, transfer learning basics\n- Meta-learning algorithms\n- Advanced meta-learning topics\n- Multi-task RL, goal-conditioned RL\n- Meta-reinforcement learning\n- Hierarchical RL\n- Lifelong learning\n- Open problems\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5) üîó [Link to Materials](https://cs330.stanford.edu/)\n\n## MIT Deep Learning in Life Sciences\n\nA course introducing foundations of ML for applications in genomics and the life sciences more broadly.\n\n- Interpreting ML Models\n- DNA Accessibility, Promoters and Enhancers\n- Chromatin and gene regulation\n- Gene Expression, Splicing\n- RNA-seq, Splicing\n- Single cell RNA-sequencing\n- Dimensionality Reduction, Genetics, and Variation\n- Drug Discovery\n- Protein Structure Prediction\n- Protein Folding\n- Imaging and Cancer\n- Neuroscience\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLypiXJdtIca5ElZMWHl4HMeyle2AzUgVB)\n\nüîó [Link to Materials](https://mit6874.github.io/)\n\n## Advanced Robotics: UC Berkeley\n\nThis is course is from Peter Abbeel and covers a review on reinforcement learning and continues to applications in robotics.\n\n- MDPs: Exact Methods\n- Discretization of Continuous State Space MDPs\n- Function Approximation / Feature-based Representations\n- LQR, iterative LQR / Differential Dynamic Programming\n- ...\n\nüîó [Link to Course](https://www.youtube.com/playlist?list=PLwRJQ4m4UJjNBPJdt8WamRAt4XKc639wF) üîó [Link to Materials](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/)\n\n---\n\nReach out on [Twitter](https://twitter.com/omarsar0) if you have any questions.\n\nIf you are interested to contribute, feel free to open a PR with a link to the course. It will take a bit of time, but I have plans to do many things with these individual lectures. We can summarize the lectures, include notes, provide additional reading material, include difficulty of content, etc.\n\nYou can now find ML Course notes [here](https://github.com/dair-ai/ML-Course-Notes).\n",
         "AI_DataScience"
        ],
        [
         "46",
         "MDEwOlJlcG9zaXRvcnk0MjM2MDYwMQ==",
         "\n# Machine Learning & Deep Learning Tutorials [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\n- This repository contains a topic-wise curated list of Machine Learning and Deep Learning tutorials, articles and other resources. Other awesome lists can be found in this [list](https://github.com/sindresorhus/awesome).\n\n- If you want to contribute to this list, please read [Contributing Guidelines](https://github.com/ujjwalkarn/Machine-Learning-Tutorials/blob/master/contributing.md).\n\n- [Curated list of R tutorials for Data Science, NLP and Machine Learning](https://github.com/ujjwalkarn/DataScienceR).\n\n- [Curated list of Python tutorials for Data Science, NLP and Machine Learning](https://github.com/ujjwalkarn/DataSciencePython).\n\n\n## Contents\n- [Introduction](#general)\n- [Interview Resources](#interview)\n- [Artificial Intelligence](#ai)\n- [Genetic Algorithms](#ga)\n- [Statistics](#stat)\n- [Useful Blogs](#blogs)\n- [Resources on Quora](#quora)\n- [Resources on Kaggle](#kaggle)\n- [Cheat Sheets](#cs)\n- [Classification](#classification)\n- [Linear Regression](#linear)\n- [Logistic Regression](#logistic)\n- [Model Validation using Resampling](#validation)\n    - [Cross Validation](#cross)\n    - [Bootstraping](#boot)\n- [Deep Learning](#deep)\n    - [Frameworks](#frame)\n    - [Feed Forward Networks](#feed)\n    - [Recurrent Neural Nets, LSTM, GRU](#rnn)\n    - [Restricted Boltzmann Machine, DBNs](#rbm)\n    - [Autoencoders](#auto)\n    - [Convolutional Neural Nets](#cnn)\n    - [Graph Representation Learning](#nrl)\n- [Natural Language Processing](#nlp)\n    - [Topic Modeling, LDA](#topic)\n    - [Word2Vec](#word2vec)\n- [Computer Vision](#vision)\n- [Support Vector Machine](#svm)\n- [Reinforcement Learning](#rl)\n- [Decision Trees](#dt)\n- [Random Forest / Bagging](#rf)\n- [Boosting](#gbm)\n- [Ensembles](#ensem)\n- [Stacking Models](#stack)\n- [VC Dimension](#vc)\n- [Bayesian Machine Learning](#bayes)\n- [Semi Supervised Learning](#semi)\n- [Optimizations](#opt)\n- [Other Useful Tutorials](#other)\n\n<a name=\"general\" />\n\n## Introduction\n\n- [Machine Learning Course by Andrew Ng (Stanford University)](https://www.coursera.org/learn/machine-learning)\n\n- [AI/ML YouTube Courses](https://github.com/dair-ai/ML-YouTube-Courses)\n\n- [Curated List of Machine Learning Resources](https://hackr.io/tutorials/learn-machine-learning-ml)\n\n- [In-depth introduction to machine learning in 15 hours of expert videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n\n- [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)\n\n- [List of Machine Learning University Courses](https://github.com/prakhar1989/awesome-courses#machine-learning)\n\n- [Machine Learning for Software Engineers](https://github.com/ZuzooVn/machine-learning-for-software-engineers)\n\n- [Dive into Machine Learning](https://github.com/hangtwenty/dive-into-machine-learning)\n\n- [A curated list of awesome Machine Learning frameworks, libraries and software](https://github.com/josephmisiti/awesome-machine-learning)\n\n- [A curated list of awesome data visualization libraries and resources.](https://github.com/fasouto/awesome-dataviz)\n\n- [An awesome Data Science repository to learn and apply for real world problems](https://github.com/okulbilisim/awesome-datascience)\n\n- [The Open Source Data Science Masters](http://datasciencemasters.org/)\n\n- [Machine Learning FAQs on Cross Validated](http://stats.stackexchange.com/questions/tagged/machine-learning)\n\n- [Machine Learning algorithms that you should always have a strong understanding of](https://www.quora.com/What-are-some-Machine-Learning-algorithms-that-you-should-always-have-a-strong-understanding-of-and-why)\n\n- [Difference between Linearly Independent, Orthogonal, and Uncorrelated Variables](http://terpconnect.umd.edu/~bmomen/BIOM621/LineardepCorrOrthogonal.pdf)\n\n- [List of Machine Learning Concepts](https://en.wikipedia.org/wiki/List_of_machine_learning_concepts)\n\n- [Slides on Several Machine Learning Topics](http://www.slideshare.net/pierluca.lanzi/presentations)\n\n- [MIT Machine Learning Lecture Slides](http://www.ai.mit.edu/courses/6.867-f04/lectures.html)\n\n- [Comparison Supervised Learning Algorithms](http://www.dataschool.io/comparing-supervised-learning-algorithms/)\n\n- [Learning Data Science Fundamentals](http://www.dataschool.io/learning-data-science-fundamentals/)\n\n- [Machine Learning mistakes to avoid](https://medium.com/@nomadic_mind/new-to-machine-learning-avoid-these-three-mistakes-73258b3848a4#.lih061l3l)\n\n- [Statistical Machine Learning Course](http://www.stat.cmu.edu/~larry/=sml/)\n\n- [TheAnalyticsEdge edX Notes and Codes](https://github.com/pedrosan/TheAnalyticsEdge)\n\n- [Have Fun With Machine Learning](https://github.com/humphd/have-fun-with-machine-learning)\n\n- [Twitter's Most Shared #machineLearning Content From The Past 7 Days](http://theherdlocker.com/tweet/popularity/machinelearning)\n\n- [Grokking Machine Learning](https://www.manning.com/books/grokking-machine-learning)\n\n<a name=\"interview\" />\n\n## Interview Resources\n\n- [41 Essential Machine Learning Interview Questions (with answers)](https://www.springboard.com/blog/machine-learning-interview-questions/)\n\n- [How can a computer science graduate student prepare himself for data scientist interviews?](https://www.quora.com/How-can-a-computer-science-graduate-student-prepare-himself-for-data-scientist-machine-learning-intern-interviews)\n\n- [How do I learn Machine Learning?](https://www.quora.com/How-do-I-learn-machine-learning-1)\n\n- [FAQs about Data Science Interviews](https://www.quora.com/topic/Data-Science-Interviews/faq)\n\n- [What are the key skills of a data scientist?](https://www.quora.com/What-are-the-key-skills-of-a-data-scientist)\n\n- [The Big List of DS/ML Interview Resources](https://towardsdatascience.com/the-big-list-of-ds-ml-interview-resources-2db4f651bd63)\n\n<a name=\"ai\" />\n\n## Artificial Intelligence\n\n- [Awesome Artificial Intelligence (GitHub Repo)](https://github.com/owainlewis/awesome-artificial-intelligence)\n\n- [UC Berkeley CS188 Intro to AI](http://ai.berkeley.edu/home.html), [Lecture Videos](http://ai.berkeley.edu/lecture_videos.html), [2](https://www.youtube.com/watch?v=W1S-HSakPTM)\n\n- [Programming Community Curated Resources for learning Artificial Intelligence](https://hackr.io/tutorials/learn-artificial-intelligence-ai) \n\n- [MIT 6.034 Artificial Intelligence Lecture Videos](https://www.youtube.com/playlist?list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi), [Complete Course](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/)\n\n- [edX course | Klein & Abbeel](https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/info)\n\n- [Udacity Course | Norvig & Thrun](https://www.udacity.com/course/intro-to-artificial-intelligence--cs271)\n\n- [TED talks on AI](http://www.ted.com/playlists/310/talks_on_artificial_intelligen)\n\n<a name=\"ga\" />\n\n## Genetic Algorithms\n\n- [Genetic Algorithms Wikipedia Page](https://en.wikipedia.org/wiki/Genetic_algorithm)\n\n- [Simple Implementation of Genetic Algorithms in Python (Part 1)](http://outlace.com/miniga.html), [Part 2](http://outlace.com/miniga_addendum.html)\n\n- [Genetic Algorithms vs Artificial Neural Networks](http://stackoverflow.com/questions/1402370/when-to-use-genetic-algorithms-vs-when-to-use-neural-networks)\n\n- [Genetic Algorithms Explained in Plain English](http://www.ai-junkie.com/ga/intro/gat1.html)\n\n- [Genetic Programming](https://en.wikipedia.org/wiki/Genetic_programming)\n\n    - [Genetic Programming in Python (GitHub)](https://github.com/trevorstephens/gplearn)\n    \n    - [Genetic Alogorithms vs Genetic Programming (Quora)](https://www.quora.com/Whats-the-difference-between-Genetic-Algorithms-and-Genetic-Programming), [StackOverflow](http://stackoverflow.com/questions/3819977/what-are-the-differences-between-genetic-algorithms-and-genetic-programming)\n\n<a name=\"stat\" />\n\n## Statistics\n\n- [Stat Trek Website](http://stattrek.com/) - A dedicated website to teach yourselves Statistics\n\n- [Learn Statistics Using Python](https://github.com/rouseguy/intro2stats) - Learn Statistics using an application-centric programming approach\n\n- [Statistics for Hackers | Slides | @jakevdp](https://speakerdeck.com/jakevdp/statistics-for-hackers) - Slides by Jake VanderPlas\n\n- [Online Statistics Book](http://onlinestatbook.com/2/index.html) - An Interactive Multimedia Course for Studying Statistics\n\n- [What is a Sampling Distribution?](http://stattrek.com/sampling/sampling-distribution.aspx)\n\n- Tutorials\n\n    - [AP Statistics Tutorial](http://stattrek.com/tutorials/ap-statistics-tutorial.aspx)\n    \n    - [Statistics and Probability Tutorial](http://stattrek.com/tutorials/statistics-tutorial.aspx)\n    \n    - [Matrix Algebra Tutorial](http://stattrek.com/tutorials/matrix-algebra-tutorial.aspx)\n    \n- [What is an Unbiased Estimator?](https://www.physicsforums.com/threads/what-is-an-unbiased-estimator.547728/)\n\n- [Goodness of Fit Explained](https://en.wikipedia.org/wiki/Goodness_of_fit)\n\n- [What are QQ Plots?](http://onlinestatbook.com/2/advanced_graphs/q-q_plots.html)\n\n- [OpenIntro Statistics](https://www.openintro.org/stat/textbook.php?stat_book=os) - Free PDF textbook\n\n<a name=\"blogs\" />\n\n## Useful Blogs\n\n- [Edwin Chen's Blog](http://blog.echen.me/) - A blog about Math, stats, ML, crowdsourcing, data science\n\n- [The Data School Blog](http://www.dataschool.io/) - Data science for beginners!\n\n- [ML Wave](http://mlwave.com/) - A blog for Learning Machine Learning\n\n- [Andrej Karpathy](http://karpathy.github.io/) - A blog about Deep Learning and Data Science in general\n\n- [Colah's Blog](http://colah.github.io/) - Awesome Neural Networks Blog\n\n- [Alex Minnaar's Blog](http://alexminnaar.com/) - A blog about Machine Learning and Software Engineering\n\n- [Statistically Significant](http://andland.github.io/) - Andrew Landgraf's Data Science Blog\n\n- [Simply Statistics](http://simplystatistics.org/) - A blog by three biostatistics professors\n\n- [Yanir Seroussi's Blog](https://yanirseroussi.com/) - A blog about Data Science and beyond\n\n- [fastML](http://fastml.com/) - Machine learning made easy\n\n- [Trevor Stephens Blog](http://trevorstephens.com/) - Trevor Stephens Personal Page\n\n- [no free hunch | kaggle](http://blog.kaggle.com/) - The Kaggle Blog about all things Data Science\n\n- [A Quantitative Journey | outlace](http://outlace.com/) -  learning quantitative applications\n\n- [r4stats](http://r4stats.com/) - analyze the world of data science, and to help people learn to use R\n\n- [Variance Explained](http://varianceexplained.org/) - David Robinson's Blog\n\n- [AI Junkie](http://www.ai-junkie.com/) - a blog about Artificial Intellingence\n\n- [Deep Learning Blog by Tim Dettmers](http://timdettmers.com/) - Making deep learning accessible\n\n- [J Alammar's Blog](http://jalammar.github.io/)- Blog posts about Machine Learning and Neural Nets\n\n- [Adam Geitgey](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.f7vwrtfne) - Easiest Introduction to machine learning\n\n- [Ethen's Notebook Collection](https://github.com/ethen8181/machine-learning) - Continuously updated machine learning documentations (mainly in Python3). Contents include educational implementation of machine learning algorithms from scratch and open-source library usage\n\n<a name=\"quora\" />\n\n## Resources on Quora\n\n- [Most Viewed Machine Learning writers](https://www.quora.com/topic/Machine-Learning/writers)\n\n- [Data Science Topic on Quora](https://www.quora.com/Data-Science)\n\n- [William Chen's Answers](https://www.quora.com/William-Chen-6/answers)\n\n- [Michael Hochster's Answers](https://www.quora.com/Michael-Hochster/answers)\n\n- [Ricardo Vladimiro's Answers](https://www.quora.com/Ricardo-Vladimiro-1/answers)\n\n- [Storytelling with Statistics](https://datastories.quora.com/)\n\n- [Data Science FAQs on Quora](https://www.quora.com/topic/Data-Science/faq)\n\n- [Machine Learning FAQs on Quora](https://www.quora.com/topic/Machine-Learning/faq)\n\n<a name=\"kaggle\" />\n\n## Kaggle Competitions WriteUp\n\n- [How to almost win Kaggle Competitions](https://yanirseroussi.com/2014/08/24/how-to-almost-win-kaggle-competitions/)\n\n- [Convolution Neural Networks for EEG detection](http://blog.kaggle.com/2015/10/05/grasp-and-lift-eeg-detection-winners-interview-3rd-place-team-hedj/)\n\n- [Facebook Recruiting III Explained](http://alexminnaar.com/tag/kaggle-competitions.html)\n\n- [Predicting CTR with Online ML](http://mlwave.com/predicting-click-through-rates-with-online-machine-learning/)\n\n- [How to Rank 10% in Your First Kaggle Competition](https://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/)\n\n<a name=\"cs\" />\n\n## Cheat Sheets\n\n- [Probability Cheat Sheet](http://static1.squarespace.com/static/54bf3241e4b0f0d81bf7ff36/t/55e9494fe4b011aed10e48e5/1441352015658/probability_cheatsheet.pdf),\n[Source](http://www.wzchen.com/probability-cheatsheet/)\n\n- [Machine Learning Cheat Sheet](https://github.com/soulmachine/machine-learning-cheat-sheet)\n\n- [ML Compiled](https://ml-compiled.readthedocs.io/en/latest/)\n\n<a name=\"classification\" />\n\n## Classification\n\n- [Does Balancing Classes Improve Classifier Performance?](http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/)\n\n- [What is Deviance?](http://stats.stackexchange.com/questions/6581/what-is-deviance-specifically-in-cart-rpart)\n\n- [When to choose which machine learning classifier?](http://stackoverflow.com/questions/2595176/when-to-choose-which-machine-learning-classifier)\n\n- [What are the advantages of different classification algorithms?](https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms)\n\n- [ROC and AUC Explained](http://www.dataschool.io/roc-curves-and-auc-explained/) ([related video](https://youtu.be/OAl6eAyP-yo))\n\n- [An introduction to ROC analysis](https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf)\n\n- [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n\n\n<a name=\"linear\" />\n\n## Linear Regression\n\n- [General](#general-)\n\n    - [Assumptions of Linear Regression](http://pareonline.net/getvn.asp?n=2&v=8), [Stack Exchange](http://stats.stackexchange.com/questions/16381/what-is-a-complete-list-of-the-usual-assumptions-for-linear-regression)\n    \n    - [Linear Regression Comprehensive Resource](http://people.duke.edu/~rnau/regintro.htm)\n    \n    - [Applying and Interpreting Linear Regression](http://www.dataschool.io/applying-and-interpreting-linear-regression/)\n    \n    - [What does having constant variance in a linear regression model mean?](http://stats.stackexchange.com/questions/52089/what-does-having-constant-variance-in-a-linear-regression-model-mean/52107?stw=2#52107)\n    \n    - [Difference between linear regression on y with x and x with y](http://stats.stackexchange.com/questions/22718/what-is-the-difference-between-linear-regression-on-y-with-x-and-x-with-y?lq=1)\n    \n    - [Is linear regression valid when the dependant variable is not normally distributed?](https://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome_dependant_variable_not_normally_distributed)\n- Multicollinearity and VIF\n\n    - [Dummy Variable Trap | Multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity)\n    \n    - [Dealing with multicollinearity using VIFs](https://jonlefcheck.net/2012/12/28/dealing-with-multicollinearity-using-variance-inflation-factors/)\n\n- [Residual Analysis](#residuals-)\n\n    - [Interpreting plot.lm() in R](http://stats.stackexchange.com/questions/58141/interpreting-plot-lm)\n    \n    - [How to interpret a QQ plot?](http://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot?lq=1)\n    \n    - [Interpreting Residuals vs Fitted Plot](http://stats.stackexchange.com/questions/76226/interpreting-the-residuals-vs-fitted-values-plot-for-verifying-the-assumptions)\n\n- [Outliers](#outliers-)\n\n    - [How should outliers be dealt with?](http://stats.stackexchange.com/questions/175/how-should-outliers-be-dealt-with-in-linear-regression-analysis)\n\n- [Elastic Net](https://en.wikipedia.org/wiki/Elastic_net_regularization)\n    - [Regularization and Variable Selection via the\nElastic Net](https://web.stanford.edu/~hastie/Papers/elasticnet.pdf)\n\n<a name=\"logistic\" />\n\n## Logistic Regression\n\n- [Logistic Regression Wiki](https://en.wikipedia.org/wiki/Logistic_regression)\n\n- [Geometric Intuition of Logistic Regression](http://florianhartl.com/logistic-regression-geometric-intuition.html)\n\n- [Obtaining predicted categories (choosing threshold)](http://stats.stackexchange.com/questions/25389/obtaining-predicted-values-y-1-or-0-from-a-logistic-regression-model-fit)\n\n- [Residuals in logistic regression](http://stats.stackexchange.com/questions/1432/what-do-the-residuals-in-a-logistic-regression-mean)\n\n- [Difference between logit and probit models](http://stats.stackexchange.com/questions/20523/difference-between-logit-and-probit-models#30909), [Logistic Regression Wiki](https://en.wikipedia.org/wiki/Logistic_regression), [Probit Model Wiki](https://en.wikipedia.org/wiki/Probit_model)\n\n- [Pseudo R2 for Logistic Regression](http://stats.stackexchange.com/questions/3559/which-pseudo-r2-measure-is-the-one-to-report-for-logistic-regression-cox-s), [How to calculate](http://stats.stackexchange.com/questions/8511/how-to-calculate-pseudo-r2-from-rs-logistic-regression), [Other Details](http://www.ats.ucla.edu/stat/mult_pkg/faq/general/Psuedo_RSquareds.htm)\n\n- [Guide to an in-depth understanding of logistic regression](http://www.dataschool.io/guide-to-logistic-regression/)\n\n<a name=\"validation\" />\n\n## Model Validation using Resampling\n\n- [Resampling Explained](https://en.wikipedia.org/wiki/Resampling_(statistics))\n\n- [Partioning data set in R](http://stackoverflow.com/questions/13536537/partitioning-data-set-in-r-based-on-multiple-classes-of-observations)\n\n- [Implementing hold-out Validaion in R](http://stackoverflow.com/questions/22972854/how-to-implement-a-hold-out-validation-in-r), [2](http://www.gettinggeneticsdone.com/2011/02/split-data-frame-into-testing-and.html)\n\n<a name=\"cross\" />\n\n- [Cross Validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n    - [How to use cross-validation in predictive modeling](http://stuartlacy.co.uk/2016/02/04/how-to-correctly-use-cross-validation-in-predictive-modelling/)\n    - [Training with Full dataset after CV?](http://stats.stackexchange.com/questions/11602/training-with-the-full-dataset-after-cross-validation)\n    \n    - [Which CV method is best?](http://stats.stackexchange.com/questions/103459/how-do-i-know-which-method-of-cross-validation-is-best)\n    \n    - [Variance Estimates in k-fold CV](http://stats.stackexchange.com/questions/31190/variance-estimates-in-k-fold-cross-validation)\n    \n    - [Is CV a subsitute for Validation Set?](http://stats.stackexchange.com/questions/18856/is-cross-validation-a-proper-substitute-for-validation-set)\n    \n    - [Choice of k in k-fold CV](http://stats.stackexchange.com/questions/27730/choice-of-k-in-k-fold-cross-validation)\n    \n    - [CV for ensemble learning](http://stats.stackexchange.com/questions/102631/k-fold-cross-validation-of-ensemble-learning)\n    \n    - [k-fold CV in R](http://stackoverflow.com/questions/22909197/creating-folds-for-k-fold-cv-in-r-using-caret)\n    \n    - [Good Resources](http://www.chioka.in/tag/cross-validation/)\n    \n    - Overfitting and Cross Validation\n    \n        - [Preventing Overfitting the Cross Validation Data | Andrew Ng](http://ai.stanford.edu/~ang/papers/cv-final.pdf)\n        \n        - [Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation](http://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf)\n\n        - [CV for detecting and preventing Overfitting](http://www.autonlab.org/tutorials/overfit10.pdf)\n        \n        - [How does CV overcome the Overfitting Problem](http://stats.stackexchange.com/questions/9053/how-does-cross-validation-overcome-the-overfitting-problem)\n\n\n<a name=\"boot\" />\n\n- [Bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))\n\n    - [Why Bootstrapping Works?](http://stats.stackexchange.com/questions/26088/explaining-to-laypeople-why-bootstrapping-works)\n    \n    - [Good Animation](https://www.stat.auckland.ac.nz/~wild/BootAnim/)\n    \n    - [Example of Bootstapping](http://statistics.about.com/od/Applications/a/Example-Of-Bootstrapping.htm)\n    \n    - [Understanding Bootstapping for Validation and Model Selection](http://stats.stackexchange.com/questions/14516/understanding-bootstrapping-for-validation-and-model-selection?rq=1)\n    \n    - [Cross Validation vs Bootstrap to estimate prediction error](http://stats.stackexchange.com/questions/18348/differences-between-cross-validation-and-bootstrapping-to-estimate-the-predictio), [Cross-validation vs .632 bootstrapping to evaluate classification performance](http://stats.stackexchange.com/questions/71184/cross-validation-or-bootstrapping-to-evaluate-classification-performance)\n\n\n<a name=\"deep\" />\n\n## Deep Learning\n\n- [fast.ai - Practical Deep Learning For Coders](http://course.fast.ai/)\n\n- [fast.ai - Cutting Edge Deep Learning For Coders](http://course.fast.ai/part2.html)\n\n- [A curated list of awesome Deep Learning tutorials, projects and communities](https://github.com/ChristosChristofidis/awesome-deep-learning)\n\n- **[Deep Learning Papers Reading Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md)**\n\n- [Lots of Deep Learning Resources](http://deeplearning4j.org/documentation.html)\n\n- [Interesting Deep Learning and NLP Projects (Stanford)](http://cs224d.stanford.edu/reports.html), [Website](http://cs224d.stanford.edu/)\n\n- [Core Concepts of Deep Learning](https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/)\n\n- [Understanding Natural Language with Deep Neural Networks Using Torch](https://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n\n- [Stanford Deep Learning Tutorial](http://ufldl.stanford.edu/tutorial/)\n\n- [Deep Learning FAQs on Quora](https://www.quora.com/topic/Deep-Learning/faq)\n\n- [Google+ Deep Learning Page](https://plus.google.com/communities/112866381580457264725)\n\n- [Recent Reddit AMAs related to Deep Learning](http://deeplearning.net/2014/11/22/recent-reddit-amas-about-deep-learning/), [Another AMA](https://www.reddit.com/r/IAmA/comments/3mdk9v/we_are_google_researchers_working_on_deep/)\n\n- [Where to Learn Deep Learning?](http://www.kdnuggets.com/2014/05/learn-deep-learning-courses-tutorials-overviews.html)\n\n- [Deep Learning nvidia concepts](http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/)\n\n- [Introduction to Deep Learning Using Python (GitHub)](https://github.com/rouseguy/intro2deeplearning), [Good Introduction Slides](https://speakerdeck.com/bargava/introduction-to-deep-learning)\n\n- [Video Lectures Oxford 2015](https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu), [Video Lectures Summer School Montreal](http://videolectures.net/deeplearning2015_montreal/)\n\n- [Deep Learning Software List](http://deeplearning.net/software_links/)\n\n- [Hacker's guide to Neural Nets](http://karpathy.github.io/neuralnets/)\n\n- [Top arxiv Deep Learning Papers explained](http://www.kdnuggets.com/2015/10/top-arxiv-deep-learning-papers-explained.html)\n\n- [Geoff Hinton Youtube Vidoes on Deep Learning](https://www.youtube.com/watch?v=IcOMKXAw5VA)\n\n- [Awesome Deep Learning Reading List](http://deeplearning.net/reading-list/)\n\n- [Deep Learning Comprehensive Website](http://deeplearning.net/), [Software](http://deeplearning.net/software_links/)\n\n- [deeplearning Tutorials](http://deeplearning4j.org/)\n\n- [AWESOME! Deep Learning Tutorial](https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks)\n\n- [Deep Learning Basics](http://alexminnaar.com/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html)\n\n- [Intuition Behind Backpropagation](https://medium.com/spidernitt/breaking-down-neural-networks-an-intuitive-approach-to-backpropagation-3b2ff958794c)\n\n- [Stanford Tutorials](http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/)\n\n- [Train, Validation & Test in Artificial Neural Networks](http://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-networ)\n\n- [Artificial Neural Networks Tutorials](http://stackoverflow.com/questions/478947/what-are-some-good-resources-for-learning-about-artificial-neural-networks)\n\n- [Neural Networks FAQs on Stack Overflow](http://stackoverflow.com/questions/tagged/neural-network?sort=votes&pageSize=50)\n\n- [Deep Learning Tutorials on deeplearning.net](http://deeplearning.net/tutorial/index.html)\n\n- [Neural Networks and Deep Learning Online Book](http://neuralnetworksanddeeplearning.com/)\n\n- Neural Machine Translation\n\n    - **[Machine Translation Reading List](https://github.com/THUNLP-MT/MT-Reading-List#machine-translation-reading-list)**\n\n    - [Introduction to Neural Machine Translation with GPUs (part 1)](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/), [Part 2](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/), [Part 3](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/)\n    \n    - [Deep Speech: Accurate Speech Recognition with GPU-Accelerated Deep Learning](https://devblogs.nvidia.com/parallelforall/deep-speech-accurate-speech-recognition-gpu-accelerated-deep-learning/)\n\n<a name=\"frame\" />\n\n- Deep Learning Frameworks\n\n    - [Torch vs. Theano](http://fastml.com/torch-vs-theano/)\n    \n    - [dl4j vs. torch7 vs. theano](http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html)\n    \n    - [Deep Learning Libraries by Language](http://www.teglor.com/b/deep-learning-libraries-language-cm569/)\n    \n\n    - [Theano](https://en.wikipedia.org/wiki/Theano_(software))\n    \n        - [Website](http://deeplearning.net/software/theano/)\n        \n        - [Theano Introduction](http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/)\n        \n        - [Theano Tutorial](http://outlace.com/Beginner-Tutorial-Theano/)\n        \n        - [Good Theano Tutorial](http://deeplearning.net/software/theano/tutorial/)\n        \n        - [Logistic Regression using Theano for classifying digits](http://deeplearning.net/tutorial/logreg.html#logreg)\n        \n        - [MLP using Theano](http://deeplearning.net/tutorial/mlp.html#mlp)\n        \n        - [CNN using Theano](http://deeplearning.net/tutorial/lenet.html#lenet)\n        \n        - [RNNs using Theano](http://deeplearning.net/tutorial/rnnslu.html#rnnslu)\n        \n        - [LSTM for Sentiment Analysis in Theano](http://deeplearning.net/tutorial/lstm.html#lstm)\n        \n        - [RBM using Theano](http://deeplearning.net/tutorial/rbm.html#rbm)\n        \n        - [DBNs using Theano](http://deeplearning.net/tutorial/DBN.html#dbn)\n        \n        - [All Codes](https://github.com/lisa-lab/DeepLearningTutorials)\n        \n        - [Deep Learning Implementation Tutorials - Keras and Lasagne](https://github.com/vict0rsch/deep_learning/)\n\n    - [Torch](http://torch.ch/)\n    \n        - [Torch ML Tutorial](http://code.madbits.com/wiki/doku.php), [Code](https://github.com/torch/tutorials)\n        \n        - [Intro to Torch](http://ml.informatik.uni-freiburg.de/_media/teaching/ws1415/presentation_dl_lect3.pdf)\n        \n        - [Learning Torch GitHub Repo](https://github.com/chetannaik/learning_torch)\n        \n        - [Awesome-Torch (Repository on GitHub)](https://github.com/carpedm20/awesome-torch)\n        \n        - [Machine Learning using Torch Oxford Univ](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/), [Code](https://github.com/oxford-cs-ml-2015)\n        \n        - [Torch Internals Overview](https://apaszke.github.io/torch-internals.html)\n        \n        - [Torch Cheatsheet](https://github.com/torch/torch7/wiki/Cheatsheet)\n        \n        - [Understanding Natural Language with Deep Neural Networks Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n\n    - Caffe\n        - [Deep Learning for Computer Vision with Caffe and cuDNN](https://devblogs.nvidia.com/parallelforall/deep-learning-computer-vision-caffe-cudnn/)\n\n    - TensorFlow\n        - [Website](http://tensorflow.org/)\n        \n        - [TensorFlow Examples for Beginners](https://github.com/aymericdamien/TensorFlow-Examples)\n        \n        - [Stanford Tensorflow for Deep Learning Research Course](https://web.stanford.edu/class/cs20si/syllabus.html)\n        \n            - [GitHub Repo](https://github.com/chiphuyen/tf-stanford-tutorials)\n            \n        - [Simplified Scikit-learn Style Interface to TensorFlow](https://github.com/tensorflow/skflow)\n        \n        - [Learning TensorFlow GitHub Repo](https://github.com/chetannaik/learning_tensorflow)\n        \n        - [Benchmark TensorFlow GitHub](https://github.com/soumith/convnet-benchmarks/issues/66)\n        \n        - [Awesome TensorFlow List](https://github.com/jtoy/awesome-tensorflow)\n        \n        - [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book)\n        \n        - [Android TensorFlow Machine Learning Example](https://blog.mindorks.com/android-tensorflow-machine-learning-example-ff0e9b2654cc)\n        \n            - [GitHub Repo](https://github.com/MindorksOpenSource/AndroidTensorFlowMachineLearningExample)\n        - [Creating Custom Model For Android Using TensorFlow](https://blog.mindorks.com/creating-custom-model-for-android-using-tensorflow-3f963d270bfb)\n            - [GitHub Repo](https://github.com/MindorksOpenSource/AndroidTensorFlowMNISTExample)            \n\n<a name=\"feed\" />\n\n- Feed Forward Networks\n\n    - [A Quick Introduction to Neural Networks](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)\n    \n    - [Implementing a Neural Network from scratch](http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/), [Code](https://github.com/dennybritz/nn-from-scratch)\n    \n    - [Speeding up your Neural Network with Theano and the gpu](http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/), [Code](https://github.com/dennybritz/nn-theano)\n    \n    - [Basic ANN Theory](https://takinginitiative.wordpress.com/2008/04/03/basic-neural-network-tutorial-theory/)\n    \n    - [Role of Bias in Neural Networks](http://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks)\n    \n    - [Choosing number of hidden layers and nodes](http://stackoverflow.com/questions/3345079/estimating-the-number-of-neurons-and-number-of-layers-of-an-artificial-neural-ne),[2](http://stackoverflow.com/questions/10565868/multi-layer-perceptron-mlp-architecture-criteria-for-choosing-number-of-hidde?lq=1),[3](http://stackoverflow.com/questions/9436209/how-to-choose-number-of-hidden-layers-and-nodes-in-neural-network/2#)\n    \n    - [Backpropagation in Matrix Form](http://sudeepraja.github.io/Neural/)\n    \n    - [ANN implemented in C++ | AI Junkie](http://www.ai-junkie.com/ann/evolved/nnt6.html)\n    \n    - [Simple Implementation](http://stackoverflow.com/questions/15395835/simple-multi-layer-neural-network-implementation)\n    \n    - [NN for Beginners](http://www.codeproject.com/Articles/16419/AI-Neural-Network-for-beginners-Part-of)\n    \n    - [Regression and Classification with NNs (Slides)](http://www.autonlab.org/tutorials/neural13.pdf)\n    \n    - [Another Intro](http://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html)\n\n<a name=\"rnn\" />\n\n- Recurrent and LSTM Networks\n    - [awesome-rnn: list of resources (GitHub Repo)](https://github.com/kjw0612/awesome-rnn)\n    \n    - [Recurrent Neural Net Tutorial Part 1](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/), [Part 2](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/), [Part 3](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/), [Code](https://github.com/dennybritz/rnn-tutorial-rnnlm/)\n    \n    - [NLP RNN Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)\n    \n    - [The Unreasonable effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), [Torch Code](https://github.com/karpathy/char-rnn), [Python Code](https://gist.github.com/karpathy/d4dee566867f8291f086)\n    \n    - [Intro to RNN](http://deeplearning4j.org/recurrentnetwork.html), [LSTM](http://deeplearning4j.org/lstm.html)\n    \n    - [An application of RNN](http://hackaday.com/2015/10/15/73-computer-scientists-created-a-neural-net-and-you-wont-believe-what-happened-next/)\n    \n    - [Optimizing RNN Performance](http://svail.github.io/)\n    \n    - [Simple RNN](http://outlace.com/Simple-Recurrent-Neural-Network/)\n    \n    - [Auto-Generating Clickbait with RNN](https://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/)\n    \n    - [Sequence Learning using RNN (Slides)](http://www.slideshare.net/indicods/general-sequence-learning-with-recurrent-neural-networks-for-next-ml)\n    \n    - [Machine Translation using RNN (Paper)](http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf)\n    \n    - [Music generation using RNNs (Keras)](https://github.com/MattVitelli/GRUV)\n    \n    - [Using RNN to create on-the-fly dialogue (Keras)](http://neuralniche.com/post/tutorial/)\n    \n    - Long Short Term Memory (LSTM)\n    \n        - [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n        \n        - [LSTM explained](https://apaszke.github.io/lstm-explained.html)\n        \n        - [Beginner‚Äôs Guide to LSTM](http://deeplearning4j.org/lstm.html)\n        \n        - [Implementing LSTM from scratch](http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/), [Python/Theano code](https://github.com/dennybritz/rnn-tutorial-gru-lstm)\n        \n        - [Torch Code for character-level language models using LSTM](https://github.com/karpathy/char-rnn)\n        \n        - [LSTM for Kaggle EEG Detection competition (Torch Code)](https://github.com/apaszke/kaggle-grasp-and-lift)\n        \n        - [LSTM for Sentiment Analysis in Theano](http://deeplearning.net/tutorial/lstm.html#lstm)\n        \n        - [Deep Learning for Visual Q&A | LSTM | CNN](http://avisingh599.github.io/deeplearning/visual-qa/), [Code](https://github.com/avisingh599/visual-qa)\n        \n        - [Computer Responds to email using LSTM | Google](http://googleresearch.blogspot.in/2015/11/computer-respond-to-this-email.html)\n        \n        - [LSTM dramatically improves Google Voice Search](http://googleresearch.blogspot.ch/2015/09/google-voice-search-faster-and-more.html), [Another Article](http://deeplearning.net/2015/09/30/long-short-term-memory-dramatically-improves-google-voice-etc-now-available-to-a-billion-users/)\n        \n        - [Understanding Natural Language with LSTM Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n        \n        - [Torch code for Visual Question Answering using a CNN+LSTM model](https://github.com/abhshkdz/neural-vqa)\n        \n        - [LSTM for Human Activity Recognition](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/)\n        \n    - Gated Recurrent Units (GRU)\n    \n        - [LSTM vs GRU](http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/)\n    \n    - [Time series forecasting with Sequence-to-Sequence (seq2seq) rnn models](https://github.com/guillaume-chevalier/seq2seq-signal-prediction)\n\n\n<a name=\"rnn2\" />\n\n- [Recursive Neural Network (not Recurrent)](https://en.wikipedia.org/wiki/Recursive_neural_network)\n\n    - [Recursive Neural Tensor Network (RNTN)](http://deeplearning4j.org/recursiveneuraltensornetwork.html)\n    \n    - [word2vec, DBN, RNTN for Sentiment Analysis ](http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html)\n\n<a name=\"rbm\" />\n\n- Restricted Boltzmann Machine\n\n    - [Beginner's Guide about RBMs](http://deeplearning4j.org/restrictedboltzmannmachine.html)\n    \n    - [Another Good Tutorial](http://deeplearning.net/tutorial/rbm.html)\n    \n    - [Introduction to RBMs](http://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines/)\n    \n    - [Hinton's Guide to Training RBMs](https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf)\n    \n    - [RBMs in R](https://github.com/zachmayer/rbm)\n    \n    - [Deep Belief Networks Tutorial](http://deeplearning4j.org/deepbeliefnetwork.html)\n    \n    - [word2vec, DBN, RNTN for Sentiment Analysis ](http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html)\n\n<a name=\"auto\" />\n\n- Autoencoders: Unsupervised (applies BackProp after setting target = input)\n\n    - [Andrew Ng Sparse Autoencoders pdf](https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf)\n    \n    - [Deep Autoencoders Tutorial](http://deeplearning4j.org/deepautoencoder.html)\n    \n    - [Denoising Autoencoders](http://deeplearning.net/tutorial/dA.html), [Theano Code](http://deeplearning.net/tutorial/code/dA.py)\n    \n    - [Stacked Denoising Autoencoders](http://deeplearning.net/tutorial/SdA.html#sda)\n\n\n<a name=\"cnn\" />\n\n- Convolutional Neural Networks\n\n    - [An Intuitive Explanation of Convolutional Neural Networks](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)\n    \n    - [Awesome Deep Vision: List of Resources (GitHub)](https://github.com/kjw0612/awesome-deep-vision)\n    \n    - [Intro to CNNs](http://deeplearning4j.org/convolutionalnets.html)\n    \n    - [Understanding CNN for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)\n    \n    - [Stanford Notes](http://vision.stanford.edu/teaching/cs231n/), [Codes](http://cs231n.github.io/), [GitHub](https://github.com/cs231n/cs231n.github.io)\n    \n    - [JavaScript Library (Browser Based) for CNNs](http://cs.stanford.edu/people/karpathy/convnetjs/)\n    \n    - [Using CNNs to detect facial keypoints](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/)\n    \n    - [Deep learning to classify business photos at Yelp](http://engineeringblog.yelp.com/2015/10/how-we-use-deep-learning-to-classify-business-photos-at-yelp.html)\n    \n    - [Interview with Yann LeCun | Kaggle](http://blog.kaggle.com/2014/12/22/convolutional-nets-and-cifar-10-an-interview-with-yan-lecun/)\n    \n    - [Visualising and Understanding CNNs](https://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)\n\n<a name=\"nrl\" />\n\n- Network Representation Learning\n\n    - [Awesome Graph Embedding](https://github.com/benedekrozemberczki/awesome-graph-embedding)\n    \n    - [Awesome Network Embedding](https://github.com/chihming/awesome-network-embedding)\n    \n    - [Network Representation Learning Papers](https://github.com/thunlp)\n    \n    - [Knowledge Representation Learning Papers](https://github.com/thunlp/KRLPapers)\n    \n    - [Graph Based Deep Learning Literature](https://github.com/naganandy/graph-based-deep-learning-literature)\n\n<a name=\"nlp\" />\n\n## Natural Language Processing\n\n- [A curated list of speech and natural language processing resources](https://github.com/edobashira/speech-language-processing)\n\n- [Understanding Natural Language with Deep Neural Networks Using Torch](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)\n\n- [tf-idf explained](http://michaelerasm.us/post/tf-idf-in-10-minutes/)\n\n- [Interesting Deep Learning NLP Projects Stanford](http://cs224d.stanford.edu/reports.html), [Website](http://cs224d.stanford.edu/)\n\n- [The Stanford NLP Group](https://nlp.stanford.edu/)\n\n- [NLP from Scratch | Google Paper](https://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/35671.pdf)\n\n- [Graph Based Semi Supervised Learning for NLP](http://graph-ssl.wdfiles.com/local--files/blog%3A_start/graph_ssl_acl12_tutorial_slides_final.pdf)\n\n- [Bag of Words](https://en.wikipedia.org/wiki/Bag-of-words_model)\n\n    - [Classification text with Bag of Words](http://fastml.com/classifying-text-with-bag-of-words-a-tutorial/)\n    \n<a name=\"topic\" />\n\n- Topic Modeling\n    - [Topic Modeling Wikipedia](https://en.wikipedia.org/wiki/Topic_model) \n    - [**Probabilistic Topic Models Princeton PDF**](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf)\n\n    - [LDA Wikipedia](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation), [LSA Wikipedia](https://en.wikipedia.org/wiki/Latent_semantic_analysis), [Probabilistic LSA Wikipedia](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis)\n    \n    - [What is a good explanation of Latent Dirichlet Allocation (LDA)?](https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation)\n    \n    - [**Introduction to LDA**](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/), [Another good explanation](http://confusedlanguagetech.blogspot.in/2012/07/jordan-boyd-graber-and-philip-resnik.html)\n    \n    - [The LDA Buffet - Intuitive Explanation](http://www.matthewjockers.net/2011/09/29/the-lda-buffet-is-now-open-or-latent-dirichlet-allocation-for-english-majors/)\n    \n    - [Your Guide to Latent Dirichlet Allocation (LDA)](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n    \n    - [Difference between LSI and LDA](https://www.quora.com/Whats-the-difference-between-Latent-Semantic-Indexing-LSI-and-Latent-Dirichlet-Allocation-LDA)\n    \n    - [Original LDA Paper](https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf)\n    \n    - [alpha and beta in LDA](http://datascience.stackexchange.com/questions/199/what-does-the-alpha-and-beta-hyperparameters-contribute-to-in-latent-dirichlet-a)\n    \n    - [Intuitive explanation of the Dirichlet distribution](https://www.quora.com/What-is-an-intuitive-explanation-of-the-Dirichlet-distribution)\n    - [topicmodels: An R Package for Fitting Topic Models](https://cran.r-project.org/web/packages/topicmodels/vignettes/topicmodels.pdf)\n\n    - [Topic modeling made just simple enough](https://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/)\n    \n    - [Online LDA](http://alexminnaar.com/online-latent-dirichlet-allocation-the-best-option-for-topic-modeling-with-large-data-sets.html), [Online LDA with Spark](http://alexminnaar.com/distributed-online-latent-dirichlet-allocation-with-apache-spark.html)\n    \n    - [LDA in Scala](http://alexminnaar.com/latent-dirichlet-allocation-in-scala-part-i-the-theory.html), [Part 2](http://alexminnaar.com/latent-dirichlet-allocation-in-scala-part-ii-the-code.html)\n    \n    - [Segmentation of Twitter Timelines via Topic Modeling](https://alexisperrier.com/nlp/2015/09/16/segmentation_twitter_timelines_lda_vs_lsa.html)\n    \n    - [Topic Modeling of Twitter Followers](http://alexperrier.github.io/jekyll/update/2015/09/04/topic-modeling-of-twitter-followers.html)\n\n    - [Multilingual Latent Dirichlet Allocation (LDA)](https://github.com/ArtificiAI/Multilingual-Latent-Dirichlet-Allocation-LDA). ([Tutorial here](https://github.com/ArtificiAI/Multilingual-Latent-Dirichlet-Allocation-LDA/blob/master/Multilingual-LDA-Pipeline-Tutorial.ipynb))\n\n    - [Deep Belief Nets for Topic Modeling](https://github.com/larsmaaloee/deep-belief-nets-for-topic-modeling)\n    - [Gaussian LDA for Topic Models with Word Embeddings](http://www.cs.cmu.edu/~rajarshd/papers/acl2015.pdf)\n    - Python\n        - [Series of lecture notes for probabilistic topic models written in ipython notebook](https://github.com/arongdari/topic-model-lecture-note)\n        - [Implementation of various topic models in Python](https://github.com/arongdari/python-topic-model)\n           \n<a name=\"word2vec\" />\n\n- word2vec\n\n    - [Google word2vec](https://code.google.com/archive/p/word2vec)\n    \n    - [Bag of Words Model Wiki](https://en.wikipedia.org/wiki/Bag-of-words_model)\n    \n    - [word2vec Tutorial](https://rare-technologies.com/word2vec-tutorial/)\n    \n    - [A closer look at Skip Gram Modeling](http://homepages.inf.ed.ac.uk/ballison/pdf/lrec_skipgrams.pdf)\n    \n    - [Skip Gram Model Tutorial](http://alexminnaar.com/word2vec-tutorial-part-i-the-skip-gram-model.html), [CBoW Model](http://alexminnaar.com/word2vec-tutorial-part-ii-the-continuous-bag-of-words-model.html)\n    \n    - [Word Vectors Kaggle Tutorial Python](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors), [Part 2](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-3-more-fun-with-word-vectors)\n    \n    - [Making sense of word2vec](http://rare-technologies.com/making-sense-of-word2vec/)\n    \n    - [word2vec explained on deeplearning4j](http://deeplearning4j.org/word2vec.html)\n    \n    - [Quora word2vec](https://www.quora.com/How-does-word2vec-work)\n    \n    - [Other Quora Resources](https://www.quora.com/What-are-the-continuous-bag-of-words-and-skip-gram-architectures-in-laymans-terms), [2](https://www.quora.com/What-is-the-difference-between-the-Bag-of-Words-model-and-the-Continuous-Bag-of-Words-model), [3](https://www.quora.com/Is-skip-gram-negative-sampling-better-than-CBOW-NS-for-word2vec-If-so-why)\n    \n    - [word2vec, DBN, RNTN for Sentiment Analysis ](http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html)\n\n- Text Clustering\n\n    - [How string clustering works](http://stackoverflow.com/questions/8196371/how-clustering-works-especially-string-clustering)\n    \n    - [Levenshtein distance for measuring the difference between two sequences](https://en.wikipedia.org/wiki/Levenshtein_distance)\n    \n    - [Text clustering with Levenshtein distances](http://stackoverflow.com/questions/21511801/text-clustering-with-levenshtein-distances)\n\n- Text Classification\n\n    - [Classification Text with Bag of Words](http://fastml.com/classifying-text-with-bag-of-words-a-tutorial/)\n\n- Named Entity Recognitation \n    \n     - [Stanford Named Entity Recognizer (NER)](https://nlp.stanford.edu/software/CRF-NER.shtml)\n\n     - [Named Entity Recognition: Applications and Use Cases- Towards Data Science](https://towardsdatascience.com/named-entity-recognition-applications-and-use-cases-acdbf57d595e)\n\t\n- [Language learning with NLP and reinforcement learning](http://blog.dennybritz.com/2015/09/11/reimagining-language-learning-with-nlp-and-reinforcement-learning/)\n\n- [Kaggle Tutorial Bag of Words and Word vectors](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words), [Part 2](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors), [Part 3](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-3-more-fun-with-word-vectors)\n\n- [What would Shakespeare say (NLP Tutorial)](https://gigadom.wordpress.com/2015/10/02/natural-language-processing-what-would-shakespeare-say/)\n\n- [A closer look at Skip Gram Modeling](http://homepages.inf.ed.ac.uk/ballison/pdf/lrec_skipgrams.pdf)\n\n<a name=\"vision\" />\n\n## Computer Vision\n- [Awesome computer vision (github)](https://github.com/jbhuang0604/awesome-computer-vision)\n\n- [Awesome deep vision (github)](https://github.com/kjw0612/awesome-deep-vision)\n\n\n<a name=\"svm\" />\n\n## Support Vector Machine\n\n- [Highest Voted Questions about SVMs on Cross Validated](http://stats.stackexchange.com/questions/tagged/svm)\n\n- [Help me Understand SVMs!](http://stats.stackexchange.com/questions/3947/help-me-understand-support-vector-machines)\n\n- [SVM in Layman's terms](https://www.quora.com/What-does-support-vector-machine-SVM-mean-in-laymans-terms)\n\n- [How does SVM Work | Comparisons](http://stats.stackexchange.com/questions/23391/how-does-a-support-vector-machine-svm-work)\n\n- [A tutorial on SVMs](http://alex.smola.org/papers/2003/SmoSch03b.pdf)\n\n- [Practical Guide to SVC](http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf), [Slides](http://www.csie.ntu.edu.tw/~cjlin/talks/freiburg.pdf)\n\n- [Introductory Overview of SVMs](http://www.statsoft.com/Textbook/Support-Vector-Machines)\n\n- Comparisons\n\n    - [SVMs > ANNs](http://stackoverflow.com/questions/6699222/support-vector-machines-better-than-artificial-neural-networks-in-which-learn?rq=1), [ANNs > SVMs](http://stackoverflow.com/questions/11632516/what-are-advantages-of-artificial-neural-networks-over-support-vector-machines), [Another Comparison](http://www.svms.org/anns.html)\n    \n    - [Trees > SVMs](http://stats.stackexchange.com/questions/57438/why-is-svm-not-so-good-as-decision-tree-on-the-same-data)\n    \n    - [Kernel Logistic Regression vs SVM](http://stats.stackexchange.com/questions/43996/kernel-logistic-regression-vs-svm)\n    \n    - [Logistic Regression vs SVM](http://stats.stackexchange.com/questions/58684/regularized-logistic-regression-and-support-vector-machine), [2](http://stats.stackexchange.com/questions/95340/svm-v-s-logistic-regression), [3](https://www.quora.com/Support-Vector-Machines/What-is-the-difference-between-Linear-SVMs-and-Logistic-Regression)\n    \n- [Optimization Algorithms in Support Vector Machines](http://pages.cs.wisc.edu/~swright/talks/sjw-complearning.pdf)\n\n- [Variable Importance from SVM](http://stats.stackexchange.com/questions/2179/variable-importance-from-svm)\n\n- Software\n\n    - [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)\n    \n    - [Intro to SVM in R](http://cbio.ensmp.fr/~jvert/svn/tutorials/practical/svmbasic/svmbasic_notes.pdf)\n    \n- Kernels\n    - [What are Kernels in ML and SVM?](https://www.quora.com/What-are-Kernels-in-Machine-Learning-and-SVM)\n    \n    - [Intuition Behind Gaussian Kernel in SVMs?](https://www.quora.com/Support-Vector-Machines/What-is-the-intuition-behind-Gaussian-kernel-in-SVM)\n    \n- Probabilities post SVM\n\n    - [Platt's Probabilistic Outputs for SVM](http://www.csie.ntu.edu.tw/~htlin/paper/doc/plattprob.pdf)\n    \n    - [Platt Calibration Wiki](https://en.wikipedia.org/wiki/Platt_scaling)\n    \n    - [Why use Platts Scaling](http://stats.stackexchange.com/questions/5196/why-use-platts-scaling)\n    \n    - [Classifier Classification with Platt's Scaling](http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/)\n\n\n<a name=\"rl\" />\n\n## Reinforcement Learning\n\n- [Awesome Reinforcement Learning (GitHub)](https://github.com/aikorea/awesome-rl)\n\n- [RL Tutorial Part 1](http://outlace.com/Reinforcement-Learning-Part-1/), [Part 2](http://outlace.com/Reinforcement-Learning-Part-2/)\n\n<a name=\"dt\" />\n\n## Decision Trees\n\n- [Wikipedia Page - Lots of Good Info](https://en.wikipedia.org/wiki/Decision_tree_learning)\n\n- [FAQs about Decision Trees](http://stats.stackexchange.com/questions/tagged/cart)\n\n- [Brief Tour of Trees and Forests](https://statistical-research.com/index.php/2013/04/29/a-brief-tour-of-the-trees-and-forests/)\n\n- [Tree Based Models in R](http://www.statmethods.net/advstats/cart.html)\n\n- [How Decision Trees work?](http://www.aihorizon.com/essays/generalai/decision_trees.htm)\n\n- [Weak side of Decision Trees](http://stats.stackexchange.com/questions/1292/what-is-the-weak-side-of-decision-trees)\n\n- [Thorough Explanation and different algorithms](http://www.ise.bgu.ac.il/faculty/liorr/hbchap9.pdf)\n\n- [What is entropy and information gain in the context of building decision trees?](http://stackoverflow.com/questions/1859554/what-is-entropy-and-information-gain)\n\n- [Slides Related to Decision Trees](http://www.slideshare.net/pierluca.lanzi/machine-learning-and-data-mining-11-decision-trees)\n\n- [How do decision tree learning algorithms deal with missing values?](http://stats.stackexchange.com/questions/96025/how-do-decision-tree-learning-algorithms-deal-with-missing-values-under-the-hoo)\n\n- [Using Surrogates to Improve Datasets with Missing Values](https://www.salford-systems.com/videos/tutorials/tips-and-tricks/using-surrogates-to-improve-datasets-with-missing-values)\n\n- [Good Article](https://www.mindtools.com/dectree.html)\n\n- [Are decision trees almost always binary trees?](http://stats.stackexchange.com/questions/12187/are-decision-trees-almost-always-binary-trees)\n\n- [Pruning Decision Trees](https://en.wikipedia.org/wiki/Pruning_(decision_trees)), [Grafting of Decision Trees](https://en.wikipedia.org/wiki/Grafting_(decision_trees))\n\n- [What is Deviance in context of Decision Trees?](http://stats.stackexchange.com/questions/6581/what-is-deviance-specifically-in-cart-rpart)\n\n- [Discover structure behind data with decision trees](http://vooban.com/en/tips-articles-geek-stuff/discover-structure-behind-data-with-decision-trees/) - Grow and plot a decision tree to automatically figure out hidden rules in your data\n\n- Comparison of Different Algorithms\n\n    - [CART vs CTREE](http://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees)\n    \n    - [Comparison of complexity or performance](https://stackoverflow.com/questions/9979461/different-decision-tree-algorithms-with-comparison-of-complexity-or-performance)\n    \n    - [CHAID vs CART](http://stats.stackexchange.com/questions/61230/chaid-vs-crt-or-cart) , [CART vs CHAID](http://www.bzst.com/2006/10/classification-trees-cart-vs-chaid.html)\n    \n    - [Good Article on comparison](http://www.ftpress.com/articles/article.aspx?p=2248639&seqNum=11)\n    \n- CART\n\n    - [Recursive Partitioning Wikipedia](https://en.wikipedia.org/wiki/Recursive_partitioning)\n    \n    - [CART Explained](http://documents.software.dell.com/Statistics/Textbook/Classification-and-Regression-Trees)\n    \n    - [How to measure/rank ‚Äúvariable importance‚Äù when using CART?](http://stats.stackexchange.com/questions/6478/how-to-measure-rank-variable-importance-when-using-cart-specifically-using)\n    \n    - [Pruning a Tree in R](http://stackoverflow.com/questions/15318409/how-to-prune-a-tree-in-r)\n    \n    - [Does rpart use multivariate splits by default?](http://stats.stackexchange.com/questions/4356/does-rpart-use-multivariate-splits-by-default)\n    \n    - [FAQs about Recursive Partitioning](http://stats.stackexchange.com/questions/tagged/rpart)\n    \n- CTREE\n\n    - [party package in R](https://cran.r-project.org/web/packages/party/party.pdf)\n    \n    - [Show volumne in each node using ctree in R](http://stackoverflow.com/questions/13772715/show-volume-in-each-node-using-ctree-plot-in-r)\n    \n    - [How to extract tree structure from ctree function?](http://stackoverflow.com/questions/8675664/how-to-extract-tree-structure-from-ctree-function)\n    \n- CHAID\n\n    - [Wikipedia Artice on CHAID](https://en.wikipedia.org/wiki/CHAID)\n    \n    - [Basic Introduction to CHAID](https://smartdrill.com/Introduction-to-CHAID.html)\n    \n    - [Good Tutorial on CHAID](http://www.statsoft.com/Textbook/CHAID-Analysis)\n    \n- MARS\n\n    - [Wikipedia Article on MARS](https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines)\n    \n- Probabilistic Decision Trees\n\n    - [Bayesian Learning in Probabilistic Decision Trees](http://www.stats.org.uk/bayesian/Jordan.pdf)\n    \n    - [Probabilistic Trees Research Paper](http://people.stern.nyu.edu/adamodar/pdfiles/papers/probabilistic.pdf)\n\n<a name=\"rf\" />\n\n## Random Forest / Bagging\n\n- [Awesome Random Forest (GitHub)**](https://github.com/kjw0612/awesome-random-forest)\n\n- [How to tune RF parameters in practice?](https://www.kaggle.com/forums/f/15/kaggle-forum/t/4092/how-to-tune-rf-parameters-in-practice)\n\n- [Measures of variable importance in random forests](http://stats.stackexchange.com/questions/12605/measures-of-variable-importance-in-random-forests)\n\n- [Compare R-squared from two different Random Forest models](http://stats.stackexchange.com/questions/13869/compare-r-squared-from-two-different-random-forest-models)\n\n- [OOB Estimate Explained | RF vs LDA](https://stat.ethz.ch/education/semesters/ss2012/ams/slides/v10.2.pdf)\n\n- [Evaluating Random Forests for Survival Analysis Using Prediction Error Curve](https://www.jstatsoft.org/index.php/jss/article/view/v050i11)\n\n- [Why doesn't Random Forest handle missing values in predictors?](http://stats.stackexchange.com/questions/98953/why-doesnt-random-forest-handle-missing-values-in-predictors)\n\n- [How to build random forests in R with missing (NA) values?](http://stackoverflow.com/questions/8370455/how-to-build-random-forests-in-r-with-missing-na-values)\n\n- [FAQs about Random Forest](http://stats.stackexchange.com/questions/tagged/random-forest), [More FAQs](http://stackoverflow.com/questions/tagged/random-forest)\n\n- [Obtaining knowledge from a random forest](http://stats.stackexchange.com/questions/21152/obtaining-knowledge-from-a-random-forest)\n\n- [Some Questions for R implementation](http://stackoverflow.com/questions/20537186/getting-predictions-after-rfimpute), [2](http://stats.stackexchange.com/questions/81609/whether-preprocessing-is-needed-before-prediction-using-finalmodel-of-randomfore), [3](http://stackoverflow.com/questions/17059432/random-forest-package-in-r-shows-error-during-prediction-if-there-are-new-fact)\n\n<a name=\"gbm\" />\n\n## Boosting\n\n- [Boosting for Better Predictions](http://www.datasciencecentral.com/profiles/blogs/boosting-algorithms-for-better-predictions)\n\n- [Boosting Wikipedia Page](https://en.wikipedia.org/wiki/Boosting_(machine_learning))\n\n- [Introduction to Boosted Trees | Tianqi Chen](https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf)\n\n- Gradient Boosting Machine\n\n    - [Gradiet Boosting Wiki](https://en.wikipedia.org/wiki/Gradient_boosting)\n    \n    - [Guidelines for GBM parameters in R](http://stats.stackexchange.com/questions/25748/what-are-some-useful-guidelines-for-gbm-parameters), [Strategy to set parameters](http://stats.stackexchange.com/questions/35984/strategy-to-set-the-gbm-parameters)\n    \n    - [Meaning of Interaction Depth](http://stats.stackexchange.com/questions/16501/what-does-interaction-depth-mean-in-gbm), [2](http://stats.stackexchange.com/questions/16501/what-does-interaction-depth-mean-in-gbm)\n    \n    - [Role of n.minobsinnode parameter of GBM in R](http://stats.stackexchange.com/questions/30645/role-of-n-minobsinnode-parameter-of-gbm-in-r)\n    \n    - [GBM in R](http://www.slideshare.net/mark_landry/gbm-package-in-r)\n    \n    - [FAQs about GBM](http://stats.stackexchange.com/tags/gbm/hot)\n    \n    - [GBM vs xgboost](https://www.kaggle.com/c/higgs-boson/forums/t/9497/r-s-gbm-vs-python-s-xgboost)\n\n- xgboost\n\n    - [xgboost tuning kaggle](https://www.kaggle.com/khozzy/rossmann-store-sales/xgboost-parameter-tuning-template/log)\n    \n    - [xgboost vs gbm](https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/13012/question-to-experienced-kagglers-and-anyone-who-wants-to-take-a-shot/68296#post68296)\n    \n    - [xgboost survey](https://www.kaggle.com/c/higgs-boson/forums/t/10335/xgboost-post-competition-survey)\n    \n    - [Practical XGBoost in Python online course (free)](http://education.parrotprediction.teachable.com/courses/practical-xgboost-in-python)\n    \n- AdaBoost\n\n    - [AdaBoost Wiki](https://en.wikipedia.org/wiki/AdaBoost), [Python Code](https://gist.github.com/tristanwietsma/5486024)\n    \n    - [AdaBoost Sparse Input Support](http://hamzehal.blogspot.com/2014/06/adaboost-sparse-input-support.html)\n    \n    - [adaBag R package](https://cran.r-project.org/web/packages/adabag/adabag.pdf)\n    \n    - [Tutorial](http://math.mit.edu/~rothvoss/18.304.3PM/Presentations/1-Eric-Boosting304FinalRpdf.pdf)\n\n- CatBoost\n\n    - [CatBoost Documentation](https://catboost.ai/docs/)\n\n    - [Benchmarks](https://catboost.ai/#benchmark)\n\n    - [Tutorial](https://github.com/catboost/tutorials)\n\n    - [GitHub Project](https://github.com/catboost)\n\n    - [CatBoost vs. Light GBM vs. XGBoost](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db)\n\n<a name=\"ensem\" />\n\n## Ensembles\n\n- [Wikipedia Article on Ensemble Learning](https://en.wikipedia.org/wiki/Ensemble_learning)\n\n- [Kaggle Ensembling Guide](http://mlwave.com/kaggle-ensembling-guide/)\n\n- [The Power of Simple Ensembles](http://www.overkillanalytics.net/more-is-always-better-the-power-of-simple-ensembles/)\n\n- [Ensemble Learning Intro](http://machine-learning.martinsewell.com/ensembles/)\n\n- [Ensemble Learning Paper](http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf)\n\n- [Ensembling models with R](http://amunategui.github.io/blending-models/), [Ensembling Regression Models in R](http://stats.stackexchange.com/questions/26790/ensembling-regression-models), [Intro to Ensembles in R](http://www.vikparuchuri.com/blog/intro-to-ensemble-learning-in-r/)\n\n- [Ensembling Models with caret](http://stats.stackexchange.com/questions/27361/stacking-ensembling-models-with-caret)\n\n- [Bagging vs Boosting vs Stacking](http://stats.stackexchange.com/questions/18891/bagging-boosting-and-stacking-in-machine-learning)\n\n- [Good Resources | Kaggle Africa Soil Property Prediction](https://www.kaggle.com/c/afsis-soil-properties/forums/t/10391/best-ensemble-references)\n\n- [Boosting vs Bagging](http://www.chioka.in/which-is-better-boosting-or-bagging/)\n\n- [Resources for learning how to implement ensemble methods](http://stats.stackexchange.com/questions/32703/resources-for-learning-how-to-implement-ensemble-methods)\n\n- [How are classifications merged in an ensemble classifier?](http://stats.stackexchange.com/questions/21502/how-are-classifications-merged-in-an-ensemble-classifier)\n\n<a name=\"stack\" />\n\n## Stacking Models\n\n- [Stacking, Blending and Stacked Generalization](http://www.chioka.in/stacking-blending-and-stacked-generalization/)\n\n- [Stacked Generalization (Stacking)](http://machine-learning.martinsewell.com/ensembles/stacking/)\n\n- [Stacked Generalization: when does it work?](http://www.ijcai.org/Proceedings/97-2/011.pdf)\n\n- [Stacked Generalization Paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1533&rep=rep1&type=pdf)\n\n<a name=\"vc\" />\n\n## Vapnik‚ÄìChervonenkis Dimension\n\n- [Wikipedia article on VC Dimension](https://en.wikipedia.org/wiki/VC_dimension)\n\n- [Intuitive Explanantion of VC Dimension](https://www.quora.com/Explain-VC-dimension-and-shattering-in-lucid-Way)\n\n- [Video explaining VC Dimension](https://www.youtube.com/watch?v=puDzy2XmR5c)\n\n- [Introduction to VC Dimension](http://www.svms.org/vc-dimension/)\n\n- [FAQs about VC Dimension](http://stats.stackexchange.com/questions/tagged/vc-dimension)\n\n- [Do ensemble techniques increase VC-dimension?](http://stats.stackexchange.com/questions/78076/do-ensemble-techniques-increase-vc-dimension)\n\n\n<a name=\"bayes\" />\n\n## Bayesian Machine Learning\n\n- [Bayesian Methods for Hackers (using pyMC)](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)\n\n- [Should all Machine Learning be Bayesian?](http://videolectures.net/bark08_ghahramani_samlbb/)\n\n- [Tutorial on Bayesian Optimisation for Machine Learning](http://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf)\n\n- [Bayesian Reasoning and Deep Learning](http://blog.shakirm.com/2015/10/bayesian-reasoning-and-deep-learning/), [Slides](http://blog.shakirm.com/wp-content/uploads/2015/10/Bayes_Deep.pdf)\n\n- [Bayesian Statistics Made Simple](http://greenteapress.com/wp/think-bayes/)\n\n- [Kalman & Bayesian Filters in Python](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python)\n\n- [Markov Chain Wikipedia Page](https://en.wikipedia.org/wiki/Markov_chain)\n\n\n<a name=\"semi\" />\n\n## Semi Supervised Learning\n\n- [Wikipedia article on Semi Supervised Learning](https://en.wikipedia.org/wiki/Semi-supervised_learning)\n\n- [Tutorial on Semi Supervised Learning](http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf)\n\n- [Graph Based Semi Supervised Learning for NLP](http://graph-ssl.wdfiles.com/local--files/blog%3A_start/graph_ssl_acl12_tutorial_slides_final.pdf)\n\n- [Taxonomy](http://is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/taxo_[0].pdf)\n\n- [Video Tutorial Weka](https://www.youtube.com/watch?v=sWxcIjZFGNM)\n\n- [Unsupervised, Supervised and Semi Supervised learning](http://stats.stackexchange.com/questions/517/unsupervised-supervised-and-semi-supervised-learning)\n\n- [Research Papers 1](http://mlg.eng.cam.ac.uk/zoubin/papers/zglactive.pdf), [2](http://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf), [3](http://icml.cc/2012/papers/616.pdf)\n\n\n<a name=\"opt\" />\n\n## Optimization\n\n- [Mean Variance Portfolio Optimization with R and Quadratic Programming](http://www.wdiam.com/2012/06/10/mean-variance-portfolio-optimization-with-r-and-quadratic-programming/?utm_content=buffer04c12&utm_medium=social&utm_source=linkedin.com&utm_campaign=buffer)\n\n- [Algorithms for Sparse Optimization and Machine Learning](http://www.ima.umn.edu/2011-2012/W3.26-30.12/activities/Wright-Steve/sjw-ima12)\n\n- [Optimization Algorithms in Machine Learning](http://pages.cs.wisc.edu/~swright/nips2010/sjw-nips10.pdf), [Video Lecture](http://videolectures.net/nips2010_wright_oaml/)\n\n- [Optimization Algorithms for Data Analysis](http://www.birs.ca/workshops/2011/11w2035/files/Wright.pdf)\n\n- [Video Lectures on Optimization](http://videolectures.net/stephen_j_wright/)\n\n- [Optimization Algorithms in Support Vector Machines](http://pages.cs.wisc.edu/~swright/talks/sjw-complearning.pdf)\n\n- [The Interplay of Optimization and Machine Learning Research](http://jmlr.org/papers/volume7/MLOPT-intro06a/MLOPT-intro06a.pdf)\n\n- [Hyperopt tutorial for Optimizing Neural Networks‚Äô Hyperparameters](http://vooban.com/en/tips-articles-geek-stuff/hyperopt-tutorial-for-optimizing-neural-networks-hyperparameters/)\n\n\n<a name=\"other\" />\n\n## Other Tutorials\n\n- For a collection of Data Science Tutorials using R, please refer to [this list](https://github.com/ujjwalkarn/DataScienceR).\n\n- For a collection of Data Science Tutorials using Python, please refer to [this list](https://github.com/ujjwalkarn/DataSciencePython).\n",
         "AI_DataScience"
        ],
        [
         "47",
         "MDEwOlJlcG9zaXRvcnkxMDcxMTk2NDk=",
         "<img src=\"/README_images/screenshot-to-code.svg?raw=true\" width=\"800px\">\n\n---\n\n**A detailed tutorial covering the code in this repository:** [Turning design mockups into code with deep learning](https://emilwallner.medium.com/how-you-can-train-an-ai-to-convert-your-design-mockups-into-html-and-css-cc7afd82fed4).\n\n**Plug:** üëâ Check out my 60-page guide, [No ML Degree](https://www.emilwallner.com/p/no-ml-degree), on how to land a machine learning job without a degree.\n\nThe neural network is built in three iterations. Starting with a Hello World version, followed by the main neural network layers, and ending by training it to generalize. \n\nThe models are based on Tony Beltramelli's [pix2code](https://github.com/tonybeltramelli/pix2code), and inspired by Airbnb's [sketching interfaces](https://airbnb.design/sketching-interfaces/), and Harvard's [im2markup](https://github.com/harvardnlp/im2markup).\n\n**Note:** only the Bootstrap version can generalize on new design mock-ups. It uses 16 domain-specific tokens which are translated into HTML/CSS. It has a 97% accuracy. The best model uses a GRU instead of an LSTM. This version can be trained on a few GPUs. The raw HTML version has potential to generalize, but is still unproven and requires a significant amount of GPUs to train. The current model is also trained on a homogeneous and small dataset, thus it's hard to tell how well it behaves on more complex layouts.\n\nDataset: https://github.com/tonybeltramelli/pix2code/tree/master/datasets\n\nA quick overview of the process: \n\n### 1) Give a design image to the trained neural network\n\n![Insert image](https://i.imgur.com/LDmoLLV.png)\n\n### 2) The neural network converts the image into HTML markup \n\n<img src=\"/README_images/html_display.gif?raw=true\" width=\"800px\">\n\n### 3) Rendered output\n\n![Screenshot](https://i.imgur.com/tEAfyZ8.png)\n\n\n## Installation\n\n### FloydHub\n\n[![Run on FloydHub](https://static.floydhub.com/button/button.svg)](https://floydhub.com/run?template=https://github.com/floydhub/pix2code-template)\n\nClick this button to open a [Workspace](https://blog.floydhub.com/workspaces/) on [FloydHub](https://www.floydhub.com/?utm_medium=readme&utm_source=pix2code&utm_campaign=aug_2018) where you will find the same environment and dataset used for the *Bootstrap version*. You can also find the trained models for testing.\n\n### Local\n``` bash\npip install keras tensorflow pillow h5py jupyter\n```\n```\ngit clone https://github.com/emilwallner/Screenshot-to-code.git\ncd Screenshot-to-code/\njupyter notebook\n```\nGo do the desired notebook, files that end with '.ipynb'. To run the model, go to the menu then click on Cell > Run all\n\nThe final version, the Bootstrap version, is prepared with a small set to test run the model. If you want to try it with all the data, you need to download the data here: https://www.floydhub.com/emilwallner/datasets/imagetocode, and specify the correct ```dir_name```.\n\n## Folder structure\n\n``` bash\n  |  |-Bootstrap                           #The Bootstrap version\n  |  |  |-compiler                         #A compiler to turn the tokens to HTML/CSS (by pix2code)\n  |  |  |-resources\t\t\t\t\t\t\t\t\t\t\t\n  |  |  |  |-eval_light                    #10 test images and markup\n  |  |-Hello_world                         #The Hello World version\n  |  |-HTML                                #The HTML version\n  |  |  |-Resources_for_index_file         #CSS,images and scripts to test index.html file\n  |  |  |-html                             #HTML files to train it on\n  |  |  |-images                           #Screenshots for training\n  |-readme_images                          #Images for the readme page\n```\n\n\n## Hello World\n<p align=\"center\"><img src=\"/README_images/Hello_world_model.png?raw=true\" width=\"400px\"></p>\n\n\n## HTML\n<p align=\"center\"><img src=\"/README_images/HTML_model.png?raw=true\" width=\"400px\"></p>\n\n\n## Bootstrap\n<p align=\"center\"><img src=\"/README_images/Bootstrap_model.png?raw=true\" width=\"400px\"></p>\n\n## Model weights\n- [Bootstrap](https://www.floydhub.com/emilwallner/datasets/imagetocode) (The pre-trained model uses GRUs instead of LSTMs)\n- [HTML](https://www.floydhub.com/emilwallner/datasets/html_models)\n\n## Acknowledgments\n- Thanks to IBM for donating computing power through their PowerAI platform\n- The code is largely influenced by Tony Beltramelli's pix2code paper. [Code](https://github.com/tonybeltramelli/pix2code) [Paper](https://arxiv.org/abs/1705.07962)\n- The structure and some of the functions are from Jason Brownlee's [excellent tutorial](https://machinelearningmastery.com/develop-a-caption-generation-model-in-keras/)\n",
         "AI_DataScience"
        ],
        [
         "48",
         "MDEwOlJlcG9zaXRvcnk5NDQ2MDcwNA==",
         "# Tensor2Tensor\n\n[![PyPI\nversion](https://badge.fury.io/py/tensor2tensor.svg)](https://badge.fury.io/py/tensor2tensor)\n[![GitHub\nIssues](https://img.shields.io/github/issues/tensorflow/tensor2tensor.svg)](https://github.com/tensorflow/tensor2tensor/issues)\n[![Contributions\nwelcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)\n[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg)](https://gitter.im/tensor2tensor/Lobby)\n[![License](https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Travis](https://img.shields.io/travis/tensorflow/tensor2tensor.svg)](https://travis-ci.org/tensorflow/tensor2tensor)\n[![Run on FH](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run)\n\n[Tensor2Tensor](https://github.com/tensorflow/tensor2tensor), or\n[T2T](https://github.com/tensorflow/tensor2tensor) for short, is a library\nof deep learning models and datasets designed to make deep learning more\naccessible and [accelerate ML\nresearch](https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html).\n\n\nT2T was developed by researchers and engineers in the\n[Google Brain team](https://research.google.com/teams/brain/) and a community\nof users. It is now deprecated &mdash; we keep it running and welcome\nbug-fixes, but encourage users to use the successor library [Trax](https://github.com/google/trax).\n\n### Quick Start\n\n[This iPython notebook](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb)\nexplains T2T and runs in your browser using a free VM from Google,\nno installation needed. Alternatively, here is a one-command version that\ninstalls T2T, downloads MNIST, trains a model and evaluates it:\n\n```\npip install tensor2tensor && t2t-trainer \\\n  --generate_data \\\n  --data_dir=~/t2t_data \\\n  --output_dir=~/t2t_train/mnist \\\n  --problem=image_mnist \\\n  --model=shake_shake \\\n  --hparams_set=shake_shake_quick \\\n  --train_steps=1000 \\\n  --eval_steps=100\n```\n\n### Contents\n\n* [Suggested Datasets and Models](#suggested-datasets-and-models)\n  * [Mathematical Language Understanding](#mathematical-language-understanding)\n  * [Story, Question and Answer](#story-question-and-answer)\n  * [Image Classification](#image-classification)\n  * [Image Generation](#image-generation)\n  * [Language Modeling](#language-modeling)\n  * [Sentiment Analysis](#sentiment-analysis)\n  * [Speech Recognition](#speech-recognition)\n  * [Summarization](#summarization)\n  * [Translation](#translation)\n* [Basics](#basics)\n  * [Walkthrough](#walkthrough)\n  * [Installation](#installation)\n  * [Features](#features)\n* [T2T Overview](#t2t-overview)\n  * [Datasets](#datasets)\n  * [Problems and Modalities](#problems-and-modalities)\n  * [Models](#models)\n  * [Hyperparameter Sets](#hyperparameter-sets)\n  * [Trainer](#trainer)\n* [Adding your own components](#adding-your-own-components)\n* [Adding a dataset](#adding-a-dataset)\n* [Papers](#papers)\n* [Run on FloydHub](#run-on-floydhub)\n\n## Suggested Datasets and Models\n\nBelow we list a number of tasks that can be solved with T2T when\nyou train the appropriate model on the appropriate problem.\nWe give the problem and model below and we suggest a setting of\nhyperparameters that we know works well in our setup. We usually\nrun either on Cloud TPUs or on 8-GPU machines; you might need\nto modify the hyperparameters if you run on a different setup.\n\n### Mathematical Language Understanding\n\nFor evaluating mathematical expressions at the character level involving addition, subtraction and multiplication of both positive and negative decimal numbers with variable digits assigned to symbolic variables, use\n\n* the [MLU](https://art.wangperawong.com/mathematical_language_understanding_train.tar.gz) data-set:\n `--problem=algorithmic_math_two_variables`\n\nYou can try solving the problem with different transformer models and hyperparameters as described in the [paper](https://arxiv.org/abs/1812.02825):\n* Standard transformer:\n`--model=transformer`\n`--hparams_set=transformer_tiny`\n* Universal transformer:\n`--model=universal_transformer`\n`--hparams_set=universal_transformer_tiny`\n* Adaptive universal transformer:\n`--model=universal_transformer`\n`--hparams_set=adaptive_universal_transformer_tiny`\n\n### Story, Question and Answer\n\nFor answering questions based on a story, use\n\n* the [bAbi](https://research.fb.com/downloads/babi/) data-set:\n `--problem=babi_qa_concat_task1_1k`\n\nYou can choose the bAbi task from the range [1,20] and the subset from 1k or\n10k. To combine test data from all tasks into a single test set, use\n`--problem=babi_qa_concat_all_tasks_10k`\n\n### Image Classification\n\nFor image classification, we have a number of standard data-sets:\n\n* ImageNet (a large data-set): `--problem=image_imagenet`, or one\n   of the re-scaled versions (`image_imagenet224`, `image_imagenet64`,\n   `image_imagenet32`)\n* CIFAR-10: `--problem=image_cifar10` (or\n    `--problem=image_cifar10_plain` to turn off data augmentation)\n* CIFAR-100: `--problem=image_cifar100`\n* MNIST: `--problem=image_mnist`\n\nFor ImageNet, we suggest to use the ResNet or Xception, i.e.,\nuse `--model=resnet --hparams_set=resnet_50` or\n`--model=xception --hparams_set=xception_base`.\nResnet should get to above 76% top-1 accuracy on ImageNet.\n\nFor CIFAR and MNIST, we suggest to try the shake-shake model:\n`--model=shake_shake --hparams_set=shakeshake_big`.\nThis setting trained for `--train_steps=700000` should yield\nclose to 97% accuracy on CIFAR-10.\n\n### Image Generation\n\nFor (un)conditional image generation, we have a number of standard data-sets:\n\n* CelebA: `--problem=img2img_celeba` for image-to-image translation, namely,\n    superresolution from 8x8 to 32x32.\n* CelebA-HQ: `--problem=image_celeba256_rev` for a downsampled 256x256.\n* CIFAR-10: `--problem=image_cifar10_plain_gen_rev` for class-conditional\n    32x32 generation.\n* LSUN Bedrooms: `--problem=image_lsun_bedrooms_rev`\n* MS-COCO: `--problem=image_text_ms_coco_rev` for text-to-image generation.\n* Small ImageNet (a large data-set): `--problem=image_imagenet32_gen_rev` for\n    32x32 or `--problem=image_imagenet64_gen_rev` for 64x64.\n\nWe suggest to use the Image Transformer, i.e., `--model=imagetransformer`, or\nthe Image Transformer Plus, i.e., `--model=imagetransformerpp` that uses\ndiscretized mixture of logistics, or variational auto-encoder, i.e.,\n`--model=transformer_ae`.\nFor CIFAR-10, using `--hparams_set=imagetransformer_cifar10_base` or\n`--hparams_set=imagetransformer_cifar10_base_dmol` yields 2.90 bits per\ndimension. For Imagenet-32, using\n`--hparams_set=imagetransformer_imagenet32_base` yields 3.77 bits per dimension.\n\n### Language Modeling\n\nFor language modeling, we have these data-sets in T2T:\n\n* PTB (a small data-set): `--problem=languagemodel_ptb10k` for\n    word-level modeling and `--problem=languagemodel_ptb_characters`\n    for character-level modeling.\n* LM1B (a billion-word corpus): `--problem=languagemodel_lm1b32k` for\n    subword-level modeling and `--problem=languagemodel_lm1b_characters`\n    for character-level modeling.\n\nWe suggest to start with `--model=transformer` on this task and use\n`--hparams_set=transformer_small` for PTB and\n`--hparams_set=transformer_base` for LM1B.\n\n### Sentiment Analysis\n\nFor the task of recognizing the sentiment of a sentence, use\n\n* the IMDB data-set: `--problem=sentiment_imdb`\n\nWe suggest to use `--model=transformer_encoder` here and since it is\na small data-set, try `--hparams_set=transformer_tiny` and train for\nfew steps (e.g., `--train_steps=2000`).\n\n### Speech Recognition\n\nFor speech-to-text, we have these data-sets in T2T:\n\n* Librispeech (US English): `--problem=librispeech` for\n    the whole set and `--problem=librispeech_clean` for a smaller\n    but nicely filtered part.\n\n* Mozilla Common Voice (US English): `--problem=common_voice` for the whole set\n    `--problem=common_voice_clean` for a quality-checked subset.\n\n### Summarization\n\nFor summarizing longer text into shorter one we have these data-sets:\n\n* CNN/DailyMail articles summarized into a few sentences:\n  `--problem=summarize_cnn_dailymail32k`\n\nWe suggest to use `--model=transformer` and\n`--hparams_set=transformer_prepend` for this task.\nThis yields good ROUGE scores.\n\n### Translation\n\nThere are a number of translation data-sets in T2T:\n\n* English-German: `--problem=translate_ende_wmt32k`\n* English-French: `--problem=translate_enfr_wmt32k`\n* English-Czech: `--problem=translate_encs_wmt32k`\n* English-Chinese: `--problem=translate_enzh_wmt32k`\n* English-Vietnamese: `--problem=translate_envi_iwslt32k`\n* English-Spanish: `--problem=translate_enes_wmt32k`\n\nYou can get translations in the other direction by appending `_rev` to\nthe problem name, e.g., for German-English use\n`--problem=translate_ende_wmt32k_rev`\n(note that you still need to download the original data with t2t-datagen\n`--problem=translate_ende_wmt32k`).\n\nFor all translation problems, we suggest to try the Transformer model:\n`--model=transformer`. At first it is best to try the base setting,\n`--hparams_set=transformer_base`. When trained on 8 GPUs for 300K steps\nthis should reach a BLEU score of about 28 on the English-German data-set,\nwhich is close to state-of-the art. If training on a single GPU, try the\n`--hparams_set=transformer_base_single_gpu` setting. For very good results\nor larger data-sets (e.g., for English-French), try the big model\nwith `--hparams_set=transformer_big`.\n\nSee this [example](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/Transformer_translate.ipynb) to know how the translation works.\n\n## Basics\n\n### Walkthrough\n\nHere's a walkthrough training a good English-to-German translation\nmodel using the Transformer model from [*Attention Is All You\nNeed*](https://arxiv.org/abs/1706.03762) on WMT data.\n\n```\npip install tensor2tensor\n\n# See what problems, models, and hyperparameter sets are available.\n# You can easily swap between them (and add new ones).\nt2t-trainer --registry_help\n\nPROBLEM=translate_ende_wmt32k\nMODEL=transformer\nHPARAMS=transformer_base_single_gpu\n\nDATA_DIR=$HOME/t2t_data\nTMP_DIR=/tmp/t2t_datagen\nTRAIN_DIR=$HOME/t2t_train/$PROBLEM/$MODEL-$HPARAMS\n\nmkdir -p $DATA_DIR $TMP_DIR $TRAIN_DIR\n\n# Generate data\nt2t-datagen \\\n  --data_dir=$DATA_DIR \\\n  --tmp_dir=$TMP_DIR \\\n  --problem=$PROBLEM\n\n# Train\n# *  If you run out of memory, add --hparams='batch_size=1024'.\nt2t-trainer \\\n  --data_dir=$DATA_DIR \\\n  --problem=$PROBLEM \\\n  --model=$MODEL \\\n  --hparams_set=$HPARAMS \\\n  --output_dir=$TRAIN_DIR\n\n# Decode\n\nDECODE_FILE=$DATA_DIR/decode_this.txt\necho \"Hello world\" >> $DECODE_FILE\necho \"Goodbye world\" >> $DECODE_FILE\necho -e 'Hallo Welt\\nAuf Wiedersehen Welt' > ref-translation.de\n\nBEAM_SIZE=4\nALPHA=0.6\n\nt2t-decoder \\\n  --data_dir=$DATA_DIR \\\n  --problem=$PROBLEM \\\n  --model=$MODEL \\\n  --hparams_set=$HPARAMS \\\n  --output_dir=$TRAIN_DIR \\\n  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n  --decode_from_file=$DECODE_FILE \\\n  --decode_to_file=translation.en\n\n# See the translations\ncat translation.en\n\n# Evaluate the BLEU score\n# Note: Report this BLEU score in papers, not the internal approx_bleu metric.\nt2t-bleu --translation=translation.en --reference=ref-translation.de\n```\n\n### Installation\n\n\n```\n# Assumes tensorflow or tensorflow-gpu installed\npip install tensor2tensor\n\n# Installs with tensorflow-gpu requirement\npip install tensor2tensor[tensorflow_gpu]\n\n# Installs with tensorflow (cpu) requirement\npip install tensor2tensor[tensorflow]\n```\n\nBinaries:\n\n```\n# Data generator\nt2t-datagen\n\n# Trainer\nt2t-trainer --registry_help\n```\n\nLibrary usage:\n\n```\npython -c \"from tensor2tensor.models.transformer import Transformer\"\n```\n\n### Features\n\n* Many state of the art and baseline models are built-in and new models can be\n  added easily (open an issue or pull request!).\n* Many datasets across modalities - text, audio, image - available for\n  generation and use, and new ones can be added easily (open an issue or pull\n  request for public datasets!).\n* Models can be used with any dataset and input mode (or even multiple); all\n  modality-specific processing (e.g. embedding lookups for text tokens) is done\n  with `bottom` and `top` transformations, which are specified per-feature in the\n  model.\n* Support for multi-GPU machines and synchronous (1 master, many workers) and\n  asynchronous (independent workers synchronizing through a parameter server)\n  [distributed training](https://tensorflow.github.io/tensor2tensor/distributed_training.html).\n* Easily swap amongst datasets and models by command-line flag with the data\n  generation script `t2t-datagen` and the training script `t2t-trainer`.\n* Train on [Google Cloud ML](https://tensorflow.github.io/tensor2tensor/cloud_mlengine.html) and [Cloud TPUs](https://tensorflow.github.io/tensor2tensor/cloud_tpu.html).\n\n## T2T overview\n\n### Problems\n\n**Problems** consist of features such as inputs and targets, and metadata such\nas each feature's modality (e.g. symbol, image, audio) and vocabularies. Problem\nfeatures are given by a dataset, which is stored as a `TFRecord` file with\n`tensorflow.Example` protocol buffers. All\nproblems are imported in\n[`all_problems.py`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/all_problems.py)\nor are registered with `@registry.register_problem`. Run\n[`t2t-datagen`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/bin/t2t-datagen)\nto see the list of available problems and download them.\n\n### Models\n\n**`T2TModel`s** define the core tensor-to-tensor computation. They apply a\ndefault transformation to each input and output so that models may deal with\nmodality-independent tensors (e.g. embeddings at the input; and a linear\ntransform at the output to produce logits for a softmax over classes). All\nmodels are imported in the\n[`models` subpackage](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/models/__init__.py),\ninherit from [`T2TModel`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/t2t_model.py),\nand are registered with\n[`@registry.register_model`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/registry.py).\n\n### Hyperparameter Sets\n\n**Hyperparameter sets** are encoded in\n[`HParams`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/hparam.py)\nobjects, and are registered with\n[`@registry.register_hparams`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/utils/registry.py).\nEvery model and problem has a `HParams`. A basic set of hyperparameters are\ndefined in\n[`common_hparams.py`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/layers/common_hparams.py)\nand hyperparameter set functions can compose other hyperparameter set functions.\n\n### Trainer\n\nThe **trainer** binary is the entrypoint for training, evaluation, and\ninference. Users can easily switch between problems, models, and hyperparameter\nsets by using the `--model`, `--problem`, and `--hparams_set` flags. Specific\nhyperparameters can be overridden with the `--hparams` flag. `--schedule` and\nrelated flags control local and distributed training/evaluation\n([distributed training documentation](https://github.com/tensorflow/tensor2tensor/tree/master/docs/distributed_training.md)).\n\n## Adding your own components\n\nT2T's components are registered using a central registration mechanism that\nenables easily adding new ones and easily swapping amongst them by command-line\nflag. You can add your own components without editing the T2T codebase by\nspecifying the `--t2t_usr_dir` flag in `t2t-trainer`.\n\nYou can do so for models, hyperparameter sets, modalities, and problems. Please\ndo submit a pull request if your component might be useful to others.\n\nSee the [`example_usr_dir`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/test_data/example_usr_dir)\nfor an example user directory.\n\n## Adding a dataset\n\nTo add a new dataset, subclass\n[`Problem`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/problem.py)\nand register it with `@registry.register_problem`. See\n[`TranslateEndeWmt8k`](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/translate_ende.py)\nfor an example. Also see the [data generators\nREADME](https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/README.md).\n\n## Run on FloydHub\n\n[![Run on FloydHub](https://static.floydhub.com/button/button.svg)](https://floydhub.com/run)\n\nClick this button to open a [Workspace](https://blog.floydhub.com/workspaces/) on [FloydHub](https://www.floydhub.com/?utm_medium=readme&utm_source=tensor2tensor&utm_campaign=jul_2018). You can use the workspace to develop and test your code on a fully configured cloud GPU machine.\n\nTensor2Tensor comes preinstalled in the environment, you can simply open a [Terminal](https://docs.floydhub.com/guides/workspace/#using-terminal) and run your code.\n\n```bash\n# Test the quick-start on a Workspace's Terminal with this command\nt2t-trainer \\\n  --generate_data \\\n  --data_dir=./t2t_data \\\n  --output_dir=./t2t_train/mnist \\\n  --problem=image_mnist \\\n  --model=shake_shake \\\n  --hparams_set=shake_shake_quick \\\n  --train_steps=1000 \\\n  --eval_steps=100\n```\n\nNote: Ensure compliance with the FloydHub [Terms of Service](https://www.floydhub.com/about/terms).\n\n## Papers\n\nWhen referencing Tensor2Tensor, please cite [this\npaper](https://arxiv.org/abs/1803.07416).\n\n```\n@article{tensor2tensor,\n  author    = {Ashish Vaswani and Samy Bengio and Eugene Brevdo and\n    Francois Chollet and Aidan N. Gomez and Stephan Gouws and Llion Jones and\n    \\L{}ukasz Kaiser and Nal Kalchbrenner and Niki Parmar and Ryan Sepassi and\n    Noam Shazeer and Jakob Uszkoreit},\n  title     = {Tensor2Tensor for Neural Machine Translation},\n  journal   = {CoRR},\n  volume    = {abs/1803.07416},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1803.07416},\n}\n```\n\nTensor2Tensor was used to develop a number of state-of-the-art models\nand deep learning methods. Here we list some papers that were based on T2T\nfrom the start and benefited from its features and architecture in ways\ndescribed in the [Google Research Blog post introducing\nT2T](https://research.googleblog.com/2017/06/accelerating-deep-learning-research.html).\n\n* [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n* [Depthwise Separable Convolutions for Neural Machine\n   Translation](https://arxiv.org/abs/1706.03059)\n* [One Model To Learn Them All](https://arxiv.org/abs/1706.05137)\n* [Discrete Autoencoders for Sequence Models](https://arxiv.org/abs/1801.09797)\n* [Generating Wikipedia by Summarizing Long\n   Sequences](https://arxiv.org/abs/1801.10198)\n* [Image Transformer](https://arxiv.org/abs/1802.05751)\n* [Training Tips for the Transformer Model](https://arxiv.org/abs/1804.00247)\n* [Self-Attention with Relative Position Representations](https://arxiv.org/abs/1803.02155)\n* [Fast Decoding in Sequence Models using Discrete Latent Variables](https://arxiv.org/abs/1803.03382)\n* [Adafactor: Adaptive Learning Rates with Sublinear Memory Cost](https://arxiv.org/abs/1804.04235)\n* [Universal Transformers](https://arxiv.org/abs/1807.03819)\n* [Attending to Mathematical Language with Transformers](https://arxiv.org/abs/1812.02825)\n* [The Evolved Transformer](https://arxiv.org/abs/1901.11117)\n* [Model-Based Reinforcement Learning for Atari](https://arxiv.org/abs/1903.00374)\n* [VideoFlow: A Flow-Based Generative Model for Video](https://arxiv.org/abs/1903.01434)\n\n*NOTE: This is not an official Google product.*\n",
         "AI_DataScience"
        ],
        [
         "49",
         "MDEwOlJlcG9zaXRvcnkxMzQ5Nzc1",
         "gensim ‚Äì Topic Modelling in Python\n==================================\n\n<!--\nThe following image URLs are obfuscated = proxied and cached through\nGoogle because of Github's proxying issues. See:\nhttps://github.com/RaRe-Technologies/gensim/issues/2805\n-->\n\n[![Build Status](https://github.com/RaRe-Technologies/gensim/actions/workflows/tests.yml/badge.svg?branch=develop)](https://github.com/RaRe-Technologies/gensim/actions)\n[![GitHub release](https://img.shields.io/github/release/rare-technologies/gensim.svg?maxAge=3600)](https://github.com/RaRe-Technologies/gensim/releases)\n[![Downloads](https://img.shields.io/pypi/dm/gensim?color=blue)](https://pepy.tech/project/gensim/)\n[![DOI](https://zenodo.org/badge/DOI/10.13140/2.1.2393.1847.svg)](https://doi.org/10.13140/2.1.2393.1847)\n[![Mailing List](https://img.shields.io/badge/-Mailing%20List-blue.svg)](https://groups.google.com/g/gensim)\n[![Follow](https://img.shields.io/twitter/follow/gensim_py.svg?style=social&style=flat&logo=twitter&label=Follow&color=blue)](https://twitter.com/gensim_py)\n\nGensim is a Python library for *topic modelling*, *document indexing*\nand *similarity retrieval* with large corpora. Target audience is the\n*natural language processing* (NLP) and *information retrieval* (IR)\ncommunity.\n\n## ‚ö†Ô∏è Want to help out? [Sponsor Gensim](https://github.com/sponsors/piskvorky) ‚ù§Ô∏è\n\n## ‚ö†Ô∏è Gensim is in stable maintenance mode: we are not accepting new features, but bug and documentation fixes are still welcome! ‚ö†Ô∏è\n\nFeatures\n--------\n\n-   All algorithms are **memory-independent** w.r.t. the corpus size\n    (can process input larger than RAM, streamed, out-of-core),\n-   **Intuitive interfaces**\n    -   easy to plug in your own input corpus/datastream (trivial\n        streaming API)\n    -   easy to extend with other Vector Space algorithms (trivial\n        transformation API)\n-   Efficient multicore implementations of popular algorithms, such as\n    online **Latent Semantic Analysis (LSA/LSI/SVD)**, **Latent\n    Dirichlet Allocation (LDA)**, **Random Projections (RP)**,\n    **Hierarchical Dirichlet Process (HDP)** or **word2vec deep\n    learning**.\n-   **Distributed computing**: can run *Latent Semantic Analysis* and\n    *Latent Dirichlet Allocation* on a cluster of computers.\n-   Extensive [documentation and Jupyter Notebook tutorials].\n\nIf this feature list left you scratching your head, you can first read\nmore about the [Vector Space Model] and [unsupervised document analysis]\non Wikipedia.\n\nInstallation\n------------\n\nThis software depends on [NumPy], a Python package for\nscientific computing. Please bear in mind that building NumPy from source\n(e.g. by installing gensim on a platform which lacks NumPy .whl distribution)\nis a non-trivial task involving [linking NumPy to a BLAS library].  \nIt is recommended to provide a fast one (such as MKL, [ATLAS] or\n[OpenBLAS]) which can improve performance by as much as an order of\nmagnitude. On OSX, NumPy picks up its vecLib BLAS automatically,\nso you don‚Äôt need to do anything special.\n\nInstall the latest version of gensim:\n\n```bash\n    pip install --upgrade gensim\n```\n\nOr, if you have instead downloaded and unzipped the [source tar.gz]\npackage:\n\n```bash\n    tar -xvzf gensim-X.X.X.tar.gz\n    cd gensim-X.X.X/\n    pip install .\n```\n\nFor alternative modes of installation, see the [documentation].\n\nGensim is being [continuously tested](https://radimrehurek.com/gensim/#testing) under all\n[supported Python versions](https://github.com/RaRe-Technologies/gensim/wiki/Gensim-And-Compatibility).\nSupport for Python 2.7 was dropped in gensim 4.0.0 ‚Äì install gensim 3.8.3 if you must use Python 2.7.\n\nHow come gensim is so fast and memory efficient? Isn‚Äôt it pure Python, and isn‚Äôt Python slow and greedy?\n--------------------------------------------------------------------------------------------------------\n\nMany scientific algorithms can be expressed in terms of large matrix\noperations (see the BLAS note above). Gensim taps into these low-level\nBLAS libraries, by means of its dependency on NumPy. So while\ngensim-the-top-level-code is pure Python, it actually executes highly\noptimized Fortran/C under the hood, including multithreading (if your\nBLAS is so configured).\n\nMemory-wise, gensim makes heavy use of Python‚Äôs built-in generators and\niterators for streamed data processing. Memory efficiency was one of\ngensim‚Äôs [design goals], and is a central feature of gensim, rather than\nsomething bolted on as an afterthought.\n\nDocumentation\n-------------\n\n-   [QuickStart]\n-   [Tutorials]\n-   [Official API Documentation]\n\n  [QuickStart]: https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html\n  [Tutorials]: https://radimrehurek.com/gensim/auto_examples/\n  [Official Documentation and Walkthrough]: https://radimrehurek.com/gensim/\n  [Official API Documentation]: https://radimrehurek.com/gensim/auto_examples/index.html#documentation\n\nSupport\n-------\n\nFor commercial support, please see [Gensim sponsorship](https://github.com/sponsors/piskvorky).\n\nAsk open-ended questions on the public [Gensim Mailing List](https://groups.google.com/g/gensim).\n\nRaise bugs on [Github](https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md) but please **make sure you follow the [issue template](https://github.com/RaRe-Technologies/gensim/blob/develop/ISSUE_TEMPLATE.md)**. Issues that are not bugs or fail to provide the requested details will be closed without inspection.\n\n\n---------\n\nAdopters\n--------\n\n| Company | Logo | Industry | Use of Gensim |\n|---------|------|----------|---------------|\n| [RARE Technologies](https://rare-technologies.com/) | ![rare](docs/src/readme_images/rare.png) | ML & NLP consulting | Creators of Gensim ‚Äì¬†this is us! |\n| [Amazon](http://www.amazon.com/) |  ![amazon](docs/src/readme_images/amazon.png) | Retail |  Document similarity. |\n| [National Institutes of Health](https://github.com/NIHOPA/pipeline_word2vec) | ![nih](docs/src/readme_images/nih.png) | Health | Processing grants and publications with word2vec. |\n| [Cisco Security](http://www.cisco.com/c/en/us/products/security/index.html) | ![cisco](docs/src/readme_images/cisco.png) | Security |  Large-scale fraud detection. |\n| [Mindseye](http://www.mindseyesolutions.com/) | ![mindseye](docs/src/readme_images/mindseye.png) | Legal | Similarities in legal documents. |\n| [Channel 4](http://www.channel4.com/) | ![channel4](docs/src/readme_images/channel4.png) | Media | Recommendation engine. |\n| [Talentpair](http://talentpair.com) | ![talent-pair](docs/src/readme_images/talent-pair.png) | HR | Candidate matching in high-touch recruiting. |\n| [Juju](http://www.juju.com/)  | ![juju](docs/src/readme_images/juju.png) | HR | Provide non-obvious related job suggestions. |\n| [Tailwind](https://www.tailwindapp.com/) | ![tailwind](docs/src/readme_images/tailwind.png) | Media | Post interesting and relevant content to Pinterest. |\n| [Issuu](https://issuu.com/) | ![issuu](docs/src/readme_images/issuu.png) | Media | Gensim's LDA module lies at the very core of the analysis we perform on each uploaded publication to figure out what it's all about. |\n| [Search Metrics](http://www.searchmetrics.com/) | ![search-metrics](docs/src/readme_images/search-metrics.png) | Content Marketing | Gensim word2vec used for entity disambiguation in Search Engine Optimisation. |\n| [12K Research](https://12k.com/) | ![12k](docs/src/readme_images/12k.png)| Media |   Document similarity analysis on media articles. |\n| [Stillwater Supercomputing](http://www.stillwater-sc.com/) | ![stillwater](docs/src/readme_images/stillwater.png) | Hardware | Document comprehension and association with word2vec. |\n| [SiteGround](https://www.siteground.com/) |  ![siteground](docs/src/readme_images/siteground.png) | Web hosting | An ensemble search engine which uses different embeddings models and similarities, including word2vec, WMD, and LDA. |\n| [Capital One](https://www.capitalone.com/) | ![capitalone](docs/src/readme_images/capitalone.png) | Finance | Topic modeling for customer complaints exploration. |\n\n-------\n\nCiting gensim\n------------\n\nWhen [citing gensim in academic papers and theses], please use this\nBibTeX entry:\n\n    @inproceedings{rehurek_lrec,\n          title = {{Software Framework for Topic Modelling with Large Corpora}},\n          author = {Radim {\\v R}eh{\\r u}{\\v r}ek and Petr Sojka},\n          booktitle = {{Proceedings of the LREC 2010 Workshop on New\n               Challenges for NLP Frameworks}},\n          pages = {45--50},\n          year = 2010,\n          month = May,\n          day = 22,\n          publisher = {ELRA},\n          address = {Valletta, Malta},\n          note={\\url{http://is.muni.cz/publication/884893/en}},\n          language={English}\n    }\n\n  [citing gensim in academic papers and theses]: https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9vG_kV0AAAAJ&citation_for_view=9vG_kV0AAAAJ:NaGl4SEjCO4C\n\n  [design goals]: https://radimrehurek.com/gensim/intro.html#design-principles\n  [RaRe Technologies]: https://rare-technologies.com/wp-content/uploads/2016/02/rare_image_only.png%20=10x20\n  [rare\\_tech]: //rare-technologies.com\n  [Talentpair]: https://avatars3.githubusercontent.com/u/8418395?v=3&s=100\n  [citing gensim in academic papers and theses]: https://scholar.google.cz/citations?view_op=view_citation&hl=en&user=9vG_kV0AAAAJ&citation_for_view=9vG_kV0AAAAJ:u-x6o8ySG0sC\n\n  [documentation and Jupyter Notebook tutorials]: https://github.com/RaRe-Technologies/gensim/#documentation\n  [Vector Space Model]: https://en.wikipedia.org/wiki/Vector_space_model\n  [unsupervised document analysis]: https://en.wikipedia.org/wiki/Latent_semantic_indexing\n  [NumPy]: https://numpy.org/install/\n  [linking NumPy to a BLAS library]: https://numpy.org/devdocs/building/blas_lapack.html\n  [ATLAS]: https://math-atlas.sourceforge.net/\n  [OpenBLAS]: https://xianyi.github.io/OpenBLAS/\n  [source tar.gz]: https://pypi.org/project/gensim/\n  [documentation]: https://radimrehurek.com/gensim/#install\n\n",
         "AI_DataScience"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 57368
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_id</th>\n",
       "      <th>readme</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNTUyMjA2NDE=</td>\n",
       "      <td>&lt;!---\\nCopyright 2020 The HuggingFace Team. Al...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==</td>\n",
       "      <td>![PyTorch Logo](https://github.com/pytorch/pyt...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_kgDOJ-2MVA</td>\n",
       "      <td># Build a Large Language Model (From Scratch)\\...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnk3MTU4MzYwMg==</td>\n",
       "      <td>&lt;!-- omit in toc --&gt;\\n# Computer Science cours...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxMTU0Nzg4MjA=</td>\n",
       "      <td>[![Logo](/logo.png)](http://awesome-scalabilit...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57363</th>\n",
       "      <td>R_kgDOHwL4GA</td>\n",
       "      <td># Monitoring ML\\n\\nLearn how to monitor ML sys...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57364</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNjM1OTEyODk=</td>\n",
       "      <td># CheckInstalledWindowsUpdates\\nScript intende...</td>\n",
       "      <td>SoftwareEngTools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57365</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxOTQ3OTYxNzM=</td>\n",
       "      <td>&lt;p align=\"center\"&gt;&lt;a href=\"https://github.com/...</td>\n",
       "      <td>SoftwareEngTools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57366</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNzMyNTMyNzE=</td>\n",
       "      <td># ![](https://github.com/sourceplusplus/source...</td>\n",
       "      <td>SoftwareEngTools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57367</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkzMTU1NDc2NQ==</td>\n",
       "      <td># es-stats\\n\\nReads key cluster metrics from E...</td>\n",
       "      <td>SoftwareEngTools</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57368 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                repo_id  \\\n",
       "0      MDEwOlJlcG9zaXRvcnkxNTUyMjA2NDE=   \n",
       "1      MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==   \n",
       "2                          R_kgDOJ-2MVA   \n",
       "3      MDEwOlJlcG9zaXRvcnk3MTU4MzYwMg==   \n",
       "4      MDEwOlJlcG9zaXRvcnkxMTU0Nzg4MjA=   \n",
       "...                                 ...   \n",
       "57363                      R_kgDOHwL4GA   \n",
       "57364  MDEwOlJlcG9zaXRvcnkxNjM1OTEyODk=   \n",
       "57365  MDEwOlJlcG9zaXRvcnkxOTQ3OTYxNzM=   \n",
       "57366  MDEwOlJlcG9zaXRvcnkxNzMyNTMyNzE=   \n",
       "57367  MDEwOlJlcG9zaXRvcnkzMTU1NDc2NQ==   \n",
       "\n",
       "                                                  readme          category  \n",
       "0      <!---\\nCopyright 2020 The HuggingFace Team. Al...    AI_DataScience  \n",
       "1      ![PyTorch Logo](https://github.com/pytorch/pyt...    AI_DataScience  \n",
       "2      # Build a Large Language Model (From Scratch)\\...    AI_DataScience  \n",
       "3      <!-- omit in toc -->\\n# Computer Science cours...    AI_DataScience  \n",
       "4      [![Logo](/logo.png)](http://awesome-scalabilit...    AI_DataScience  \n",
       "...                                                  ...               ...  \n",
       "57363  # Monitoring ML\\n\\nLearn how to monitor ML sys...    AI_DataScience  \n",
       "57364  # CheckInstalledWindowsUpdates\\nScript intende...  SoftwareEngTools  \n",
       "57365  <p align=\"center\"><a href=\"https://github.com/...  SoftwareEngTools  \n",
       "57366  # ![](https://github.com/sourceplusplus/source...  SoftwareEngTools  \n",
       "57367  # es-stats\\n\\nReads key cluster metrics from E...  SoftwareEngTools  \n",
       "\n",
       "[57368 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.drop_duplicates(subset=['repo_id'],inplace=True)\n",
    "final_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTskrHqZcvF6",
    "outputId": "e5d769de-133a-4076-cc36-31dce1b871fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57368 entries, 0 to 57412\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   repo_id   57368 non-null  object\n",
      " 1   readme    57368 non-null  object\n",
      " 2   category  57368 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgOElEfLT_UO"
   },
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QpLBL0vdUD7s"
   },
   "outputs": [],
   "source": [
    "class BertTextPreprocessor:\n",
    "    \"\"\" Preprocess using regex and remove unecessary words\"\"\"\n",
    "    def __init__(self, remove_code=True, remove_urls=True, lowercase=True):\n",
    "        self.remove_code = remove_code\n",
    "        self.remove_urls = remove_urls\n",
    "        self.lowercase = lowercase\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        # Add common programming keywords to stop words\n",
    "        self.programming_stop_words = {\n",
    "            'install', 'installation', 'usage', 'example', 'documentation',\n",
    "            'license', 'contributing', 'readme', 'github', 'git','href','src','link',\n",
    "            'fire','logo','bottom','language','icon','title','platform','source','like',\n",
    "            'pain','convenience','summary','release','default', 'created','last', 'mark',\n",
    "            'code','updated','loading','file','unless','project','title','effortlessly',\n",
    "            'csinternship','found','first','favorite','favourite','app','new','awesome',\n",
    "            'welcome','getting','started','trying','please','need', 'believe','feel',\n",
    "            'instead','let','think','use', 'thank','everyone','anyone', 'edit','run',\n",
    "            'without','see','simple', 'work','additional','information' ,'regarding',\n",
    "            'copyright', 'ownership' ,'asf','needed','system','building','helped','fix',\n",
    "            'discussion','fixed','install','useful','come','several','consist','of','follow',\n",
    "            'want','get','unique','way','changing','making','might','can','different','know',\n",
    "            'used','one','fastest','fast','also','various','could','try','noted','note',\n",
    "            'contribute','to','known','professional','community','team','usually','resarch',\n",
    "            'paper','download','often','rarely','never','png','conversation','karate','alt',\n",
    "            'friendly', 'icon','heavy','communication', 'resource','adjust','using','pre','built',\n",
    "            'optional','option','platform','bug','fix','magical','commit','main','build','version',\n",
    "            'repository','img','test','issue','create','tool','support','command','add'\n",
    "        }\n",
    "        self.stop_words.update(self.programming_stop_words)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        Clean and normalize text\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "\n",
    "        # Remove URLs\n",
    "        if self.remove_urls:\n",
    "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "        # Remove code blocks (markdown)\n",
    "        if self.remove_code:\n",
    "            text = re.sub(r'```[\\s\\S]*?```', '', text)  # Code blocks\n",
    "            text = re.sub(r'`[^`]*`', '', text)  # Inline code\n",
    "\n",
    "        # Remove markdown syntax\n",
    "        text = re.sub(r'#+\\s', '', text)  # Headers\n",
    "        text = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', text)  # Bold\n",
    "        text = re.sub(r'\\*([^*]+)\\*', r'\\1', text)  # Italic\n",
    "        text = re.sub(r'```math([^```]+)```KATEX_INLINE_OPEN[^KATEX_INLINE_CLOSE]+KATEX_INLINE_CLOSE', r'\\1', text)  # Links\n",
    "\n",
    "        # Remove special characters but keep spaces\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        # Convert to lowercase\n",
    "        if self.lowercase:\n",
    "            text = text.lower()\n",
    "\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        return text\n",
    "\n",
    "    def tokenize_and_lemmatize(self, text):\n",
    "        \"\"\"\n",
    "        Tokenize and lemmatize text\n",
    "        \"\"\"\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "        tokens = [token for token in tokens if token.lower() not in self.stop_words and len(token) > 2]\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Full preprocessing pipeline\n",
    "        \"\"\"\n",
    "        text = self.clean_text(text)\n",
    "        text = self.tokenize_and_lemmatize(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nt9DGNxZLJfZ"
   },
   "outputs": [],
   "source": [
    "preprocessor_bert = BertTextPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LORxHNCDLMtP"
   },
   "outputs": [],
   "source": [
    "final_dataset['cleanedText'] = final_dataset['readme'].apply(preprocessor_bert.preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "collapsed": true,
    "id": "JpzI-zxFdb07",
    "outputId": "ecc4b423-b19f-481d-fcb7-11802c6de3f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_id</th>\n",
       "      <th>readme</th>\n",
       "      <th>category</th>\n",
       "      <th>cleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNTUyMjA2NDE=</td>\n",
       "      <td>&lt;!---\\nCopyright 2020 The HuggingFace Team. Al...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "      <td>huggingface rights reserved licensed apache ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==</td>\n",
       "      <td>![PyTorch Logo](https://github.com/pytorch/pyt...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "      <td>pytorch pytorch python package provides two hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_kgDOJ-2MVA</td>\n",
       "      <td># Build a Large Language Model (From Scratch)\\...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "      <td>large model scratch contains developing pretra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnk3MTU4MzYwMg==</td>\n",
       "      <td>&lt;!-- omit in toc --&gt;\\n# Computer Science cours...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "      <td>omit toc computer science courses video lectur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxMTU0Nzg4MjA=</td>\n",
       "      <td>[![Logo](/logo.png)](http://awesome-scalabilit...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "      <td>organized reading list illustrating patterns s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57408</th>\n",
       "      <td>R_kgDOHwL4GA</td>\n",
       "      <td># Monitoring ML\\n\\nLearn how to monitor ML sys...</td>\n",
       "      <td>AI_DataScience</td>\n",
       "      <td>monitoring learn monitor systems identify addr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57409</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNjM1OTEyODk=</td>\n",
       "      <td># CheckInstalledWindowsUpdates\\nScript intende...</td>\n",
       "      <td>SoftwareEngTools</td>\n",
       "      <td>checkinstalledwindowsupdates script intended a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57410</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxOTQ3OTYxNzM=</td>\n",
       "      <td>&lt;p align=\"center\"&gt;&lt;a href=\"https://github.com/...</td>\n",
       "      <td>SoftwareEngTools</td>\n",
       "      <td>align center frontend public svg grafolean wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57411</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNzMyNTMyNzE=</td>\n",
       "      <td># ![](https://github.com/sourceplusplus/source...</td>\n",
       "      <td>SoftwareEngTools</td>\n",
       "      <td>plugin description contains jetbrains ide plug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57412</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkzMTU1NDc2NQ==</td>\n",
       "      <td># es-stats\\n\\nReads key cluster metrics from E...</td>\n",
       "      <td>SoftwareEngTools</td>\n",
       "      <td>stats reads key cluster metrics elasticsearch ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57368 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                repo_id  \\\n",
       "0      MDEwOlJlcG9zaXRvcnkxNTUyMjA2NDE=   \n",
       "1      MDEwOlJlcG9zaXRvcnk2NTYwMDk3NQ==   \n",
       "2                          R_kgDOJ-2MVA   \n",
       "3      MDEwOlJlcG9zaXRvcnk3MTU4MzYwMg==   \n",
       "4      MDEwOlJlcG9zaXRvcnkxMTU0Nzg4MjA=   \n",
       "...                                 ...   \n",
       "57408                      R_kgDOHwL4GA   \n",
       "57409  MDEwOlJlcG9zaXRvcnkxNjM1OTEyODk=   \n",
       "57410  MDEwOlJlcG9zaXRvcnkxOTQ3OTYxNzM=   \n",
       "57411  MDEwOlJlcG9zaXRvcnkxNzMyNTMyNzE=   \n",
       "57412  MDEwOlJlcG9zaXRvcnkzMTU1NDc2NQ==   \n",
       "\n",
       "                                                  readme          category  \\\n",
       "0      <!---\\nCopyright 2020 The HuggingFace Team. Al...    AI_DataScience   \n",
       "1      ![PyTorch Logo](https://github.com/pytorch/pyt...    AI_DataScience   \n",
       "2      # Build a Large Language Model (From Scratch)\\...    AI_DataScience   \n",
       "3      <!-- omit in toc -->\\n# Computer Science cours...    AI_DataScience   \n",
       "4      [![Logo](/logo.png)](http://awesome-scalabilit...    AI_DataScience   \n",
       "...                                                  ...               ...   \n",
       "57408  # Monitoring ML\\n\\nLearn how to monitor ML sys...    AI_DataScience   \n",
       "57409  # CheckInstalledWindowsUpdates\\nScript intende...  SoftwareEngTools   \n",
       "57410  <p align=\"center\"><a href=\"https://github.com/...  SoftwareEngTools   \n",
       "57411  # ![](https://github.com/sourceplusplus/source...  SoftwareEngTools   \n",
       "57412  # es-stats\\n\\nReads key cluster metrics from E...  SoftwareEngTools   \n",
       "\n",
       "                                             cleanedText  \n",
       "0      huggingface rights reserved licensed apache ma...  \n",
       "1      pytorch pytorch python package provides two hi...  \n",
       "2      large model scratch contains developing pretra...  \n",
       "3      omit toc computer science courses video lectur...  \n",
       "4      organized reading list illustrating patterns s...  \n",
       "...                                                  ...  \n",
       "57408  monitoring learn monitor systems identify addr...  \n",
       "57409  checkinstalledwindowsupdates script intended a...  \n",
       "57410  align center frontend public svg grafolean wid...  \n",
       "57411  plugin description contains jetbrains ide plug...  \n",
       "57412  stats reads key cluster metrics elasticsearch ...  \n",
       "\n",
       "[57368 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_O4hJgRLdqqU"
   },
   "outputs": [],
   "source": [
    "final_dataset['category']= final_dataset['category'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "CJK_qfXpihxr",
    "outputId": "a19c2aae-0e7a-4ae8-d908-7d89354c9862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of classes in dataset')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='category',data=final_dataset)\n",
    "plt.title('Number of classes in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oj5XY9i1UBVV"
   },
   "source": [
    "### Split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZWiIGdMwfBQ",
    "outputId": "9dcc1c8d-dc20-4dca-fbef-3abd6281a338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45894, 4) (11474, 4)\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(final_dataset,random_state=42,test_size=0.2,stratify=final_dataset['category'])\n",
    "print(train_set.shape, test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\84941\\AppData\\Local\\Temp\\ipykernel_10776\\2523633153.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x='category', data=train_set, palette='viridis')\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\84941\\AppData\\Local\\Temp\\ipykernel_10776\\2523633153.py:14: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x='category', data=test_set, palette='viridis')\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Users\\84941\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# v·∫Ω bar chart s·ªë l∆∞·ª£ng m·∫´u trong t·ª´ng l·ªõp c·ªßa t·∫≠p train v√† test b·∫±ng read csv train v√† test\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "train_set = pd.read_csv(r\"D:\\22DKHA1\\social\\train_set.csv\")\n",
    "test_set = pd.read_csv(r\"D:\\22DKHA1\\social\\test_set.csv\")\n",
    "\n",
    "# th√™m m√†u s·∫Øc v√†o bar chart\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='category', data=train_set, palette='viridis')\n",
    "plt.title('Number of classes in Train Set')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='category', data=test_set, palette='viridis')\n",
    "plt.title('Number of classes in Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "id": "9lMm-7KNxBy3",
    "outputId": "5736b90b-fe40-4e54-f2b2-cf9f8cb8decd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.countplot(x='category',data=train_set)\n",
    "plt.title('Number of classes in train_set')\n",
    "plt.show()\n",
    "sns.countplot(x='category',data=test_set)\n",
    "plt.title('Number of classes in test_set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "eBIs0w6yxEUO",
    "outputId": "a0c43a59-a872-4378-ac0f-30cee4244a2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of classes in test_set')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPflJREFUeJzt3Qd0VNX69/EnIZBQE3pAICAiTQQJRQRRAQlFBMGCoqIgWCgC3oi50kVBQKp0pahgFxRUelVCCyJVREXJXwzhXkoELgHCedez15p5Z0ICAQMzk/39rHWYzDl7Zs6ZGTK/7P3sM0GO4zgCAABgsWBf7wAAAICvEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiIAAtmbNGgkKCpLPPvtMAsHhw4flwQcflKJFi5r9Hj9+/D+6v/Lly8tTTz0lOdWcOXPM8/T777/7eleAHI9ABGTxQyksLEz+/PPPi7bffffdcsstt/hk3wJN3759ZenSpRIXFyfvv/++tGjRwte7ZJXTp0/LkCFDTJC+lr755hvzOL42f/78fxy6YQ8CEZBFqampMnLkSF/vRkBbtWqVtG3bVv71r3/J448/LlWqVPH1Lvm1J554Qv73v/9JVFRUtgWioUOHXpdApI/jawQiXAkCEZBFtWrVkpkzZ8qhQ4fENqdOncqW+0lOTpaIiIhsuS8b5MqVy/RMag8lgGuLQARk0b///W9JS0u7bC+R1nvoB5gOtaWn6z2HEvRnXffzzz+bHpPw8HApXry4DBw4UBzHkcTERNOjUqhQIYmMjJS33norw8fU/dL90zb58+eX+++/39w2vU2bNplhKn2cfPnyyV133SXff/+9VxvXPu3Zs0cee+wxKVy4sDRq1OiSx/zbb7/JQw89JEWKFDH3e/vtt8vXX3990bCjHtPkyZPNz5f7kL9w4YJMmDBBatSoYUKBPi+671u3bs30NkePHjW9T3qbAgUKmOetZcuW8uOPP17UdtKkSVK9enWzv3qMderUMT0KLn///bf06dPH1CmFhoZKiRIl5N5775Vt27Zd8XOa1fvKSg2R3sd9990n3333ndSrV888NzfeeKO89957l7wvvQ99DpX23rheA8/3408//WRqvPR11PvV5+Srr77yup9z586Z21eqVMm00XowfX8sX77cbNeaLn2NlesxriTQ7d+/Xzp06GDey3r/ZcqUkY4dO8qJEye82n3wwQcSHR0tefPmNfurbTzf8zqUre/BP/74w70P+twBmQnJdAsALxUqVJAnn3zS9BK98sorUrp06Wy770ceeUSqVq1qwpb+Eh8+fLj5JT99+nRp0qSJvPnmmzJv3jzzYV+3bl1p3Lix1+1ff/118wu/f//+phdGhwmaNWsm27dvNx8YruEqDQf6ITJ48GAJDg6W2bNnm/tfv369+XD1pAFHP/TeeOMNE2QuVSh9xx13mOGY3r17mw/IuXPnmlCmxd4PPPCA2V+tGdIhIA0C+jxeTteuXU0g0H1+5pln5Pz582Y/N27caD6oMwtmCxcuNPuur5fumz6HGlI04LleM30NdV/1w//FF1+UM2fOyI4dO0y40RConnvuObP/PXv2lGrVqsl///tfE0L27t0rtWvXvqLnNCv3dSV++eUXs+/6HHXu3FlmzZplgojuh4a8jGgYmjp1qjz//PPmNWnfvr1Zf+utt5rL3bt3S8OGDeWGG24w728N1p988om0a9dOPv/8c3MbpQFqxIgR5jXR40tJSTEhVcOdvrbPPvus6UXVgKSv+ZU4e/asxMTEmOHpXr16mVCkdXuLFy+W48ePm9Dper/rHw0PP/yw2Y8jR46YgKvvsx9++MH0Qr766qsmRP3f//2fjBs3ztxOQzKQKQfAJc2ePVvTgLNlyxbn119/dUJCQpzevXu7t991111O9erV3dcPHDhg2uvt0tP1gwcPdl/Xn3Vd9+7d3evOnz/vlClTxgkKCnJGjhzpXn/s2DEnb968TufOnd3rVq9ebW5/ww03OCkpKe71n3zyiVk/YcIEc/3ChQtOpUqVnJiYGPOzy+nTp50KFSo4995770X79Oijj2bp+enTp49pv379eve6v//+29xv+fLlnbS0NK/j79Gjx2Xvc9WqVaat5/Ps4rn/UVFRXs/HmTNnvB7P9XqEhoY6w4YNc69r27at12uWkfDw8Evu65U8p5e7r8u99/QYPI9Z161bt869Ljk52RzjSy+9dMn7O3LkyEXvQZemTZs6NWrUMM+h5zHecccd5jhdatas6bRu3fqSj6PHejUfLz/88IO53aeffpppm99//93JlSuX8/rrr3ut37lzp/m/6ble91OfLyArGDIDroAOTWgvx4wZM+Svv/7KtvvVv3I960a0B0Tzg/YAuOhfvZUrVza9IOlpj0vBggXd17X3oFSpUqa4VWlPkQ5FaO+H9k785z//MYvWBjVt2lTWrVtnhqg8aa9GVuhjaE+B57Ca/iXevXt3M0yjPTNXSnsktMdLe13Su9Twiw5HaS+NaxhRj1X3RZ83z+EpfS6152DLli2Z3pe20R6jzGrGruQ5vdx9XSntZbrzzju9en8ye29khQ41am+X9rjo8J7rWPS4tMdGj9M1w1KPRXuTdF12c/UA6UxE7XHMyBdffGGeV91X137qor1J2qO5evXqbN8v2IFABFyhAQMGmOGb7JxxVq5cuYs+GLR+olixYhetP3bs2EW31w+C9KHhpptucteeuD68dHhFPzw9l3feeccMUaSv0dAhp6zQGg39ME5PhwBd26/Ur7/+aoa3dNjwSugHpQ6P6POh4UifPz1GHQ7zPD4dWtSgpEFO2/bo0eOiup9Ro0bJrl27pGzZsqadDhV5Bo4reU4vd1//9P2itA4qo/dGVofgNIDrMFT6Y3GFUh2KVcOGDTPDVzfffLOp1YqNjTXPb3bQ91y/fv3M86evnYYxrUfyfO30edd91dct/b7qEKRrP4ErRQ0RcBW9RFoArb1EWmuR1R4M7bHIjPYKZWWdulQ9T2ZcPRWjR482s+Uykr6+wlV7FEi03kk/1Lt06SKvvfaaCVTaY6QFzZ49YBrW9u3bZ2pTlixZYnqkpkyZIoMGDXJPF9ceCO2FWbBggSxbtsw8d1rLpT0UWjd0Jc/p5e7rSmXne0O5jkVr1DSEZEQDttI6HQ2sX375pTkWDS8aQqdNm+bV03m1dOKA1kO57l9rvbRmSWvHtMBa91X/j3377bcZPg/UCeFqEYiAq+wl0lku+qGW0V/qSv+K9nQ1PSVZlX74Qj8Y9a9+V8FsxYoVzaXOutJi6+yk58jRcJGezlhybb9Sur86bKJDOVfSS6SFy/fcc4+8++67Xuv1tUjf26ZFw1rMrosW82qRsRbr6kkjtXdO6bDjCy+8YBbtedACaG2jIeZKn9NL3df1kllY15CvcufOnaVj0dfk6aefNsvJkydNSNJeL1cg+qenCdCeJ130/9mGDRtMsbcGLp1soM+7vr+1N0l7qS6F0xXgSjBkBlwF/aWsvUQ6gykpKclrm35A6oev1pB40h6Ia0WnXGvth2cw0Bon14etzj7SfR4zZoz5AEtPZ+lcrVatWsnmzZslPj7evU7raLQHTac5a73LldJp1/qhl9HJ/S7VC6I9Bum3f/rppxedYVxrYzzlyZPH7KfeVqeVa29e+iFEnSqvw3g6FHYlz2lW7ut60dMCZBTWdX90mrq+nzOqjfN8f6R/7rRHRnuPPI9Fw2ZGj3M5OmNNh6M9aTDSXj7X/Wtw1ddZ3xvpX2u97rl/uh/pn3sgM/QQAVdJp/XqtGLtHUk/1Vn/UtYaI73UAmkNR3quoWtF/2LXomb9i12nmuu0e/2Q6tatm9muHyg6tKEBSfdV2+n0ag0KWoSqIW7RokVX9dg6bPjhhx+a+9bhDd0XnXZ/4MABMxTlKnK+EtrLo8XrEydONL1fep4fHSrRqey6TaevZ0TPz6M1Lnp8eiqAnTt3mtMVuHpAXJo3b26KcLXnoWTJkqb25O2335bWrVub4nT9INfhGS1Or1mzpvnQX7FihSnCdp0LKqvPqQbVy93X9aLDoBr8Pv74Y9O7oq+Vfu2MLlqro+8hDSD6vtHnTN9LGnS1AN11Lie9vYYnDYR6e51y7zqlgItuU/p+0CE4DTB6nqDL0cJuvR89bYLun4Yj/T+mt9eQrDSEak+R9uRpjZyeFkBfM32/6ZCkFvPr0J9rP/RYtS5JT1ehz32bNm2u0bOLgJeluWiAxTyn3aenU751W/op3Dr1umvXrma6dcGCBZ2HH37YTI3ObNq9TodOf7/58+e/6PHST/F3Tbv/8MMPnbi4OKdEiRJmar5ON/7jjz8ynNbcvn17p2jRomaatk5J1n1buXLlZffpUvR0BA8++KATERHhhIWFOfXq1XMWL158UbusTrt3nX5g9OjRTpUqVZw8efI4xYsXd1q2bOkkJCRcctq9Tj0vVaqUeR4aNmzoxMfHm+dNF5fp06c7jRs3dj8PFStWdGJjY50TJ06Y7ampqea6TjHX109fC/15ypQpV/ycXsl9ZXXafUbT3tMfY2Y2bNjgREdHm+c0/ftRX8cnn3zSiYyMdHLnzm1O53Dfffc5n332mbvN8OHDzeurr7U+x/r66FT3s2fPer12vXr1Mq+Znj4iqx81v/32m9OlSxfzeuj7qEiRIs4999zjrFix4qK2n3/+udOoUSPzfOqi+6HvrX379rnbnDx50nnsscfMvuo+MAUflxKk//g6lAEAAPgSNUQAAMB61BABAK45nTGos/kyo3VCru9aA3yBITMAwDWnhdhr167NdLuensHzS2yB641ABAC45hISEi55Jm2dAaez/gBfIRABAADrUVQNAACsR1F1FulJ4fSbqvUEYJwOHgCAwKADYXqCVD07/KVOFEsgyiINQ/pN1QAAIPAkJiaas8ZnhkCURdoz5HpC9ZT8AADA/+l35GmHhutzPDMEoixyDZNpGCIQAQAQWC5X7kJRNQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADW82kgWrdunbRp00ZKly5tvnRt4cKFF7XZu3ev3H///RIeHi758+eXunXrysGDB93bz5w5Iz169JCiRYtKgQIFpEOHDnL48GGv+9D2rVu3lnz58kmJEiUkNjZWzp8/f12OEQAA+D+fBqJTp05JzZo1ZfLkyRlu//XXX6VRo0ZSpUoVWbNmjezYsUMGDhwoYWFh7jZ9+/aVRYsWyaeffipr166VQ4cOSfv27d3b09LSTBg6e/asbNiwQebOnStz5syRQYMGXZdjBAAA/i/IcRxH/ID2EC1YsEDatWvnXtexY0fJnTu3vP/++xne5sSJE1K8eHGZP3++PPjgg2bdTz/9JFWrVpX4+Hi5/fbb5dtvv5X77rvPBKWSJUuaNtOmTZP+/fvLkSNHJE+ePFnav5SUFNNLpY9ZqFChbDlmAABwbWX18ztE/NSFCxfk66+/lpdfflliYmLkhx9+kAoVKkhcXJw7NCUkJMi5c+ekWbNm7ttpb1K5cuXcgUgva9So4Q5DSu/v+eefl927d8ttt92W4eOnpqaaxfMJBQDAdtGx74k/Sxj9ZM4qqk5OTpaTJ0/KyJEjpUWLFrJs2TJ54IEHzHCYDo2ppKQk08MTERHhdVsNP7rN1cYzDLm2u7ZlZsSIESZRupayZcteg6MEAAD+INife4hU27ZtTZ1QrVq15JVXXjHDXzrkda1pT5R2r7mWxMTEa/6YAADAN/w2EBUrVkxCQkKkWrVqXuu1Psg1yywyMtIUSx8/ftyrjc4y022uNulnnbmuu9pkJDQ01Iw1ei4AACBn8ttApENhOsV+3759Xut//vlniYqKMj9HR0ebouuVK1e6t2t7DUwNGjQw1/Vy586dZgjOZfny5SbgpA9bAADATj4tqtYaoV9++cV9/cCBA7J9+3YpUqSIKYzW8wU98sgj0rhxY7nnnntkyZIlZoq9TsFXWtvTtWtX6devn7mNhpxevXqZEKQF1ap58+Ym+DzxxBMyatQoUzc0YMAAc+4i7QUCAADwaSDaunWrCTouGmxU586dzbmCtIha64W0wLl3795SuXJl+fzzz825iVzGjRsnwcHB5oSMOitMZ5BNmTLFvT1XrlyyePFiM6tMg5Ke3FHvf9iwYdf5aAEAgL/ym/MQ+TvOQwQAgATctPusfn77bQ0RAADA9UIgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYz6eBaN26ddKmTRspXbq0BAUFycKFCzNt+9xzz5k248eP91p/9OhR6dSpkxQqVEgiIiKka9eucvLkSa82O3bskDvvvFPCwsKkbNmyMmrUqGt2TAAAIPD4NBCdOnVKatasKZMnT75kuwULFsjGjRtNcEpPw9Du3btl+fLlsnjxYhOyunfv7t6ekpIizZs3l6ioKElISJDRo0fLkCFDZMaMGdfkmAAAQOAJ8eWDt2zZ0iyX8ueff0qvXr1k6dKl0rp1a69te/fulSVLlsiWLVukTp06Zt2kSZOkVatWMmbMGBOg5s2bJ2fPnpVZs2ZJnjx5pHr16rJ9+3YZO3asV3ACAAD28usaogsXLsgTTzwhsbGxJsikFx8fb4bJXGFINWvWTIKDg2XTpk3uNo0bNzZhyCUmJkb27dsnx44du05HAgAA/JlPe4gu580335SQkBDp3bt3htuTkpKkRIkSXuu0fZEiRcw2V5sKFSp4tSlZsqR7W+HChTO879TUVLN4Dr0BAICcyW97iLTeZ8KECTJnzhxTTH29jRgxQsLDw92LFmMDAICcyW8D0fr16yU5OVnKlStnen10+eOPP+Sll16S8uXLmzaRkZGmjafz58+bmWe6zdXm8OHDXm1c111tMhIXFycnTpxwL4mJidfgKAEAgD/w2yEzrR3SeiBPWvuj659++mlzvUGDBnL8+HHTmxQdHW3WrVq1ytQe1a9f393m1VdflXPnzknu3LnNOp2RVrly5UyHy1RoaKhZAABAzufTQKTnC/rll1/c1w8cOGBmgGkNkPYMFS1a1Ku9Bhrt1dEwo6pWrSotWrSQbt26ybRp00zo6dmzp3Ts2NE9Rf+xxx6ToUOHmvMT9e/fX3bt2mWG4saNG3edjxYAAPgrnwairVu3yj333OO+3q9fP3PZuXNnUzuUFTqtXkNQ06ZNzeyyDh06yMSJE93btf5n2bJl0qNHD9OLVKxYMRk0aBBT7gEAgFuQ4zjO/7+KzOgsMw1XWk+kZ8UGAMBG0bHviT9LGP3kVX1++21RNQAAwPVCIAIAANbz21lmAOBLgTYsAOCfoYcIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9zkOEHMOfzxvDOWMAwL/RQwQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgvRBf70Agi459T/xZwugnfb0LAAAEBHqIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADW82kgWrdunbRp00ZKly4tQUFBsnDhQve2c+fOSf/+/aVGjRqSP39+0+bJJ5+UQ4cOed3H0aNHpVOnTlKoUCGJiIiQrl27ysmTJ73a7NixQ+68804JCwuTsmXLyqhRo67bMQIAAP/n00B06tQpqVmzpkyePPmibadPn5Zt27bJwIEDzeUXX3wh+/btk/vvv9+rnYah3bt3y/Lly2Xx4sUmZHXv3t29PSUlRZo3by5RUVGSkJAgo0ePliFDhsiMGTOuyzECAAD/59MzVbds2dIsGQkPDzchx9Pbb78t9erVk4MHD0q5cuVk7969smTJEtmyZYvUqVPHtJk0aZK0atVKxowZY3qV5s2bJ2fPnpVZs2ZJnjx5pHr16rJ9+3YZO3asV3ACkH04izuAQBNQNUQnTpwwQ2s6NKbi4+PNz64wpJo1aybBwcGyadMmd5vGjRubMOQSExNjepuOHTvmg6MAAAD+JmC+y+zMmTOmpujRRx819UIqKSlJSpQo4dUuJCREihQpYra52lSoUMGrTcmSJd3bChcunOHjpaammsVz6A0AAORMAdFDpAXWDz/8sDiOI1OnTr0ujzlixAgzbOdatBgbAADkTMGBEob++OMPU1Pk6h1SkZGRkpyc7NX+/PnzZuaZbnO1OXz4sFcb13VXm4zExcWZITrXkpiYmM1HBgAA/IVfByJXGNq/f7+sWLFCihYt6rW9QYMGcvz4cTN7zGXVqlVy4cIFqV+/vruNzjzT+3LRYFW5cuVMh8tUaGioCV+eCwAAyJl8WkOk5wv65Zdf3NcPHDhgZoBpDVCpUqXkwQcfNFPudTp9Wlqauy5It2uRdNWqVaVFixbSrVs3mTZtmgk9PXv2lI4dO5oZZuqxxx6ToUOHmvMTaQ3Srl27ZMKECTJu3DifHTcAXC/M+AMCIBBt3bpV7rnnHvf1fv36mcvOnTubcwV99dVX5nqtWrW8brd69Wq5++67zc86rV5DUNOmTc3ssg4dOsjEiRPdbbX+Z9myZdKjRw+Jjo6WYsWKyaBBg5hyDwAA/CMQaajRQunMXGqbi/YWzZ8//5Jtbr31Vlm/fv1V7SMAAMj5/LqGCAAA4HogEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1vNpIFq3bp20adNGSpcuLUFBQbJw4UKv7Y7jyKBBg6RUqVKSN29eadasmezfv9+rzdGjR6VTp05SqFAhiYiIkK5du8rJkye92uzYsUPuvPNOCQsLk7Jly8qoUaOuy/EBAIDA4NNAdOrUKalZs6ZMnjw5w+0aXCZOnCjTpk2TTZs2Sf78+SUmJkbOnDnjbqNhaPfu3bJ8+XJZvHixCVndu3d3b09JSZHmzZtLVFSUJCQkyOjRo2XIkCEyY8aM63KMAADA/4X48sFbtmxploxo79D48eNlwIAB0rZtW7Puvffek5IlS5qepI4dO8revXtlyZIlsmXLFqlTp45pM2nSJGnVqpWMGTPG9DzNmzdPzp49K7NmzZI8efJI9erVZfv27TJ27Fiv4AQAAOzltzVEBw4ckKSkJDNM5hIeHi7169eX+Ph4c10vdZjMFYaUtg8ODjY9Sq42jRs3NmHIRXuZ9u3bJ8eOHcv08VNTU03vkucCAAByJr8NRBqGlPYIedLrrm16WaJECa/tISEhUqRIEa82Gd2H52NkZMSIESaAuRatPQIAADmT3wYiX4uLi5MTJ064l8TERF/vEgAAsC0QRUZGmsvDhw97rdfrrm16mZyc7LX9/PnzZuaZZ5uM7sPzMTISGhpqZq55LgAAIGfy20BUoUIFE1hWrlzpXqd1PFob1KBBA3NdL48fP25mj7msWrVKLly4YGqNXG105tm5c+fcbXRGWuXKlaVw4cLX9ZgAAIB/8mkg0vMF6YwvXVyF1PrzwYMHzXmJ+vTpI8OHD5evvvpKdu7cKU8++aSZOdauXTvTvmrVqtKiRQvp1q2bbN68Wb7//nvp2bOnmYGm7dRjjz1mCqr1/EQ6Pf/jjz+WCRMmSL9+/Xx56AAAwI/4dNr91q1b5Z577nFfd4WUzp07y5w5c+Tll1825yrS6fHaE9SoUSMzzV5PsOii0+o1BDVt2tTMLuvQoYM5d5GLFkQvW7ZMevToIdHR0VKsWDFzskem3AMAAL8IRHfffbc531BmtJdo2LBhZsmMziibP3/+JR/n1ltvlfXr1/+jfQUAADmX39YQAQAAXC8EIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACw3lUFoiZNmpgvW00vJSXFbAMAAMjxgWjNmjVy9uzZi9afOXOGL1EFAAA5+9vud+zY4f55z549kpSU5L6elpYmS5YskRtuuCF79xAAAMCfAlGtWrUkKCjILBkNjeXNm1cmTZqUnfsHAADgX4HowIED4jiO3HjjjbJ582YpXry4e1uePHmkRIkSkitXrmuxn7iGomPfE3+WMPpJX+8CACCHu6JAFBUVZS4vXLhwrfYHAADAvwORp/3798vq1aslOTn5ooA0aNCg7Ng3AAAA/w1EM2fOlOeff16KFSsmkZGRpqbIRX8mEAFXh+FLAAigQDR8+HB5/fXXpX///tm/RwAAAIFwHqJjx47JQw89lP17AwAAECg9RBqGli1bJs8991z27xEAAAE0nMxQssWB6KabbpKBAwfKxo0bpUaNGpI7d26v7b17986u/QMAIEfw51CnbA92VxWIZsyYIQUKFJC1a9eaxZMWVROIAABAjg9EeoJGAAAAq4uqAQAAxPYeoi5dulxy+6xZs652fwAAAAIjEOm0e0/nzp2TXbt2yfHjxzP80lcAAIAcF4gWLFhw0Tr9+g49e3XFihWzY78AAAACr4YoODhY+vXrJ+PGjcuuuwQAAAi8oupff/1Vzp8/n513CQAA4J9DZtoT5MlxHPnrr7/k66+/ls6dO2fXvgEAAPhvIPrhhx8uGi4rXry4vPXWW5edgQYAAJAjhsxWr17ttaxcuVI++ugj6d69u4SEXFXGylBaWpr5ipAKFSpI3rx5TcH2a6+9ZnqkXPTnQYMGSalSpUybZs2ayf79+73u5+jRo9KpUycpVKiQRERESNeuXeXkyZPZtp8AAMDiGqIjR47Id999Zxb9Obu9+eabMnXqVHn77bdl79695vqoUaNk0qRJ7jZ6feLEiTJt2jTZtGmT5M+fX2JiYuTMmTPuNhqGdu/eLcuXL5fFixfLunXrTHgDAAC46kB06tQpMzSmvTKNGzc2S+nSpU3Py+nTp7Ptmd2wYYO0bdtWWrduLeXLl5cHH3xQmjdvLps3b3b3Do0fP14GDBhg2t16663y3nvvyaFDh2ThwoWmjQapJUuWyDvvvCP169eXRo0amUClPVraDgAAIPhqi6r1S10XLVpkTsaoy5dffmnWvfTSS9m2c3fccYcZjvv555/N9R9//NH0RrVs2dL9nWpJSUlmmMwlPDzcBJ/4+HhzXS91mKxOnTruNtpe6560RykzqampkpKS4rUAAICc6aoKfj7//HP57LPP5O6773ava9Wqlanhefjhh80wV3Z45ZVXTBCpUqWK5MqVy9QUvf7662YITGkYUiVLlvS6nV53bdPLEiVKeG3XOqciRYq422RkxIgRMnTo0Gw5DgAAkAN7iHRYLH0IURo8snPI7JNPPpF58+bJ/PnzZdu2bTJ37lwZM2aMubzW4uLi5MSJE+4lMTHxmj8mAAAIoEDUoEEDGTx4sFfh8v/+9z/To6LbsktsbKzpJerYsaPUqFFDnnjiCenbt6/pvVGRkZHm8vDhw1630+uubXqZnJzstV1PHqkzz1xtMhIaGmpmpXkuAAAgZ7qqITMtZG7RooWUKVNGatas6a7v0RCxbNmybNs57W3SWh9POnSm35umdDq+hhqtM6pVq5ZZp0NsWhuk36umNKBpjVNCQoJER0ebdatWrTL3obVGAAAAVxWItLdGz/Wjw1k//fSTWffoo4+a2h6tI8oubdq0MTVD5cqVk+rVq5sTQo4dO9Z98segoCDp06ePDB8+XCpVqmQCkp63SGe8tWvXzrSpWrWqCW/dunUzU/PPnTsnPXv2NL1O2g4AAOCqApEOWWkNkYYMT7NmzTLnI+rfv3+27JxOj9eA88ILL5hhLw0wzz77rDkRo8vLL79sTgOg5xXSniCdVq/T7MPCwtxtNLhpCGratKnpcerQoYM5dxEAAMBVB6Lp06ebQuf0tBdHe16yKxAVLFjQDM/pkhntJRo2bJhZMqMzyjLaXwAAgKsuqtbp6npSxvT0+8z0S14BAAByfCAqW7asfP/99xet13XU5QAAACuGzLR2SIuZtUC5SZMmZp3O9NJ6nuw8UzUAAIDfBiI9P9B///tfU+x89uxZs06LmLV2SE9oCAAAkOMDkRYy6zfP6www/fJUnWqv0971PEQAAABWBCKXAgUKSN26dbNvbwAAAAKlqBoAACAnIRABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1/D4Q/fnnn/L4449L0aJFJW/evFKjRg3ZunWre7vjODJo0CApVaqU2d6sWTPZv3+/130cPXpUOnXqJIUKFZKIiAjp2rWrnDx50gdHAwAA/JFfB6Jjx45Jw4YNJXfu3PLtt9/Knj175K233pLChQu724waNUomTpwo06ZNk02bNkn+/PklJiZGzpw5426jYWj37t2yfPlyWbx4saxbt066d+/uo6MCAAD+JkT82Jtvvilly5aV2bNnu9dVqFDBq3do/PjxMmDAAGnbtq1Z995770nJkiVl4cKF0rFjR9m7d68sWbJEtmzZInXq1DFtJk2aJK1atZIxY8ZI6dKlfXBkAADAn/h1D9FXX31lQsxDDz0kJUqUkNtuu01mzpzp3n7gwAFJSkoyw2Qu4eHhUr9+fYmPjzfX9VKHyVxhSGn74OBg06OUmdTUVElJSfFaAABAzuTXgei3336TqVOnSqVKlWTp0qXy/PPPS+/evWXu3Llmu4YhpT1CnvS6a5teapjyFBISIkWKFHG3yciIESNMuHIt2lMFAAByJr8ORBcuXJDatWvLG2+8YXqHtO6nW7dupl7oWouLi5MTJ064l8TExGv+mAAAwDf8OhDpzLFq1ap5ratataocPHjQ/BwZGWkuDx8+7NVGr7u26WVycrLX9vPnz5uZZ642GQkNDTWz0jwXAACQM/l1INIZZvv27fNa9/PPP0tUVJS7wFpDzcqVK93btdZHa4MaNGhgruvl8ePHJSEhwd1m1apVpvdJa40AAAD8epZZ37595Y477jBDZg8//LBs3rxZZsyYYRYVFBQkffr0keHDh5s6Iw1IAwcONDPH2rVr5+5RatGihXuo7dy5c9KzZ08zA40ZZgAAwO8DUd26dWXBggWmnmfYsGEm8Og0ez2vkMvLL78sp06dMvVF2hPUqFEjM80+LCzM3WbevHkmBDVt2tTMLuvQoYM5dxEAAIDfByJ13333mSUz2kukYUmXzOiMsvnz51+jPQQAAIHOr2uIAAAArgcCEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgvYAKRCNHjpSgoCDp06ePe92ZM2ekR48eUrRoUSlQoIB06NBBDh8+7HW7gwcPSuvWrSVfvnxSokQJiY2NlfPnz/vgCAAAgD8KmEC0ZcsWmT59utx6661e6/v27SuLFi2STz/9VNauXSuHDh2S9u3bu7enpaWZMHT27FnZsGGDzJ07V+bMmSODBg3ywVEAAAB/FBCB6OTJk9KpUyeZOXOmFC5c2L3+xIkT8u6778rYsWOlSZMmEh0dLbNnzzbBZ+PGjabNsmXLZM+ePfLBBx9IrVq1pGXLlvLaa6/J5MmTTUgCAAAIiECkQ2Lay9OsWTOv9QkJCXLu3Dmv9VWqVJFy5cpJfHy8ua6XNWrUkJIlS7rbxMTESEpKiuzevTvTx0xNTTVtPBcAAJAzhYif++ijj2Tbtm1myCy9pKQkyZMnj0RERHit1/Cj21xtPMOQa7trW2ZGjBghQ4cOzaajAAAA/syve4gSExPlxRdflHnz5klYWNh1fey4uDgzJOdadF8AAEDO5NeBSIfEkpOTpXbt2hISEmIWLZyeOHGi+Vl7erQO6Pjx416301lmkZGR5me9TD/rzHXd1SYjoaGhUqhQIa8FAADkTH4diJo2bSo7d+6U7du3u5c6deqYAmvXz7lz55aVK1e6b7Nv3z4zzb5Bgwbmul7qfWiwclm+fLkJONWqVfPJcQEAAP/i1zVEBQsWlFtuucVrXf78+c05h1zru3btKv369ZMiRYqYkNOrVy8Tgm6//XazvXnz5ib4PPHEEzJq1ChTNzRgwABTqK29QAAAAH4diLJi3LhxEhwcbE7IqDPDdAbZlClT3Ntz5colixcvlueff94EJQ1UnTt3lmHDhvl0vwEAgP8IuEC0Zs0ar+tabK3nFNIlM1FRUfLNN99ch70DAACByK9riAAAAK4HAhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD2/D0QjRoyQunXrSsGCBaVEiRLSrl072bdvn1ebM2fOSI8ePaRo0aJSoEAB6dChgxw+fNirzcGDB6V169aSL18+cz+xsbFy/vz563w0AADAH/l9IFq7dq0JOxs3bpTly5fLuXPnpHnz5nLq1Cl3m759+8qiRYvk008/Ne0PHTok7du3d29PS0szYejs2bOyYcMGmTt3rsyZM0cGDRrko6MCAAD+JET83JIlS7yua5DRHp6EhARp3LixnDhxQt59912ZP3++NGnSxLSZPXu2VK1a1YSo22+/XZYtWyZ79uyRFStWSMmSJaVWrVry2muvSf/+/WXIkCGSJ08eHx0dAADwB37fQ5SeBiBVpEgRc6nBSHuNmjVr5m5TpUoVKVeunMTHx5vrelmjRg0ThlxiYmIkJSVFdu/eneHjpKammu2eCwAAyJkCKhBduHBB+vTpIw0bNpRbbrnFrEtKSjI9PBEREV5tNfzoNlcbzzDk2u7allntUnh4uHspW7bsNToqAADgawEViLSWaNeuXfLRRx9d88eKi4szvVGuJTEx8Zo/JgAA8A2/ryFy6dmzpyxevFjWrVsnZcqUca+PjIw0xdLHjx/36iXSWWa6zdVm8+bNXvfnmoXmapNeaGioWQAAQM7n9z1EjuOYMLRgwQJZtWqVVKhQwWt7dHS05M6dW1auXOlep9PydZp9gwYNzHW93LlzpyQnJ7vb6Iy1QoUKSbVq1a7j0QAAAH8UEgjDZDqD7MsvvzTnInLV/GhdT968ec1l165dpV+/fqbQWkNOr169TAjSGWZKp+lr8HniiSdk1KhR5j4GDBhg7pteIAAA4PeBaOrUqeby7rvv9lqvU+ufeuop8/O4ceMkODjYnJBRZ4fpDLIpU6a42+bKlcsMtz3//PMmKOXPn186d+4sw4YNu85HAwAA/FFIIAyZXU5YWJhMnjzZLJmJioqSb775Jpv3DgAA5AR+X0MEAABwrRGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAADrEYgAAID1CEQAAMB6BCIAAGA9AhEAALAegQgAAFiPQAQAAKxHIAIAANYjEAEAAOsRiAAAgPUIRAAAwHoEIgAAYD0CEQAAsB6BCAAAWI9ABAAArEcgAgAA1iMQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWsyoQTZ48WcqXLy9hYWFSv3592bx5s693CQAA+AFrAtHHH38s/fr1k8GDB8u2bdukZs2aEhMTI8nJyb7eNQAA4GPWBKKxY8dKt27d5Omnn5Zq1arJtGnTJF++fDJr1ixf7xoAAPAxKwLR2bNnJSEhQZo1a+ZeFxwcbK7Hx8f7dN8AAIDvhYgF/vOf/0haWpqULFnSa71e/+mnnzK8TWpqqllcTpw4YS5TUlLc69JS/yf+zHNfL4XjuPZywjHYdhw54RgUx3Ht5YRjyMnH4bruOM6lb+hY4M8//9RnwdmwYYPX+tjYWKdevXoZ3mbw4MHmNiwsLCwsLCwS8EtiYuIls4IVPUTFihWTXLlyyeHDh73W6/XIyMgMbxMXF2eKsF0uXLggR48elaJFi0pQUFC276Mm2LJly0piYqIUKlRIAhXH4T9ywjHklOPICcegOA7/kROO4Xodh/YM/f3331K6dOlLtrMiEOXJk0eio6Nl5cqV0q5dO3fA0es9e/bM8DahoaFm8RQREXHN91XfEIH85nbhOPxHTjiGnHIcOeEYFMfhP3LCMVyP4wgPD79sGysCkdLens6dO0udOnWkXr16Mn78eDl16pSZdQYAAOxmTSB65JFH5MiRIzJo0CBJSkqSWrVqyZIlSy4qtAYAAPaxJhApHR7LbIjM13R4Tk8amX6YLtBwHP4jJxxDTjmOnHAMiuPwHznhGPztOIK0strXOwEAAOBLVpyYEQAA4FIIRAAAwHoEIgAAYD0CEQAAsB6ByE9MnjxZypcvL2FhYVK/fn3ZvHmzBJJ169ZJmzZtzJlA9UzeCxculEAzYsQIqVu3rhQsWFBKlChhTuK5b98+CTRTp06VW2+91X2iswYNGsi3334rgWzkyJHmfdWnTx8JJEOGDDH77blUqVJFAs2ff/4pjz/+uDlTf968eaVGjRqydetWCST6+zX9a6FLjx49JJDo93IOHDhQKlSoYF6LihUrymuvvXb57+nyM3///bf5/xwVFWWO44477pAtW7b4dJ8IRH7g448/NieO1KmH27Ztk5o1a0pMTIwkJydLoNCTXOp+a7ALVGvXrjW/HDdu3CjLly+Xc+fOSfPmzc2xBZIyZcqYAJGQkGA+tJo0aSJt27aV3bt3SyDSX5LTp083IS8QVa9eXf766y/38t1330kgOXbsmDRs2FBy585tgvWePXvkrbfeksKFC0ugvY88Xwf9P64eeughCSRvvvmm+aPn7bfflr1795rro0aNkkmTJkkgeeaZZ8xr8P7778vOnTvN79pmzZqZ8O0z2fklqrg6+gWzPXr0cF9PS0tzSpcu7YwYMcIJRPq2WrBggRPokpOTzbGsXbvWCXSFCxd23nnnHSfQ/P33306lSpWc5cuXO3fddZfz4osvOoFEvyS6Zs2aTiDr37+/06hRIyen0fdSxYoVnQsXLjiBpHXr1k6XLl281rVv397p1KmTEyhOnz7t5MqVy1m8eLHX+tq1azuvvvqqz/aLHiIfO3v2rPlLXpOxS3BwsLkeHx/v032z3YkTJ8xlkSJFJFBp9/pHH31kerl06CzQaI9d69atvf5/BJr9+/eboeQbb7xROnXqJAcPHpRA8tVXX5mvPNKeFB1Kvu2222TmzJkS6L93P/jgA+nSpcs1+bLua0mHlvR7OH/++Wdz/ccffzS9ji1btpRAcf78efO7SUtEPOnQmS97UK06U7U/+s9//mPeGOm/QkSv//TTTz7bL9vpl//q+LYOFdxyyy0SaLQLWgPQmTNnpECBArJgwQKpVq2aBBINcjqE7Ou6gn9C6wHnzJkjlStXNsM0Q4cOlTvvvFN27dplatUCwW+//WaGaHRY/9///rd5PXr37m2+NFu/HzIQaY3j8ePH5amnnpJA88orr5hviNdatFy5cpnPj9dff92E7UBRsGBB8/tJa5+qVq1qPu8+/PBD0wlw0003+Wy/CERAJj0T+qEVaPUeLvoBvH37dtPL9dlnn5kPLq2RCpRQlJiYKC+++KKpMUj/V2Qg8fyrXWugNCBpEeknn3wiXbt2lUD540B7iN544w1zXXuI9P/GtGnTAjYQvfvuu+a10Z67QKPvnXnz5sn8+fNNfZr+P9c/3vRYAun1eP/9900P3Q033GCCXe3ateXRRx81Iya+QiDysWLFipk3w+HDh73W6/XIyEif7ZfN9PvuFi9ebGbOaYFyINK/3l1/aUVHR5u/6idMmGCKkwOB/lLUSQX6S9JF/xLW10SLSVNTU83/m0ATEREhN998s/zyyy8SKEqVKnVRkNa/6j///HMJRH/88YesWLFCvvjiCwlEsbGxppeoY8eO5rrO+NNj0lmygRSIKlasaP5I0+F87fHS95l+CbsOLfsKNUR+8MGlH1g6Juz5F5leD8Saj0Cm9eAahnR4adWqVWZaa06h7ykNEYGiadOmZthP//p1LdpLocMC+nMghiF18uRJ+fXXX80v/0Chw8bpTz+h9Sva0xWIZs+ebWqhtDYtEJ0+fdrUmXrS/w/6fzwQ5c+f3/x/0NmMS5cuNTNifYUeIj+gY/Oa7PUXfr169WT8+PEmNT/99NMSSL/oPf/qPXDggPng0oLkcuXKSaAMk2k39JdffmnGuJOSksz68PBwU+wXKOLi4sxwgD7veq4PPaY1a9aYXzaBQp//9LVb+otTz4MTSDVd//rXv8z5uTQ8HDp0yJxaQz+8dGggUPTt29cU8uqQ2cMPP2zOkTZjxgyzBBoNDRqI9PdtSEhgfvzp+0lrhvT/tw6Z/fDDDzJ27Fgz/BRIli5dav4I1eF9/ezQni+ti/Lp557P5rfBy6RJk5xy5co5efLkMdPwN27c6ASS1atXmynq6ZfOnTs7gSKj/ddl9uzZTiDRKblRUVHmvVS8eHGnadOmzrJly5xAF4jT7h955BGnVKlS5rW44YYbzPVffvnFCTSLFi1ybrnlFic0NNSpUqWKM2PGDCcQLV261Pyf3rdvnxOoUlJSzP8D/bwICwtzbrzxRjNVPTU11QkkH3/8sdl3/b8RGRlpTj1z/Phxn+5TkP7juzgGAADge9QQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxAByDGGDBkitWrV8vVuAAhABCIAuEbOnTvn610AkEUEIgB+9wWco0aNkptuuklCQ0PNl1jql1mq/v37y8033yz58uWTG2+8UQYOHOgOHXPmzJGhQ4fKjz/+KEFBQWbRder48ePyzDPPSPHixaVQoULSpEkT087T8OHDzbeg6xfLattXXnnFq7dJ92vYsGFSpkwZs1+6bcmSJe7tv//+u3nMjz/+WO666y4JCwszX4Cqj/fZZ595PdbChQvNl9Xql+8C8A+B+XW/AHKsuLg4mTlzpowbN04aNWokf/31l/z0009mm4YVDTmlS5eWnTt3Srdu3cy6l19+WR555BHZtWuXCSkrVqww7cPDw83lQw89JHnz5pVvv/3WrJs+fbo0bdpUfv75ZylSpIjMmzfPhK4pU6ZIw4YN5aOPPpK33npLKlSo4N6vCRMmmHV629tuu01mzZol999/v+zevVsqVarkbqdBSttpGw1FGrz0G9YffPBBdxvXdd13AH7Cp18tCwDpvslbv1F95syZWWo/evRoJzo62n198ODBTs2aNb3arF+/3ilUqJBz5swZr/UVK1Z0pk+fbn6uX7+++bZtTw0bNvS6r9KlSzuvv/66V5u6des6L7zwgvn5wIED5pvUx48f79Vm06ZNTq5cuZxDhw6Z64cPH3ZCQkKcNWvWZOkYAVwfDJkB8Bt79+6V1NRU03uTER2O0h6cyMhIKVCggAwYMEAOHjx4yfvUHpqTJ09K0aJFzW1cy4EDB+TXX381bfbt2yf16tXzup3n9ZSUFDl06JB5bE96XffZU506dS66n+rVq8vcuXPN9Q8++ECioqKkcePGWXpOAFwfDJkB8Bs6rJWZ+Ph46dSpk6kTiomJMUNfrqGtS9EwVKpUKVmzZs1F2yIiIiS7aW1QelqTNHnyZDOcpsNlTz/9tKk3AuA/6CEC4De0FkdD0cqVKy/atmHDBtOz8uqrr5peGG37xx9/eLXJkyePpKWlea2rXbu2JCUlSUhIiCnU9lyKFStm2lSuXFm2bNnidTvP61oYrXVL33//vVcbvV6tWrXLHtfjjz9u9nXixImyZ88e6dy5cxafEQDXCz1EAPyGFiHrTDItktZwo0NSR44ccRcu6/CY9grVrVtXvv76a1mwYIHX7cuXL2+GwrZv325mg2nRcrNmzaRBgwbSrl07M3tNZ6np8Jfe/oEHHjDhqlevXqZAW3++4447zNDcjh07zEw2l9jYWBk8eLBUrFjRzDDTnh59HC3IvpzChQtL+/btzX00b97c7BsAP3OdapUAIEvS0tKc4cOHO1FRUU7u3LmdcuXKOW+88YbZFhsb6xQtWtQpUKCA88gjjzjjxo1zwsPD3bfVwukOHTo4ERERpsB59uzZ7mLtXr16mcJovc+yZcs6nTp1cg4ePOi+7bBhw5xixYqZ++7SpYvTu3dv5/bbb/faryFDhjg33HCDuQ8tuP7222/d211F1T/88EOGx7Vy5Uqz/ZNPPrkmzxuAfyZI//F1KAMAf3Pvvfea4u33338/W+5P76dv376md0p7vwD4F4bMAFjv9OnTMm3aNFOsnStXLvnwww/NuYyWL1+eLfet51IaOXKkPPvss4QhwE9RVA3Aejrj65tvvjFT4aOjo2XRokXy+eefm/qjf0rrlqpUqWJ6m/SkkwD8E0NmAADAevQQAQAA6xGIAACA9QhEAADAegQiAABgPQIRAACwHoEIAABYj0AEAACsRyACAADWIxABAACx3f8Dkiew6Xtr3zwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='category',data=test_set)\n",
    "plt.title('Number of classes in test_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "R1Ec_3LvyACS"
   },
   "outputs": [],
   "source": [
    "train_set = train_set[['cleanedText','category']]\n",
    "test_set = test_set[['cleanedText','category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "9fQDerQpUy27"
   },
   "outputs": [],
   "source": [
    "## Optional: save both train and test set\n",
    "train_set.to_csv('train_set.csv',index=False)\n",
    "test_set.to_csv('test_set.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxiBaXjIVv9x"
   },
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RXIRJew495jh"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "idpJQuDAV5u5"
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(r\"C:\\Users\\Admin\\OneDrive\\Desktop\\test\\train_set.csv\")\n",
    "test_set = pd.read_csv(r'C:\\Users\\Admin\\OneDrive\\Desktop\\test\\test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45894, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11474, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "f93b408426f7438f92f09732f3819354",
      "6a8302fb09854ad0871de2b0910107bd",
      "53bff930d6514a0cb209c3cddad2e843",
      "2ebdd00f45924cd686c95eb3436c713b",
      "ec681f087dd04700976c273862693533",
      "d577e7892a5144e5aa40de259e61b678",
      "56abe15c264940d8b43cd03f2a4bbffb",
      "662a7ce2a0634c078810d9ed23c3bf1a",
      "839e979904394bbfb24faa5e9936c9cb",
      "4ec2a04656de4acb8e51c8953d55a84d",
      "77e63b0922ac44ae9cccfe14e2793c93",
      "57ee5aa7c342437782b18752dbf15d05",
      "cf68429d328f4b68bdd614250bb52f78",
      "a3659723444d4101b0da61ac1ab85cb4",
      "23b28eb5961b454f92c437a3ae568309",
      "251b1941e2c14aa6867e1dd3735651f2",
      "06aaf20f4ffb4ce4a7e77eb6073a5e8b",
      "ce8f48efee94426aae48b570d31f6857",
      "fbf65d2e19544485ba243388207f2d36",
      "211142819a024c14b93b6091b55e6220",
      "5f10dfb4041d4c58ba2b6b2c885c2ac6",
      "6c2c8cb3e92c4b2aaa8c8701f63db37c",
      "909150e33c9b4fb7a672591f3b57b8d0",
      "33206883edf34cb9a7abf86029e6d255",
      "022c863738be42ffa8a4983f36ace3b4",
      "cfef9e05c29749b4b1172b990fc05d97",
      "0e14c54631ae451680e9f43f6d835a0b",
      "5e390b05326943b3917c81436aebcd0c",
      "b34bc41c27dc4eacac040b7137307d9c",
      "c8fcb385230743fe9901071a59d4839b",
      "2d2a493ed0634b6eb1915c4af4376ca7",
      "0d38a18474ba4a529964086a80d84e1d",
      "3960c123b4074b7498c79d27a3187a1b",
      "94ca767c128c48f8860ca47fa1ac78c7",
      "524aeec26c5043b5a71ea2bc8acfea1a",
      "430cf0be9a41436f9cb934069ff664fb",
      "b73ac02c2c3241ab83f92e1499dbecac",
      "191f415300d642e684ffcd3ac12b4a94",
      "0169cee5568a47a3ab512c2322322be1",
      "9b65e54569964aa5860ee51653bf93f7",
      "a758e863695545a7ad6f5249fd2e9537",
      "b12d3630243a4b309cfe9047add5402a",
      "08f7a5a3c8004f518d817aeaf3122b83",
      "7defb164fd554243abd8125b15ea61a8",
      "a9d3bb68839240789e0c12e3a1296721",
      "53d2985fda0c4551ba3e5b2fb33d3cff",
      "bd7477934c0a47a980cb907cf62fd34a",
      "9574b5edd42c4747b548ee234199d8e7",
      "6ddc83765947421a9e857f38252e822c",
      "f853fd70d989474c932fbcd4d588e2d8",
      "c98e7d6a921749e4bde7613e1003b19a",
      "e592062541d84ef58496200262d9a08f",
      "9df2607c9ab740c5819a86a7ea70f4da",
      "8076cf9758c549cdad7ccca83eede87b",
      "1fe6cdb3be0746a09318aab441a16758",
      "ce016ccfa47c4495a1e6a917521aba8e",
      "f6b32eb0132647fd8be9b84c39eb21cb",
      "55845baf6faf48f5abf2e85c54929326",
      "82aef96d39f84c2fb34721ff0aacc206",
      "38dffce11f8e4371b5116f85af5930e0",
      "7703ae4887b84606a1d3fcc4abe10ac3",
      "445c3e1e07ab4f3cbefc92fffea626aa",
      "daa983a72b41479380cf260190fc8e2f",
      "dccab4106c374f6daa97e26baef0c911",
      "9b902b18213e479282eee0cbedbb32f9",
      "d7377e9140054086a16e0ce214b3a177",
      "2e262486833e4f9fa2cb1035d95d1860",
      "a8988a8a2618434ba48ff5582d442ace",
      "bb85ee2afbae4caf89678caff1d08468",
      "bc29dee14cfc4d6081e953e11421903a",
      "a60e192f150c4cbaa699eacd0fc93c0c",
      "296eeae2fb0b4bbd96945ed26518e698",
      "91260080651141a8ae6811e8625de4e5",
      "b612b0b5abc44eca9d721ac4959d5f64",
      "12d3cd51f50546e7a643490ed468ec45",
      "5681debd18e145bdabcca9e7b5936a11",
      "1ee7103c246b419f96de370d8324b2d8",
      "9a1fad34a32e403e877a790cece8c447",
      "54745fd6c39241e6b4c0cab83bc97509",
      "53e86116a0cf4241868fe009df628fa8",
      "b3f52aa4323e4583add71f7b3d91609d",
      "a58a5ae67c6e4c87b2e70dd384f1a5e4",
      "390e19dada2743ce868ea3b1091e1a0d",
      "c8511058bca8490b898fff046893940a",
      "04b1bac2ff9b4b3c8e1ba724d42180be",
      "acba0d009729454780c22b1c1a999a2b",
      "cddf3d63b64d46eea164048f2c5d5d34",
      "f240440364c64584ac41269e0ec501d1",
      "525e0da0e7344a6398114ee89b006a2c",
      "5dc06023b12f44188bde26dc162203ea",
      "2240c3147bcc4585a3944ae84fd66776",
      "5eb6d23a192843c48a491c99d525f51f",
      "36d3a8aa46994ed5aa76404cc68f3ee0",
      "fb2847c75b4e4dc289788db73db101e3",
      "380ef43c23fc41fb8ad642757cb7a641",
      "946a1b19b66548a79d76febcc98d717a",
      "685ca463b2e44160a1272c572e7aae73",
      "594a066dad8f4fa99e4511ff698ba892",
      "8520c8de9cb84294b6756d8be2547d57",
      "fa1aa9043950456ab46e30c940b23b04",
      "6d503ef557a44363af58e0e8f3b2321d",
      "7400505283bd47359975d7662634400b",
      "29082cbaad2d42dca9e6b6a48ee7be95",
      "dc4021cf89a74ef0bd16221ce4e5cdf1",
      "790998fdfde2468289ffea78d5baf4b9",
      "7b7594b3a26846b393db480331ac5a48",
      "fc03ffd630334218b0ea153cea7f8b46",
      "1b49b6769b5e450f8225bb517057be1c",
      "9048d7c85b7441c2a4c3a5e2e7f4a5f1",
      "86566dca7e62419eb697dad8dd96e069",
      "ff2a73008ba243eabfe82ea40e9773c3",
      "0d77b292c1674dd882f483cc148c8afe",
      "d1aa166e1e90407b81b860f13fce0bec",
      "e14e5459b858495bbe85c10adf494583",
      "8a752aef198d493e85b26f39d1f0e297",
      "1d708a35f27e4b30aba6351ff1ee17a4",
      "00bd8b53cd004796b11e22137ec6c15b",
      "198e9c1554b8436db8a69e2577826d6b",
      "de968b0b3e8f4a338cc0af5bcadfbf66",
      "481989955fea41e7b01a9e223f5a8a02",
      "ae16a65401e648d8a16228b30c825784"
     ]
    },
    "collapsed": true,
    "id": "gkXUrwDkKLgb",
    "outputId": "76461424-0954-4beb-8074-6c7e9b07714c"
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ugm0y3yo1_XU"
   },
   "outputs": [],
   "source": [
    "train_list = train_set['cleanedText'].tolist()\n",
    "test_list = test_set['cleanedText'].tolist()\n",
    "train_list = [str(text) for text in train_list]\n",
    "test_list = [str(text) for text in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371,
     "referenced_widgets": [
      "d049344ed07c41d9a2857edd8d91cb3c",
      "9b9f617f3cc941edaa400a7249c763a0",
      "dda95bc65c934123975e28ca23d653c2",
      "eaf834c2b659478181ea3fef53fb005a",
      "e99ef7d682bb452c86359f9d068d1c7a",
      "d3b2bfa3069340cf8f3eefce7ee703e7",
      "a611c39bcdb0400fb8af5865c8eef5b9",
      "e075514a60d649408ca32332ff042313",
      "84fe0dba580b4c9cba3a0938ff075984",
      "390aafa792f143a4bbc41073cc6e94d5",
      "4ace2bb1d33343a4b6b3dfbfd2952fc9"
     ]
    },
    "collapsed": true,
    "id": "ZBy0SaF03Nu1",
    "outputId": "87e4347f-f7c9-4c79-bd65-4b813806befb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1435/1435 [01:29<00:00, 15.98it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 359/359 [00:23<00:00, 15.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_encoded = model.encode(train_list, show_progress_bar=True, convert_to_numpy=True,\n",
    "                          device=device,normalize_embeddings=True)\n",
    "test_encoded = model.encode(test_list, show_progress_bar=True, convert_to_numpy=True,\n",
    "                          device=device,normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Ucm49DIngVW5"
   },
   "outputs": [],
   "source": [
    "## use for ML and non transformer\n",
    "X = train_encoded\n",
    "y = train_set['category']\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aL-0b43WOHSC"
   },
   "source": [
    "## classic ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZbOuduLQeXK"
   },
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "dSwJWLXNQdTl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression(class_weight='balanced',max_iter=1000)\n",
    "model_lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "qIVTiFv3QmQF"
   },
   "outputs": [],
   "source": [
    "y_pred = model_lr.predict(x_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "8_O-hduWTY4v"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_report_df = report_df.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(class_report_df, annot=True, cmap='Blues', fmt='.2f')\n",
    "\n",
    "plt.title('Logistic Regression Classification Report')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LjlAkE4Tb1J"
   },
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "KpEJRtezTdyB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(class_weight='balanced')\n",
    "model_rf.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "VMJQrVmTTtUU"
   },
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(x_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "jmufnHyGTyFk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_report_df = report_df.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(class_report_df, annot=True, cmap='Blues', fmt='.2f')\n",
    "\n",
    "plt.title('Random Forest Classification Report')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC2ZXbpVT0u8"
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "__PPP9b6T1t_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('kernel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">kernel&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;linear&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('degree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">degree&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;scale&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('coef0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">coef0&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinking',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shrinking&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('probability',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">probability&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cache_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cache_size&nbsp;</td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decision_function_shape',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decision_function_shape&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;ovr&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('break_ties',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">break_ties&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "SVC(class_weight='balanced', kernel='linear')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc = SVC(class_weight='balanced',kernel='linear')\n",
    "model_svc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "eREDKeaWT9iA"
   },
   "outputs": [],
   "source": [
    "y_pred = model_svc.predict(x_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "ju7a1PVgUH9z"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_report_df = report_df.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(class_report_df, annot=True, cmap='Blues', fmt='.2f')\n",
    "\n",
    "plt.title('SVC Classification Report')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jnj86jKKUNVo"
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(class_weight='balanced')\n",
    "model_knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "uZNgW1gYUjyQ"
   },
   "outputs": [],
   "source": [
    "y_pred = model_knn.predict(x_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "V2HkWz4-UnJq"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_report_df = report_df.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(class_report_df, annot=True, cmap='Blues', fmt='.2f')\n",
    "\n",
    "plt.title('KNN Classification Report')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9R3h6GsuM_W"
   },
   "source": [
    "## Transformer using peft techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTlYNOGF6Vkq"
   },
   "source": [
    "#### Dataset for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "2a9a607be90d4429ab9a52424e96c4f4",
      "598959af2146445b92b89623e9604c66",
      "38ff5a10551944319c8b4566f3b8125b",
      "b63f0f4cf7a04f8784bbef77b4020adc",
      "ae4d3856b3104982b94629339429e159",
      "0f4c00e63954412f9260bd2f0dc7e829",
      "b87af8dd31304a38b1a2fa64fd1a5c3b",
      "22c1f53114434e8b9531a69dd266b37f",
      "d3765d28c39b4d279be4352e29be1d24",
      "dfd73d9a4f1a4c2da6c8aee0d64e615a",
      "de8e8ce1912342fd84d92657476a875c",
      "c98120efe862448abba050017ebbd944",
      "74bf718cde7846628d143ba5f5cb9122",
      "3b308619fd754bf89270c4771599bdf9",
      "babf3dd70286486ca9888fd1bfe10fcb",
      "8f3c9446d25e4fa8978cef51513c0f82",
      "dc4ecc22998a4ad39471514c6eb02c9a",
      "5bb94edbca854a55919d6010055fdf99",
      "193e2ca8a47a4d26baf54d52648f5d50",
      "96f61ff8c94b45fb8b58d7e81cbe331a",
      "5c457eb081a549d9b41fefa9db872294",
      "14a96ec3caac4bc0bbcb8f685e76f5b8",
      "71a868f1e4314fb28bd85b3f4beadc66",
      "c5fa38dcd46a41659889806f2379d48e",
      "fcf74be4b7034c86a2639b8c9f753a75",
      "1f124327566048adae26ccdbe50601a8",
      "a3caea1243244ad09da6ad95b5a07b53",
      "6d3cf112064f44779dd51ccd9b8afdde",
      "7fd5b36bc02c441d8eebc6cba2129239",
      "91d76f816b8945f78d786a38a3a4eff4",
      "27b33c6317384adb8d821a7df1c56a1c",
      "1aa12ed48d62458d9dcee44a1a35d1e0",
      "fa3b6c4b99234531bcc8850cee1c3ffd",
      "b71d56baa6e24f738457d3e571f97f0d",
      "c11c8fae6cb9462d9628b80231aa51f3",
      "e4dd6efeb8f44abdbab172bc8af96dc8",
      "9396f1a24933463983c5329df2487775",
      "7d105aa0f9904c14975a7b03f11d36cd",
      "db5df1e5fdbb42468375c847682d3bad",
      "886aae932cc14b08ad1c210568836c81",
      "89467159b1374b9a842b7e9fa5410bf6",
      "6cdc09bb0d74450ab17dfe306a12079c",
      "7b021dd0c3284d9ea683dc19896fb219",
      "791a4caf52d74632975083a952d8fe4b"
     ]
    },
    "collapsed": true,
    "id": "kn5Whse1ieQM",
    "outputId": "40eaaf58-6501-46aa-9dce-35fc8a7e8482"
   },
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\" # Example open-source model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "h5OcS5Gv-qLe"
   },
   "outputs": [],
   "source": [
    "train_set.dropna( inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "collapsed": true,
    "id": "XSIqToHv8ebs",
    "outputId": "7b41f4ed-90c5-4907-bd80-7173cc512ac6"
   },
   "outputs": [],
   "source": [
    "tokenized_train_data = tokenizer(\n",
    "    train_list, # Pass the clean list here\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=512\n",
    ")\n",
    "tokenized_test_data = tokenizer(\n",
    "    test_list, # Pass the clean list here\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fAsDfRgvKv7n"
   },
   "outputs": [],
   "source": [
    "class TextEncodingDataset(Dataset):\n",
    "    def __init__(self, tokenized_data, labels):\n",
    "        # This now expects 'labels' to be a NumPy array or list\n",
    "        self.tokenized_data = tokenized_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # This will now work perfectly because self.labels[idx] is an integer\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.tokenized_data.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zbGYZNXvMUW5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "R3rvNI1QMGrJ"
   },
   "outputs": [],
   "source": [
    "train_dataset = TextEncodingDataset(tokenized_train_data, train_set['category'].to_numpy())\n",
    "test_dataset = TextEncodingDataset(tokenized_test_data, test_set['category'].to_numpy())\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "25KMCVOyMQaC"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256, # Small batch size for example\n",
    "    collate_fn=data_collator # Use the collator here!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "r6XjKcvyNEg0"
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256, # Small batch size for example\n",
    "    collate_fn=data_collator # Use the collator here!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0n1BBrk6YhR"
   },
   "source": [
    "#### initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16, # Rank of the update matrices\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "700254e1f741433cb7b111d262072316",
      "3a8d6be99c444d54b64717bfacc66113",
      "6bf75dcec0c64c248880ba7dc73b9403",
      "eb81ec79b48e4bde873da26519a56b44",
      "d98711034f1a44e7a477e57eabc3e077",
      "d9b654809cfa4caf942c0f1c07bad128",
      "2d27f343fa834240bfa7f52646ab4af0",
      "ceacb88e7032484587d940a986b0d6e1",
      "7670ea4134ad40b3957c55d679f603fa",
      "4e9742b1bd9e41cba25cbcbd61a6fd0b",
      "4d6c65d6fa4a4f0f8de3f995243f5577",
      "039bf20f87004152910f7ae8e1428ab9",
      "1aa399b74c1843eb893f462d35537d4e",
      "e11582529bb342ad95141e316eceefc0",
      "f3a3366181a641af8dd08af79cb5382f",
      "65f4e9d280e543e787dd1e76e11112ff",
      "3ee6dffe56374489b1245b7f1dee3879",
      "b0452728f98b4af480bdfcfbd6c1e686",
      "1bbb68b0a1724099bdb73d3bf5ac2b02",
      "2732f256f3094e909ebb9d4b5c98bb5f",
      "d217315af99e4b61aef836d609f739c9",
      "605ed5facd00470bb1b3f25874ed5d55",
      "d97231a9a89741f78cbc40503ad281ed",
      "373ed425a2ec44aca01e8669884654cd",
      "94158723e42a4c5b884bd74c0d8eeeb0",
      "e38882a4830c4f538e0bbd5b2cfc51bf",
      "606bd0a7db9845eb95e1f900bf4213b8",
      "c3af235c1629428da518197a0e491ed5",
      "43df6ce686604b5baec24c3563497ac7",
      "dbd7bd051ca7462aaea997948b914975",
      "8661ebc98915474c8f6a2b1539998ff2",
      "9073d21876e74946985e95934c66fb56",
      "53acd4ca6f174611a28f157290569702",
      "c86f3295ea204ed583f00957409b10e8",
      "e06133f5958b41af9fc4d635a0406570",
      "3a123da5ea11417a87b455694edc4a0f",
      "f70742c4716842c5b80ac2168802fabd",
      "d21294d2863a4b7396fab0766eeccc24",
      "53fde07ae0be43b1acc0b52048cc0657",
      "0acf677eabe44d5cb38745fa98f15d05",
      "a629c7544218446b9a9f323a64afd420",
      "853d83d592d544198d32a2f321a71595",
      "990f9da38e884618aa0b8410aca6ac08",
      "1b11202a0e354293a51e63ffbcfe22ea",
      "91ca2184f6024648892e6804c1dd5e9d",
      "c169f423601c47ac99c21b228d1fb048",
      "c6fcceeb329047af99254ac69b644256",
      "8720221d03bf45bcbfd62fdd295ab7f6",
      "151068318f5b4db896292fa3e7838589",
      "e6e1fecaf05d41a0aa83222d9ca6eab7",
      "b92662fb90b94e5f85c1aceb1cac651b",
      "e5ab64458f9e454fb1154e1205b24d25",
      "90ee3389c8ca48409cd5e4686c51fefb",
      "33483d1859834e0b98b835c7a89d60bc",
      "6a265eddfc67416e9a01bc76b1a04b29",
      "2ca094372c6f476abc7b90c43c8c204c",
      "2c7eadce07ea47089406808287356041",
      "b30a5b084b94433c9942f42ffb259940",
      "ae4c764d1f6f4da9915d43d7147b8a3c",
      "7cc97491ee8945e18dccf5d606e9d703",
      "d2c1c55c04d244aa892450ea0d7ddbe5",
      "6fb352f733f84f6fa40500808d251ff5",
      "ea3c7ad6a2a747029f912705618dd6ce",
      "084c2d7cd5eb4ed698d3623cf53cebd8",
      "10fb2e1e10014963bbdb97e3b2ddbbde",
      "660dbf76a76d4ac4bf6e33980dabb528"
     ]
    },
    "id": "7zYc7hyCkqBa",
    "outputId": "0a890ae1-502a-4f7b-cf6e-d8a34742f68a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "path = (r'C:\\Users\\Administrator\\Downloads\\project\\Mistral-7B-v0.1')\n",
    "peft_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    path,\n",
    "    num_labels=10, # number of classes\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "peft_model = get_peft_model(peft_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_VkW7fTxzH1",
    "outputId": "9e9c8ea8-e722-43e1-c878-0ec1f1a71d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\OneDrive\\Desktop\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\OneDrive\\Desktop\\test\\.venv\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/Admin/OneDrive/Desktop/test\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=256,\n",
    "    warmup_steps=100,                   # Number of steps for learning rate warmup\n",
    "    weight_decay=0.01,\n",
    "    # logging_dir=\"./logs\",              # Directory for storing logs\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=10,\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy=\"epoch\",             # Save a checkpoint at the end of each epoch\n",
    "    load_best_model_at_end=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=5,\n",
    "    remove_unused_columns=False,      # Load the best model after training is done\n",
    "    gradient_accumulation_steps=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MqSaJL_kM8QK"
   },
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Use the new metric object to compute\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "## rollback to this version if needed\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTag2W_Gxlis",
    "outputId": "147e562a-3394-4f23-f0c5-db40ddc0db5b"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(peft_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "r0qfhwFKuEEE",
    "outputId": "b61ebb9b-7c26-4ec3-d378-17baaa2cb343"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_HMohkzUyk0"
   },
   "outputs": [],
   "source": [
    "trainer.save_pretrained(save_directory = 'C:\\Users\\Administrator\\Desktop\\project',safe_serialization = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1emP_6eQ5KP"
   },
   "source": [
    "### Visualize the output of transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAWn7i_uN_Jw"
   },
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "y_true = predictions.label_ids\n",
    "logits = predictions.predictions\n",
    "y_pred = np.argmax(logits, axis=1)\n",
    "\n",
    "# Apply softmax to logits to get probabilities\n",
    "from scipy.special import softmax\n",
    "y_score = softmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EnOGNGxZRTfh"
   },
   "outputs": [],
   "source": [
    "target_names = [\"0\", \"1\", \"2\", \"3\", \"4\",\"5\", \"6\", \"7\", \"8\", \"9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "\n",
    "# 2. Convert to a DataFrame and remove unnecessary rows\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "#report_df = report_df.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
    "\n",
    "# 3. Plot the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(report_df, annot=True, cmap='viridis', fmt='.2f')\n",
    "plt.title('Classification Report Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score    support\n",
      "            0        0.95      0.96      0.95       1255\n",
      "            1        0.96      0.95      0.95        901\n",
      "            2        0.95      0.95      0.95       1326\n",
      "            3        0.95      0.97      0.96        886\n",
      "            4        0.94      0.92      0.93       1210\n",
      "            5        0.95      0.92      0.94       1361\n",
      "            6        0.94      0.92      0.93       1183\n",
      "            7        0.96      0.96      0.96        876\n",
      "            8        0.97      0.96      0.96        871\n",
      "            9        0.94      0.96      0.95       1605\n",
      "\n",
      "     accuracy                            0.95      11474\n",
      "    macro avg        0.95      0.95      0.95      11474\n",
      " weighted avg        0.95      0.95      0.95      11474\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "u9Mb3oEYo2nT",
    "KDo3C3uTo47V"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00bd8b53cd004796b11e22137ec6c15b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0169cee5568a47a3ab512c2322322be1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "022c863738be42ffa8a4983f36ace3b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8fcb385230743fe9901071a59d4839b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d2a493ed0634b6eb1915c4af4376ca7",
      "value": 1
     }
    },
    "039bf20f87004152910f7ae8e1428ab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1aa399b74c1843eb893f462d35537d4e",
       "IPY_MODEL_e11582529bb342ad95141e316eceefc0",
       "IPY_MODEL_f3a3366181a641af8dd08af79cb5382f"
      ],
      "layout": "IPY_MODEL_65f4e9d280e543e787dd1e76e11112ff"
     }
    },
    "04b1bac2ff9b4b3c8e1ba724d42180be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "06aaf20f4ffb4ce4a7e77eb6073a5e8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "084c2d7cd5eb4ed698d3623cf53cebd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "08f7a5a3c8004f518d817aeaf3122b83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0acf677eabe44d5cb38745fa98f15d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d38a18474ba4a529964086a80d84e1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d77b292c1674dd882f483cc148c8afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d708a35f27e4b30aba6351ff1ee17a4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_00bd8b53cd004796b11e22137ec6c15b",
      "value": "config.json:‚Äá100%"
     }
    },
    "0e14c54631ae451680e9f43f6d835a0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f4c00e63954412f9260bd2f0dc7e829": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10fb2e1e10014963bbdb97e3b2ddbbde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12d3cd51f50546e7a643490ed468ec45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "14a96ec3caac4bc0bbcb8f685e76f5b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "151068318f5b4db896292fa3e7838589": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "191f415300d642e684ffcd3ac12b4a94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "193e2ca8a47a4d26baf54d52648f5d50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "198e9c1554b8436db8a69e2577826d6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1aa12ed48d62458d9dcee44a1a35d1e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1aa399b74c1843eb893f462d35537d4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ee6dffe56374489b1245b7f1dee3879",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b0452728f98b4af480bdfcfbd6c1e686",
      "value": "model.safetensors.index.json:‚Äá"
     }
    },
    "1b11202a0e354293a51e63ffbcfe22ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b49b6769b5e450f8225bb517057be1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1bbb68b0a1724099bdb73d3bf5ac2b02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "1d708a35f27e4b30aba6351ff1ee17a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ee7103c246b419f96de370d8324b2d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f124327566048adae26ccdbe50601a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1aa12ed48d62458d9dcee44a1a35d1e0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fa3b6c4b99234531bcc8850cee1c3ffd",
      "value": "‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá3.06MB/s]"
     }
    },
    "1fe6cdb3be0746a09318aab441a16758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "211142819a024c14b93b6091b55e6220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2240c3147bcc4585a3944ae84fd66776": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_946a1b19b66548a79d76febcc98d717a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_685ca463b2e44160a1272c572e7aae73",
      "value": 1
     }
    },
    "22c1f53114434e8b9531a69dd266b37f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23b28eb5961b454f92c437a3ae568309": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f10dfb4041d4c58ba2b6b2c885c2ac6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6c2c8cb3e92c4b2aaa8c8701f63db37c",
      "value": "‚Äá116/116‚Äá[00:00&lt;00:00,‚Äá9.81kB/s]"
     }
    },
    "251b1941e2c14aa6867e1dd3735651f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2732f256f3094e909ebb9d4b5c98bb5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27b33c6317384adb8d821a7df1c56a1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "29082cbaad2d42dca9e6b6a48ee7be95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9048d7c85b7441c2a4c3a5e2e7f4a5f1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_86566dca7e62419eb697dad8dd96e069",
      "value": "‚Äá112/112‚Äá[00:00&lt;00:00,‚Äá8.44kB/s]"
     }
    },
    "296eeae2fb0b4bbd96945ed26518e698": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a9a607be90d4429ab9a52424e96c4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_598959af2146445b92b89623e9604c66",
       "IPY_MODEL_38ff5a10551944319c8b4566f3b8125b",
       "IPY_MODEL_b63f0f4cf7a04f8784bbef77b4020adc"
      ],
      "layout": "IPY_MODEL_ae4d3856b3104982b94629339429e159"
     }
    },
    "2c7eadce07ea47089406808287356041": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2c1c55c04d244aa892450ea0d7ddbe5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6fb352f733f84f6fa40500808d251ff5",
      "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
     }
    },
    "2ca094372c6f476abc7b90c43c8c204c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c7eadce07ea47089406808287356041",
       "IPY_MODEL_b30a5b084b94433c9942f42ffb259940",
       "IPY_MODEL_ae4c764d1f6f4da9915d43d7147b8a3c"
      ],
      "layout": "IPY_MODEL_7cc97491ee8945e18dccf5d606e9d703"
     }
    },
    "2d27f343fa834240bfa7f52646ab4af0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d2a493ed0634b6eb1915c4af4376ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e262486833e4f9fa2cb1035d95d1860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8988a8a2618434ba48ff5582d442ace",
       "IPY_MODEL_bb85ee2afbae4caf89678caff1d08468",
       "IPY_MODEL_bc29dee14cfc4d6081e953e11421903a"
      ],
      "layout": "IPY_MODEL_a60e192f150c4cbaa699eacd0fc93c0c"
     }
    },
    "2ebdd00f45924cd686c95eb3436c713b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ec2a04656de4acb8e51c8953d55a84d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_77e63b0922ac44ae9cccfe14e2793c93",
      "value": "‚Äá349/349‚Äá[00:00&lt;00:00,‚Äá23.9kB/s]"
     }
    },
    "33206883edf34cb9a7abf86029e6d255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e390b05326943b3917c81436aebcd0c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b34bc41c27dc4eacac040b7137307d9c",
      "value": "README.md:‚Äá"
     }
    },
    "33483d1859834e0b98b835c7a89d60bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36d3a8aa46994ed5aa76404cc68f3ee0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "373ed425a2ec44aca01e8669884654cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3af235c1629428da518197a0e491ed5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_43df6ce686604b5baec24c3563497ac7",
      "value": "Fetching‚Äá2‚Äáfiles:‚Äá100%"
     }
    },
    "380ef43c23fc41fb8ad642757cb7a641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38dffce11f8e4371b5116f85af5930e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38ff5a10551944319c8b4566f3b8125b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22c1f53114434e8b9531a69dd266b37f",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d3765d28c39b4d279be4352e29be1d24",
      "value": 48
     }
    },
    "390aafa792f143a4bbc41073cc6e94d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "390e19dada2743ce868ea3b1091e1a0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3960c123b4074b7498c79d27a3187a1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a123da5ea11417a87b455694edc4a0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a629c7544218446b9a9f323a64afd420",
      "max": 4540516344,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_853d83d592d544198d32a2f321a71595",
      "value": 4540516344
     }
    },
    "3a8d6be99c444d54b64717bfacc66113": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9b654809cfa4caf942c0f1c07bad128",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2d27f343fa834240bfa7f52646ab4af0",
      "value": "config.json:‚Äá100%"
     }
    },
    "3b308619fd754bf89270c4771599bdf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_193e2ca8a47a4d26baf54d52648f5d50",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_96f61ff8c94b45fb8b58d7e81cbe331a",
      "value": 570
     }
    },
    "3ee6dffe56374489b1245b7f1dee3879": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "430cf0be9a41436f9cb934069ff664fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a758e863695545a7ad6f5249fd2e9537",
      "max": 53,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b12d3630243a4b309cfe9047add5402a",
      "value": 53
     }
    },
    "43df6ce686604b5baec24c3563497ac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "445c3e1e07ab4f3cbefc92fffea626aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "481989955fea41e7b01a9e223f5a8a02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ace2bb1d33343a4b6b3dfbfd2952fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d6c65d6fa4a4f0f8de3f995243f5577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e9742b1bd9e41cba25cbcbd61a6fd0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ec2a04656de4acb8e51c8953d55a84d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "524aeec26c5043b5a71ea2bc8acfea1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0169cee5568a47a3ab512c2322322be1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9b65e54569964aa5860ee51653bf93f7",
      "value": "sentence_bert_config.json:‚Äá100%"
     }
    },
    "525e0da0e7344a6398114ee89b006a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5dc06023b12f44188bde26dc162203ea",
       "IPY_MODEL_2240c3147bcc4585a3944ae84fd66776",
       "IPY_MODEL_5eb6d23a192843c48a491c99d525f51f"
      ],
      "layout": "IPY_MODEL_36d3a8aa46994ed5aa76404cc68f3ee0"
     }
    },
    "53acd4ca6f174611a28f157290569702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53bff930d6514a0cb209c3cddad2e843": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_662a7ce2a0634c078810d9ed23c3bf1a",
      "max": 349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_839e979904394bbfb24faa5e9936c9cb",
      "value": 349
     }
    },
    "53d2985fda0c4551ba3e5b2fb33d3cff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f853fd70d989474c932fbcd4d588e2d8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c98e7d6a921749e4bde7613e1003b19a",
      "value": "config.json:‚Äá100%"
     }
    },
    "53e86116a0cf4241868fe009df628fa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04b1bac2ff9b4b3c8e1ba724d42180be",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_acba0d009729454780c22b1c1a999a2b",
      "value": 1
     }
    },
    "53fde07ae0be43b1acc0b52048cc0657": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54745fd6c39241e6b4c0cab83bc97509": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_390e19dada2743ce868ea3b1091e1a0d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c8511058bca8490b898fff046893940a",
      "value": "vocab.txt:‚Äá"
     }
    },
    "55845baf6faf48f5abf2e85c54929326": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daa983a72b41479380cf260190fc8e2f",
      "max": 90868376,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dccab4106c374f6daa97e26baef0c911",
      "value": 90868376
     }
    },
    "5681debd18e145bdabcca9e7b5936a11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56abe15c264940d8b43cd03f2a4bbffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57ee5aa7c342437782b18752dbf15d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cf68429d328f4b68bdd614250bb52f78",
       "IPY_MODEL_a3659723444d4101b0da61ac1ab85cb4",
       "IPY_MODEL_23b28eb5961b454f92c437a3ae568309"
      ],
      "layout": "IPY_MODEL_251b1941e2c14aa6867e1dd3735651f2"
     }
    },
    "594a066dad8f4fa99e4511ff698ba892": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "598959af2146445b92b89623e9604c66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f4c00e63954412f9260bd2f0dc7e829",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b87af8dd31304a38b1a2fa64fd1a5c3b",
      "value": "tokenizer_config.json:‚Äá100%"
     }
    },
    "5bb94edbca854a55919d6010055fdf99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c457eb081a549d9b41fefa9db872294": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dc06023b12f44188bde26dc162203ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb2847c75b4e4dc289788db73db101e3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_380ef43c23fc41fb8ad642757cb7a641",
      "value": "tokenizer.json:‚Äá"
     }
    },
    "5e390b05326943b3917c81436aebcd0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eb6d23a192843c48a491c99d525f51f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_594a066dad8f4fa99e4511ff698ba892",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8520c8de9cb84294b6756d8be2547d57",
      "value": "‚Äá466k/?‚Äá[00:00&lt;00:00,‚Äá20.6MB/s]"
     }
    },
    "5f10dfb4041d4c58ba2b6b2c885c2ac6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "605ed5facd00470bb1b3f25874ed5d55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "606bd0a7db9845eb95e1f900bf4213b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65f4e9d280e543e787dd1e76e11112ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "660dbf76a76d4ac4bf6e33980dabb528": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "662a7ce2a0634c078810d9ed23c3bf1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "685ca463b2e44160a1272c572e7aae73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a265eddfc67416e9a01bc76b1a04b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a8302fb09854ad0871de2b0910107bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d577e7892a5144e5aa40de259e61b678",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_56abe15c264940d8b43cd03f2a4bbffb",
      "value": "modules.json:‚Äá100%"
     }
    },
    "6bf75dcec0c64c248880ba7dc73b9403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ceacb88e7032484587d940a986b0d6e1",
      "max": 571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7670ea4134ad40b3957c55d679f603fa",
      "value": 571
     }
    },
    "6c2c8cb3e92c4b2aaa8c8701f63db37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cdc09bb0d74450ab17dfe306a12079c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6d3cf112064f44779dd51ccd9b8afdde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d503ef557a44363af58e0e8f3b2321d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_790998fdfde2468289ffea78d5baf4b9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7b7594b3a26846b393db480331ac5a48",
      "value": "special_tokens_map.json:‚Äá100%"
     }
    },
    "6ddc83765947421a9e857f38252e822c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fb352f733f84f6fa40500808d251ff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "700254e1f741433cb7b111d262072316": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a8d6be99c444d54b64717bfacc66113",
       "IPY_MODEL_6bf75dcec0c64c248880ba7dc73b9403",
       "IPY_MODEL_eb81ec79b48e4bde873da26519a56b44"
      ],
      "layout": "IPY_MODEL_d98711034f1a44e7a477e57eabc3e077"
     }
    },
    "71a868f1e4314fb28bd85b3f4beadc66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5fa38dcd46a41659889806f2379d48e",
       "IPY_MODEL_fcf74be4b7034c86a2639b8c9f753a75",
       "IPY_MODEL_1f124327566048adae26ccdbe50601a8"
      ],
      "layout": "IPY_MODEL_a3caea1243244ad09da6ad95b5a07b53"
     }
    },
    "7400505283bd47359975d7662634400b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc03ffd630334218b0ea153cea7f8b46",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1b49b6769b5e450f8225bb517057be1c",
      "value": 112
     }
    },
    "74bf718cde7846628d143ba5f5cb9122": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc4ecc22998a4ad39471514c6eb02c9a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5bb94edbca854a55919d6010055fdf99",
      "value": "config.json:‚Äá100%"
     }
    },
    "7670ea4134ad40b3957c55d679f603fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7703ae4887b84606a1d3fcc4abe10ac3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77e63b0922ac44ae9cccfe14e2793c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "790998fdfde2468289ffea78d5baf4b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "791a4caf52d74632975083a952d8fe4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b021dd0c3284d9ea683dc19896fb219": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b7594b3a26846b393db480331ac5a48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cc97491ee8945e18dccf5d606e9d703": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d105aa0f9904c14975a7b03f11d36cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7defb164fd554243abd8125b15ea61a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fd5b36bc02c441d8eebc6cba2129239": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8076cf9758c549cdad7ccca83eede87b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82aef96d39f84c2fb34721ff0aacc206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b902b18213e479282eee0cbedbb32f9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d7377e9140054086a16e0ce214b3a177",
      "value": "‚Äá90.9M/90.9M‚Äá[00:01&lt;00:00,‚Äá84.6MB/s]"
     }
    },
    "839e979904394bbfb24faa5e9936c9cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "84fe0dba580b4c9cba3a0938ff075984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8520c8de9cb84294b6756d8be2547d57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "853d83d592d544198d32a2f321a71595": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "86566dca7e62419eb697dad8dd96e069": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8661ebc98915474c8f6a2b1539998ff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8720221d03bf45bcbfd62fdd295ab7f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33483d1859834e0b98b835c7a89d60bc",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6a265eddfc67416e9a01bc76b1a04b29",
      "value": "‚Äá9.94G/9.94G‚Äá[21:08&lt;00:00,‚Äá11.6MB/s]"
     }
    },
    "886aae932cc14b08ad1c210568836c81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89467159b1374b9a842b7e9fa5410bf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a752aef198d493e85b26f39d1f0e297": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f3c9446d25e4fa8978cef51513c0f82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9048d7c85b7441c2a4c3a5e2e7f4a5f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9073d21876e74946985e95934c66fb56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "909150e33c9b4fb7a672591f3b57b8d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_33206883edf34cb9a7abf86029e6d255",
       "IPY_MODEL_022c863738be42ffa8a4983f36ace3b4",
       "IPY_MODEL_cfef9e05c29749b4b1172b990fc05d97"
      ],
      "layout": "IPY_MODEL_0e14c54631ae451680e9f43f6d835a0b"
     }
    },
    "90ee3389c8ca48409cd5e4686c51fefb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "91260080651141a8ae6811e8625de4e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91ca2184f6024648892e6804c1dd5e9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c169f423601c47ac99c21b228d1fb048",
       "IPY_MODEL_c6fcceeb329047af99254ac69b644256",
       "IPY_MODEL_8720221d03bf45bcbfd62fdd295ab7f6"
      ],
      "layout": "IPY_MODEL_151068318f5b4db896292fa3e7838589"
     }
    },
    "91d76f816b8945f78d786a38a3a4eff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9396f1a24933463983c5329df2487775": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b021dd0c3284d9ea683dc19896fb219",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_791a4caf52d74632975083a952d8fe4b",
      "value": "‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá6.20MB/s]"
     }
    },
    "94158723e42a4c5b884bd74c0d8eeeb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbd7bd051ca7462aaea997948b914975",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8661ebc98915474c8f6a2b1539998ff2",
      "value": 2
     }
    },
    "946a1b19b66548a79d76febcc98d717a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "94ca767c128c48f8860ca47fa1ac78c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_524aeec26c5043b5a71ea2bc8acfea1a",
       "IPY_MODEL_430cf0be9a41436f9cb934069ff664fb",
       "IPY_MODEL_b73ac02c2c3241ab83f92e1499dbecac"
      ],
      "layout": "IPY_MODEL_191f415300d642e684ffcd3ac12b4a94"
     }
    },
    "9574b5edd42c4747b548ee234199d8e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8076cf9758c549cdad7ccca83eede87b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1fe6cdb3be0746a09318aab441a16758",
      "value": "‚Äá612/612‚Äá[00:00&lt;00:00,‚Äá19.2kB/s]"
     }
    },
    "96f61ff8c94b45fb8b58d7e81cbe331a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "990f9da38e884618aa0b8410aca6ac08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a1fad34a32e403e877a790cece8c447": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54745fd6c39241e6b4c0cab83bc97509",
       "IPY_MODEL_53e86116a0cf4241868fe009df628fa8",
       "IPY_MODEL_b3f52aa4323e4583add71f7b3d91609d"
      ],
      "layout": "IPY_MODEL_a58a5ae67c6e4c87b2e70dd384f1a5e4"
     }
    },
    "9b65e54569964aa5860ee51653bf93f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b902b18213e479282eee0cbedbb32f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b9f617f3cc941edaa400a7249c763a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3b2bfa3069340cf8f3eefce7ee703e7",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a611c39bcdb0400fb8af5865c8eef5b9",
      "value": "Batches:‚Äá‚Äá14%"
     }
    },
    "9df2607c9ab740c5819a86a7ea70f4da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a3659723444d4101b0da61ac1ab85cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbf65d2e19544485ba243388207f2d36",
      "max": 116,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_211142819a024c14b93b6091b55e6220",
      "value": 116
     }
    },
    "a3caea1243244ad09da6ad95b5a07b53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58a5ae67c6e4c87b2e70dd384f1a5e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a60e192f150c4cbaa699eacd0fc93c0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a611c39bcdb0400fb8af5865c8eef5b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a629c7544218446b9a9f323a64afd420": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a758e863695545a7ad6f5249fd2e9537": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8988a8a2618434ba48ff5582d442ace": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_296eeae2fb0b4bbd96945ed26518e698",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_91260080651141a8ae6811e8625de4e5",
      "value": "tokenizer_config.json:‚Äá100%"
     }
    },
    "a9d3bb68839240789e0c12e3a1296721": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53d2985fda0c4551ba3e5b2fb33d3cff",
       "IPY_MODEL_bd7477934c0a47a980cb907cf62fd34a",
       "IPY_MODEL_9574b5edd42c4747b548ee234199d8e7"
      ],
      "layout": "IPY_MODEL_6ddc83765947421a9e857f38252e822c"
     }
    },
    "acba0d009729454780c22b1c1a999a2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ae16a65401e648d8a16228b30c825784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae4c764d1f6f4da9915d43d7147b8a3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10fb2e1e10014963bbdb97e3b2ddbbde",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_660dbf76a76d4ac4bf6e33980dabb528",
      "value": "‚Äá2/2‚Äá[01:09&lt;00:00,‚Äá32.09s/it]"
     }
    },
    "ae4d3856b3104982b94629339429e159": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0452728f98b4af480bdfcfbd6c1e686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b12d3630243a4b309cfe9047add5402a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b30a5b084b94433c9942f42ffb259940": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea3c7ad6a2a747029f912705618dd6ce",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_084c2d7cd5eb4ed698d3623cf53cebd8",
      "value": 2
     }
    },
    "b34bc41c27dc4eacac040b7137307d9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3f52aa4323e4583add71f7b3d91609d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cddf3d63b64d46eea164048f2c5d5d34",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f240440364c64584ac41269e0ec501d1",
      "value": "‚Äá232k/?‚Äá[00:00&lt;00:00,‚Äá10.8MB/s]"
     }
    },
    "b612b0b5abc44eca9d721ac4959d5f64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b63f0f4cf7a04f8784bbef77b4020adc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfd73d9a4f1a4c2da6c8aee0d64e615a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_de8e8ce1912342fd84d92657476a875c",
      "value": "‚Äá48.0/48.0‚Äá[00:00&lt;00:00,‚Äá2.14kB/s]"
     }
    },
    "b71d56baa6e24f738457d3e571f97f0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c11c8fae6cb9462d9628b80231aa51f3",
       "IPY_MODEL_e4dd6efeb8f44abdbab172bc8af96dc8",
       "IPY_MODEL_9396f1a24933463983c5329df2487775"
      ],
      "layout": "IPY_MODEL_7d105aa0f9904c14975a7b03f11d36cd"
     }
    },
    "b73ac02c2c3241ab83f92e1499dbecac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08f7a5a3c8004f518d817aeaf3122b83",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7defb164fd554243abd8125b15ea61a8",
      "value": "‚Äá53.0/53.0‚Äá[00:00&lt;00:00,‚Äá4.99kB/s]"
     }
    },
    "b87af8dd31304a38b1a2fa64fd1a5c3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b92662fb90b94e5f85c1aceb1cac651b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "babf3dd70286486ca9888fd1bfe10fcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c457eb081a549d9b41fefa9db872294",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_14a96ec3caac4bc0bbcb8f685e76f5b8",
      "value": "‚Äá570/570‚Äá[00:00&lt;00:00,‚Äá62.6kB/s]"
     }
    },
    "bb85ee2afbae4caf89678caff1d08468": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b612b0b5abc44eca9d721ac4959d5f64",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_12d3cd51f50546e7a643490ed468ec45",
      "value": 350
     }
    },
    "bc29dee14cfc4d6081e953e11421903a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5681debd18e145bdabcca9e7b5936a11",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1ee7103c246b419f96de370d8324b2d8",
      "value": "‚Äá350/350‚Äá[00:00&lt;00:00,‚Äá22.4kB/s]"
     }
    },
    "bd7477934c0a47a980cb907cf62fd34a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e592062541d84ef58496200262d9a08f",
      "max": 612,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9df2607c9ab740c5819a86a7ea70f4da",
      "value": 612
     }
    },
    "c11c8fae6cb9462d9628b80231aa51f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db5df1e5fdbb42468375c847682d3bad",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_886aae932cc14b08ad1c210568836c81",
      "value": "tokenizer.json:‚Äá100%"
     }
    },
    "c169f423601c47ac99c21b228d1fb048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6e1fecaf05d41a0aa83222d9ca6eab7",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b92662fb90b94e5f85c1aceb1cac651b",
      "value": "model-00001-of-00002.safetensors:‚Äá100%"
     }
    },
    "c3af235c1629428da518197a0e491ed5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5fa38dcd46a41659889806f2379d48e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d3cf112064f44779dd51ccd9b8afdde",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7fd5b36bc02c441d8eebc6cba2129239",
      "value": "vocab.txt:‚Äá100%"
     }
    },
    "c6fcceeb329047af99254ac69b644256": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5ab64458f9e454fb1154e1205b24d25",
      "max": 9942981696,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_90ee3389c8ca48409cd5e4686c51fefb",
      "value": 9942981696
     }
    },
    "c8511058bca8490b898fff046893940a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c86f3295ea204ed583f00957409b10e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e06133f5958b41af9fc4d635a0406570",
       "IPY_MODEL_3a123da5ea11417a87b455694edc4a0f",
       "IPY_MODEL_f70742c4716842c5b80ac2168802fabd"
      ],
      "layout": "IPY_MODEL_d21294d2863a4b7396fab0766eeccc24"
     }
    },
    "c8fcb385230743fe9901071a59d4839b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "c98120efe862448abba050017ebbd944": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74bf718cde7846628d143ba5f5cb9122",
       "IPY_MODEL_3b308619fd754bf89270c4771599bdf9",
       "IPY_MODEL_babf3dd70286486ca9888fd1bfe10fcb"
      ],
      "layout": "IPY_MODEL_8f3c9446d25e4fa8978cef51513c0f82"
     }
    },
    "c98e7d6a921749e4bde7613e1003b19a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cddf3d63b64d46eea164048f2c5d5d34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce016ccfa47c4495a1e6a917521aba8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6b32eb0132647fd8be9b84c39eb21cb",
       "IPY_MODEL_55845baf6faf48f5abf2e85c54929326",
       "IPY_MODEL_82aef96d39f84c2fb34721ff0aacc206"
      ],
      "layout": "IPY_MODEL_38dffce11f8e4371b5116f85af5930e0"
     }
    },
    "ce8f48efee94426aae48b570d31f6857": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ceacb88e7032484587d940a986b0d6e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf68429d328f4b68bdd614250bb52f78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06aaf20f4ffb4ce4a7e77eb6073a5e8b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ce8f48efee94426aae48b570d31f6857",
      "value": "config_sentence_transformers.json:‚Äá100%"
     }
    },
    "cfef9e05c29749b4b1172b990fc05d97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d38a18474ba4a529964086a80d84e1d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3960c123b4074b7498c79d27a3187a1b",
      "value": "‚Äá10.5k/?‚Äá[00:00&lt;00:00,‚Äá775kB/s]"
     }
    },
    "d049344ed07c41d9a2857edd8d91cb3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b9f617f3cc941edaa400a7249c763a0",
       "IPY_MODEL_dda95bc65c934123975e28ca23d653c2",
       "IPY_MODEL_eaf834c2b659478181ea3fef53fb005a"
      ],
      "layout": "IPY_MODEL_e99ef7d682bb452c86359f9d068d1c7a"
     }
    },
    "d1aa166e1e90407b81b860f13fce0bec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_198e9c1554b8436db8a69e2577826d6b",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de968b0b3e8f4a338cc0af5bcadfbf66",
      "value": 190
     }
    },
    "d21294d2863a4b7396fab0766eeccc24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d217315af99e4b61aef836d609f739c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2c1c55c04d244aa892450ea0d7ddbe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3765d28c39b4d279be4352e29be1d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3b2bfa3069340cf8f3eefce7ee703e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d577e7892a5144e5aa40de259e61b678": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7377e9140054086a16e0ce214b3a177": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d97231a9a89741f78cbc40503ad281ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_373ed425a2ec44aca01e8669884654cd",
       "IPY_MODEL_94158723e42a4c5b884bd74c0d8eeeb0",
       "IPY_MODEL_e38882a4830c4f538e0bbd5b2cfc51bf"
      ],
      "layout": "IPY_MODEL_606bd0a7db9845eb95e1f900bf4213b8"
     }
    },
    "d98711034f1a44e7a477e57eabc3e077": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9b654809cfa4caf942c0f1c07bad128": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa983a72b41479380cf260190fc8e2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db5df1e5fdbb42468375c847682d3bad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbd7bd051ca7462aaea997948b914975": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc4021cf89a74ef0bd16221ce4e5cdf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc4ecc22998a4ad39471514c6eb02c9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dccab4106c374f6daa97e26baef0c911": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dda95bc65c934123975e28ca23d653c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e075514a60d649408ca32332ff042313",
      "max": 1435,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84fe0dba580b4c9cba3a0938ff075984",
      "value": 208
     }
    },
    "de8e8ce1912342fd84d92657476a875c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de968b0b3e8f4a338cc0af5bcadfbf66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dfd73d9a4f1a4c2da6c8aee0d64e615a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e06133f5958b41af9fc4d635a0406570": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53fde07ae0be43b1acc0b52048cc0657",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0acf677eabe44d5cb38745fa98f15d05",
      "value": "model-00002-of-00002.safetensors:‚Äá100%"
     }
    },
    "e075514a60d649408ca32332ff042313": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e11582529bb342ad95141e316eceefc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bbb68b0a1724099bdb73d3bf5ac2b02",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2732f256f3094e909ebb9d4b5c98bb5f",
      "value": 1
     }
    },
    "e14e5459b858495bbe85c10adf494583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_481989955fea41e7b01a9e223f5a8a02",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ae16a65401e648d8a16228b30c825784",
      "value": "‚Äá190/190‚Äá[00:00&lt;00:00,‚Äá15.3kB/s]"
     }
    },
    "e38882a4830c4f538e0bbd5b2cfc51bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9073d21876e74946985e95934c66fb56",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_53acd4ca6f174611a28f157290569702",
      "value": "‚Äá2/2‚Äá[21:09&lt;00:00,‚Äá1269.34s/it]"
     }
    },
    "e4dd6efeb8f44abdbab172bc8af96dc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89467159b1374b9a842b7e9fa5410bf6",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6cdc09bb0d74450ab17dfe306a12079c",
      "value": 466062
     }
    },
    "e592062541d84ef58496200262d9a08f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5ab64458f9e454fb1154e1205b24d25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6e1fecaf05d41a0aa83222d9ca6eab7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e99ef7d682bb452c86359f9d068d1c7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea3c7ad6a2a747029f912705618dd6ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaf834c2b659478181ea3fef53fb005a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_390aafa792f143a4bbc41073cc6e94d5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4ace2bb1d33343a4b6b3dfbfd2952fc9",
      "value": "‚Äá208/1435‚Äá[18:59&lt;1:33:18,‚Äá‚Äá4.56s/it]"
     }
    },
    "eb81ec79b48e4bde873da26519a56b44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e9742b1bd9e41cba25cbcbd61a6fd0b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4d6c65d6fa4a4f0f8de3f995243f5577",
      "value": "‚Äá571/571‚Äá[00:00&lt;00:00,‚Äá60.6kB/s]"
     }
    },
    "ec681f087dd04700976c273862693533": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f240440364c64584ac41269e0ec501d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3a3366181a641af8dd08af79cb5382f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d217315af99e4b61aef836d609f739c9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_605ed5facd00470bb1b3f25874ed5d55",
      "value": "‚Äá25.1k/?‚Äá[00:00&lt;00:00,‚Äá966kB/s]"
     }
    },
    "f6b32eb0132647fd8be9b84c39eb21cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7703ae4887b84606a1d3fcc4abe10ac3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_445c3e1e07ab4f3cbefc92fffea626aa",
      "value": "model.safetensors:‚Äá100%"
     }
    },
    "f70742c4716842c5b80ac2168802fabd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_990f9da38e884618aa0b8410aca6ac08",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1b11202a0e354293a51e63ffbcfe22ea",
      "value": "‚Äá4.54G/4.54G‚Äá[13:16&lt;00:00,‚Äá4.98MB/s]"
     }
    },
    "f853fd70d989474c932fbcd4d588e2d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f93b408426f7438f92f09732f3819354": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6a8302fb09854ad0871de2b0910107bd",
       "IPY_MODEL_53bff930d6514a0cb209c3cddad2e843",
       "IPY_MODEL_2ebdd00f45924cd686c95eb3436c713b"
      ],
      "layout": "IPY_MODEL_ec681f087dd04700976c273862693533"
     }
    },
    "fa1aa9043950456ab46e30c940b23b04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d503ef557a44363af58e0e8f3b2321d",
       "IPY_MODEL_7400505283bd47359975d7662634400b",
       "IPY_MODEL_29082cbaad2d42dca9e6b6a48ee7be95"
      ],
      "layout": "IPY_MODEL_dc4021cf89a74ef0bd16221ce4e5cdf1"
     }
    },
    "fa3b6c4b99234531bcc8850cee1c3ffd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb2847c75b4e4dc289788db73db101e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbf65d2e19544485ba243388207f2d36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc03ffd630334218b0ea153cea7f8b46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcf74be4b7034c86a2639b8c9f753a75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91d76f816b8945f78d786a38a3a4eff4",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_27b33c6317384adb8d821a7df1c56a1c",
      "value": 231508
     }
    },
    "ff2a73008ba243eabfe82ea40e9773c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d77b292c1674dd882f483cc148c8afe",
       "IPY_MODEL_d1aa166e1e90407b81b860f13fce0bec",
       "IPY_MODEL_e14e5459b858495bbe85c10adf494583"
      ],
      "layout": "IPY_MODEL_8a752aef198d493e85b26f39d1f0e297"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
